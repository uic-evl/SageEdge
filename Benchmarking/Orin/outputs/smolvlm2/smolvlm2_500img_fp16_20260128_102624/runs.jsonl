{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3760.56, "latencies_ms": [3760.56], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A woman is standing in a kitchen with a dining table and chairs, a television on the wall, and a fireplace in the background.", "error": null, "sys_before": {"cpu_percent": 9.6, "ram_used_mb": 12553.6, "ram_available_mb": 50287.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12550.0, "ram_available_mb": 50290.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5632.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 5632.0, "gpu_utilization_percent": 77.452}, "power_stats": {"power_gpu_soc_mean_watts": 22.741, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 77.452}, "timestamp": "2026-01-28T10:28:00.544947"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10287.662, "latencies_ms": [10287.662], "images_per_second": 0.097, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " television: 1, television stand: 1, television screen: 1, television cord: 1, television stand base: 1, television stand top: 1, television stand back: 1, television stand side: 1, television stand front: 1, television stand bottom: 1, television stand top right: 1, television stand top left: 1, television stand bottom: 1, television stand bottom right: 1, television stand bottom left: 1, television stand bottom center: 1, television stand bottom center right: 1, television stand bottom center left: ", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12550.0, "ram_available_mb": 50290.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12548.4, "ram_available_mb": 50292.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5632.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 5632.0, "gpu_utilization_percent": 68.663}, "power_stats": {"power_gpu_soc_mean_watts": 15.239, "power_cpu_cv_mean_watts": 2.05, "power_sys_5v0_mean_watts": 7.436, "gpu_utilization_percent_mean": 68.663}, "timestamp": "2026-01-28T10:28:12.854541"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5734.997, "latencies_ms": [5734.997], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The living room is adjacent to the kitchen, with the dining area in between. The living room is located to the left of the kitchen, and the dining area is situated in the middle. The living room is closer to the viewer than the kitchen, which is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12548.4, "ram_available_mb": 50292.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12547.8, "ram_available_mb": 50293.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5632.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 5632.0, "gpu_utilization_percent": 71.896}, "power_stats": {"power_gpu_soc_mean_watts": 18.261, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 7.45, "gpu_utilization_percent_mean": 71.896}, "timestamp": "2026-01-28T10:28:20.608826"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3097.578, "latencies_ms": [3097.578], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is standing in a kitchen with a dining table and chairs.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12547.8, "ram_available_mb": 50293.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12547.8, "ram_available_mb": 50293.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5632.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 5632.0, "gpu_utilization_percent": 80.48}, "power_stats": {"power_gpu_soc_mean_watts": 22.845, "power_cpu_cv_mean_watts": 1.218, "power_sys_5v0_mean_watts": 7.606, "gpu_utilization_percent_mean": 80.48}, "timestamp": "2026-01-28T10:28:25.736070"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4738.919, "latencies_ms": [4738.919], "images_per_second": 0.211, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with hardwood floors and a large window letting in natural light. The walls are painted a vibrant green, and the furniture is made of wood and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12547.8, "ram_available_mb": 50293.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12549.0, "ram_available_mb": 50291.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 5632.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 5632.0, "gpu_utilization_percent": 73.205}, "power_stats": {"power_gpu_soc_mean_watts": 19.371, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 7.476, "gpu_utilization_percent_mean": 73.205}, "timestamp": "2026-01-28T10:28:32.511426"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4586.231, "latencies_ms": [4586.231], "images_per_second": 0.218, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a large brown bear with a thick coat of fur, sitting on a grassy field and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 12549.0, "ram_available_mb": 50291.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13344.1, "ram_available_mb": 49496.8, "ram_percent": 21.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.842}, "power_stats": {"power_gpu_soc_mean_watts": 21.993, "power_cpu_cv_mean_watts": 1.339, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 78.842}, "timestamp": "2026-01-28T10:28:39.156333"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6487.265, "latencies_ms": [6487.265], "images_per_second": 0.154, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 1\n2. grass: 1\n3. nose: 1\n4. eyes: 1\n5. mouth: 1\n6. ears: 1\n7. fur: 1\n8. fur color: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13344.1, "ram_available_mb": 49496.8, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 13362.2, "ram_available_mb": 49478.7, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.204}, "power_stats": {"power_gpu_soc_mean_watts": 20.002, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 75.204}, "timestamp": "2026-01-28T10:28:47.655914"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4746.657, "latencies_ms": [4746.657], "images_per_second": 0.211, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bear is in the foreground, with the grass in the background. The bear is facing the camera, with its head turned slightly to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13362.2, "ram_available_mb": 49478.7, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13391.8, "ram_available_mb": 49449.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.744}, "power_stats": {"power_gpu_soc_mean_watts": 22.754, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 7.881, "gpu_utilization_percent_mean": 76.744}, "timestamp": "2026-01-28T10:28:54.423540"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3795.762, "latencies_ms": [3795.762], "images_per_second": 0.263, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large brown bear is sitting on the grass and looking at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.8, "ram_available_mb": 49449.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13391.8, "ram_available_mb": 49449.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.161}, "power_stats": {"power_gpu_soc_mean_watts": 24.719, "power_cpu_cv_mean_watts": 1.111, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 83.161}, "timestamp": "2026-01-28T10:29:00.253897"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4080.834, "latencies_ms": [4080.834], "images_per_second": 0.245, "prompt_tokens": 1442, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bear has a brown fur coat with a black nose and is sitting on a green lawn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13391.8, "ram_available_mb": 49449.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13393.0, "ram_available_mb": 49447.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.724, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 7.923, "gpu_utilization_percent_mean": 80.5}, "timestamp": "2026-01-28T10:29:06.377773"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5823.819, "latencies_ms": [5823.819], "images_per_second": 0.172, "prompt_tokens": 1432, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed covered in blue comforters, a wooden dresser with a mirror and a lamp, a bookshelf filled with books, and a window that offers a view of a lush green tree outside.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 13393.0, "ram_available_mb": 49447.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 13392.9, "ram_available_mb": 49448.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.723, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 7.861, "gpu_utilization_percent_mean": 76.5}, "timestamp": "2026-01-28T10:29:14.236981"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6623.838, "latencies_ms": [6623.838], "images_per_second": 0.151, "prompt_tokens": 1446, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. bed: 1\n2. mirror: 1\n3. dresser: 1\n4. bookshelf: 1\n5. window: 1\n6. books: 100\n7. plants: 4\n8. blanket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13392.9, "ram_available_mb": 49448.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 13395.3, "ram_available_mb": 49445.6, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.196}, "power_stats": {"power_gpu_soc_mean_watts": 19.788, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 73.196}, "timestamp": "2026-01-28T10:29:22.907366"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5817.747, "latencies_ms": [5817.747], "images_per_second": 0.172, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the window on the right side. The bookshelf is positioned in the background, near the window, while the dresser is situated in the foreground, closer to the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13395.3, "ram_available_mb": 49445.6, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13395.5, "ram_available_mb": 49445.4, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.479}, "power_stats": {"power_gpu_soc_mean_watts": 21.392, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 7.848, "gpu_utilization_percent_mean": 76.479}, "timestamp": "2026-01-28T10:29:30.746777"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6605.689, "latencies_ms": [6605.689], "images_per_second": 0.151, "prompt_tokens": 1444, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed covered in blue comforter, a dresser with a mirror, and a bookshelf filled with books. The room is well-lit by natural light coming through a window, and there are plants placed around the room, adding a touch of greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.5, "ram_available_mb": 49445.4, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13395.8, "ram_available_mb": 49445.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.236}, "power_stats": {"power_gpu_soc_mean_watts": 20.403, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.841, "gpu_utilization_percent_mean": 75.236}, "timestamp": "2026-01-28T10:29:39.377710"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4833.473, "latencies_ms": [4833.473], "images_per_second": 0.207, "prompt_tokens": 1442, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The room is bathed in natural light from a window, the walls are adorned with floral wallpaper, and the bed is covered with a blue comforter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13395.8, "ram_available_mb": 49445.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13396.6, "ram_available_mb": 49444.3, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.875}, "power_stats": {"power_gpu_soc_mean_watts": 22.784, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 7.947, "gpu_utilization_percent_mean": 80.875}, "timestamp": "2026-01-28T10:29:46.230390"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2945.839, "latencies_ms": [2945.839], "images_per_second": 0.339, "prompt_tokens": 1100, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A red stop sign is standing on the side of the road.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 13396.6, "ram_available_mb": 49444.3, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13396.1, "ram_available_mb": 49444.8, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.125}, "power_stats": {"power_gpu_soc_mean_watts": 23.528, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 78.125}, "timestamp": "2026-01-28T10:29:51.230332"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2447.13, "latencies_ms": [2447.13], "images_per_second": 0.409, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " stop sign: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13396.1, "ram_available_mb": 49444.8, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13396.9, "ram_available_mb": 49444.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.324, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 87.0}, "timestamp": "2026-01-28T10:29:55.726756"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4819.661, "latencies_ms": [4819.661], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The stop sign is located in the foreground of the image, with the street and trees in the background. The stop sign is positioned to the left of the street, and the trees are located behind the sign.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13396.9, "ram_available_mb": 49444.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13397.8, "ram_available_mb": 49443.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.15}, "power_stats": {"power_gpu_soc_mean_watts": 19.335, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.521, "gpu_utilization_percent_mean": 72.15}, "timestamp": "2026-01-28T10:30:02.563261"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3358.644, "latencies_ms": [3358.644], "images_per_second": 0.298, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A stop sign is on the side of the road, and there are trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13397.8, "ram_available_mb": 49443.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 13398.5, "ram_available_mb": 49442.4, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.786}, "power_stats": {"power_gpu_soc_mean_watts": 21.997, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 76.786}, "timestamp": "2026-01-28T10:30:07.984544"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3315.015, "latencies_ms": [3315.015], "images_per_second": 0.302, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The stop sign is red and octagonal, and it is in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.5, "ram_available_mb": 49442.4, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13398.9, "ram_available_mb": 49442.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.036}, "power_stats": {"power_gpu_soc_mean_watts": 22.327, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 79.036}, "timestamp": "2026-01-28T10:30:13.340190"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3067.188, "latencies_ms": [3067.188], "images_per_second": 0.326, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three teddy bears of different colors are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13398.9, "ram_available_mb": 49442.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13398.7, "ram_available_mb": 49442.2, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.067, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 7.696, "gpu_utilization_percent_mean": 81.4}, "timestamp": "2026-01-28T10:30:18.450453"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2533.735, "latencies_ms": [2533.735], "images_per_second": 0.395, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " teddy bear: 4", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 13398.7, "ram_available_mb": 49442.2, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13398.6, "ram_available_mb": 49442.3, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.042, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 7.684, "gpu_utilization_percent_mean": 86.75}, "timestamp": "2026-01-28T10:30:23.005827"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5317.786, "latencies_ms": [5317.786], "images_per_second": 0.188, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The teddy bears are positioned in a close cluster, with the brown teddy bear in the center and the orange teddy bear on the right. The blue blanket is partially visible in the foreground, while the brown teddy bear is positioned slightly behind the orange teddy bear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13398.6, "ram_available_mb": 49442.3, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13399.5, "ram_available_mb": 49441.4, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.733}, "power_stats": {"power_gpu_soc_mean_watts": 19.102, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.611, "gpu_utilization_percent_mean": 72.733}, "timestamp": "2026-01-28T10:30:30.345103"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3620.567, "latencies_ms": [3620.567], "images_per_second": 0.276, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Three teddy bears are sitting on a couch, one of them is brown, one is orange, and one is tan.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13399.5, "ram_available_mb": 49441.4, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 13399.1, "ram_available_mb": 49441.8, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.424, "power_cpu_cv_mean_watts": 1.536, "power_sys_5v0_mean_watts": 7.646, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-28T10:30:35.997463"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5010.74, "latencies_ms": [5010.74], "images_per_second": 0.2, "prompt_tokens": 1110, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The teddy bears are in a variety of colors, including brown, orange, and beige. The lighting is soft and natural, coming from a window out of frame. The material of the teddy bears is plush and soft.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13399.1, "ram_available_mb": 49441.8, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13399.5, "ram_available_mb": 49441.4, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.378, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.621, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-28T10:30:43.020629"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3595.581, "latencies_ms": [3595.581], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A woman wearing a red jacket, black pants, and a black and white striped hat is skiing down a snowy slope.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13399.5, "ram_available_mb": 49441.4, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13400.0, "ram_available_mb": 49440.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.767}, "power_stats": {"power_gpu_soc_mean_watts": 22.042, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 76.767}, "timestamp": "2026-01-28T10:30:48.668651"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6100.585, "latencies_ms": [6100.585], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. skis: 2\n2. poles: 2\n3. ski poles: 2\n4. skier: 1\n5. ski suit: 1\n6. ski boots: 1\n7. ski bindings: 1\n8. helmet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.0, "ram_available_mb": 49440.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 13398.9, "ram_available_mb": 49442.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.392}, "power_stats": {"power_gpu_soc_mean_watts": 18.23, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.595, "gpu_utilization_percent_mean": 68.392}, "timestamp": "2026-01-28T10:30:56.787079"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5198.382, "latencies_ms": [5198.382], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski slope stretching out into the background. The skier is skiing towards the right side of the image, with the ski poles held in a forward-leaning position.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13398.9, "ram_available_mb": 49442.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13400.9, "ram_available_mb": 49439.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.93}, "power_stats": {"power_gpu_soc_mean_watts": 18.864, "power_cpu_cv_mean_watts": 1.901, "power_sys_5v0_mean_watts": 7.547, "gpu_utilization_percent_mean": 73.93}, "timestamp": "2026-01-28T10:31:04.004396"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3252.745, "latencies_ms": [3252.745], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman is skiing down a snowy slope with ski poles and wearing a red jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.9, "ram_available_mb": 49439.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13401.6, "ram_available_mb": 49439.3, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.654}, "power_stats": {"power_gpu_soc_mean_watts": 22.736, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 77.654}, "timestamp": "2026-01-28T10:31:09.274387"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4857.375, "latencies_ms": [4857.375], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The skier is wearing a vibrant red jacket and black pants, with a white and black striped beanie. The snow is pristine white, and the sky is overcast, casting a soft light over the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13401.6, "ram_available_mb": 49439.3, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 13401.8, "ram_available_mb": 49439.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.375}, "power_stats": {"power_gpu_soc_mean_watts": 19.539, "power_cpu_cv_mean_watts": 1.733, "power_sys_5v0_mean_watts": 7.632, "gpu_utilization_percent_mean": 70.375}, "timestamp": "2026-01-28T10:31:16.144731"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3908.636, "latencies_ms": [3908.636], "images_per_second": 0.256, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a white refrigerator, and a white stove, all set against a beige tiled floor.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 13401.8, "ram_available_mb": 49439.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 13401.9, "ram_available_mb": 49439.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.758}, "power_stats": {"power_gpu_soc_mean_watts": 20.815, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.605, "gpu_utilization_percent_mean": 75.758}, "timestamp": "2026-01-28T10:31:22.095530"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6340.763, "latencies_ms": [6340.763], "images_per_second": 0.158, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. white refrigerator: 1\n2. white stove: 1\n3. white oven: 1\n4. white cabinet: 1\n5. white dishwasher: 1\n6. white sink: 1\n7. white countertop: 1\n8. white tile floor: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13401.9, "ram_available_mb": 49439.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 13400.6, "ram_available_mb": 49440.3, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.17}, "power_stats": {"power_gpu_soc_mean_watts": 17.588, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 7.531, "gpu_utilization_percent_mean": 70.17}, "timestamp": "2026-01-28T10:31:30.462852"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4428.247, "latencies_ms": [4428.247], "images_per_second": 0.226, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The stove is located to the left of the refrigerator, which is situated in the background. The sink is positioned near the stove, while the dishwasher is placed further to the right.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13400.6, "ram_available_mb": 49440.3, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13400.7, "ram_available_mb": 49440.2, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.471, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.626, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-28T10:31:36.905761"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3334.647, "latencies_ms": [3334.647], "images_per_second": 0.3, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image depicts a small kitchen with wooden cabinets, a white refrigerator, and a white stove.", "error": null, "sys_before": {"cpu_percent": 36.4, "ram_used_mb": 13400.7, "ram_available_mb": 49440.2, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13400.9, "ram_available_mb": 49440.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.481}, "power_stats": {"power_gpu_soc_mean_watts": 22.19, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 7.671, "gpu_utilization_percent_mean": 78.481}, "timestamp": "2026-01-28T10:31:42.267734"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3294.284, "latencies_ms": [3294.284], "images_per_second": 0.304, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13400.9, "ram_available_mb": 49440.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13399.9, "ram_available_mb": 49441.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.111}, "power_stats": {"power_gpu_soc_mean_watts": 22.498, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 7.69, "gpu_utilization_percent_mean": 80.111}, "timestamp": "2026-01-28T10:31:47.581683"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4747.771, "latencies_ms": [4747.771], "images_per_second": 0.211, "prompt_tokens": 1432, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A baseball player in a green shirt and cap is running towards the camera, while another player in a white shirt and cap is running away from the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13399.9, "ram_available_mb": 49441.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13400.2, "ram_available_mb": 49440.7, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.225}, "power_stats": {"power_gpu_soc_mean_watts": 22.318, "power_cpu_cv_mean_watts": 1.512, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 79.225}, "timestamp": "2026-01-28T10:31:54.387658"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6880.153, "latencies_ms": [6880.153], "images_per_second": 0.145, "prompt_tokens": 1446, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. baseball player: 1\n3. baseball player: 1\n4. baseball player: 1\n5. baseball player: 1\n6. baseball player: 1\n7. baseball player: 1\n8. baseball player: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13400.2, "ram_available_mb": 49440.7, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 13401.6, "ram_available_mb": 49439.3, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.603}, "power_stats": {"power_gpu_soc_mean_watts": 19.724, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 75.603}, "timestamp": "2026-01-28T10:32:03.277764"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5741.145, "latencies_ms": [5741.145], "images_per_second": 0.174, "prompt_tokens": 1450, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The baseball player in the foreground is running towards the camera, while the other player is in the background, running towards the outfield. The baseball player in the foreground is closer to the camera than the other player in the background.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 13401.0, "ram_available_mb": 49439.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 13402.4, "ram_available_mb": 49438.5, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.792}, "power_stats": {"power_gpu_soc_mean_watts": 21.141, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 7.897, "gpu_utilization_percent_mean": 74.792}, "timestamp": "2026-01-28T10:32:11.044129"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4423.632, "latencies_ms": [4423.632], "images_per_second": 0.226, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " Two baseball players are running on the field. One player is wearing a green shirt and the other is wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13402.4, "ram_available_mb": 49438.5, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13402.8, "ram_available_mb": 49438.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.351}, "power_stats": {"power_gpu_soc_mean_watts": 23.318, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 81.351}, "timestamp": "2026-01-28T10:32:17.502386"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5850.798, "latencies_ms": [5850.798], "images_per_second": 0.171, "prompt_tokens": 1442, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is a photograph capturing a moment of action in a baseball game. The colors are vibrant, with the green of the grass contrasting against the brown of the dirt field. The lighting is natural, suggesting it was taken during the day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13402.8, "ram_available_mb": 49438.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 13403.0, "ram_available_mb": 49437.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.24}, "power_stats": {"power_gpu_soc_mean_watts": 20.928, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 7.916, "gpu_utilization_percent_mean": 75.24}, "timestamp": "2026-01-28T10:32:25.372835"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3533.892, "latencies_ms": [3533.892], "images_per_second": 0.283, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A tennis player is preparing to hit a tennis ball with a red and black racket on a blue court.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13403.0, "ram_available_mb": 49437.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 13405.0, "ram_available_mb": 49435.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.042, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 78.724}, "timestamp": "2026-01-28T10:32:30.927499"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6482.12, "latencies_ms": [6482.12], "images_per_second": 0.154, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. tennis player: 1\n2. racket: 1\n3. ball: 1\n4. tennis court: 1\n5. J.P. Morgan: 1\n6. POLO: 1\n7. man in black shirt: 1\n8. man in white shirt: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13405.0, "ram_available_mb": 49435.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13405.9, "ram_available_mb": 49435.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.547, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 7.614, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-28T10:32:39.426262"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4894.043, "latencies_ms": [4894.043], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the J.P. Morgan advertisement in the background. The player is positioned to the left of the advertisement, and the advertisement is located near the baseline of the tennis court.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13405.9, "ram_available_mb": 49435.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 13406.0, "ram_available_mb": 49434.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.585}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 2.482, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 71.585}, "timestamp": "2026-01-28T10:32:46.347923"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3412.153, "latencies_ms": [3412.153], "images_per_second": 0.293, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A tennis player is playing on a court with a J.P. Morgan advertisement in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13406.0, "ram_available_mb": 49434.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 13407.4, "ram_available_mb": 49433.5, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.269, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 76.286}, "timestamp": "2026-01-28T10:32:51.782647"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3279.456, "latencies_ms": [3279.456], "images_per_second": 0.305, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The tennis player is wearing a white shirt and black shorts, and the court is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.4, "ram_available_mb": 49433.5, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13405.4, "ram_available_mb": 49435.5, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.963}, "power_stats": {"power_gpu_soc_mean_watts": 22.505, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 78.963}, "timestamp": "2026-01-28T10:32:57.125527"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3732.017, "latencies_ms": [3732.017], "images_per_second": 0.268, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court, with one of the adults holding a trophy.", "error": null, "sys_before": {"cpu_percent": 8.6, "ram_used_mb": 13405.4, "ram_available_mb": 49435.5, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13406.1, "ram_available_mb": 49434.8, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.677}, "power_stats": {"power_gpu_soc_mean_watts": 21.447, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.693, "gpu_utilization_percent_mean": 75.677}, "timestamp": "2026-01-28T10:33:02.900298"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5655.383, "latencies_ms": [5655.383], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. boy: 4\n2. boy: 2\n3. boy: 2\n4. boy: 2\n5. boy: 2\n6. boy: 2\n7. boy: 2\n8. boy: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13406.1, "ram_available_mb": 49434.8, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13407.4, "ram_available_mb": 49433.5, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.208}, "power_stats": {"power_gpu_soc_mean_watts": 18.585, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.643, "gpu_utilization_percent_mean": 70.208}, "timestamp": "2026-01-28T10:33:10.599320"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5656.314, "latencies_ms": [5656.314], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The group of children is standing in front of the man, with the man being in the center of the group. The tennis rackets are held by the children, with some children holding multiple rackets. The tennis court is in the background, with the fence surrounding the court.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13407.4, "ram_available_mb": 49433.5, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 13407.3, "ram_available_mb": 49433.6, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.936}, "power_stats": {"power_gpu_soc_mean_watts": 18.733, "power_cpu_cv_mean_watts": 1.926, "power_sys_5v0_mean_watts": 7.634, "gpu_utilization_percent_mean": 70.936}, "timestamp": "2026-01-28T10:33:18.287075"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3145.977, "latencies_ms": [3145.977], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13407.3, "ram_available_mb": 49433.6, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13407.3, "ram_available_mb": 49433.6, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.231}, "power_stats": {"power_gpu_soc_mean_watts": 22.857, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.761, "gpu_utilization_percent_mean": 79.231}, "timestamp": "2026-01-28T10:33:23.472703"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3907.202, "latencies_ms": [3907.202], "images_per_second": 0.256, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken on a sunny day with clear blue skies. The tennis court is blue and the players are wearing various colors of tennis attire.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13407.3, "ram_available_mb": 49433.6, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13407.2, "ram_available_mb": 49433.7, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.616, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 77.844}, "timestamp": "2026-01-28T10:33:29.396559"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4234.538, "latencies_ms": [4234.538], "images_per_second": 0.236, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a group of people are enjoying a day by the river, with a bridge arching above them, and a swan gracefully swimming in the water.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 13407.2, "ram_available_mb": 49433.7, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 13407.5, "ram_available_mb": 49433.4, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.943}, "power_stats": {"power_gpu_soc_mean_watts": 20.668, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 7.692, "gpu_utilization_percent_mean": 73.943}, "timestamp": "2026-01-28T10:33:35.654512"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5832.981, "latencies_ms": [5832.981], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. people: 4\n3. birds: 2\n4. rocks: 2\n5. river: 1\n6. stones: 1\n7. woman: 1\n8. woman's bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13407.5, "ram_available_mb": 49433.4, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 13407.9, "ram_available_mb": 49433.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.96}, "power_stats": {"power_gpu_soc_mean_watts": 18.25, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 7.624, "gpu_utilization_percent_mean": 69.96}, "timestamp": "2026-01-28T10:33:43.501036"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4885.792, "latencies_ms": [4885.792], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The woman is standing on the right side of the image, while the bridge spans across the river in the background. The ducks are located near the woman, and the people are sitting on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13407.9, "ram_available_mb": 49433.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13408.4, "ram_available_mb": 49432.5, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.049}, "power_stats": {"power_gpu_soc_mean_watts": 19.628, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.695, "gpu_utilization_percent_mean": 72.049}, "timestamp": "2026-01-28T10:33:50.447086"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5123.599, "latencies_ms": [5123.599], "images_per_second": 0.195, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a serene scene of a group of people enjoying a day by the river, with a bridge arching over the water in the background. The sun is setting, casting a warm glow on the scene and highlighting the tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13408.4, "ram_available_mb": 49432.5, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13408.8, "ram_available_mb": 49432.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.151, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.667, "gpu_utilization_percent_mean": 71.07}, "timestamp": "2026-01-28T10:33:57.601855"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5938.505, "latencies_ms": [5938.505], "images_per_second": 0.168, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a woman in a black top and a long skirt, standing on a stone pavement, with a bridge in the background. The bridge is made of metal and has a curved design. The lighting in the image is natural, with the sun shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13408.8, "ram_available_mb": 49432.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 13408.8, "ram_available_mb": 49432.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.843}, "power_stats": {"power_gpu_soc_mean_watts": 18.347, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 7.607, "gpu_utilization_percent_mean": 69.843}, "timestamp": "2026-01-28T10:34:05.599808"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3156.881, "latencies_ms": [3156.881], "images_per_second": 0.317, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is taking a picture of herself with a Hello Kitty phone case.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 13408.8, "ram_available_mb": 49432.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 13409.8, "ram_available_mb": 49431.1, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.346}, "power_stats": {"power_gpu_soc_mean_watts": 22.733, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 79.346}, "timestamp": "2026-01-28T10:34:10.785892"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5777.765, "latencies_ms": [5777.765], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. woman: 1\n2. phone: 1\n3. ear: 1\n4. hair: 1\n5. wrist: 1\n6. hand: 1\n7. wristwatch: 1\n8. bracelet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13409.8, "ram_available_mb": 49431.1, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13410.7, "ram_available_mb": 49430.2, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.375}, "power_stats": {"power_gpu_soc_mean_watts": 18.643, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 7.658, "gpu_utilization_percent_mean": 70.375}, "timestamp": "2026-01-28T10:34:18.594820"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5862.429, "latencies_ms": [5862.429], "images_per_second": 0.171, "prompt_tokens": 1118, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The woman is holding the phone in her right hand, which is positioned in the foreground of the image. The phone is in front of her, and she is looking at it with her left hand. The background of the image is blurred, indicating that the focus is on the woman and her phone.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13410.7, "ram_available_mb": 49430.2, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 13409.9, "ram_available_mb": 49431.0, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.633}, "power_stats": {"power_gpu_soc_mean_watts": 18.482, "power_cpu_cv_mean_watts": 1.946, "power_sys_5v0_mean_watts": 7.655, "gpu_utilization_percent_mean": 71.633}, "timestamp": "2026-01-28T10:34:26.474657"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3025.714, "latencies_ms": [3025.714], "images_per_second": 0.331, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is taking a picture of herself with a Hello Kitty phone case.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13409.9, "ram_available_mb": 49431.0, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13410.6, "ram_available_mb": 49430.3, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.031, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 78.56}, "timestamp": "2026-01-28T10:34:31.539796"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4613.775, "latencies_ms": [4613.775], "images_per_second": 0.217, "prompt_tokens": 1110, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The woman is wearing a white shirt with a black and white print, and she is holding a Hello Kitty phone case. The lighting is bright and natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13410.6, "ram_available_mb": 49430.3, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 13412.0, "ram_available_mb": 49428.9, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.944, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.679, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-28T10:34:38.171144"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3172.936, "latencies_ms": [3172.936], "images_per_second": 0.315, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of children are riding in a red and yellow train car on a track.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 13412.0, "ram_available_mb": 49428.9, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 13414.7, "ram_available_mb": 49426.2, "ram_percent": 21.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.918, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-28T10:34:43.394907"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6402.796, "latencies_ms": [6402.796], "images_per_second": 0.156, "prompt_tokens": 1114, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. children: 6\n2. train: 1\n3. children's seats: 2\n4. train track: 1\n5. children's hands: 2\n6. children's feet: 2\n7. children's legs: 2\n8. children's heads: 2", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13414.7, "ram_available_mb": 49426.2, "ram_percent": 21.3}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12652.4, "ram_available_mb": 50188.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 17.477, "power_cpu_cv_mean_watts": 2.382, "power_sys_5v0_mean_watts": 7.668, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-28T10:34:51.816677"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5589.847, "latencies_ms": [5589.847], "images_per_second": 0.179, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The children are sitting in a row on a red and yellow train car, which is positioned in the foreground of the image. The train car is moving along a track that is located in the middle of the image, with the children seated on the left side of the track.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12652.4, "ram_available_mb": 50188.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12648.0, "ram_available_mb": 50192.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.261}, "power_stats": {"power_gpu_soc_mean_watts": 18.895, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 72.261}, "timestamp": "2026-01-28T10:34:59.427272"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2979.04, "latencies_ms": [2979.04], "images_per_second": 0.336, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of children are riding in a red and yellow train car.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12648.0, "ram_available_mb": 50192.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12648.1, "ram_available_mb": 50192.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.059, "power_cpu_cv_mean_watts": 1.235, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 80.333}, "timestamp": "2026-01-28T10:35:04.428630"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3744.621, "latencies_ms": [3744.621], "images_per_second": 0.267, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a wooden floor. The lighting is dim and the colors are muted.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12648.1, "ram_available_mb": 50192.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12647.9, "ram_available_mb": 50193.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.548}, "power_stats": {"power_gpu_soc_mean_watts": 21.795, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 77.548}, "timestamp": "2026-01-28T10:35:10.211896"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3948.921, "latencies_ms": [3948.921], "images_per_second": 0.253, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a sandwich on a plate with a side of fries.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12647.9, "ram_available_mb": 50193.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12645.7, "ram_available_mb": 50195.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.375}, "power_stats": {"power_gpu_soc_mean_watts": 23.62, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 82.375}, "timestamp": "2026-01-28T10:35:16.201136"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6629.34, "latencies_ms": [6629.34], "images_per_second": 0.151, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. plate: 1\n2. sandwich: 1\n3. cup: 1\n4. food: 1\n5. table: 1\n6. background: 1\n7. person: 0\n8. tablecloth: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12645.7, "ram_available_mb": 50195.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12645.9, "ram_available_mb": 50195.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.571}, "power_stats": {"power_gpu_soc_mean_watts": 19.251, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 75.571}, "timestamp": "2026-01-28T10:35:24.867561"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5970.616, "latencies_ms": [5970.616], "images_per_second": 0.167, "prompt_tokens": 1450, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The main object, a sandwich, is located in the foreground of the image, with the plate and cup positioned in the background. The sandwich is situated to the left of the plate, and the cup is placed to the right of the plate.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12645.9, "ram_available_mb": 50195.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12645.6, "ram_available_mb": 50195.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.2}, "power_stats": {"power_gpu_soc_mean_watts": 21.151, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 76.2}, "timestamp": "2026-01-28T10:35:32.885148"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3958.599, "latencies_ms": [3958.599], "images_per_second": 0.253, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a sandwich on a plate with a cup of sauce.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12645.6, "ram_available_mb": 50195.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12645.6, "ram_available_mb": 50195.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.42, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-28T10:35:38.860923"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4620.554, "latencies_ms": [4620.554], "images_per_second": 0.216, "prompt_tokens": 1442, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is in black and white, with a white plate and a white bowl on a dark table. The lighting is soft and natural.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12645.6, "ram_available_mb": 50195.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12645.0, "ram_available_mb": 50195.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.945, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 79.821}, "timestamp": "2026-01-28T10:35:45.532505"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2587.912, "latencies_ms": [2587.912], "images_per_second": 0.386, "prompt_tokens": 766, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A person is standing on a paddleboard in the water, with a city in the background.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12645.0, "ram_available_mb": 50195.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12645.0, "ram_available_mb": 50195.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5033.1, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.987, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-28T10:35:50.164150"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3404.502, "latencies_ms": [3404.502], "images_per_second": 0.294, "prompt_tokens": 780, "response_tokens_est": 32, "n_tiles": 1, "output_text": " person: 1\npaddle: 1\nsurfboard: 1\nwater: 1\nsky: 1\nland: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12645.0, "ram_available_mb": 50195.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12644.2, "ram_available_mb": 50196.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.786}, "power_stats": {"power_gpu_soc_mean_watts": 19.405, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.652, "gpu_utilization_percent_mean": 70.786}, "timestamp": "2026-01-28T10:35:55.581060"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3525.716, "latencies_ms": [3525.716], "images_per_second": 0.284, "prompt_tokens": 784, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The person is in the foreground of the image, paddling a surfboard on the water. The background shows a shoreline with buildings and trees, indicating a coastal location.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12644.2, "ram_available_mb": 50196.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12645.0, "ram_available_mb": 50195.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.724}, "power_stats": {"power_gpu_soc_mean_watts": 18.723, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.611, "gpu_utilization_percent_mean": 68.724}, "timestamp": "2026-01-28T10:36:01.125746"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2555.806, "latencies_ms": [2555.806], "images_per_second": 0.391, "prompt_tokens": 778, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A person is standing on a paddle board in the water, with a city in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12645.0, "ram_available_mb": 50195.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12644.6, "ram_available_mb": 50196.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.313, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-28T10:36:05.718993"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3441.084, "latencies_ms": [3441.084], "images_per_second": 0.291, "prompt_tokens": 776, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is in black and white, with the water being the most prominent color. The sky is clear, and the person is wearing a wetsuit.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12644.6, "ram_available_mb": 50196.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12644.5, "ram_available_mb": 50196.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.214}, "power_stats": {"power_gpu_soc_mean_watts": 18.947, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.626, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-28T10:36:11.183421"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3380.694, "latencies_ms": [3380.694], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A white computer desk with a laptop, keyboard, mouse, speakers, and a computer monitor.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12644.5, "ram_available_mb": 50196.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12644.8, "ram_available_mb": 50196.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.165, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 77.893}, "timestamp": "2026-01-28T10:36:16.617190"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4332.771, "latencies_ms": [4332.771], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " computer: 1, laptop: 1, keyboard: 1, mouse: 1, speakers: 2, monitor: 1, mousepad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12644.8, "ram_available_mb": 50196.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12644.7, "ram_available_mb": 50196.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.429}, "power_stats": {"power_gpu_soc_mean_watts": 20.619, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 71.429}, "timestamp": "2026-01-28T10:36:22.963853"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4860.253, "latencies_ms": [4860.253], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The computer monitor is positioned to the right of the keyboard, and the laptop is to the left of the monitor. The speakers are placed in front of the keyboard, and the mouse is to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12644.7, "ram_available_mb": 50196.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12644.9, "ram_available_mb": 50196.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.674, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 73.463}, "timestamp": "2026-01-28T10:36:29.874031"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2986.116, "latencies_ms": [2986.116], "images_per_second": 0.335, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A desk with a computer, laptop, and speakers on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12644.9, "ram_available_mb": 50196.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12644.8, "ram_available_mb": 50196.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.92}, "power_stats": {"power_gpu_soc_mean_watts": 22.951, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 79.92}, "timestamp": "2026-01-28T10:36:34.900006"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2755.209, "latencies_ms": [2755.209], "images_per_second": 0.363, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The desk is white and the computer is silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12644.8, "ram_available_mb": 50196.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12644.8, "ram_available_mb": 50196.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.591}, "power_stats": {"power_gpu_soc_mean_watts": 24.129, "power_cpu_cv_mean_watts": 1.165, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 83.591}, "timestamp": "2026-01-28T10:36:39.673131"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7875.296, "latencies_ms": [7875.296], "images_per_second": 0.127, "prompt_tokens": 1099, "response_tokens_est": 92, "n_tiles": 1, "output_text": " The image captures a bustling highway scene under a concrete overpass, where multiple vehicles are in motion, including a taxi with the number 120 on its side, and a black SUV with the license plate \"4T0055\". The overpass is adorned with green highway signs, prominently displaying \"North 101 Ventura Blvd\" and \"Hollywood Blvd Sunset Blvd\", guiding drivers along their routes.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12644.2, "ram_available_mb": 50196.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12644.0, "ram_available_mb": 50196.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.552}, "power_stats": {"power_gpu_soc_mean_watts": 16.958, "power_cpu_cv_mean_watts": 1.979, "power_sys_5v0_mean_watts": 7.604, "gpu_utilization_percent_mean": 68.552}, "timestamp": "2026-01-28T10:36:49.611201"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4927.601, "latencies_ms": [4927.601], "images_per_second": 0.203, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " TAXI: 1, VAN: 1, SUV: 1, CAR: 1, BUS: 1, CAR: 1, CAR: 1, CAR: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12644.0, "ram_available_mb": 50196.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12644.6, "ram_available_mb": 50196.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.098}, "power_stats": {"power_gpu_soc_mean_watts": 19.397, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.651, "gpu_utilization_percent_mean": 71.098}, "timestamp": "2026-01-28T10:36:56.562795"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5991.574, "latencies_ms": [5991.574], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The vehicles are positioned on the right side of the road, with the taxi closest to the camera. The highway sign is located above the road, with the North Ventura and Hollywood Blvd signs positioned to the left of the taxi. The Sunset Blvd sign is positioned to the right of the taxi.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12644.6, "ram_available_mb": 50196.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12644.4, "ram_available_mb": 50196.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.06}, "power_stats": {"power_gpu_soc_mean_watts": 18.276, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 70.06}, "timestamp": "2026-01-28T10:37:04.614025"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5934.554, "latencies_ms": [5934.554], "images_per_second": 0.169, "prompt_tokens": 1111, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures a bustling highway scene under a concrete overpass. Vehicles of various colors and sizes are seen moving in both directions, with a white taxi cab prominently displayed in the foreground. The overpass, a crucial part of the highway infrastructure, is adorned with green signs that guide drivers towards their destinations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12644.4, "ram_available_mb": 50196.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12644.3, "ram_available_mb": 50196.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.7}, "power_stats": {"power_gpu_soc_mean_watts": 18.11, "power_cpu_cv_mean_watts": 1.971, "power_sys_5v0_mean_watts": 7.65, "gpu_utilization_percent_mean": 69.7}, "timestamp": "2026-01-28T10:37:12.563490"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4828.988, "latencies_ms": [4828.988], "images_per_second": 0.207, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image depicts a busy highway with multiple lanes of traffic, vehicles of various colors and sizes, and a clear blue sky. The vehicles are moving in different directions, and the road is lined with trees and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12644.3, "ram_available_mb": 50196.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12644.4, "ram_available_mb": 50196.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.6}, "power_stats": {"power_gpu_soc_mean_watts": 19.562, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 74.6}, "timestamp": "2026-01-28T10:37:19.430408"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4135.449, "latencies_ms": [4135.449], "images_per_second": 0.242, "prompt_tokens": 1432, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A red double decker bus is driving down a street with a sign that says Aldwych on it.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12644.4, "ram_available_mb": 50196.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12642.8, "ram_available_mb": 50198.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.441}, "power_stats": {"power_gpu_soc_mean_watts": 23.77, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 80.441}, "timestamp": "2026-01-28T10:37:25.637290"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5251.942, "latencies_ms": [5251.942], "images_per_second": 0.19, "prompt_tokens": 1446, "response_tokens_est": 38, "n_tiles": 1, "output_text": " 1. red double decker bus\n2. license plate\n3. street sign\n4. building\n5. trees\n6. people\n7. advertisement\n8. sky", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12642.8, "ram_available_mb": 50198.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12641.3, "ram_available_mb": 50199.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.764, "power_cpu_cv_mean_watts": 1.466, "power_sys_5v0_mean_watts": 7.963, "gpu_utilization_percent_mean": 76.273}, "timestamp": "2026-01-28T10:37:32.905474"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4774.494, "latencies_ms": [4774.494], "images_per_second": 0.209, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The red double-decker bus is in the foreground, parked on the street, while the background features a city street with other vehicles and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12641.3, "ram_available_mb": 50199.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12641.2, "ram_available_mb": 50199.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.385}, "power_stats": {"power_gpu_soc_mean_watts": 22.88, "power_cpu_cv_mean_watts": 1.376, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 80.385}, "timestamp": "2026-01-28T10:37:39.701576"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3709.063, "latencies_ms": [3709.063], "images_per_second": 0.27, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A red double decker bus is driving down a street in London.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12641.2, "ram_available_mb": 50199.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12640.5, "ram_available_mb": 50200.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.752, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 85.0}, "timestamp": "2026-01-28T10:37:45.443028"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4452.457, "latencies_ms": [4452.457], "images_per_second": 0.225, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The bus is red with a yellow stripe and has a black front grill. The sky is cloudy and the sun is shining.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12640.5, "ram_available_mb": 50200.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12641.0, "ram_available_mb": 50199.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.919}, "power_stats": {"power_gpu_soc_mean_watts": 23.294, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 77.919}, "timestamp": "2026-01-28T10:37:51.909132"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2965.049, "latencies_ms": [2965.049], "images_per_second": 0.337, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12641.0, "ram_available_mb": 50199.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12639.5, "ram_available_mb": 50201.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.606, "power_cpu_cv_mean_watts": 1.235, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 81.042}, "timestamp": "2026-01-28T10:37:56.920433"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5123.336, "latencies_ms": [5123.336], "images_per_second": 0.195, "prompt_tokens": 1113, "response_tokens_est": 48, "n_tiles": 1, "output_text": " 1. black and white cat\n2. laptop\n3. keyboard\n4. white wall\n5. white baseboard\n6. black and white whiskers\n7. black and white fur\n8. black and white eyes", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12639.5, "ram_available_mb": 50201.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12639.6, "ram_available_mb": 50201.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.837}, "power_stats": {"power_gpu_soc_mean_watts": 19.102, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.696, "gpu_utilization_percent_mean": 69.837}, "timestamp": "2026-01-28T10:38:04.087852"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4946.475, "latencies_ms": [4946.475], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The black and white cat is positioned to the left of the laptop keyboard, which is situated in the middle of the image. The laptop keyboard is located in the foreground of the image, while the cat is in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12639.6, "ram_available_mb": 50201.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12639.9, "ram_available_mb": 50201.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.439}, "power_stats": {"power_gpu_soc_mean_watts": 19.407, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.678, "gpu_utilization_percent_mean": 70.439}, "timestamp": "2026-01-28T10:38:11.059103"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3001.485, "latencies_ms": [3001.485], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12639.9, "ram_available_mb": 50201.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12640.0, "ram_available_mb": 50200.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.173, "power_cpu_cv_mean_watts": 1.25, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 80.12}, "timestamp": "2026-01-28T10:38:16.117579"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3019.144, "latencies_ms": [3019.144], "images_per_second": 0.331, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is black and white, and the laptop is silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12640.0, "ram_available_mb": 50200.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12640.5, "ram_available_mb": 50200.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.046, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 81.88}, "timestamp": "2026-01-28T10:38:21.175209"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3841.122, "latencies_ms": [3841.122], "images_per_second": 0.26, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In the image, there are two airplanes flying in the sky above a large bridge, with the Sydney Opera House visible in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12640.5, "ram_available_mb": 50200.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12641.3, "ram_available_mb": 50199.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.968}, "power_stats": {"power_gpu_soc_mean_watts": 21.465, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 74.968}, "timestamp": "2026-01-28T10:38:27.042642"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5801.922, "latencies_ms": [5801.922], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. Airplane: 2\n2. Bridge: 1\n3. Building: 1\n4. Cityscape: 1\n5. Clouds: 1\n6. Flags: 1\n7. Water: 1\n8. People: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12641.3, "ram_available_mb": 50199.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12642.9, "ram_available_mb": 50198.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.562}, "power_stats": {"power_gpu_soc_mean_watts": 18.664, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 70.562}, "timestamp": "2026-01-28T10:38:34.869569"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4512.84, "latencies_ms": [4512.84], "images_per_second": 0.222, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The two airplanes are flying above the Sydney Harbour Bridge, which is positioned in the foreground of the image. The Sydney Opera House is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12642.9, "ram_available_mb": 50198.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12643.3, "ram_available_mb": 50197.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.108}, "power_stats": {"power_gpu_soc_mean_watts": 20.404, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 70.108}, "timestamp": "2026-01-28T10:38:41.402330"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5119.637, "latencies_ms": [5119.637], "images_per_second": 0.195, "prompt_tokens": 1112, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a moment of aerial spectacle over the iconic Sydney Harbour Bridge and the Sydney Opera House. Two military jets, painted in shades of red and white, are soaring in formation, their wings spread wide as they traverse the sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12643.3, "ram_available_mb": 50197.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12643.1, "ram_available_mb": 50197.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.605}, "power_stats": {"power_gpu_soc_mean_watts": 18.785, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.635, "gpu_utilization_percent_mean": 72.605}, "timestamp": "2026-01-28T10:38:48.565592"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3421.144, "latencies_ms": [3421.144], "images_per_second": 0.292, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the bridge is a dark brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12643.1, "ram_available_mb": 50197.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12642.2, "ram_available_mb": 50198.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.036}, "power_stats": {"power_gpu_soc_mean_watts": 22.178, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 77.036}, "timestamp": "2026-01-28T10:38:54.027744"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2862.03, "latencies_ms": [2862.03], "images_per_second": 0.349, "prompt_tokens": 1099, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A black and white photo of a zebra nursing its young.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12642.2, "ram_available_mb": 50198.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12641.9, "ram_available_mb": 50199.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.304}, "power_stats": {"power_gpu_soc_mean_watts": 23.919, "power_cpu_cv_mean_watts": 1.236, "power_sys_5v0_mean_watts": 7.824, "gpu_utilization_percent_mean": 80.304}, "timestamp": "2026-01-28T10:38:58.911694"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3089.987, "latencies_ms": [3089.987], "images_per_second": 0.324, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " zebra: 1\ngrass: 1\nbaby zebra: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12641.9, "ram_available_mb": 50199.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12642.1, "ram_available_mb": 50198.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.154}, "power_stats": {"power_gpu_soc_mean_watts": 22.991, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 82.154}, "timestamp": "2026-01-28T10:39:04.023094"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4625.217, "latencies_ms": [4625.217], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The zebra on the left is positioned in the foreground, while the other zebra is in the background. The zebra on the left is also in the foreground, while the other zebra is in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12642.1, "ram_available_mb": 50198.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12642.3, "ram_available_mb": 50198.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.103}, "power_stats": {"power_gpu_soc_mean_watts": 20.04, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.702, "gpu_utilization_percent_mean": 74.103}, "timestamp": "2026-01-28T10:39:10.690279"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3115.893, "latencies_ms": [3115.893], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A black and white photo of a zebra nursing its baby in the wild.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12642.3, "ram_available_mb": 50198.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12642.3, "ram_available_mb": 50198.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.846}, "power_stats": {"power_gpu_soc_mean_watts": 22.88, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 81.846}, "timestamp": "2026-01-28T10:39:15.830132"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4716.368, "latencies_ms": [4716.368], "images_per_second": 0.212, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image is in black and white, with the zebra's stripes standing out against the grayscale background. The lighting is natural, coming from the side, casting shadows and highlights on the zebra's fur.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12642.3, "ram_available_mb": 50198.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12642.3, "ram_available_mb": 50198.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.231}, "power_stats": {"power_gpu_soc_mean_watts": 19.888, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 7.666, "gpu_utilization_percent_mean": 72.231}, "timestamp": "2026-01-28T10:39:22.577221"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5104.967, "latencies_ms": [5104.967], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a bed adorned with a colorful quilt, a round wooden table, and a chair, all set against a backdrop of a stone wall and a window that offers a view of a building across the street.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12642.3, "ram_available_mb": 50198.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12645.9, "ram_available_mb": 50195.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.238}, "power_stats": {"power_gpu_soc_mean_watts": 19.365, "power_cpu_cv_mean_watts": 1.803, "power_sys_5v0_mean_watts": 7.668, "gpu_utilization_percent_mean": 73.238}, "timestamp": "2026-01-28T10:39:29.716110"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5633.088, "latencies_ms": [5633.088], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. chair: 1\n3. table: 1\n4. lamp: 1\n5. window: 2\n6. door: 1\n7. wall: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12645.9, "ram_available_mb": 50195.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12645.8, "ram_available_mb": 50195.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.632, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 7.665, "gpu_utilization_percent_mean": 73.333}, "timestamp": "2026-01-28T10:39:37.395464"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4675.592, "latencies_ms": [4675.592], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the round table and chair to its left. The window is located to the right of the bed, and the purple carpet covers the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12645.8, "ram_available_mb": 50195.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12646.8, "ram_available_mb": 50194.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.949}, "power_stats": {"power_gpu_soc_mean_watts": 20.073, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 71.949}, "timestamp": "2026-01-28T10:39:44.101885"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3108.479, "latencies_ms": [3108.479], "images_per_second": 0.322, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A small room with a bed, a table, and a chair is shown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12646.8, "ram_available_mb": 50194.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.099, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 78.269}, "timestamp": "2026-01-28T10:39:49.252020"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4135.591, "latencies_ms": [4135.591], "images_per_second": 0.242, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The room is painted in a deep purple color, and the walls are made of stone. The room is well-lit by natural light coming through the windows.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.176}, "power_stats": {"power_gpu_soc_mean_watts": 21.091, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.702, "gpu_utilization_percent_mean": 74.176}, "timestamp": "2026-01-28T10:39:55.412956"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3211.293, "latencies_ms": [3211.293], "images_per_second": 0.311, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down the street.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.571, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 81.222}, "timestamp": "2026-01-28T10:40:00.686947"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5669.567, "latencies_ms": [5669.567], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. person: 1\n3. pole: 1\n4. sign: 1\n5. tree: 1\n6. building: 1\n7. street: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12519.8, "ram_available_mb": 50321.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.723}, "power_stats": {"power_gpu_soc_mean_watts": 18.705, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.663, "gpu_utilization_percent_mean": 72.723}, "timestamp": "2026-01-28T10:40:08.392824"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4501.03, "latencies_ms": [4501.03], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The purple bus is parked on the left side of the street, with a person walking on the right side. The bus is in the foreground, while the background shows a building and trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12519.8, "ram_available_mb": 50321.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.526}, "power_stats": {"power_gpu_soc_mean_watts": 20.222, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 74.526}, "timestamp": "2026-01-28T10:40:14.914540"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3133.912, "latencies_ms": [3133.912], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A purple bus is driving down a street with a man walking on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.083, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 80.846}, "timestamp": "2026-01-28T10:40:20.090987"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4396.291, "latencies_ms": [4396.291], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bus is purple with a white roof and has a license plate that reads \"NA52 BUU\". The sky is clear and blue, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.699, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 76.667}, "timestamp": "2026-01-28T10:40:26.532915"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2956.579, "latencies_ms": [2956.579], "images_per_second": 0.338, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A white bowl filled with green apples is placed on a table.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.833}, "power_stats": {"power_gpu_soc_mean_watts": 23.419, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 81.833}, "timestamp": "2026-01-28T10:40:31.538310"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2526.765, "latencies_ms": [2526.765], "images_per_second": 0.396, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " apple: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.2}, "power_stats": {"power_gpu_soc_mean_watts": 23.697, "power_cpu_cv_mean_watts": 1.141, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 87.2}, "timestamp": "2026-01-28T10:40:36.083180"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4540.554, "latencies_ms": [4540.554], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The apples are in the foreground, with the bowl placed in the background. The apples are positioned on the left side of the bowl, with the bowl taking up the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.391, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 73.789}, "timestamp": "2026-01-28T10:40:42.673337"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2800.265, "latencies_ms": [2800.265], "images_per_second": 0.357, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A bunch of green apples are in a white bowl.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.174}, "power_stats": {"power_gpu_soc_mean_watts": 23.883, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 7.846, "gpu_utilization_percent_mean": 82.174}, "timestamp": "2026-01-28T10:40:47.521778"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2924.311, "latencies_ms": [2924.311], "images_per_second": 0.342, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The apples are green and shiny, and the bowl is white.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.083}, "power_stats": {"power_gpu_soc_mean_watts": 23.404, "power_cpu_cv_mean_watts": 1.285, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 80.083}, "timestamp": "2026-01-28T10:40:52.486058"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4337.47, "latencies_ms": [4337.47], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a baseball game is in progress with a batter, catcher, and umpire positioned at home plate, while a pitcher is preparing to throw the ball.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12525.6, "ram_available_mb": 50315.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.556}, "power_stats": {"power_gpu_soc_mean_watts": 20.578, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 74.556}, "timestamp": "2026-01-28T10:40:58.847169"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5820.213, "latencies_ms": [5820.213], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. baseball: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12525.6, "ram_available_mb": 50315.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12525.3, "ram_available_mb": 50315.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.453, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 69.49}, "timestamp": "2026-01-28T10:41:06.722347"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4740.634, "latencies_ms": [4740.634], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire behind him. The pitcher is in the background, standing on the mound. The batter is closer to the camera than the pitcher.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12525.3, "ram_available_mb": 50315.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12525.3, "ram_available_mb": 50315.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.872, "power_cpu_cv_mean_watts": 1.742, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 75.95}, "timestamp": "2026-01-28T10:41:13.501351"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3427.673, "latencies_ms": [3427.673], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A baseball game is being played on a field with a batter, catcher, and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.3, "ram_available_mb": 50315.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12526.9, "ram_available_mb": 50314.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.565, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 76.464}, "timestamp": "2026-01-28T10:41:18.951486"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5768.177, "latencies_ms": [5768.177], "images_per_second": 0.173, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a moment of intense action in a baseball game, with the vibrant colors of the players' uniforms contrasting against the lush green of the field. The lighting is natural, casting a warm glow over the scene, and the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12526.9, "ram_available_mb": 50314.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12529.5, "ram_available_mb": 50311.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.653}, "power_stats": {"power_gpu_soc_mean_watts": 18.448, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 69.653}, "timestamp": "2026-01-28T10:41:26.739998"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5494.118, "latencies_ms": [5494.118], "images_per_second": 0.182, "prompt_tokens": 1099, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant outdoor gathering, where a white cake adorned with an array of red and blue berries sits on a red tablecloth, accompanied by a variety of plates filled with an assortment of cheeses, grapes, and crackers, all neatly arranged on the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12529.5, "ram_available_mb": 50311.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12529.4, "ram_available_mb": 50311.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.152}, "power_stats": {"power_gpu_soc_mean_watts": 18.668, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.652, "gpu_utilization_percent_mean": 72.152}, "timestamp": "2026-01-28T10:41:34.263306"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4468.643, "latencies_ms": [4468.643], "images_per_second": 0.224, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cake: 1, glasses: 10, plates: 10, cheese: 1, bread: 1, knife: 1, grapes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12529.4, "ram_available_mb": 50311.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12531.7, "ram_available_mb": 50309.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.514}, "power_stats": {"power_gpu_soc_mean_watts": 20.002, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.669, "gpu_utilization_percent_mean": 75.514}, "timestamp": "2026-01-28T10:41:40.756503"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4518.09, "latencies_ms": [4518.09], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The cake is positioned to the left of the plates, with the glasses arranged in a row behind it. The plates are placed in the foreground, with the cake and glasses in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12531.7, "ram_available_mb": 50309.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12533.3, "ram_available_mb": 50307.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.181, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 73.789}, "timestamp": "2026-01-28T10:41:47.298160"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3259.826, "latencies_ms": [3259.826], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A table is set up outside with a cake, wine glasses, and plates of food.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12533.3, "ram_available_mb": 50307.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12532.7, "ram_available_mb": 50308.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.673, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 79.63}, "timestamp": "2026-01-28T10:41:52.616503"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5203.966, "latencies_ms": [5203.966], "images_per_second": 0.192, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image depicts a vibrant outdoor gathering with a red tablecloth, a white cake adorned with red and blue berries, and a variety of cheeses and grapes. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12532.7, "ram_available_mb": 50308.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.419}, "power_stats": {"power_gpu_soc_mean_watts": 19.323, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 71.419}, "timestamp": "2026-01-28T10:41:59.833764"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3116.164, "latencies_ms": [3116.164], "images_per_second": 0.321, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is riding a wave on a blue surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12532.5, "ram_available_mb": 50308.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.884, "power_cpu_cv_mean_watts": 1.346, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 76.8}, "timestamp": "2026-01-28T10:42:04.987644"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5603.501, "latencies_ms": [5603.501], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. sand: 0\n7. rocks: 0\n8. sky: 0", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12532.5, "ram_available_mb": 50308.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.894}, "power_stats": {"power_gpu_soc_mean_watts": 18.786, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 70.894}, "timestamp": "2026-01-28T10:42:12.604601"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4593.487, "latencies_ms": [4593.487], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave and the ocean extending into the background. The surfer is relatively close to the camera, while the wave is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12533.2, "ram_available_mb": 50307.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.897}, "power_stats": {"power_gpu_soc_mean_watts": 20.133, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 74.897}, "timestamp": "2026-01-28T10:42:19.235847"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3149.441, "latencies_ms": [3149.441], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young man is riding a wave on a blue surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.2, "ram_available_mb": 50307.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12533.2, "ram_available_mb": 50307.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.385}, "power_stats": {"power_gpu_soc_mean_watts": 22.802, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 77.385}, "timestamp": "2026-01-28T10:42:24.440636"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5988.944, "latencies_ms": [5988.944], "images_per_second": 0.167, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures a dynamic scene of a surfer riding a wave, with the surfer's blue surfboard contrasting against the green of the ocean. The lighting is natural and bright, suggesting a sunny day, and the water appears to be a deep green color, indicating a clear and possibly deep ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.2, "ram_available_mb": 50307.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12532.7, "ram_available_mb": 50308.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.18}, "power_stats": {"power_gpu_soc_mean_watts": 17.978, "power_cpu_cv_mean_watts": 2.035, "power_sys_5v0_mean_watts": 7.635, "gpu_utilization_percent_mean": 71.18}, "timestamp": "2026-01-28T10:42:32.446488"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3499.301, "latencies_ms": [3499.301], "images_per_second": 0.286, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A black and white photo of a group of children posing for a picture in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12532.7, "ram_available_mb": 50308.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12532.7, "ram_available_mb": 50308.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.483}, "power_stats": {"power_gpu_soc_mean_watts": 21.867, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 79.483}, "timestamp": "2026-01-28T10:42:37.974137"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4967.763, "latencies_ms": [4967.763], "images_per_second": 0.201, "prompt_tokens": 1113, "response_tokens_est": 45, "n_tiles": 1, "output_text": " 1. group of children\n2. brick wall\n3. steps\n4. children's clothing\n5. children's shoes\n6. children's hair\n7. children's faces\n8. children's eyes", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12532.7, "ram_available_mb": 50308.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12532.9, "ram_available_mb": 50308.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.683}, "power_stats": {"power_gpu_soc_mean_watts": 19.659, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 73.683}, "timestamp": "2026-01-28T10:42:44.962217"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4767.904, "latencies_ms": [4767.904], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The group of children is positioned in front of a brick building, with the children arranged in rows and columns. The children are standing and sitting in various poses, with some children positioned closer to the camera than others.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.9, "ram_available_mb": 50308.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.575}, "power_stats": {"power_gpu_soc_mean_watts": 19.889, "power_cpu_cv_mean_watts": 1.903, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 70.575}, "timestamp": "2026-01-28T10:42:51.784471"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3329.468, "latencies_ms": [3329.468], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.481}, "power_stats": {"power_gpu_soc_mean_watts": 22.686, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 77.481}, "timestamp": "2026-01-28T10:42:57.140569"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5054.771, "latencies_ms": [5054.771], "images_per_second": 0.198, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is a black and white photograph with a grainy texture, capturing a group of children in a school setting. The children are dressed in various styles of clothing, suggesting a time period from the mid-20th century.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.535}, "power_stats": {"power_gpu_soc_mean_watts": 19.108, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 71.535}, "timestamp": "2026-01-28T10:43:04.234772"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2923.898, "latencies_ms": [2923.898], "images_per_second": 0.342, "prompt_tokens": 1100, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A plate of bread and a wine glass are on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.484, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 78.417}, "timestamp": "2026-01-28T10:43:09.215476"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4414.194, "latencies_ms": [4414.194], "images_per_second": 0.227, "prompt_tokens": 1114, "response_tokens_est": 37, "n_tiles": 1, "output_text": " knife: 1, plate: 1, bread: 2, wine glass: 1, bread roll: 1, butter: 1, napkin: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12537.4, "ram_available_mb": 50303.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.405}, "power_stats": {"power_gpu_soc_mean_watts": 20.247, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 73.405}, "timestamp": "2026-01-28T10:43:15.670794"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3854.887, "latencies_ms": [3854.887], "images_per_second": 0.259, "prompt_tokens": 1118, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The bread is on the left side of the plate, the knife is on the right side, and the wine glass is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.4, "ram_available_mb": 50303.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.472, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 73.844}, "timestamp": "2026-01-28T10:43:21.585541"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3298.942, "latencies_ms": [3298.942], "images_per_second": 0.303, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " In a restaurant, a plate of bread and a glass of wine are served on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.346}, "power_stats": {"power_gpu_soc_mean_watts": 22.758, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 77.346}, "timestamp": "2026-01-28T10:43:26.916742"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3515.029, "latencies_ms": [3515.029], "images_per_second": 0.284, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a wooden table, the lighting is natural and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12541.9, "ram_available_mb": 50299.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.034}, "power_stats": {"power_gpu_soc_mean_watts": 22.106, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 77.034}, "timestamp": "2026-01-28T10:43:32.452471"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3793.942, "latencies_ms": [3793.942], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A skier in a colorful suit is jumping in the air with skis attached to their feet, while another skier stands nearby.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12541.9, "ram_available_mb": 50299.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12541.8, "ram_available_mb": 50299.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.839}, "power_stats": {"power_gpu_soc_mean_watts": 21.62, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 76.839}, "timestamp": "2026-01-28T10:43:38.293590"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6714.191, "latencies_ms": [6714.191], "images_per_second": 0.149, "prompt_tokens": 1113, "response_tokens_est": 74, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snowboard: 1\n5. snowboarder: 1\n6. snowboarder's pants: 1\n7. snowboarder's helmet: 1\n8. snowboarder's goggles: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12541.8, "ram_available_mb": 50299.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12540.8, "ram_available_mb": 50300.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.464}, "power_stats": {"power_gpu_soc_mean_watts": 17.747, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 7.654, "gpu_utilization_percent_mean": 68.464}, "timestamp": "2026-01-28T10:43:47.054322"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4376.029, "latencies_ms": [4376.029], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The skier is in the foreground, jumping over a snow ramp, while the trees are in the background. The skier is closer to the camera than the trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.8, "ram_available_mb": 50300.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.75}, "power_stats": {"power_gpu_soc_mean_watts": 20.176, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 74.75}, "timestamp": "2026-01-28T10:43:53.449519"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4277.321, "latencies_ms": [4277.321], "images_per_second": 0.234, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A skier is jumping in the air with skis attached to their feet. There are trees in the background and another skier standing on the snow.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.314}, "power_stats": {"power_gpu_soc_mean_watts": 19.848, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.591, "gpu_utilization_percent_mean": 73.314}, "timestamp": "2026-01-28T10:43:59.763585"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4754.413, "latencies_ms": [4754.413], "images_per_second": 0.21, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skier in mid-air against a backdrop of a clear blue sky, with snow-covered trees in the background. The skier is wearing a colorful outfit and is holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.631, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.648, "gpu_utilization_percent_mean": 72.4}, "timestamp": "2026-01-28T10:44:06.562863"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4098.387, "latencies_ms": [4098.387], "images_per_second": 0.244, "prompt_tokens": 1100, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A person is standing in the snow with ski poles, wearing a green shirt and black pants, and looking at the snow-covered mountains in the distance.", "error": null, "sys_before": {"cpu_percent": 12.9, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.003, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-28T10:44:12.712304"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5658.658, "latencies_ms": [5658.658], "images_per_second": 0.177, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. ski poles: 2\n3. snow: 1\n4. rocks: 2\n5. trees: 1\n6. clouds: 2\n7. sky: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12539.1, "ram_available_mb": 50301.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.447}, "power_stats": {"power_gpu_soc_mean_watts": 18.734, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 71.447}, "timestamp": "2026-01-28T10:44:20.405747"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4542.456, "latencies_ms": [4542.456], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The person is standing in the foreground, with the snowy landscape stretching out into the background. The person is positioned to the left of the frame, with the snowy mountain range visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.1, "ram_available_mb": 50301.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.073, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 71.974}, "timestamp": "2026-01-28T10:44:26.997110"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3335.736, "latencies_ms": [3335.736], "images_per_second": 0.3, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain with ski poles, wearing a green shirt and black pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.39, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 80.556}, "timestamp": "2026-01-28T10:44:32.346365"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5082.996, "latencies_ms": [5082.996], "images_per_second": 0.197, "prompt_tokens": 1110, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a person wearing a green jacket and black pants, standing in a snowy landscape with a clear blue sky and white clouds in the background. The snow is pristine white, and the person is using ski poles to navigate the terrain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.86}, "power_stats": {"power_gpu_soc_mean_watts": 19.34, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 72.86}, "timestamp": "2026-01-28T10:44:39.469153"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2953.752, "latencies_ms": [2953.752], "images_per_second": 0.339, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and a chocolate donut are placed on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.875}, "power_stats": {"power_gpu_soc_mean_watts": 23.368, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.784, "gpu_utilization_percent_mean": 82.875}, "timestamp": "2026-01-28T10:44:44.443102"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3187.762, "latencies_ms": [3187.762], "images_per_second": 0.314, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " banana: 1, donut: 1, plastic bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.769}, "power_stats": {"power_gpu_soc_mean_watts": 22.554, "power_cpu_cv_mean_watts": 1.34, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 82.769}, "timestamp": "2026-01-28T10:44:49.663596"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4353.522, "latencies_ms": [4353.522], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The banana is located in the foreground, to the left of the donut. The donut is positioned in the middle of the image, with the banana placed directly beneath it.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.429, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 73.639}, "timestamp": "2026-01-28T10:44:56.059655"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3001.587, "latencies_ms": [3001.587], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and a chocolate donut are placed on a table.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.64}, "power_stats": {"power_gpu_soc_mean_watts": 22.975, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 81.64}, "timestamp": "2026-01-28T10:45:01.108409"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4448.944, "latencies_ms": [4448.944], "images_per_second": 0.225, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a banana and a chocolate donut placed on a table. The banana is yellow and the donut is brown. The lighting is bright and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.189}, "power_stats": {"power_gpu_soc_mean_watts": 20.527, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 73.189}, "timestamp": "2026-01-28T10:45:07.591019"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4457.086, "latencies_ms": [4457.086], "images_per_second": 0.224, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design and the words \"PIRATE WELLS EXTREME\" is placed on a table next to a large knife.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.459}, "power_stats": {"power_gpu_soc_mean_watts": 20.441, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 74.459}, "timestamp": "2026-01-28T10:45:14.101128"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3125.665, "latencies_ms": [3125.665], "images_per_second": 0.32, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " mug: 1, knife: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12540.0, "ram_available_mb": 50300.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.991, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 81.6}, "timestamp": "2026-01-28T10:45:19.245706"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5223.675, "latencies_ms": [5223.675], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The mug is located to the left of the knife, which is positioned in the foreground of the image. The mug is placed on a surface that appears to be a table or countertop, while the knife is resting on the same surface.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12540.0, "ram_available_mb": 50300.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.365, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T10:45:26.486023"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3563.574, "latencies_ms": [3563.574], "images_per_second": 0.281, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design is sitting on a table next to a large knife.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.9}, "power_stats": {"power_gpu_soc_mean_watts": 22.018, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 78.9}, "timestamp": "2026-01-28T10:45:32.084035"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3705.843, "latencies_ms": [3705.843], "images_per_second": 0.27, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The mug is white and the knife is black. The mug is on a table and the knife is on the table.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.903}, "power_stats": {"power_gpu_soc_mean_watts": 21.903, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 75.903}, "timestamp": "2026-01-28T10:45:37.805412"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4345.611, "latencies_ms": [4345.611], "images_per_second": 0.23, "prompt_tokens": 1432, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of people are gathered around a bar counter in a wine tasting room, with bottles of wine and glasses on display.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.639}, "power_stats": {"power_gpu_soc_mean_watts": 23.024, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 81.639}, "timestamp": "2026-01-28T10:45:44.222224"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6308.5, "latencies_ms": [6308.5], "images_per_second": 0.159, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. woman: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.491}, "power_stats": {"power_gpu_soc_mean_watts": 20.801, "power_cpu_cv_mean_watts": 1.632, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 75.491}, "timestamp": "2026-01-28T10:45:52.552257"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10644.699, "latencies_ms": [10644.699], "images_per_second": 0.094, "prompt_tokens": 1450, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The man in the white shirt is standing near the bar, while the woman in the black jacket is standing near the door. The man in the blue shirt is standing near the woman in the black jacket. The man in the white shirt is standing near the man in the blue shirt. The man in the white shirt is standing near the man in the blue shirt. The man in the white shirt is standing near the man in the blue shirt. The man in the white shirt is standing near the man in the blue shirt. The man in the white shirt is standing near the man in the blue shirt. The man in the white shirt is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.344}, "power_stats": {"power_gpu_soc_mean_watts": 18.21, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.901, "gpu_utilization_percent_mean": 70.344}, "timestamp": "2026-01-28T10:46:05.224172"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4257.804, "latencies_ms": [4257.804], "images_per_second": 0.235, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are gathered in a wine tasting room, standing around a wooden counter with wine bottles on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.143}, "power_stats": {"power_gpu_soc_mean_watts": 24.125, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 82.143}, "timestamp": "2026-01-28T10:46:11.501883"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4650.484, "latencies_ms": [4650.484], "images_per_second": 0.215, "prompt_tokens": 1442, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a room with a wooden floor and a green wall. The lighting is natural, coming from the windows in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.026}, "power_stats": {"power_gpu_soc_mean_watts": 23.109, "power_cpu_cv_mean_watts": 1.499, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 80.026}, "timestamp": "2026-01-28T10:46:18.210660"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4666.618, "latencies_ms": [4666.618], "images_per_second": 0.214, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, there is a large field with two white birds standing in the grass, and in the background, there is a large industrial facility with multiple white structures and a few boats docked nearby.", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.256}, "power_stats": {"power_gpu_soc_mean_watts": 20.101, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 73.256}, "timestamp": "2026-01-28T10:46:24.908935"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5677.528, "latencies_ms": [5677.528], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. birds: 2\n2. boats: 1\n3. cranes: 1\n4. oil rigs: 1\n5. sky: 1\n6. clouds: 1\n7. grass: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.938}, "power_stats": {"power_gpu_soc_mean_watts": 18.729, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 72.938}, "timestamp": "2026-01-28T10:46:32.615236"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4475.011, "latencies_ms": [4475.011], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The white birds are in the foreground, while the oil rigs are in the background. The sky is above the birds and the oil rigs, and the water is below them.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.081}, "power_stats": {"power_gpu_soc_mean_watts": 20.419, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 74.081}, "timestamp": "2026-01-28T10:46:39.122144"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4119.34, "latencies_ms": [4119.34], "images_per_second": 0.243, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the foreground, a field of tall grass stretches out, while in the background, a large industrial complex with numerous tall towers and cranes dominates the skyline.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.412}, "power_stats": {"power_gpu_soc_mean_watts": 21.042, "power_cpu_cv_mean_watts": 1.59, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 74.412}, "timestamp": "2026-01-28T10:46:45.271266"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5460.394, "latencies_ms": [5460.394], "images_per_second": 0.183, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a field of tall grass with two white birds standing in the foreground, while in the background, there is a large industrial facility with multiple white structures and a blue crane. The sky is filled with clouds and there is a small bird flying in the distance.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.239}, "power_stats": {"power_gpu_soc_mean_watts": 18.852, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 72.239}, "timestamp": "2026-01-28T10:46:52.760911"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3383.415, "latencies_ms": [3383.415], "images_per_second": 0.296, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom with a checkerboard pattern on the wall.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.203, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 79.857}, "timestamp": "2026-01-28T10:46:58.191275"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4900.059, "latencies_ms": [4900.059], "images_per_second": 0.204, "prompt_tokens": 1114, "response_tokens_est": 45, "n_tiles": 1, "output_text": " 1. man\n2. toilet\n3. man's pants\n4. man's shirt\n5. man's shoes\n6. man's belt\n7. man's shirt pocket\n8. man's ear", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.585}, "power_stats": {"power_gpu_soc_mean_watts": 19.842, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 74.585}, "timestamp": "2026-01-28T10:47:05.119961"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5598.747, "latencies_ms": [5598.747], "images_per_second": 0.179, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The man is sitting on the toilet, which is in the foreground of the image. The toilet is located in the middle of the image, with the man's body positioned in the foreground. The man is looking down at the toilet, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.85, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-28T10:47:12.733222"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2821.763, "latencies_ms": [2821.763], "images_per_second": 0.354, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.087}, "power_stats": {"power_gpu_soc_mean_watts": 23.14, "power_cpu_cv_mean_watts": 1.34, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 81.087}, "timestamp": "2026-01-28T10:47:17.614325"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3254.433, "latencies_ms": [3254.433], "images_per_second": 0.307, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The image is in black and white, with a man squatting next to a toilet.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.771, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 79.815}, "timestamp": "2026-01-28T10:47:22.909320"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3810.734, "latencies_ms": [3810.734], "images_per_second": 0.262, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In the image, a group of people are standing on a snow-covered mountain, with their footprints creating a trail in the snow.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.367, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 77.156}, "timestamp": "2026-01-28T10:47:28.764558"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6151.124, "latencies_ms": [6151.124], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. group of people: 4\n2. mountain: 1\n3. snow: 1\n4. rocks: 1\n5. sky: 1\n6. snow-covered mountain: 1\n7. ski tracks: 1\n8. snow-covered slope: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.25, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.673, "gpu_utilization_percent_mean": 71.25}, "timestamp": "2026-01-28T10:47:36.944808"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4826.011, "latencies_ms": [4826.011], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The group of people is positioned in the foreground of the image, with the mountain range in the background. The mountain range is located to the right of the group, and the sky is visible above the mountain range.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12537.4, "ram_available_mb": 50303.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.688, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-28T10:47:43.825198"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3470.907, "latencies_ms": [3470.907], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A group of people are standing on a snow-covered mountain, with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.4, "ram_available_mb": 50303.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.414}, "power_stats": {"power_gpu_soc_mean_watts": 22.226, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 76.414}, "timestamp": "2026-01-28T10:47:49.308924"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4660.061, "latencies_ms": [4660.061], "images_per_second": 0.215, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a group of people standing on a snow-covered mountain, with the sky above them being a clear blue. The snow is pristine white, and the mountain's surface is rugged and rocky.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.158}, "power_stats": {"power_gpu_soc_mean_watts": 20.376, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 73.158}, "timestamp": "2026-01-28T10:47:55.998814"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3866.646, "latencies_ms": [3866.646], "images_per_second": 0.259, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A bowl of rice, broccoli, and a red bean dish is on a table.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12533.8, "ram_available_mb": 50307.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.156}, "power_stats": {"power_gpu_soc_mean_watts": 23.897, "power_cpu_cv_mean_watts": 1.126, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 83.156}, "timestamp": "2026-01-28T10:48:01.892024"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6365.642, "latencies_ms": [6365.642], "images_per_second": 0.157, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. broccoli: 2\n2. rice: 1\n3. bean: 1\n4. bowl: 1\n5. table: 1\n6. plate: 1\n7. food: 1\n8. tablecloth: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12533.8, "ram_available_mb": 50307.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.887}, "power_stats": {"power_gpu_soc_mean_watts": 20.605, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 75.887}, "timestamp": "2026-01-28T10:48:10.296865"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5485.017, "latencies_ms": [5485.017], "images_per_second": 0.182, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The broccoli is located to the left of the rice, which is in the center of the bowl. The red bean dish is on top of the rice, and the white rice is on the bottom of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.913}, "power_stats": {"power_gpu_soc_mean_watts": 21.841, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 76.913}, "timestamp": "2026-01-28T10:48:17.805069"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3354.643, "latencies_ms": [3354.643], "images_per_second": 0.298, "prompt_tokens": 1444, "response_tokens_est": 9, "n_tiles": 1, "output_text": " A bowl of food is on a table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12539.1, "ram_available_mb": 50301.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.821}, "power_stats": {"power_gpu_soc_mean_watts": 25.924, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 86.821}, "timestamp": "2026-01-28T10:48:23.202359"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3594.497, "latencies_ms": [3594.497], "images_per_second": 0.278, "prompt_tokens": 1442, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The bowl is white and the food is red and green.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12539.1, "ram_available_mb": 50301.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.448}, "power_stats": {"power_gpu_soc_mean_watts": 25.4, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 87.448}, "timestamp": "2026-01-28T10:48:28.813546"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3608.631, "latencies_ms": [3608.631], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is standing on a wooden platform with their feet on a skateboard, wearing black and white sneakers.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.933}, "power_stats": {"power_gpu_soc_mean_watts": 21.603, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 75.933}, "timestamp": "2026-01-28T10:48:34.460993"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6244.004, "latencies_ms": [6244.004], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. wooden plank: 1\n4. grass: 1\n5. person's legs: 1\n6. person's feet: 1\n7. person's shoes: 1\n8. person's pants: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.096}, "power_stats": {"power_gpu_soc_mean_watts": 18.356, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 7.657, "gpu_utilization_percent_mean": 72.096}, "timestamp": "2026-01-28T10:48:42.751769"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4785.128, "latencies_ms": [4785.128], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The skateboard is in the foreground, with the person's feet on it. The person is standing on the skateboard, with their feet on the deck. The background is a grassy area with some wooden structures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.966, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 75.275}, "timestamp": "2026-01-28T10:48:49.570261"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3185.211, "latencies_ms": [3185.211], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp in a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.615}, "power_stats": {"power_gpu_soc_mean_watts": 22.893, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 78.615}, "timestamp": "2026-01-28T10:48:54.811485"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5749.965, "latencies_ms": [5749.965], "images_per_second": 0.174, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a person wearing black and white sneakers with a checkered pattern on the bottom, standing on a wooden ramp with a skateboard. The lighting is natural and bright, suggesting it is daytime. The weather appears to be clear, as there are no visible clouds in the sky.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.673}, "power_stats": {"power_gpu_soc_mean_watts": 18.803, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 71.673}, "timestamp": "2026-01-28T10:49:02.601747"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3333.876, "latencies_ms": [3333.876], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a keyboard and a computer monitor in the background.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.407}, "power_stats": {"power_gpu_soc_mean_watts": 22.474, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 81.407}, "timestamp": "2026-01-28T10:49:07.955608"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2434.077, "latencies_ms": [2434.077], "images_per_second": 0.411, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 5", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.85}, "power_stats": {"power_gpu_soc_mean_watts": 24.193, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 82.85}, "timestamp": "2026-01-28T10:49:12.403959"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4817.506, "latencies_ms": [4817.506], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The bananas are located in the foreground of the image, with the keyboard and computer monitor in the background. The bananas are positioned to the left of the keyboard, and the computer monitor is to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12540.0, "ram_available_mb": 50300.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.1}, "power_stats": {"power_gpu_soc_mean_watts": 19.878, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 74.1}, "timestamp": "2026-01-28T10:49:19.233684"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3235.714, "latencies_ms": [3235.714], "images_per_second": 0.309, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a keyboard and computer monitor in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.0, "ram_available_mb": 50300.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.889}, "power_stats": {"power_gpu_soc_mean_watts": 22.79, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 79.889}, "timestamp": "2026-01-28T10:49:24.530197"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3044.458, "latencies_ms": [3044.458], "images_per_second": 0.328, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.25, "power_cpu_cv_mean_watts": 1.426, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 80.28}, "timestamp": "2026-01-28T10:49:29.628613"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3532.494, "latencies_ms": [3532.494], "images_per_second": 0.283, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image depicts a plate of food, including white rice, vegetables, and chicken, placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.253, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 77.724}, "timestamp": "2026-01-28T10:49:35.196790"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4523.256, "latencies_ms": [4523.256], "images_per_second": 0.221, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " plate: 1, fork: 1, knife: 1, glass: 1, rice: 1, carrots: 2, broccoli: 2, chicken: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.475, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 72.868}, "timestamp": "2026-01-28T10:49:41.763923"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4688.012, "latencies_ms": [4688.012], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the glass of water is in the background. The fork and knife are placed on the plate, and the rice is on the right side of the plate.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.872}, "power_stats": {"power_gpu_soc_mean_watts": 20.051, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 72.872}, "timestamp": "2026-01-28T10:49:48.496813"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3192.771, "latencies_ms": [3192.771], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A plate of food is on a table with a glass of water and a fork.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.654}, "power_stats": {"power_gpu_soc_mean_watts": 22.957, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 80.654}, "timestamp": "2026-01-28T10:49:53.725134"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5506.755, "latencies_ms": [5506.755], "images_per_second": 0.182, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a plate of food with a variety of colors, including red, green, and white. The lighting in the image is bright and natural, suggesting that the photo was taken during the day. The plate is made of ceramic and is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.404}, "power_stats": {"power_gpu_soc_mean_watts": 18.921, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 73.404}, "timestamp": "2026-01-28T10:50:01.274641"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4174.652, "latencies_ms": [4174.652], "images_per_second": 0.24, "prompt_tokens": 1100, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A little girl wearing a white shirt and a colorful skirt is playing with a Wii remote in a living room with a couch, a coffee table, and a rug.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12538.2, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.086}, "power_stats": {"power_gpu_soc_mean_watts": 20.787, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 74.086}, "timestamp": "2026-01-28T10:50:07.490783"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6265.259, "latencies_ms": [6265.259], "images_per_second": 0.16, "prompt_tokens": 1114, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. couch: 1\n2. woman: 1\n3. girl: 1\n4. woman in white: 1\n5. woman in green: 1\n6. woman in white dress: 1\n7. woman in black: 1\n8. woman in blue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.2, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.981}, "power_stats": {"power_gpu_soc_mean_watts": 17.905, "power_cpu_cv_mean_watts": 2.101, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 71.981}, "timestamp": "2026-01-28T10:50:15.795884"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4877.576, "latencies_ms": [4877.576], "images_per_second": 0.205, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The girl is in the foreground, playing with a toy on the floor. The couch is in the background, and the people are standing behind it. The rug is in the foreground, and the stairs are in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.681, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 73.195}, "timestamp": "2026-01-28T10:50:22.727417"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3411.773, "latencies_ms": [3411.773], "images_per_second": 0.293, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A little girl is playing with a Wii remote in a living room with a couch and a coffee table.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.332, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.845, "gpu_utilization_percent_mean": 79.286}, "timestamp": "2026-01-28T10:50:28.151287"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4322.991, "latencies_ms": [4322.991], "images_per_second": 0.231, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming in from the windows. The colors in the room are vibrant and the materials are mostly wood and fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.111}, "power_stats": {"power_gpu_soc_mean_watts": 20.495, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 74.111}, "timestamp": "2026-01-28T10:50:34.518952"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4939.769, "latencies_ms": [4939.769], "images_per_second": 0.202, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a man in a dark suit and tie is shaking hands with another man in a patterned shirt and tie, both standing in a large room filled with tables and chairs, suggesting a formal event or gathering.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.61}, "power_stats": {"power_gpu_soc_mean_watts": 19.424, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 7.658, "gpu_utilization_percent_mean": 72.61}, "timestamp": "2026-01-28T10:50:41.516790"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5716.443, "latencies_ms": [5716.443], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. tie: 1\n3. glasses: 1\n4. shirt: 1\n5. tie: 1\n6. suit: 1\n7. shirt: 1\n8. tie: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.958}, "power_stats": {"power_gpu_soc_mean_watts": 18.319, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.623, "gpu_utilization_percent_mean": 71.958}, "timestamp": "2026-01-28T10:50:49.261841"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5670.323, "latencies_ms": [5670.323], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man in the dark suit is standing to the right of the man in the patterned shirt, and the man in the patterned shirt is standing to the left of the man in the dark suit. The man in the patterned shirt is closer to the camera than the man in the dark suit.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12537.4, "ram_available_mb": 50303.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.542}, "power_stats": {"power_gpu_soc_mean_watts": 18.62, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 70.542}, "timestamp": "2026-01-28T10:50:56.987261"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4155.666, "latencies_ms": [4155.666], "images_per_second": 0.241, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In a formal setting, two men are shaking hands, one in a traditional outfit and the other in a business suit, indicating a possible cultural exchange or business meeting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.4, "ram_available_mb": 50303.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.314}, "power_stats": {"power_gpu_soc_mean_watts": 20.844, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 75.314}, "timestamp": "2026-01-28T10:51:03.177938"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3291.942, "latencies_ms": [3291.942], "images_per_second": 0.304, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is well-lit with warm lighting, and the attendees are dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.852}, "power_stats": {"power_gpu_soc_mean_watts": 22.791, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 78.852}, "timestamp": "2026-01-28T10:51:08.497064"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3181.914, "latencies_ms": [3181.914], "images_per_second": 0.314, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a white shirt and a striped tie is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12538.5, "ram_available_mb": 50302.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.038}, "power_stats": {"power_gpu_soc_mean_watts": 22.91, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 81.038}, "timestamp": "2026-01-28T10:51:13.700490"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5508.217, "latencies_ms": [5508.217], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tie: 1\n2. shirt: 1\n3. hand: 1\n4. person: 1\n5. tie: 1\n6. shirt: 1\n7. hand: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12538.5, "ram_available_mb": 50302.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12539.0, "ram_available_mb": 50301.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.261}, "power_stats": {"power_gpu_soc_mean_watts": 19.211, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 72.261}, "timestamp": "2026-01-28T10:51:21.224233"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4452.096, "latencies_ms": [4452.096], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is standing in the foreground, wearing a white shirt and a striped tie. The background is dark and out of focus, suggesting that the man is in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12539.0, "ram_available_mb": 50301.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.703}, "power_stats": {"power_gpu_soc_mean_watts": 20.55, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 74.703}, "timestamp": "2026-01-28T10:51:27.724591"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3025.365, "latencies_ms": [3025.365], "images_per_second": 0.331, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a tie and a shirt is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.32}, "power_stats": {"power_gpu_soc_mean_watts": 22.831, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 82.32}, "timestamp": "2026-01-28T10:51:32.799086"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3513.282, "latencies_ms": [3513.282], "images_per_second": 0.285, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The man is wearing a white shirt and a striped tie. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12539.7, "ram_available_mb": 50301.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.897}, "power_stats": {"power_gpu_soc_mean_watts": 22.212, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 73.897}, "timestamp": "2026-01-28T10:51:38.364405"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4825.904, "latencies_ms": [4825.904], "images_per_second": 0.207, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the room, there is a red armchair, a blue and red plaid couch, a television on a wooden stand, a whiteboard with writing on it, and a picture of a man and a woman.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.7}, "power_stats": {"power_gpu_soc_mean_watts": 19.579, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 72.7}, "timestamp": "2026-01-28T10:51:45.225809"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3927.476, "latencies_ms": [3927.476], "images_per_second": 0.255, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " chair: 1, sofa: 1, television: 1, whiteboard: 1, wall: 1, poster: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.465, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 75.97}, "timestamp": "2026-01-28T10:51:51.197363"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5837.407, "latencies_ms": [5837.407], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The red armchair is positioned to the left of the blue and red plaid couch, which is in the foreground of the room. The television is placed on a wooden stand in the middle of the room, with the whiteboard on the left wall and the framed picture on the right wall in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.184}, "power_stats": {"power_gpu_soc_mean_watts": 18.608, "power_cpu_cv_mean_watts": 1.962, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 70.184}, "timestamp": "2026-01-28T10:51:59.069120"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3360.551, "latencies_ms": [3360.551], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A room with a plaid couch, a red chair, and a TV on a stand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12540.6, "ram_available_mb": 50300.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.771, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-28T10:52:04.439641"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3109.22, "latencies_ms": [3109.22], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The room is painted yellow and has a plaid couch and a red chair.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12540.6, "ram_available_mb": 50300.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.034, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 79.654}, "timestamp": "2026-01-28T10:52:09.594602"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3888.204, "latencies_ms": [3888.204], "images_per_second": 0.257, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12540.5, "ram_available_mb": 50300.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.188}, "power_stats": {"power_gpu_soc_mean_watts": 24.112, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 84.188}, "timestamp": "2026-01-28T10:52:15.539492"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7248.847, "latencies_ms": [7248.847], "images_per_second": 0.138, "prompt_tokens": 1446, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Water: 1\n6. Surfboard's edge: 1\n7. Surfer's arm: 1\n8. Surfer's leg: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12540.5, "ram_available_mb": 50300.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.377}, "power_stats": {"power_gpu_soc_mean_watts": 19.0, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 7.899, "gpu_utilization_percent_mean": 73.377}, "timestamp": "2026-01-28T10:52:24.800361"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5494.909, "latencies_ms": [5494.909], "images_per_second": 0.182, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, riding a wave that is in the middle ground. The surfer is facing towards the right side of the image, with the wave moving towards the left.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.043}, "power_stats": {"power_gpu_soc_mean_watts": 21.842, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 78.043}, "timestamp": "2026-01-28T10:52:32.356078"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3915.737, "latencies_ms": [3915.737], "images_per_second": 0.255, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a yellow shirt is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.173, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 83.75}, "timestamp": "2026-01-28T10:52:38.301904"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5004.885, "latencies_ms": [5004.885], "images_per_second": 0.2, "prompt_tokens": 1442, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The surfer is wearing a yellow shirt and black pants while riding a wave on a white surfboard. The water is a deep blue color and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.585}, "power_stats": {"power_gpu_soc_mean_watts": 22.393, "power_cpu_cv_mean_watts": 1.387, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 78.585}, "timestamp": "2026-01-28T10:52:45.345183"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3172.35, "latencies_ms": [3172.35], "images_per_second": 0.315, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.972, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 82.0}, "timestamp": "2026-01-28T10:52:50.554035"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4333.59, "latencies_ms": [4333.59], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " 1. black cat\n2. laptop\n3. keyboard\n4. computer monitor\n5. phone\n6. mouse\n7. white keyboard\n8. white mouse", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.564, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 75.639}, "timestamp": "2026-01-28T10:52:56.922452"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4875.647, "latencies_ms": [4875.647], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at the computer screen. The laptop is on the left side of the desk, and the phone is on the right side. The cat is closer to the computer screen than the laptop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.951}, "power_stats": {"power_gpu_soc_mean_watts": 19.893, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 72.951}, "timestamp": "2026-01-28T10:53:03.826478"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3228.325, "latencies_ms": [3228.325], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.686, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 82.185}, "timestamp": "2026-01-28T10:53:09.089454"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4426.927, "latencies_ms": [4426.927], "images_per_second": 0.226, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a room with a black cat sitting on a desk, looking at a computer screen. The room is well-lit with natural light coming in from a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.5, "ram_available_mb": 50301.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.73}, "power_stats": {"power_gpu_soc_mean_watts": 20.431, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 72.73}, "timestamp": "2026-01-28T10:53:15.530923"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4214.317, "latencies_ms": [4214.317], "images_per_second": 0.237, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A group of people, including a child wearing a helmet, are gathered outside a building, with one person cutting a red ribbon as part of a ribbon-cutting ceremony.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12538.5, "ram_available_mb": 50302.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.658, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 74.971}, "timestamp": "2026-01-28T10:53:21.765822"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5949.871, "latencies_ms": [5949.871], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. People: 10\n2. Balloons: 2\n3. Helmet: 1\n4. Helmet: 1\n5. Helmet: 1\n6. Helmet: 1\n7. Helmet: 1\n8. Helmet: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12538.5, "ram_available_mb": 50302.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.431}, "power_stats": {"power_gpu_soc_mean_watts": 18.491, "power_cpu_cv_mean_watts": 1.979, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 70.431}, "timestamp": "2026-01-28T10:53:29.756482"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5017.711, "latencies_ms": [5017.711], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The red ribbon is in the foreground, held by the man in the black suit. The child is in the middle of the image, holding the ribbon. The man in the blue shirt is in the background, standing behind the child.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.024}, "power_stats": {"power_gpu_soc_mean_watts": 19.744, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 73.024}, "timestamp": "2026-01-28T10:53:36.800651"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4758.652, "latencies_ms": [4758.652], "images_per_second": 0.21, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " A group of people are gathered outside a building, cutting a red ribbon with a pair of scissors. The ribbon is being held by a man in a suit, while a little girl in a pink jacket stands nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.675}, "power_stats": {"power_gpu_soc_mean_watts": 19.979, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 74.675}, "timestamp": "2026-01-28T10:53:43.602784"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4867.198, "latencies_ms": [4867.198], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting. The colors in the image are vibrant, with the red ribbon being the most prominent. The weather appears to be clear, as there are no signs of rain or snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.61}, "power_stats": {"power_gpu_soc_mean_watts": 19.855, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 72.61}, "timestamp": "2026-01-28T10:53:50.497009"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3721.958, "latencies_ms": [3721.958], "images_per_second": 0.269, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A white and pink bus with the number 65745 on the front is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.613}, "power_stats": {"power_gpu_soc_mean_watts": 21.851, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 78.613}, "timestamp": "2026-01-28T10:53:56.268858"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5653.29, "latencies_ms": [5653.29], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 1\n3. building: 1\n4. flowers: 1\n5. sky: 1\n6. road: 1\n7. sidewalk: 1\n8. license plate: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.99, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-28T10:54:03.951211"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4457.361, "latencies_ms": [4457.361], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the sidewalk and street on the right. The bus is in the foreground, with the buildings and people in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.297}, "power_stats": {"power_gpu_soc_mean_watts": 20.429, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 75.297}, "timestamp": "2026-01-28T10:54:10.458755"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3048.436, "latencies_ms": [3048.436], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A white and pink bus is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.6}, "power_stats": {"power_gpu_soc_mean_watts": 23.184, "power_cpu_cv_mean_watts": 1.97, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 80.6}, "timestamp": "2026-01-28T10:54:15.540007"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4287.439, "latencies_ms": [4287.439], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bus is white, pink, and blue, and it is parked on a street with a yellow line. The sky is cloudy and the bus is in motion.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.083}, "power_stats": {"power_gpu_soc_mean_watts": 20.918, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 79.083}, "timestamp": "2026-01-28T10:54:21.876201"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3791.482, "latencies_ms": [3791.482], "images_per_second": 0.264, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man is sitting cross-legged in front of a mirror, holding a cup in his hand.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.387}, "power_stats": {"power_gpu_soc_mean_watts": 21.035, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.525, "gpu_utilization_percent_mean": 80.387}, "timestamp": "2026-01-28T10:54:27.712928"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5601.429, "latencies_ms": [5601.429], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. mirror - 1\n2. man - 1\n3. chair - 1\n4. wall - 2\n5. floor - 1\n6. door - 1\n7. table - 1\n8. picture - 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.809}, "power_stats": {"power_gpu_soc_mean_watts": 18.876, "power_cpu_cv_mean_watts": 2.616, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 71.809}, "timestamp": "2026-01-28T10:54:35.375400"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5363.869, "latencies_ms": [5363.869], "images_per_second": 0.186, "prompt_tokens": 1118, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The man is sitting in front of the mirror, which is positioned on the left side of the image. The mirror is reflecting the room, which is located in the background. The man is sitting on the floor, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.556}, "power_stats": {"power_gpu_soc_mean_watts": 19.084, "power_cpu_cv_mean_watts": 2.501, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 72.556}, "timestamp": "2026-01-28T10:54:42.760358"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3501.924, "latencies_ms": [3501.924], "images_per_second": 0.286, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man is sitting in front of a mirror, holding a cup. He is wearing a green shirt and black shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.586}, "power_stats": {"power_gpu_soc_mean_watts": 22.348, "power_cpu_cv_mean_watts": 2.389, "power_sys_5v0_mean_watts": 7.86, "gpu_utilization_percent_mean": 76.586}, "timestamp": "2026-01-28T10:54:48.304340"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3342.878, "latencies_ms": [3342.878], "images_per_second": 0.299, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.393}, "power_stats": {"power_gpu_soc_mean_watts": 22.331, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 80.393}, "timestamp": "2026-01-28T10:54:53.690155"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6023.348, "latencies_ms": [6023.348], "images_per_second": 0.166, "prompt_tokens": 1099, "response_tokens_est": 63, "n_tiles": 1, "output_text": " In the image, a group of people are gathered in a room, each holding a surfboard. The surfboards are adorned with vibrant designs and colors, and one of them prominently features the word \"JE\". The people are standing close to each other, creating a sense of camaraderie and shared enthusiasm for surfing.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.633, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 70.02}, "timestamp": "2026-01-28T10:55:01.768601"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5793.77, "latencies_ms": [5793.77], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 4\n2. surfboard: 4\n3. camera: 1\n4. person: 1\n5. surfboard: 1\n6. person: 1\n7. surfboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.592}, "power_stats": {"power_gpu_soc_mean_watts": 18.605, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 7.685, "gpu_utilization_percent_mean": 71.592}, "timestamp": "2026-01-28T10:55:09.583078"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4987.33, "latencies_ms": [4987.33], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The surfboards are positioned in the foreground, with the group of people standing behind them. The person taking the photo is positioned to the left of the surfboards, while the person holding the camera is positioned to the right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.429}, "power_stats": {"power_gpu_soc_mean_watts": 19.424, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 75.429}, "timestamp": "2026-01-28T10:55:16.589446"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3137.251, "latencies_ms": [3137.251], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are posing for a photo in a room with surfboards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.654}, "power_stats": {"power_gpu_soc_mean_watts": 22.94, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 80.654}, "timestamp": "2026-01-28T10:55:21.784415"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3870.573, "latencies_ms": [3870.573], "images_per_second": 0.258, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the surfboards are made of wood with vibrant colors.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.306, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 74.844}, "timestamp": "2026-01-28T10:55:27.672888"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5109.091, "latencies_ms": [5109.091], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a large, golden-colored airplane with the text \"POLSKIE LINIE LICZNICZE\" and \"LOT\" written on its side, parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.405}, "power_stats": {"power_gpu_soc_mean_watts": 19.417, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 69.405}, "timestamp": "2026-01-28T10:55:34.804967"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5523.941, "latencies_ms": [5523.941], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. engine: 2\n5. runway: 1\n6. clouds: 1\n7. sky: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.995, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 71.511}, "timestamp": "2026-01-28T10:55:42.368987"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4208.597, "latencies_ms": [4208.597], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The airplane is in the foreground, with the runway and other planes in the background. The airplane is to the left of the runway, and the sky is above it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12536.5, "ram_available_mb": 50304.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.143}, "power_stats": {"power_gpu_soc_mean_watts": 20.952, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 73.143}, "timestamp": "2026-01-28T10:55:48.599390"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5055.007, "latencies_ms": [5055.007], "images_per_second": 0.198, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a moment on a runway where a golden-colored airplane, adorned with blue and white accents, is parked. The sky above is a canvas of blue, dotted with fluffy white clouds, creating a serene backdrop for the scene.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12536.5, "ram_available_mb": 50304.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12536.5, "ram_available_mb": 50304.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.833}, "power_stats": {"power_gpu_soc_mean_watts": 19.521, "power_cpu_cv_mean_watts": 2.346, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 73.833}, "timestamp": "2026-01-28T10:55:55.693905"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3153.965, "latencies_ms": [3153.965], "images_per_second": 0.317, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The airplane is gold and blue, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.5, "ram_available_mb": 50304.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.48}, "power_stats": {"power_gpu_soc_mean_watts": 23.246, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.823, "gpu_utilization_percent_mean": 75.48}, "timestamp": "2026-01-28T10:56:00.875913"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3107.666, "latencies_ms": [3107.666], "images_per_second": 0.322, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a toilet with a lid up and water in it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.276, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 80.462}, "timestamp": "2026-01-28T10:56:06.035787"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3029.514, "latencies_ms": [3029.514], "images_per_second": 0.33, "prompt_tokens": 1114, "response_tokens_est": 14, "n_tiles": 1, "output_text": " toilet: 1\nlid: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.167, "power_cpu_cv_mean_watts": 1.441, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 76.76}, "timestamp": "2026-01-28T10:56:11.123550"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4525.793, "latencies_ms": [4525.793], "images_per_second": 0.221, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the person's legs visible in the bottom left corner. The sink is situated in the background, with the faucet and mirror above it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.329, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 72.676}, "timestamp": "2026-01-28T10:56:17.679048"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2987.57, "latencies_ms": [2987.57], "images_per_second": 0.335, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is standing in a bathroom with a toilet and a sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12540.1, "ram_available_mb": 50300.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.96}, "power_stats": {"power_gpu_soc_mean_watts": 22.91, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 80.96}, "timestamp": "2026-01-28T10:56:22.716452"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2797.037, "latencies_ms": [2797.037], "images_per_second": 0.358, "prompt_tokens": 1110, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The toilet is white and the floor is grey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.1, "ram_available_mb": 50300.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.435}, "power_stats": {"power_gpu_soc_mean_watts": 23.526, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 79.435}, "timestamp": "2026-01-28T10:56:27.536716"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3696.474, "latencies_ms": [3696.474], "images_per_second": 0.271, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A person is skiing down a snowy trail in the woods, wearing a blue jacket, black pants, and a yellow helmet.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.044, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-28T10:56:33.264847"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5842.657, "latencies_ms": [5842.657], "images_per_second": 0.171, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. skis: 2\n3. ski poles: 2\n4. snow: 1\n5. trees: 1\n6. snowboard: 0\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.898}, "power_stats": {"power_gpu_soc_mean_watts": 18.433, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.642, "gpu_utilization_percent_mean": 72.898}, "timestamp": "2026-01-28T10:56:41.132876"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4931.444, "latencies_ms": [4931.444], "images_per_second": 0.203, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the snowy forest and trees in the background. The skier is moving towards the right side of the image, with the snowy trail leading off into the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.3, "ram_available_mb": 50302.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.19}, "power_stats": {"power_gpu_soc_mean_watts": 19.587, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 7.688, "gpu_utilization_percent_mean": 74.19}, "timestamp": "2026-01-28T10:56:48.087711"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2963.148, "latencies_ms": [2963.148], "images_per_second": 0.337, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.792}, "power_stats": {"power_gpu_soc_mean_watts": 23.129, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 82.792}, "timestamp": "2026-01-28T10:56:53.083364"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4392.067, "latencies_ms": [4392.067], "images_per_second": 0.228, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a person skiing in a snowy forest with a white background and a gray sky. The skier is wearing a blue jacket, black pants, and a yellow helmet.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12536.0, "ram_available_mb": 50304.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.624, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 72.972}, "timestamp": "2026-01-28T10:56:59.513588"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5444.331, "latencies_ms": [5444.331], "images_per_second": 0.184, "prompt_tokens": 1099, "response_tokens_est": 52, "n_tiles": 1, "output_text": " In the image, a tennis player is seen in the midst of a game, wearing a yellow shirt and black shorts, while a man in an orange shirt watches from the stands. The court is marked with white lines, and the background is filled with spectators.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12537.7, "ram_available_mb": 50303.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.044}, "power_stats": {"power_gpu_soc_mean_watts": 18.957, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 73.044}, "timestamp": "2026-01-28T10:57:06.997619"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5817.527, "latencies_ms": [5817.527], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. ball: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.104}, "power_stats": {"power_gpu_soc_mean_watts": 18.549, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.652, "gpu_utilization_percent_mean": 72.104}, "timestamp": "2026-01-28T10:57:14.850641"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4616.539, "latencies_ms": [4616.539], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the audience in the background. The tennis court is in the foreground, with the player and the audience in the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.053}, "power_stats": {"power_gpu_soc_mean_watts": 19.88, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 7.678, "gpu_utilization_percent_mean": 71.053}, "timestamp": "2026-01-28T10:57:21.495980"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3161.242, "latencies_ms": [3161.242], "images_per_second": 0.316, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A tennis player is playing on a blue court with a crowd of spectators watching.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.44}, "power_stats": {"power_gpu_soc_mean_watts": 23.244, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 75.44}, "timestamp": "2026-01-28T10:57:26.671834"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3191.354, "latencies_ms": [3191.354], "images_per_second": 0.313, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The tennis court is blue with white lines, and the crowd is wearing various colors.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12537.8, "ram_available_mb": 50303.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.136, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 77.654}, "timestamp": "2026-01-28T10:57:31.921619"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4077.267, "latencies_ms": [4077.267], "images_per_second": 0.245, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image shows a dining table with two bowls of food, one containing a curry dish and the other a bowl of fruit, placed on a white napkin.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.941}, "power_stats": {"power_gpu_soc_mean_watts": 20.934, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 74.941}, "timestamp": "2026-01-28T10:57:38.061302"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5855.33, "latencies_ms": [5855.33], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bowl: 2\n2. plate: 1\n3. napkin: 1\n4. glass: 1\n5. tablecloth: 1\n6. food: 2\n7. table: 1\n8. tablecloth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.592}, "power_stats": {"power_gpu_soc_mean_watts": 18.415, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 7.673, "gpu_utilization_percent_mean": 72.592}, "timestamp": "2026-01-28T10:57:45.954217"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5178.477, "latencies_ms": [5178.477], "images_per_second": 0.193, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The bowl of pickled vegetables is located to the left of the bowl of fruit, with the latter being closer to the camera. The tablecloth is positioned in the background, while the glass of water is placed near the edge of the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.5, "ram_available_mb": 50304.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12552.9, "ram_available_mb": 50288.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.837}, "power_stats": {"power_gpu_soc_mean_watts": 19.105, "power_cpu_cv_mean_watts": 2.133, "power_sys_5v0_mean_watts": 7.675, "gpu_utilization_percent_mean": 72.837}, "timestamp": "2026-01-28T10:57:53.175065"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4590.258, "latencies_ms": [4590.258], "images_per_second": 0.218, "prompt_tokens": 1111, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In a dimly lit restaurant, a plate of food is presented on a table. The plate contains two bowls of food, one filled with a red curry and the other with a sweet dessert.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12552.9, "ram_available_mb": 50288.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.737}, "power_stats": {"power_gpu_soc_mean_watts": 20.132, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 71.737}, "timestamp": "2026-01-28T10:57:59.782132"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5185.703, "latencies_ms": [5185.703], "images_per_second": 0.193, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a table with two bowls of food, one containing a curry dish and the other containing a bowl of fruit. The curry dish is brown and the fruit is orange and white. The lighting is dim and the tablecloth is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.93}, "power_stats": {"power_gpu_soc_mean_watts": 19.654, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 73.93}, "timestamp": "2026-01-28T10:58:06.998950"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4285.397, "latencies_ms": [4285.397], "images_per_second": 0.233, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, there are three sheep standing in a grassy area, with one sheep looking directly at the camera, and the other two sheep facing away from the camera.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12546.0, "ram_available_mb": 50294.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.2}, "power_stats": {"power_gpu_soc_mean_watts": 20.39, "power_cpu_cv_mean_watts": 2.231, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 75.2}, "timestamp": "2026-01-28T10:58:13.317191"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5819.666, "latencies_ms": [5819.666], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. sheep: 4\n2. grass: 1\n3. fence: 1\n4. brick wall: 1\n5. wooden structure: 1\n6. metal structure: 1\n7. wooden planks: 1\n8. metal fence: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.0, "ram_available_mb": 50294.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.367}, "power_stats": {"power_gpu_soc_mean_watts": 18.678, "power_cpu_cv_mean_watts": 2.288, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 71.367}, "timestamp": "2026-01-28T10:58:21.171496"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4759.121, "latencies_ms": [4759.121], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the brick wall serving as the background. The sheep are standing close to each other, with one sheep in the foreground and two others in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12544.4, "ram_available_mb": 50296.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.137, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 74.718}, "timestamp": "2026-01-28T10:58:27.947016"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4733.215, "latencies_ms": [4733.215], "images_per_second": 0.211, "prompt_tokens": 1111, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In a sunny day, a group of sheep are standing in a grassy field, looking at the camera. The sheep are of different sizes and colors, with some having curly wool and others having straight wool.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12544.4, "ram_available_mb": 50296.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.154}, "power_stats": {"power_gpu_soc_mean_watts": 19.654, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 75.154}, "timestamp": "2026-01-28T10:58:34.717184"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3526.454, "latencies_ms": [3526.454], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The sheep are in a grassy area with a brick wall in the background, and the lighting is natural daylight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.345}, "power_stats": {"power_gpu_soc_mean_watts": 21.987, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 80.345}, "timestamp": "2026-01-28T10:58:40.273045"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4050.627, "latencies_ms": [4050.627], "images_per_second": 0.247, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image features a bunch of bananas and an apple placed on a blue and white patterned background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.545}, "power_stats": {"power_gpu_soc_mean_watts": 23.644, "power_cpu_cv_mean_watts": 1.237, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 81.545}, "timestamp": "2026-01-28T10:58:46.379343"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3449.2, "latencies_ms": [3449.2], "images_per_second": 0.29, "prompt_tokens": 1446, "response_tokens_est": 9, "n_tiles": 1, "output_text": " apple: 1, banana: 7", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.071}, "power_stats": {"power_gpu_soc_mean_watts": 25.501, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 85.071}, "timestamp": "2026-01-28T10:58:51.843418"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6297.336, "latencies_ms": [6297.336], "images_per_second": 0.159, "prompt_tokens": 1450, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The apple is positioned in the center of the image, with the bananas surrounding it. The bananas are arranged in a circular pattern around the apple, creating a symmetrical composition. The background is a blue and white floral pattern, which provides a contrasting backdrop to the vibrant colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.509}, "power_stats": {"power_gpu_soc_mean_watts": 20.924, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 76.509}, "timestamp": "2026-01-28T10:59:00.172983"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5059.554, "latencies_ms": [5059.554], "images_per_second": 0.198, "prompt_tokens": 1444, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a bunch of bananas and an apple placed on a blue patterned background. The bananas are arranged in a circular formation around the apple, creating a visually appealing display.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.262}, "power_stats": {"power_gpu_soc_mean_watts": 22.371, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 78.262}, "timestamp": "2026-01-28T10:59:07.274649"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6774.502, "latencies_ms": [6774.502], "images_per_second": 0.148, "prompt_tokens": 1442, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image features a vibrant display of bananas and an apple, with the bananas arranged in a circular pattern around the apple. The bananas are a bright yellow color, while the apple is a striking combination of red and yellow hues. The background is a textured blue and white pattern, providing a stark contrast to the colorful fruits.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.632}, "power_stats": {"power_gpu_soc_mean_watts": 20.427, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.932, "gpu_utilization_percent_mean": 74.632}, "timestamp": "2026-01-28T10:59:16.070550"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3679.08, "latencies_ms": [3679.08], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A blue and white tram with red seats is parked on a track, with trees and a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12546.9, "ram_available_mb": 50294.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.133}, "power_stats": {"power_gpu_soc_mean_watts": 21.802, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.761, "gpu_utilization_percent_mean": 77.133}, "timestamp": "2026-01-28T10:59:21.771920"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5703.17, "latencies_ms": [5703.17], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. tram: 1\n2. windows: 12\n3. doors: 4\n4. people: 2\n5. trees: 1\n6. cables: 10\n7. tracks: 1\n8. trolley: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.9, "ram_available_mb": 50294.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12547.4, "ram_available_mb": 50293.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.125}, "power_stats": {"power_gpu_soc_mean_watts": 18.816, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 73.125}, "timestamp": "2026-01-28T10:59:29.488956"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4642.059, "latencies_ms": [4642.059], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The tram is positioned on the left side of the image, with the tracks running parallel to it. The background features a clear blue sky and trees, while the foreground shows a concrete platform and a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12547.4, "ram_available_mb": 50293.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12546.2, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.256}, "power_stats": {"power_gpu_soc_mean_watts": 20.058, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 73.256}, "timestamp": "2026-01-28T10:59:36.186083"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3302.311, "latencies_ms": [3302.311], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A blue and white tram is parked at a station, with trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12546.2, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12546.2, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.074}, "power_stats": {"power_gpu_soc_mean_watts": 22.681, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 79.074}, "timestamp": "2026-01-28T10:59:41.522000"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3090.783, "latencies_ms": [3090.783], "images_per_second": 0.324, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The train is blue and white, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.2, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12544.8, "ram_available_mb": 50296.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.04}, "power_stats": {"power_gpu_soc_mean_watts": 23.051, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 82.04}, "timestamp": "2026-01-28T10:59:46.630713"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4350.697, "latencies_ms": [4350.697], "images_per_second": 0.23, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white bathtub, a shower with a red curtain, a double sink vanity with two mirrors above it, and a red bath mat on the floor.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12544.8, "ram_available_mb": 50296.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.917}, "power_stats": {"power_gpu_soc_mean_watts": 20.527, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 74.917}, "timestamp": "2026-01-28T10:59:53.031470"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5785.907, "latencies_ms": [5785.907], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Shower: 1\n3. Mirror: 2\n4. Sink: 2\n5. Cabinet: 2\n6. Towel: 1\n7. Floor: 1\n8. Wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.469}, "power_stats": {"power_gpu_soc_mean_watts": 18.708, "power_cpu_cv_mean_watts": 1.92, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 70.469}, "timestamp": "2026-01-28T11:00:00.846392"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4587.784, "latencies_ms": [4587.784], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The shower is located to the left of the sink, and the bathtub is situated behind the shower curtain. The sink is positioned in the foreground, with the mirror above it reflecting the bathroom's interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.605}, "power_stats": {"power_gpu_soc_mean_watts": 20.206, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 72.605}, "timestamp": "2026-01-28T11:00:07.480776"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3149.567, "latencies_ms": [3149.567], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a shower, bathtub, and sink is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12542.6, "ram_available_mb": 50298.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.962}, "power_stats": {"power_gpu_soc_mean_watts": 22.858, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 79.962}, "timestamp": "2026-01-28T11:00:12.670730"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4102.39, "latencies_ms": [4102.39], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The bathroom has a warm color scheme with beige walls and a red rug on the floor. The lighting is bright and natural, coming from the ceiling lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.6, "ram_available_mb": 50298.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.941}, "power_stats": {"power_gpu_soc_mean_watts": 20.954, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 74.941}, "timestamp": "2026-01-28T11:00:18.815186"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4206.649, "latencies_ms": [4206.649], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A black and white photo captures a surfer riding a wave, with the water splashing around them and the logo \"STB\" in the top right corner.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.714}, "power_stats": {"power_gpu_soc_mean_watts": 20.858, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 75.714}, "timestamp": "2026-01-28T11:00:25.091499"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6705.286, "latencies_ms": [6705.286], "images_per_second": 0.149, "prompt_tokens": 1113, "response_tokens_est": 72, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Ocean: 1\n5. Surfboard leash: 1\n6. Water droplets: 1\n7. Surfer's hair: 1\n8. Surfer's wetsuit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12543.0, "ram_available_mb": 50297.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.368, "power_cpu_cv_mean_watts": 2.255, "power_sys_5v0_mean_watts": 7.64, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-28T11:00:33.838041"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5577.065, "latencies_ms": [5577.065], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The surfer is in the middle of the wave, with the crest of the wave to the right of the surfer. The background is the ocean, which fills the entire image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12543.0, "ram_available_mb": 50297.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.849, "power_cpu_cv_mean_watts": 2.096, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-28T11:00:41.456117"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3311.099, "latencies_ms": [3311.099], "images_per_second": 0.302, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, performing a trick on his surfboard.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.648, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-28T11:00:46.788353"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5429.307, "latencies_ms": [5429.307], "images_per_second": 0.184, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image is in black and white, with the surfer and the wave being the main subjects. The surfer is wearing a wetsuit, and the wave is crashing around him. The lighting is natural, and the water appears to be a deep blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12543.1, "ram_available_mb": 50297.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.761}, "power_stats": {"power_gpu_soc_mean_watts": 19.056, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 72.761}, "timestamp": "2026-01-28T11:00:54.245178"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3744.355, "latencies_ms": [3744.355], "images_per_second": 0.267, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A baseball player in a white uniform with the number 10 on it is standing at home plate with a bat in his hand.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12543.1, "ram_available_mb": 50297.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12543.0, "ram_available_mb": 50297.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.839}, "power_stats": {"power_gpu_soc_mean_watts": 21.819, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 75.839}, "timestamp": "2026-01-28T11:01:00.017065"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5896.613, "latencies_ms": [5896.613], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. baseball: 1\n6. baseball bat: 1\n7. baseball glove: 1\n8. baseball field: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12543.0, "ram_available_mb": 50297.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.551}, "power_stats": {"power_gpu_soc_mean_watts": 18.587, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 69.551}, "timestamp": "2026-01-28T11:01:07.949261"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4315.042, "latencies_ms": [4315.042], "images_per_second": 0.232, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.636, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 74.278}, "timestamp": "2026-01-28T11:01:14.285883"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3420.041, "latencies_ms": [3420.041], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A baseball game is being played in a stadium with a batter, catcher, and umpire.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12541.7, "ram_available_mb": 50299.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.527, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 78.286}, "timestamp": "2026-01-28T11:01:19.727563"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 9925.352, "latencies_ms": [9925.352], "images_per_second": 0.101, "prompt_tokens": 1109, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the batter, catcher, and umpire all dressed in their respective uniforms. The batter is poised in the batter's box, ready to swing at the incoming pitch, while the catcher is crouched behind him, ready to catch the ball if the batter misses. The umpire stands behind the catcher, overseeing the play. The colors in the image are predominantly green from the grass of the field, with the players' uniforms adding splashes of red, white, and black. The lighting is natural, suggesting it's daytime, and the weather appears to", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12541.7, "ram_available_mb": 50299.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12541.8, "ram_available_mb": 50299.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.405}, "power_stats": {"power_gpu_soc_mean_watts": 16.305, "power_cpu_cv_mean_watts": 2.198, "power_sys_5v0_mean_watts": 7.672, "gpu_utilization_percent_mean": 68.405}, "timestamp": "2026-01-28T11:01:31.703861"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3862.295, "latencies_ms": [3862.295], "images_per_second": 0.259, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12541.8, "ram_available_mb": 50299.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12540.7, "ram_available_mb": 50300.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.906}, "power_stats": {"power_gpu_soc_mean_watts": 23.906, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.113, "gpu_utilization_percent_mean": 81.906}, "timestamp": "2026-01-28T11:01:37.633492"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4990.34, "latencies_ms": [4990.34], "images_per_second": 0.2, "prompt_tokens": 1446, "response_tokens_est": 34, "n_tiles": 1, "output_text": " apple: 1, grapes: 1, pear: 1, orange: 1, grapes: 2, peanuts: 1, grapes: 2", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12540.7, "ram_available_mb": 50300.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12540.5, "ram_available_mb": 50300.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.595}, "power_stats": {"power_gpu_soc_mean_watts": 22.439, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 75.595}, "timestamp": "2026-01-28T11:01:44.665448"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7506.431, "latencies_ms": [7506.431], "images_per_second": 0.133, "prompt_tokens": 1450, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The main objects are arranged in a diagonal line from the top left to the bottom right, with the largest object, a large fruit, positioned at the top center and the smallest, a small fruit, at the bottom right. The objects are placed on a flat surface, with the grapes and the small fruit positioned in the foreground, while the larger fruits are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.5, "ram_available_mb": 50300.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.286}, "power_stats": {"power_gpu_soc_mean_watts": 19.302, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.906, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-28T11:01:54.186297"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6070.808, "latencies_ms": [6070.808], "images_per_second": 0.165, "prompt_tokens": 1444, "response_tokens_est": 54, "n_tiles": 1, "output_text": " In this black and white photo, we see a collection of fruits and nuts arranged on a white surface. The fruits include a large orange, a bunch of grapes, and a few apples. The nuts are scattered around the fruits, adding a contrast to the white background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12540.4, "ram_available_mb": 50300.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12540.6, "ram_available_mb": 50300.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.961}, "power_stats": {"power_gpu_soc_mean_watts": 21.213, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 75.961}, "timestamp": "2026-01-28T11:02:02.289786"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4242.747, "latencies_ms": [4242.747], "images_per_second": 0.236, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is a black and white photograph with a high contrast, and the fruits are placed on a white surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.6, "ram_available_mb": 50300.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12540.6, "ram_available_mb": 50300.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.943}, "power_stats": {"power_gpu_soc_mean_watts": 23.745, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 81.943}, "timestamp": "2026-01-28T11:02:08.580933"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8771.244, "latencies_ms": [8771.244], "images_per_second": 0.114, "prompt_tokens": 1099, "response_tokens_est": 110, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where a variety of vehicles, including cars and a bus, are in motion, while pedestrians navigate the sidewalks. The buildings lining the street are a mix of modern and older architectural styles, with some featuring balconies and others boasting large windows. The street itself is marked by clear lane markings and a bike lane, indicating a well-organized traffic system. The sky overhead is a clear blue, suggesting a pleasant day, and the presence of greenery along the sidewalk adds a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12540.6, "ram_available_mb": 50300.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12540.8, "ram_available_mb": 50300.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.707}, "power_stats": {"power_gpu_soc_mean_watts": 16.63, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.688, "gpu_utilization_percent_mean": 68.707}, "timestamp": "2026-01-28T11:02:19.414218"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5600.233, "latencies_ms": [5600.233], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. street: 2\n2. car: 2\n3. building: 4\n4. streetlight: 2\n5. sidewalk: 1\n6. tree: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.8, "ram_available_mb": 50300.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12541.1, "ram_available_mb": 50299.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.84, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 71.511}, "timestamp": "2026-01-28T11:02:27.031737"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6154.635, "latencies_ms": [6154.635], "images_per_second": 0.162, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The main objects in the image are positioned in a way that the street is in the foreground, with the buildings and trees in the background. The street is on the left side of the image, while the buildings and trees are on the right side. The vehicles are parked on the street, and the trees are located near the sidewalk.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12541.1, "ram_available_mb": 50299.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.712}, "power_stats": {"power_gpu_soc_mean_watts": 18.324, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 70.712}, "timestamp": "2026-01-28T11:02:35.228442"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6152.246, "latencies_ms": [6152.246], "images_per_second": 0.163, "prompt_tokens": 1111, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where modern buildings of varying heights line the street, their facades painted in a palette of white, red, and gray. Cars are seen parked along the side of the road, while pedestrians can be seen walking on the sidewalk, adding a dynamic element to the otherwise static cityscape.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.176}, "power_stats": {"power_gpu_soc_mean_watts": 18.296, "power_cpu_cv_mean_watts": 2.104, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 70.176}, "timestamp": "2026-01-28T11:02:43.405398"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3649.509, "latencies_ms": [3649.509], "images_per_second": 0.274, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image features a street with a clear blue sky and white clouds, and the buildings are made of brick and concrete.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.813, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-28T11:02:49.067712"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4576.431, "latencies_ms": [4576.431], "images_per_second": 0.219, "prompt_tokens": 1100, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In the image, there are two people standing close to each other, with one person wearing a blue shirt and the other wearing a white top. They are both smiling and appear to be enjoying themselves.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12540.3, "ram_available_mb": 50300.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.121, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 72.658}, "timestamp": "2026-01-28T11:02:55.682021"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5710.821, "latencies_ms": [5710.821], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. wall: 1\n3. television: 1\n4. chair: 1\n5. table: 1\n6. wall decoration: 1\n7. picture: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.234}, "power_stats": {"power_gpu_soc_mean_watts": 18.852, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 70.234}, "timestamp": "2026-01-28T11:03:03.409445"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4908.485, "latencies_ms": [4908.485], "images_per_second": 0.204, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is standing to the left of the woman, with his arm around her shoulder. The woman is standing in front of the man, with her arm around his waist. The man is closer to the camera than the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.854}, "power_stats": {"power_gpu_soc_mean_watts": 19.917, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 71.854}, "timestamp": "2026-01-28T11:03:10.346499"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3190.362, "latencies_ms": [3190.362], "images_per_second": 0.313, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man and a woman are standing close together in a bar, smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.6, "ram_available_mb": 50301.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.154}, "power_stats": {"power_gpu_soc_mean_watts": 22.75, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 80.154}, "timestamp": "2026-01-28T11:03:15.557860"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4916.986, "latencies_ms": [4916.986], "images_per_second": 0.203, "prompt_tokens": 1110, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image is taken in a dimly lit bar with a warm ambiance. The walls are adorned with various pictures and posters, adding to the cozy atmosphere. The lighting is soft and ambient, creating a relaxed and inviting environment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12539.4, "ram_available_mb": 50301.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.268}, "power_stats": {"power_gpu_soc_mean_watts": 19.724, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 72.268}, "timestamp": "2026-01-28T11:03:22.517692"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4333.117, "latencies_ms": [4333.117], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a woman is seen wearing a costume that includes a crown and a black and gold outfit, while a man with glasses and a beard is standing next to her.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.943, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 74.971}, "timestamp": "2026-01-28T11:03:28.905304"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5696.861, "latencies_ms": [5696.861], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. crown: 1\n3. phone: 1\n4. hat: 1\n5. shirt: 1\n6. necklace: 1\n7. earring: 1\n8. wristband: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.8, "ram_available_mb": 50301.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.936}, "power_stats": {"power_gpu_soc_mean_watts": 18.902, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.936}, "timestamp": "2026-01-28T11:03:36.616354"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4975.633, "latencies_ms": [4975.633], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a crown and a black and gold costume. The man is in the background, wearing a black and white hat. The crowd is in the background, and the buildings are in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12539.9, "ram_available_mb": 50301.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.048}, "power_stats": {"power_gpu_soc_mean_watts": 19.455, "power_cpu_cv_mean_watts": 1.983, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 71.048}, "timestamp": "2026-01-28T11:03:43.647050"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3281.099, "latencies_ms": [3281.099], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are gathered in a public place, with one person dressed in a costume.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.852}, "power_stats": {"power_gpu_soc_mean_watts": 22.755, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 79.852}, "timestamp": "2026-01-28T11:03:48.970852"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3951.478, "latencies_ms": [3951.478], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the woman is wearing a costume with a golden headpiece and black and gold armor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12539.1, "ram_available_mb": 50301.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.212}, "power_stats": {"power_gpu_soc_mean_watts": 21.191, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 77.212}, "timestamp": "2026-01-28T11:03:54.937410"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4426.61, "latencies_ms": [4426.61], "images_per_second": 0.226, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a small, white bathroom with a white toilet, a white sink, and a white bathtub, all set against a backdrop of white tiled walls and a white floor.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12539.1, "ram_available_mb": 50301.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.514}, "power_stats": {"power_gpu_soc_mean_watts": 20.468, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 73.514}, "timestamp": "2026-01-28T11:04:01.392618"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4578.617, "latencies_ms": [4578.617], "images_per_second": 0.218, "prompt_tokens": 1114, "response_tokens_est": 39, "n_tiles": 1, "output_text": " sink: 1, toilet: 1, window: 1, pipe: 1, bucket: 2, floor: 1, wall: 1, drain: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.053}, "power_stats": {"power_gpu_soc_mean_watts": 20.321, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 72.053}, "timestamp": "2026-01-28T11:04:07.994525"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5489.191, "latencies_ms": [5489.191], "images_per_second": 0.182, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The green bucket is located in the foreground, near the red bucket, which is positioned closer to the camera than the green bucket. The white pipe is situated in the background, behind the toilet, while the white wall is located in the foreground, in front of the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.478}, "power_stats": {"power_gpu_soc_mean_watts": 19.279, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 69.478}, "timestamp": "2026-01-28T11:04:15.537844"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4056.591, "latencies_ms": [4056.591], "images_per_second": 0.247, "prompt_tokens": 1112, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a small, cramped bathroom with white tiled walls and floors. The bathroom features a small window, a toilet, and a sink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.499, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-28T11:04:21.638691"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3733.015, "latencies_ms": [3733.015], "images_per_second": 0.268, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The bathroom is painted white with a blue and white tile floor. The lighting is dim and the walls are covered in white tiles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.419}, "power_stats": {"power_gpu_soc_mean_watts": 21.616, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 76.419}, "timestamp": "2026-01-28T11:04:27.394245"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3700.359, "latencies_ms": [3700.359], "images_per_second": 0.27, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In the image, a man is standing next to an elephant, both of them are smiling and enjoying each other's company.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12540.0, "ram_available_mb": 50300.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.084, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 76.1}, "timestamp": "2026-01-28T11:04:33.139966"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4620.003, "latencies_ms": [4620.003], "images_per_second": 0.216, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " elephant: 1, man: 1, glasses: 1, shirt: 1, elephant's trunk: 1, elephant's ear: 1, elephant's eye: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.0, "ram_available_mb": 50300.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.895}, "power_stats": {"power_gpu_soc_mean_watts": 20.333, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 74.895}, "timestamp": "2026-01-28T11:04:39.780412"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5202.23, "latencies_ms": [5202.23], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The man is standing to the left of the elephant, with the elephant's trunk reaching towards his head. The man is in the foreground of the image, while the elephant is in the background. The man is closer to the camera than the elephant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12539.3, "ram_available_mb": 50301.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.558}, "power_stats": {"power_gpu_soc_mean_watts": 19.35, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 7.692, "gpu_utilization_percent_mean": 72.558}, "timestamp": "2026-01-28T11:04:47.003158"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3442.413, "latencies_ms": [3442.413], "images_per_second": 0.29, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man wearing glasses and a beige shirt is standing next to a large elephant in a lush green forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.587, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 7.837, "gpu_utilization_percent_mean": 79.679}, "timestamp": "2026-01-28T11:04:52.479277"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6808.828, "latencies_ms": [6808.828], "images_per_second": 0.147, "prompt_tokens": 1109, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The image features a man wearing glasses and a beige shirt standing next to a large gray elephant. The elephant's skin is wrinkled and rough, and the man's hand is gently touching the elephant's ear. The background is a lush green forest with trees and hills visible in the distance. The lighting is bright and natural, suggesting that the photo was taken during the day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.825}, "power_stats": {"power_gpu_soc_mean_watts": 17.722, "power_cpu_cv_mean_watts": 2.136, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 70.825}, "timestamp": "2026-01-28T11:05:01.303708"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3353.471, "latencies_ms": [3353.471], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " In the image, there are several children sitting on the grass, each holding a frisbee.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12538.7, "ram_available_mb": 50302.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.358, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 80.25}, "timestamp": "2026-01-28T11:05:06.710271"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3580.825, "latencies_ms": [3580.825], "images_per_second": 0.279, "prompt_tokens": 1113, "response_tokens_est": 23, "n_tiles": 1, "output_text": " 1. grass: 4\n2. children: 5\n3. frisbee: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12538.9, "ram_available_mb": 50302.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.909, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 78.367}, "timestamp": "2026-01-28T11:05:12.326886"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7072.283, "latencies_ms": [7072.283], "images_per_second": 0.141, "prompt_tokens": 1117, "response_tokens_est": 81, "n_tiles": 1, "output_text": " The frisbee is held by the child on the right, while the child on the left is holding a frisbee with a black and white design. The frisbee with the black and white design is in the foreground, while the frisbee with the red and white design is in the background. The child on the left is sitting closer to the camera than the child on the right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12538.4, "ram_available_mb": 50302.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.117}, "power_stats": {"power_gpu_soc_mean_watts": 17.555, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 7.683, "gpu_utilization_percent_mean": 71.117}, "timestamp": "2026-01-28T11:05:21.445774"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3075.876, "latencies_ms": [3075.876], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A group of children are sitting on the grass playing with frisbees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.2}, "power_stats": {"power_gpu_soc_mean_watts": 23.212, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 83.2}, "timestamp": "2026-01-28T11:05:26.550088"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4061.163, "latencies_ms": [4061.163], "images_per_second": 0.246, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in a bright, sunny day with green grass and trees in the background. The children are wearing colorful clothes and holding frisbees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.9, "ram_available_mb": 50303.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.559}, "power_stats": {"power_gpu_soc_mean_watts": 20.885, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 73.559}, "timestamp": "2026-01-28T11:05:32.651531"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3865.039, "latencies_ms": [3865.039], "images_per_second": 0.259, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young girl wearing a red coat and holding a black umbrella with pink polka dots stands on a wet sidewalk in front of a bush.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12538.6, "ram_available_mb": 50302.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.313, "power_cpu_cv_mean_watts": 1.514, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 76.5}, "timestamp": "2026-01-28T11:05:38.591272"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4227.11, "latencies_ms": [4227.11], "images_per_second": 0.237, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " umbrella: 1, girl: 1, coat: 1, shoes: 1, bush: 1, house: 1, car: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.8, "ram_available_mb": 50302.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.059}, "power_stats": {"power_gpu_soc_mean_watts": 21.144, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.88, "gpu_utilization_percent_mean": 78.059}, "timestamp": "2026-01-28T11:05:44.841985"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4457.558, "latencies_ms": [4457.558], "images_per_second": 0.224, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The umbrella is held by the child, who is standing in front of the bush. The child is positioned in the foreground of the image, with the bush and the house in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12539.2, "ram_available_mb": 50301.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12538.5, "ram_available_mb": 50302.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.649}, "power_stats": {"power_gpu_soc_mean_watts": 20.557, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 74.649}, "timestamp": "2026-01-28T11:05:51.328437"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3424.118, "latencies_ms": [3424.118], "images_per_second": 0.292, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A little girl wearing a red coat and white shoes is standing on a wet sidewalk holding a black umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12538.1, "ram_available_mb": 50302.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.75}, "power_stats": {"power_gpu_soc_mean_watts": 22.17, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 77.75}, "timestamp": "2026-01-28T11:05:56.769702"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4456.147, "latencies_ms": [4456.147], "images_per_second": 0.224, "prompt_tokens": 1110, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a young girl wearing a red coat and holding a black umbrella with pink polka dots. The scene is set on a rainy day with wet pavement and a gray sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12538.2, "ram_available_mb": 50302.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.284, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 74.676}, "timestamp": "2026-01-28T11:06:03.286118"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4205.11, "latencies_ms": [4205.11], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a young elephant is walking towards the camera, while a group of elephants is walking away from the camera, with one elephant in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12538.0, "ram_available_mb": 50302.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.294}, "power_stats": {"power_gpu_soc_mean_watts": 20.946, "power_cpu_cv_mean_watts": 1.59, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 73.294}, "timestamp": "2026-01-28T11:06:09.521122"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4307.783, "latencies_ms": [4307.783], "images_per_second": 0.232, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " elephant: 1, trunk: 1, ear: 1, eye: 1, leg: 1, tail: 1, trunk tip: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.5, "ram_available_mb": 50303.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.657, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-28T11:06:15.851648"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4256.952, "latencies_ms": [4256.952], "images_per_second": 0.235, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking towards the camera, with the main elephant in the center of the frame.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.827, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-28T11:06:22.134395"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5120.067, "latencies_ms": [5120.067], "images_per_second": 0.195, "prompt_tokens": 1111, "response_tokens_est": 49, "n_tiles": 1, "output_text": " In the image, a group of elephants is walking through a dry, dusty landscape. The elephants are of various sizes, with the smallest one being a baby elephant. The elephants are walking in a line, with the baby elephant in the front.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12536.5, "ram_available_mb": 50304.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.628}, "power_stats": {"power_gpu_soc_mean_watts": 19.419, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 72.628}, "timestamp": "2026-01-28T11:06:29.289181"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5090.519, "latencies_ms": [5090.519], "images_per_second": 0.196, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a group of elephants walking through a muddy area, with the elephants' skin appearing wet and their trunks hanging down. The lighting is natural, and the sky is overcast, giving the scene a soft and diffused look.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.791}, "power_stats": {"power_gpu_soc_mean_watts": 19.226, "power_cpu_cv_mean_watts": 1.779, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 73.791}, "timestamp": "2026-01-28T11:06:36.417386"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4930.801, "latencies_ms": [4930.801], "images_per_second": 0.203, "prompt_tokens": 1432, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a surfer skillfully riding a large wave, with the surfer wearing a red and green wetsuit, and the wave displaying a gradient of green and white.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.732}, "power_stats": {"power_gpu_soc_mean_watts": 22.364, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 78.732}, "timestamp": "2026-01-28T11:06:43.389732"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6396.726, "latencies_ms": [6396.726], "images_per_second": 0.156, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. wave: 1\n3. surfboard: 1\n4. water: 1\n5. sky: 0\n6. logo: 1\n7. text: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.185}, "power_stats": {"power_gpu_soc_mean_watts": 20.732, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 74.185}, "timestamp": "2026-01-28T11:06:51.838770"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5843.232, "latencies_ms": [5843.232], "images_per_second": 0.171, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The surfer is positioned on the left side of the image, with the wave dominating the right side. The surfer is in the foreground, with the wave in the background. The surfer is closer to the camera than the wave.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.102}, "power_stats": {"power_gpu_soc_mean_watts": 21.357, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 78.102}, "timestamp": "2026-01-28T11:06:59.697172"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4379.824, "latencies_ms": [4379.824], "images_per_second": 0.228, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard. The surfer is wearing a red shirt and is upside down.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.639, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 80.417}, "timestamp": "2026-01-28T11:07:06.095108"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4180.218, "latencies_ms": [4180.218], "images_per_second": 0.239, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a red and green wetsuit, and the wave is a deep green color.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12535.9, "ram_available_mb": 50305.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.6}, "power_stats": {"power_gpu_soc_mean_watts": 24.031, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 82.6}, "timestamp": "2026-01-28T11:07:12.302825"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3427.427, "latencies_ms": [3427.427], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean and a few people in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.393}, "power_stats": {"power_gpu_soc_mean_watts": 22.239, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 79.393}, "timestamp": "2026-01-28T11:07:17.753398"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6362.269, "latencies_ms": [6362.269], "images_per_second": 0.157, "prompt_tokens": 1113, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. rider's hat: 1\n4. rider's shirt: 1\n5. rider's pants: 1\n6. rider's boots: 1\n7. rider's belt: 1\n8. rider's boots: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.698}, "power_stats": {"power_gpu_soc_mean_watts": 17.955, "power_cpu_cv_mean_watts": 2.093, "power_sys_5v0_mean_watts": 7.684, "gpu_utilization_percent_mean": 70.698}, "timestamp": "2026-01-28T11:07:26.152832"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5459.582, "latencies_ms": [5459.582], "images_per_second": 0.183, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The two men are positioned on the left side of the image, with the horse on the right side. The horse is in the foreground, while the men are in the background. The beach is in the middle ground, with the ocean and sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.156}, "power_stats": {"power_gpu_soc_mean_watts": 19.125, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 71.156}, "timestamp": "2026-01-28T11:07:33.627948"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3247.134, "latencies_ms": [3247.134], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.692}, "power_stats": {"power_gpu_soc_mean_watts": 22.825, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 81.692}, "timestamp": "2026-01-28T11:07:38.887017"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4239.839, "latencies_ms": [4239.839], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features a sandy beach with a clear blue sky and ocean in the background. The two men are dressed in white and are riding horses, which are also white.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.723, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 74.486}, "timestamp": "2026-01-28T11:07:45.172076"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3382.865, "latencies_ms": [3382.865], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A motorcycle with a sidecar is parked in front of a garage, with a dog standing nearby.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.383, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 76.536}, "timestamp": "2026-01-28T11:07:50.584326"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5695.48, "latencies_ms": [5695.48], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. tire: 2\n3. wheel: 1\n4. handlebar: 1\n5. seat: 1\n6. headlight: 1\n7. garage door: 1\n8. dog: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.708}, "power_stats": {"power_gpu_soc_mean_watts": 18.713, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 71.708}, "timestamp": "2026-01-28T11:07:58.322981"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4518.047, "latencies_ms": [4518.047], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The motorcycle is positioned to the left of the garage, with the dog standing in front of it. The motorcycle is in the foreground, while the garage and the blue truck are in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.224, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 73.789}, "timestamp": "2026-01-28T11:08:04.877299"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3266.354, "latencies_ms": [3266.354], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A motorcycle is parked outside a garage with a dog standing next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.222}, "power_stats": {"power_gpu_soc_mean_watts": 21.995, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.631, "gpu_utilization_percent_mean": 75.222}, "timestamp": "2026-01-28T11:08:10.183722"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3042.224, "latencies_ms": [3042.224], "images_per_second": 0.329, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The motorcycle is red and silver, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.833}, "power_stats": {"power_gpu_soc_mean_watts": 23.394, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 80.833}, "timestamp": "2026-01-28T11:08:15.259358"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3372.791, "latencies_ms": [3372.791], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is flying a kite on a beach with a blue and black kite in the sky.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.485, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 79.259}, "timestamp": "2026-01-28T11:08:20.657745"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5516.988, "latencies_ms": [5516.988], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. kite: 2\n3. beach: 1\n4. sand: 1\n5. water: 1\n6. trees: 1\n7. buildings: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.63}, "power_stats": {"power_gpu_soc_mean_watts": 18.884, "power_cpu_cv_mean_watts": 2.037, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 72.63}, "timestamp": "2026-01-28T11:08:28.192568"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4570.364, "latencies_ms": [4570.364], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, with the beach and the lake in the background. The kite is flying in the sky, which is positioned above the man and the beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.842}, "power_stats": {"power_gpu_soc_mean_watts": 20.479, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 73.842}, "timestamp": "2026-01-28T11:08:34.795960"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3093.479, "latencies_ms": [3093.479], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is flying a kite on a beach with a lake in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.058, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 81.423}, "timestamp": "2026-01-28T11:08:39.916663"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2726.264, "latencies_ms": [2726.264], "images_per_second": 0.367, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The sky is blue and the sun is shining.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.136}, "power_stats": {"power_gpu_soc_mean_watts": 24.1, "power_cpu_cv_mean_watts": 1.219, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 82.136}, "timestamp": "2026-01-28T11:08:44.670777"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3313.32, "latencies_ms": [3313.32], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a stainless steel refrigerator, and a black countertop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.75}, "power_stats": {"power_gpu_soc_mean_watts": 22.557, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.831, "gpu_utilization_percent_mean": 76.75}, "timestamp": "2026-01-28T11:08:50.043136"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6127.257, "latencies_ms": [6127.257], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. Kitchen cabinets: 10\n2. Sink: 1\n3. Countertop: 1\n4. Refrigerator: 1\n5. Stove: 1\n6. Microwave: 1\n7. Toaster: 1\n8. Toaster oven: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.216}, "power_stats": {"power_gpu_soc_mean_watts": 18.32, "power_cpu_cv_mean_watts": 2.049, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 71.216}, "timestamp": "2026-01-28T11:08:58.210882"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4750.762, "latencies_ms": [4750.762], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The green bottle is near the sink, the blue bottle is near the stove, and the red bow is near the stove. The microwave is above the stove, and the refrigerator is to the left of the stove.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.65}, "power_stats": {"power_gpu_soc_mean_watts": 19.948, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 73.65}, "timestamp": "2026-01-28T11:09:04.976818"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2953.358, "latencies_ms": [2953.358], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A messy kitchen with a lot of stuff on the counter and cabinets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.25}, "power_stats": {"power_gpu_soc_mean_watts": 23.86, "power_cpu_cv_mean_watts": 1.218, "power_sys_5v0_mean_watts": 7.867, "gpu_utilization_percent_mean": 82.25}, "timestamp": "2026-01-28T11:09:09.955196"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3233.753, "latencies_ms": [3233.753], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.796, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 80.556}, "timestamp": "2026-01-28T11:09:15.205126"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2966.958, "latencies_ms": [2966.958], "images_per_second": 0.337, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white pattern is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.875}, "power_stats": {"power_gpu_soc_mean_watts": 23.512, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 7.88, "gpu_utilization_percent_mean": 80.875}, "timestamp": "2026-01-28T11:09:20.203705"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4504.407, "latencies_ms": [4504.407], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " kite: 1, string: 2, kite string: 1, kite tail: 1, kite frame: 1, kite fabric: 1, kite handle: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.135}, "power_stats": {"power_gpu_soc_mean_watts": 20.383, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 74.135}, "timestamp": "2026-01-28T11:09:26.727019"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4823.701, "latencies_ms": [4823.701], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the kite strings are in the background. The kite is positioned to the left of the frame, and the kite strings are extending towards the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.075}, "power_stats": {"power_gpu_soc_mean_watts": 19.865, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 74.075}, "timestamp": "2026-01-28T11:09:33.580652"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3086.254, "latencies_ms": [3086.254], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white pattern is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.32}, "power_stats": {"power_gpu_soc_mean_watts": 23.002, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 82.32}, "timestamp": "2026-01-28T11:09:38.698762"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3261.765, "latencies_ms": [3261.765], "images_per_second": 0.307, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kite is white with red and black patterns and is flying in a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.77, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 77.519}, "timestamp": "2026-01-28T11:09:43.980114"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5038.577, "latencies_ms": [5038.577], "images_per_second": 0.198, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a spacious bedroom with two queen-sized beds, each adorned with white linens and a dark-colored bedspread, positioned side by side, with a window in the background allowing natural light to filter into the room.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.095}, "power_stats": {"power_gpu_soc_mean_watts": 19.356, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 72.095}, "timestamp": "2026-01-28T11:09:51.041390"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5582.034, "latencies_ms": [5582.034], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 55, "n_tiles": 1, "output_text": " 1. beds: 2\n2. pillows: 12\n3. lamps: 2\n4. paintings: 2\n5. window: 1\n6. door: 1\n7. floor: wooden\n8. ceiling: white", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.891}, "power_stats": {"power_gpu_soc_mean_watts": 18.824, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 7.69, "gpu_utilization_percent_mean": 71.891}, "timestamp": "2026-01-28T11:09:58.643883"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4547.603, "latencies_ms": [4547.603], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The beds are positioned on the left side of the room, with the window and door located on the right side. The beds are in the foreground, with the window and door in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.211}, "power_stats": {"power_gpu_soc_mean_watts": 20.207, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 75.211}, "timestamp": "2026-01-28T11:10:05.225020"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3141.199, "latencies_ms": [3141.199], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The room is a bedroom with two beds, a window, and a door.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.92}, "power_stats": {"power_gpu_soc_mean_watts": 23.357, "power_cpu_cv_mean_watts": 1.954, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 80.92}, "timestamp": "2026-01-28T11:10:10.398615"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4660.195, "latencies_ms": [4660.195], "images_per_second": 0.215, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The room is bathed in soft light from the large windows, and the walls are painted a soothing light green. The beds are made with crisp white linens and are adorned with dark brown and black pillows.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.103}, "power_stats": {"power_gpu_soc_mean_watts": 20.107, "power_cpu_cv_mean_watts": 2.721, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 74.103}, "timestamp": "2026-01-28T11:10:17.106436"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4066.923, "latencies_ms": [4066.923], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle down a road with a crowd of people watching from behind a fence.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12535.8, "ram_available_mb": 50305.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.794}, "power_stats": {"power_gpu_soc_mean_watts": 21.062, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 73.794}, "timestamp": "2026-01-28T11:10:23.243616"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4259.795, "latencies_ms": [4259.795], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. rider: 1\n3. helmet: 1\n4. fence: 1\n5. people: 8", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.746, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 76.278}, "timestamp": "2026-01-28T11:10:29.551926"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4788.418, "latencies_ms": [4788.418], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider leaning into a turn. The spectators are located in the background, behind a fence, and appear to be watching the motorcycle from a distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.875}, "power_stats": {"power_gpu_soc_mean_watts": 19.944, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 74.875}, "timestamp": "2026-01-28T11:10:36.357569"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3126.071, "latencies_ms": [3126.071], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is riding a motorcycle down a road with a crowd of people watching.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.043, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 78.423}, "timestamp": "2026-01-28T11:10:41.507653"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3702.545, "latencies_ms": [3702.545], "images_per_second": 0.27, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The motorcycle is white and green, and the rider is wearing a white helmet. The sky is cloudy and the road is wet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.903}, "power_stats": {"power_gpu_soc_mean_watts": 21.961, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 75.903}, "timestamp": "2026-01-28T11:10:47.237075"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3452.702, "latencies_ms": [3452.702], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A table set with white tablecloths and glasses is adorned with a centerpiece of white flowers and candles.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.248, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 79.103}, "timestamp": "2026-01-28T11:10:52.730850"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4821.695, "latencies_ms": [4821.695], "images_per_second": 0.207, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " tablecloth: 1\nglass: 4\nflowers: 1\nstem: 1\nstems: 2\nstems: 2\nstems: 2\nstems: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.735, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 73.4}, "timestamp": "2026-01-28T11:10:59.581453"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5369.473, "latencies_ms": [5369.473], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The vase is placed in the center of the table, with the glasses arranged around it. The glasses are positioned on either side of the vase, creating a symmetrical arrangement. The table is set against a dark background, which helps to draw attention to the centerpiece.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.822}, "power_stats": {"power_gpu_soc_mean_watts": 19.203, "power_cpu_cv_mean_watts": 1.841, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 70.822}, "timestamp": "2026-01-28T11:11:06.968031"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6079.635, "latencies_ms": [6079.635], "images_per_second": 0.164, "prompt_tokens": 1111, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a serene dining setting, where a table draped in pristine white tablecloth is elegantly set for a meal. The table is adorned with a centerpiece of white flowers, which are nestled in a clear glass vase, and surrounded by four empty wine glasses, their stems gleaming under the soft light.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.235}, "power_stats": {"power_gpu_soc_mean_watts": 18.311, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 70.235}, "timestamp": "2026-01-28T11:11:15.095476"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4408.222, "latencies_ms": [4408.222], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The table is set with white tablecloths and napkins, and the flowers are white and green. The lighting is soft and ambient, and the table is set in a dark room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.405}, "power_stats": {"power_gpu_soc_mean_watts": 20.525, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 74.405}, "timestamp": "2026-01-28T11:11:21.518547"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3956.166, "latencies_ms": [3956.166], "images_per_second": 0.253, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.005, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 82.25}, "timestamp": "2026-01-28T11:11:27.501123"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6196.219, "latencies_ms": [6196.219], "images_per_second": 0.161, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. clock: 2\n2. pole: 1\n3. sky: 1\n4. clouds: 1\n5. grass: 1\n6. person: 1\n7. bird: 1\n8. smoke: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.986, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 74.057}, "timestamp": "2026-01-28T11:11:35.725487"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4914.494, "latencies_ms": [4914.494], "images_per_second": 0.203, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The clock is positioned in the foreground, with the sky in the background. The clock is located to the left of the image, while the sky fills the entire background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.341}, "power_stats": {"power_gpu_soc_mean_watts": 22.898, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 78.341}, "timestamp": "2026-01-28T11:11:42.666486"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3986.862, "latencies_ms": [3986.862], "images_per_second": 0.251, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.364}, "power_stats": {"power_gpu_soc_mean_watts": 24.429, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 83.364}, "timestamp": "2026-01-28T11:11:48.693592"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3681.892, "latencies_ms": [3681.892], "images_per_second": 0.272, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The clock is black and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.935}, "power_stats": {"power_gpu_soc_mean_watts": 24.919, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.136, "gpu_utilization_percent_mean": 84.935}, "timestamp": "2026-01-28T11:11:54.417849"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3574.697, "latencies_ms": [3574.697], "images_per_second": 0.28, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A young man wearing a black cap and a black shirt is riding a skateboard on a paved surface in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.041, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 77.5}, "timestamp": "2026-01-28T11:12:00.039003"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6114.366, "latencies_ms": [6114.366], "images_per_second": 0.164, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. black t-shirt: 1\n4. black pants: 1\n5. blue cap: 1\n6. gray shoes: 1\n7. red and white logo: 1\n8. tree: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.196}, "power_stats": {"power_gpu_soc_mean_watts": 18.391, "power_cpu_cv_mean_watts": 2.057, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 72.196}, "timestamp": "2026-01-28T11:12:08.187345"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4420.433, "latencies_ms": [4420.433], "images_per_second": 0.226, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on the pavement. The skateboarder is in the middle of the image, with the background featuring trees and a building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.944}, "power_stats": {"power_gpu_soc_mean_watts": 20.513, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 73.944}, "timestamp": "2026-01-28T11:12:14.635414"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3051.02, "latencies_ms": [3051.02], "images_per_second": 0.328, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young man is skateboarding on a paved area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.05, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 7.843, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-28T11:12:19.726789"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4983.681, "latencies_ms": [4983.681], "images_per_second": 0.201, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a young man wearing a black t-shirt and a blue cap, performing a trick on a skateboard in an outdoor setting. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.643, "power_cpu_cv_mean_watts": 2.041, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 70.976}, "timestamp": "2026-01-28T11:12:26.753305"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3975.989, "latencies_ms": [3975.989], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white plate filled with orange carrots and green beans is placed on a kitchen counter, with a blue peeler and a bunch of red onions nearby.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.364}, "power_stats": {"power_gpu_soc_mean_watts": 21.224, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 77.364}, "timestamp": "2026-01-28T11:12:32.775352"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4425.833, "latencies_ms": [4425.833], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " carrot: 10, plate: 1, scissors: 1, knife: 1, bottle: 1, bean: 1, carrot peeler: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.108}, "power_stats": {"power_gpu_soc_mean_watts": 20.512, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 75.108}, "timestamp": "2026-01-28T11:12:39.249967"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4740.224, "latencies_ms": [4740.224], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The plate of carrots is located in the foreground, with the peeler and beetroots placed nearby. The peeler is positioned to the right of the plate, while the beetroots are situated to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.667}, "power_stats": {"power_gpu_soc_mean_watts": 19.966, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 72.667}, "timestamp": "2026-01-28T11:12:46.008160"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3556.749, "latencies_ms": [3556.749], "images_per_second": 0.281, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " In a kitchen, a white plate is filled with fresh carrots and beets, while a blue peeler lies nearby.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.304, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 78.103}, "timestamp": "2026-01-28T11:12:51.592420"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3434.867, "latencies_ms": [3434.867], "images_per_second": 0.291, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image is taken in a kitchen with natural lighting, and the carrots are fresh and vibrant in color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12534.1, "ram_available_mb": 50306.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.862}, "power_stats": {"power_gpu_soc_mean_watts": 22.319, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 78.862}, "timestamp": "2026-01-28T11:12:57.052458"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3257.059, "latencies_ms": [3257.059], "images_per_second": 0.307, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man in a suit is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12534.1, "ram_available_mb": 50306.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12534.1, "ram_available_mb": 50306.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.859, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 79.815}, "timestamp": "2026-01-28T11:13:02.337868"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5510.399, "latencies_ms": [5510.399], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 2\n3. head: 2\n4. hair: 2\n5. glasses: 1\n6. tie: 1\n7. suit: 1\n8. shirt: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12534.1, "ram_available_mb": 50306.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.413}, "power_stats": {"power_gpu_soc_mean_watts": 19.138, "power_cpu_cv_mean_watts": 1.967, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 72.413}, "timestamp": "2026-01-28T11:13:09.877495"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4682.099, "latencies_ms": [4682.099], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is in the foreground, and the audience is in the background. The man is standing in front of a large screen, which is in the foreground. The audience is watching the man on the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.3}, "power_stats": {"power_gpu_soc_mean_watts": 20.115, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 75.3}, "timestamp": "2026-01-28T11:13:16.595189"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3092.545, "latencies_ms": [3092.545], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12532.4, "ram_available_mb": 50308.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.31, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 80.28}, "timestamp": "2026-01-28T11:13:21.708560"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4912.403, "latencies_ms": [4912.403], "images_per_second": 0.204, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image is of a man giving a presentation on a large screen. The colors are vibrant, with the man wearing a suit and tie. The lighting is bright and focused on the man, while the audience is in shadow.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12532.4, "ram_available_mb": 50308.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12532.1, "ram_available_mb": 50308.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.146}, "power_stats": {"power_gpu_soc_mean_watts": 19.807, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 74.146}, "timestamp": "2026-01-28T11:13:28.682900"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7375.06, "latencies_ms": [7375.06], "images_per_second": 0.136, "prompt_tokens": 1099, "response_tokens_est": 87, "n_tiles": 1, "output_text": " In the image, two workers clad in blue uniforms and hard hats are diligently engaged in the task of laying down a street curb. The worker on the left, equipped with a tool, is actively participating in the process, while his counterpart on the right, holding a clipboard, appears to be overseeing the task. The backdrop of the scene is a bustling street lined with parked motorcycles, adding a dynamic element to the otherwise static scene.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12532.1, "ram_available_mb": 50308.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.339}, "power_stats": {"power_gpu_soc_mean_watts": 17.348, "power_cpu_cv_mean_watts": 2.17, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 70.339}, "timestamp": "2026-01-28T11:13:38.098725"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6016.546, "latencies_ms": [6016.546], "images_per_second": 0.166, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Scooter: 2\n2. Motorcycle: 1\n3. Banners: 2\n4. Signboards: 2\n5. People: 2\n6. Posters: 1\n7. Banners: 1\n8. Banners: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.353}, "power_stats": {"power_gpu_soc_mean_watts": 18.384, "power_cpu_cv_mean_watts": 2.152, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 71.353}, "timestamp": "2026-01-28T11:13:46.159683"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4318.399, "latencies_ms": [4318.399], "images_per_second": 0.232, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The two workers are standing on the sidewalk, with the motorcycles parked on the street behind them. The workers are positioned in the foreground, while the motorcycles are in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.625, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-28T11:13:52.505224"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3285.017, "latencies_ms": [3285.017], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two construction workers are standing on a street corner, one of them is holding a metal rod.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.768, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 77.815}, "timestamp": "2026-01-28T11:13:57.814886"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4274.075, "latencies_ms": [4274.075], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a rainy day with a gray sky and wet pavement. The two workers are wearing blue uniforms and hard hats, and they are standing on a street corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12531.9, "ram_available_mb": 50309.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.678, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 73.629}, "timestamp": "2026-01-28T11:14:04.115362"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4400.684, "latencies_ms": [4400.684], "images_per_second": 0.227, "prompt_tokens": 1432, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A black plastic container filled with a green and yellow mixture of vegetables and chicken is placed on a white paper plate, accompanied by a fork.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12531.9, "ram_available_mb": 50309.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.564, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 8.138, "gpu_utilization_percent_mean": 83.0}, "timestamp": "2026-01-28T11:14:10.552353"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6721.756, "latencies_ms": [6721.756], "images_per_second": 0.149, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. black bowl: 1\n2. white plate: 1\n3. fork: 1\n4. shredded chicken: 1\n5. broccoli: 1\n6. mashed potatoes: 1\n7. green sauce: 1\n8. beige carpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.0, "ram_available_mb": 50308.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12531.7, "ram_available_mb": 50309.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.305, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.963, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-28T11:14:19.312567"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5200.06, "latencies_ms": [5200.06], "images_per_second": 0.192, "prompt_tokens": 1450, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The black bowl of food is on the left side of the plate, and the fork is on the right side. The plate is in the foreground, and the carpet is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12531.7, "ram_available_mb": 50309.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12531.7, "ram_available_mb": 50309.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.86}, "power_stats": {"power_gpu_soc_mean_watts": 22.258, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 78.86}, "timestamp": "2026-01-28T11:14:26.525880"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3908.079, "latencies_ms": [3908.079], "images_per_second": 0.256, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black plastic container with food is on a white plate with a fork on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12531.7, "ram_available_mb": 50309.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.182}, "power_stats": {"power_gpu_soc_mean_watts": 24.417, "power_cpu_cv_mean_watts": 1.225, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 84.182}, "timestamp": "2026-01-28T11:14:32.480903"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4584.579, "latencies_ms": [4584.579], "images_per_second": 0.218, "prompt_tokens": 1442, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a room with a carpeted floor and a white plate on it. The lighting is natural and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.895}, "power_stats": {"power_gpu_soc_mean_watts": 23.438, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 80.895}, "timestamp": "2026-01-28T11:14:39.105947"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3560.277, "latencies_ms": [3560.277], "images_per_second": 0.281, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man wearing a blue shirt, red tie, and a plaid hat stands in front of a building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12532.5, "ram_available_mb": 50308.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.862}, "power_stats": {"power_gpu_soc_mean_watts": 22.01, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 78.862}, "timestamp": "2026-01-28T11:14:44.717915"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5516.909, "latencies_ms": [5516.909], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. glasses: 1\n3. tie: 1\n4. shirt: 1\n5. cap: 1\n6. building: 1\n7. window: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12532.5, "ram_available_mb": 50308.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12533.0, "ram_available_mb": 50307.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.553}, "power_stats": {"power_gpu_soc_mean_watts": 18.894, "power_cpu_cv_mean_watts": 2.045, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.553}, "timestamp": "2026-01-28T11:14:52.263118"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4861.644, "latencies_ms": [4861.644], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the background consisting of a building and a pool. The man is wearing a blue shirt and a red tie, and he is also wearing a plaid hat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.0, "ram_available_mb": 50307.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.35}, "power_stats": {"power_gpu_soc_mean_watts": 19.796, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 71.35}, "timestamp": "2026-01-28T11:14:59.144755"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3249.186, "latencies_ms": [3249.186], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a blue shirt and a red tie stands in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.231}, "power_stats": {"power_gpu_soc_mean_watts": 22.886, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 77.231}, "timestamp": "2026-01-28T11:15:04.408576"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4688.453, "latencies_ms": [4688.453], "images_per_second": 0.213, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and a red tie, and he is standing in front of a building with a green roof. The lighting is bright and sunny, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.872}, "power_stats": {"power_gpu_soc_mean_watts": 20.012, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 73.872}, "timestamp": "2026-01-28T11:15:11.135660"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4322.461, "latencies_ms": [4322.461], "images_per_second": 0.231, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza, each with a different topping, on a white plate.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.306}, "power_stats": {"power_gpu_soc_mean_watts": 23.238, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 78.306}, "timestamp": "2026-01-28T11:15:17.492468"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3063.87, "latencies_ms": [3063.87], "images_per_second": 0.326, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pizza: 6", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12533.5, "ram_available_mb": 50307.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 89.92}, "power_stats": {"power_gpu_soc_mean_watts": 26.669, "power_cpu_cv_mean_watts": 1.057, "power_sys_5v0_mean_watts": 8.289, "gpu_utilization_percent_mean": 89.92}, "timestamp": "2026-01-28T11:15:22.607153"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6105.387, "latencies_ms": [6105.387], "images_per_second": 0.164, "prompt_tokens": 1450, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The main objects are arranged in a grid pattern, with the largest pizza slice in the top left and the smallest slice in the bottom right. The slices are positioned at varying distances from the camera, with the largest slice closest to the lens and the smallest slice farthest away.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12534.4, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.216}, "power_stats": {"power_gpu_soc_mean_watts": 21.247, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 76.216}, "timestamp": "2026-01-28T11:15:30.728328"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3697.327, "latencies_ms": [3697.327], "images_per_second": 0.27, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12534.4, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.097}, "power_stats": {"power_gpu_soc_mean_watts": 24.801, "power_cpu_cv_mean_watts": 1.136, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 83.097}, "timestamp": "2026-01-28T11:15:36.484310"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4439.506, "latencies_ms": [4439.506], "images_per_second": 0.225, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The pizza has a golden brown crust and is topped with melted cheese and various ingredients. The lighting is warm and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.757}, "power_stats": {"power_gpu_soc_mean_watts": 23.647, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 8.159, "gpu_utilization_percent_mean": 81.757}, "timestamp": "2026-01-28T11:15:42.941756"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3290.952, "latencies_ms": [3290.952], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two young girls pet a goat in a fenced area, with a third goat in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12533.9, "ram_available_mb": 50306.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.926}, "power_stats": {"power_gpu_soc_mean_watts": 23.019, "power_cpu_cv_mean_watts": 2.699, "power_sys_5v0_mean_watts": 7.879, "gpu_utilization_percent_mean": 78.926}, "timestamp": "2026-01-28T11:15:48.275678"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4799.697, "latencies_ms": [4799.697], "images_per_second": 0.208, "prompt_tokens": 1113, "response_tokens_est": 43, "n_tiles": 1, "output_text": " goat: 2, girl: 2, fence: 1, girl's dress: 1, girl's hair: 1, girl's hair clip: 1, girl's shirt: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12533.9, "ram_available_mb": 50306.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.15}, "power_stats": {"power_gpu_soc_mean_watts": 19.811, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 73.15}, "timestamp": "2026-01-28T11:15:55.093139"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4145.48, "latencies_ms": [4145.48], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The goat is in the foreground, with the two girls standing behind it. The girls are positioned to the left of the goat, with the fence in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.353}, "power_stats": {"power_gpu_soc_mean_watts": 21.155, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 74.353}, "timestamp": "2026-01-28T11:16:01.273596"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3468.855, "latencies_ms": [3468.855], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two young girls pet a goat in a fenced area, with a grassy field and trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.586}, "power_stats": {"power_gpu_soc_mean_watts": 22.426, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 78.586}, "timestamp": "2026-01-28T11:16:06.764953"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4029.047, "latencies_ms": [4029.047], "images_per_second": 0.248, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in bright daylight with a clear blue sky in the background. The girls are wearing colorful dresses, and the goats are black and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.118}, "power_stats": {"power_gpu_soc_mean_watts": 21.093, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 76.118}, "timestamp": "2026-01-28T11:16:12.843169"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5468.138, "latencies_ms": [5468.138], "images_per_second": 0.183, "prompt_tokens": 1099, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a nighttime scene at an intersection, where a traffic light is illuminated by a green light, and a street sign is visible in the background, indicating the intersection of \"AVENUE OF THE DOLLS\" and \"SANTA FE DRIVE\".", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.826}, "power_stats": {"power_gpu_soc_mean_watts": 18.854, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 71.826}, "timestamp": "2026-01-28T11:16:20.342465"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4286.588, "latencies_ms": [4286.588], "images_per_second": 0.233, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. traffic light\n2. street sign\n3. street light\n4. car\n5. road\n6. mountain\n7. building\n8. sky", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.722}, "power_stats": {"power_gpu_soc_mean_watts": 20.722, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 75.722}, "timestamp": "2026-01-28T11:16:26.682382"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5138.091, "latencies_ms": [5138.091], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The traffic light is on the left side of the image, while the street sign is on the right side. The traffic light is closer to the viewer than the street sign. The street sign is in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12535.9, "ram_available_mb": 50305.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.368, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 74.488}, "timestamp": "2026-01-28T11:16:33.878021"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6218.691, "latencies_ms": [6218.691], "images_per_second": 0.161, "prompt_tokens": 1111, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a quiet night at an intersection in a city, where the traffic lights are glowing green, signaling the start of a new day. The sky is painted with hues of blue and orange, reflecting the setting sun. The streetlights cast a warm glow on the buildings and the road, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.9, "ram_available_mb": 50305.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12535.9, "ram_available_mb": 50305.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.151}, "power_stats": {"power_gpu_soc_mean_watts": 17.951, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.655, "gpu_utilization_percent_mean": 70.151}, "timestamp": "2026-01-28T11:16:42.133056"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6513.162, "latencies_ms": [6513.162], "images_per_second": 0.154, "prompt_tokens": 1109, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The image captures a tranquil night scene at an intersection, where the sky is painted in shades of deep blue, and the moon casts a soft glow. The streetlights and traffic signals, glowing with a cool green hue, stand out against the dark backdrop. The buildings in the distance are silhouetted against the night sky, their details obscured by the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.9, "ram_available_mb": 50305.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.411}, "power_stats": {"power_gpu_soc_mean_watts": 17.984, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 71.411}, "timestamp": "2026-01-28T11:16:50.668537"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3933.45, "latencies_ms": [3933.45], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, a woman is standing in front of a building, smiling at the camera, with a bunch of bananas placed in front of her.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.061}, "power_stats": {"power_gpu_soc_mean_watts": 21.32, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 74.061}, "timestamp": "2026-01-28T11:16:56.624664"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5600.036, "latencies_ms": [5600.036], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. bananas: 2\n3. building: 1\n4. door: 1\n5. wall: 1\n6. sign: 1\n7. window: 1\n8. door frame: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.943, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 73.021}, "timestamp": "2026-01-28T11:17:04.251119"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4178.539, "latencies_ms": [4178.539], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bananas are in the foreground, with the woman standing behind them. The woman is positioned to the right of the bananas, and the building is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.912}, "power_stats": {"power_gpu_soc_mean_watts": 21.13, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.912}, "timestamp": "2026-01-28T11:17:10.467899"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3311.867, "latencies_ms": [3311.867], "images_per_second": 0.302, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman is standing in front of a building with a bunch of bananas in front of her.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.407}, "power_stats": {"power_gpu_soc_mean_watts": 22.617, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 77.407}, "timestamp": "2026-01-28T11:17:15.801520"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4474.93, "latencies_ms": [4474.93], "images_per_second": 0.223, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a woman standing in front of a building with a yellow exterior, and the bananas she is selling are yellow and ripe. The lighting is natural and bright, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.027}, "power_stats": {"power_gpu_soc_mean_watts": 20.521, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 74.027}, "timestamp": "2026-01-28T11:17:22.307222"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 10413.007, "latencies_ms": [10413.007], "images_per_second": 0.096, "prompt_tokens": 1432, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene featuring a red brick building with two shuttered storefronts, each adorned with a variety of graffiti tags. The building's green fire escape, a common sight in many cityscapes, adds a touch of color and character to the scene. A solitary fire hydrant stands guard on the sidewalk, while a tree with lush green leaves adds a touch of nature to the urban landscape. The building's address, \"127,\" is prominently displayed on the door, hinting at the building's identity. The overall composition of the image suggests a bustling city life, where art and architecture coexist in harmony.", "error": null, "sys_before": {"cpu_percent": 16.1, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.068}, "power_stats": {"power_gpu_soc_mean_watts": 18.194, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 71.068}, "timestamp": "2026-01-28T11:17:34.769898"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6417.478, "latencies_ms": [6417.478], "images_per_second": 0.156, "prompt_tokens": 1446, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. fire hydrant: 1\n2. tree: 1\n3. building: 1\n4. door: 1\n5. window: 2\n6. fire escape: 1\n7. graffiti: 2\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.852}, "power_stats": {"power_gpu_soc_mean_watts": 20.669, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 72.852}, "timestamp": "2026-01-28T11:17:43.229108"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6541.076, "latencies_ms": [6541.076], "images_per_second": 0.153, "prompt_tokens": 1450, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The green door is located in the middle of the building, with the fire escape above it. The fire hydrant is on the left side of the building, and the tree is on the right side. The sidewalk is in front of the building, and the street is in front of the sidewalk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.727}, "power_stats": {"power_gpu_soc_mean_watts": 20.614, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 73.727}, "timestamp": "2026-01-28T11:17:51.805783"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5664.561, "latencies_ms": [5664.561], "images_per_second": 0.177, "prompt_tokens": 1444, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, where a red brick building stands proudly on a city street corner. The building's green fire escape and shuttered storefronts add a touch of color to the otherwise monochrome setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.021}, "power_stats": {"power_gpu_soc_mean_watts": 21.409, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 76.021}, "timestamp": "2026-01-28T11:17:59.522184"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6049.045, "latencies_ms": [6049.045], "images_per_second": 0.165, "prompt_tokens": 1442, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image depicts a red brick building with green shutters and a fire escape. The building is covered in graffiti, and the sidewalk is lined with a fire hydrant. The weather appears to be overcast, as the sky is gray and the lighting is flat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.7, "ram_available_mb": 50305.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.059}, "power_stats": {"power_gpu_soc_mean_watts": 21.226, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 76.059}, "timestamp": "2026-01-28T11:18:07.591724"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3236.646, "latencies_ms": [3236.646], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a blue beanie is holding a yellow frisbee in his hand.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.889}, "power_stats": {"power_gpu_soc_mean_watts": 22.693, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 80.889}, "timestamp": "2026-01-28T11:18:12.874652"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5709.143, "latencies_ms": [5709.143], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. head: 1\n3. hair: 1\n4. shirt: 1\n5. frisbee: 1\n6. hand: 1\n7. wrist: 1\n8. wristwatch: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12535.4, "ram_available_mb": 50305.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.542}, "power_stats": {"power_gpu_soc_mean_watts": 18.814, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 72.542}, "timestamp": "2026-01-28T11:18:20.612086"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4474.046, "latencies_ms": [4474.046], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The yellow frisbee is in the foreground, close to the camera. The person is in the background, far from the camera. The crowd is in the background, behind the person.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.6, "ram_available_mb": 50305.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.243}, "power_stats": {"power_gpu_soc_mean_watts": 20.465, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 75.243}, "timestamp": "2026-01-28T11:18:27.108312"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3263.375, "latencies_ms": [3263.375], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is throwing a frisbee in a room with a crowd of people watching.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.63, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-28T11:18:32.408554"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4186.181, "latencies_ms": [4186.181], "images_per_second": 0.239, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is a black and white photo with a sepia tone, and the lighting is dim. The subject is wearing a black shirt and a blue beanie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.114}, "power_stats": {"power_gpu_soc_mean_watts": 20.674, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 74.114}, "timestamp": "2026-01-28T11:18:38.616250"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3333.719, "latencies_ms": [3333.719], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are sitting around a table with laptops and books, working on their projects.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12536.0, "ram_available_mb": 50304.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.926}, "power_stats": {"power_gpu_soc_mean_watts": 22.57, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 75.926}, "timestamp": "2026-01-28T11:18:43.972522"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4226.671, "latencies_ms": [4226.671], "images_per_second": 0.237, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 3, keyboard: 1, mouse: 1, cup: 1, bottle: 1, book: 1, person: 7", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12536.0, "ram_available_mb": 50304.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.833, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 73.971}, "timestamp": "2026-01-28T11:18:50.256878"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4566.839, "latencies_ms": [4566.839], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The laptops are positioned in the foreground, with the keyboard in the foreground and the computer monitor in the background. The people are positioned in the background, with the person in the foreground closest to the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.4, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 74.342}, "timestamp": "2026-01-28T11:18:56.850251"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3289.123, "latencies_ms": [3289.123], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are sitting around a table with laptops and books, working on a project together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.148}, "power_stats": {"power_gpu_soc_mean_watts": 23.047, "power_cpu_cv_mean_watts": 1.943, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 81.148}, "timestamp": "2026-01-28T11:19:02.167353"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3483.085, "latencies_ms": [3483.085], "images_per_second": 0.287, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is dimly lit with yellow and green lighting, and the walls are covered in black and white tiles.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.586}, "power_stats": {"power_gpu_soc_mean_watts": 22.301, "power_cpu_cv_mean_watts": 2.43, "power_sys_5v0_mean_watts": 7.85, "gpu_utilization_percent_mean": 77.586}, "timestamp": "2026-01-28T11:19:07.683365"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3957.185, "latencies_ms": [3957.185], "images_per_second": 0.253, "prompt_tokens": 1432, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is holding a blue umbrella and a brown cookie.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12537.2, "ram_available_mb": 50303.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.594}, "power_stats": {"power_gpu_soc_mean_watts": 24.277, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.162, "gpu_utilization_percent_mean": 79.594}, "timestamp": "2026-01-28T11:19:13.690063"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7017.214, "latencies_ms": [7017.214], "images_per_second": 0.143, "prompt_tokens": 1446, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. girl: 1\n2. blue umbrella: 1\n3. girl's hand: 1\n4. girl's leg: 1\n5. girl's foot: 1\n6. girl's shoe: 1\n7. girl's pant: 1\n8. girl's shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12537.3, "ram_available_mb": 50303.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.915}, "power_stats": {"power_gpu_soc_mean_watts": 20.375, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 73.915}, "timestamp": "2026-01-28T11:19:22.766288"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4657.962, "latencies_ms": [4657.962], "images_per_second": 0.215, "prompt_tokens": 1450, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding the umbrella in her right hand. The umbrella is positioned above her, providing shade.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.3, "ram_available_mb": 50303.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.256}, "power_stats": {"power_gpu_soc_mean_watts": 23.112, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 81.256}, "timestamp": "2026-01-28T11:19:29.479233"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4144.888, "latencies_ms": [4144.888], "images_per_second": 0.241, "prompt_tokens": 1444, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is holding a blue umbrella and a brown cookie.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.853}, "power_stats": {"power_gpu_soc_mean_watts": 24.038, "power_cpu_cv_mean_watts": 1.248, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 81.853}, "timestamp": "2026-01-28T11:19:35.658298"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4525.153, "latencies_ms": [4525.153], "images_per_second": 0.221, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The girl is wearing a pink jacket and blue jeans, and the umbrella is blue. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12537.6, "ram_available_mb": 50303.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.676}, "power_stats": {"power_gpu_soc_mean_watts": 23.518, "power_cpu_cv_mean_watts": 1.309, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 79.676}, "timestamp": "2026-01-28T11:19:42.202603"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3176.106, "latencies_ms": [3176.106], "images_per_second": 0.315, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man stands in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12536.9, "ram_available_mb": 50304.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.385}, "power_stats": {"power_gpu_soc_mean_watts": 22.778, "power_cpu_cv_mean_watts": 1.293, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 81.385}, "timestamp": "2026-01-28T11:19:47.423730"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4492.907, "latencies_ms": [4492.907], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " man: 1, chair: 1, computer: 2, monitor: 1, keyboard: 1, mouse: 1, desk: 1, window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.162}, "power_stats": {"power_gpu_soc_mean_watts": 20.422, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 71.162}, "timestamp": "2026-01-28T11:19:53.951586"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5982.524, "latencies_ms": [5982.524], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The man is standing to the left of the desk, which is in the foreground of the image. The desk is located in the middle of the image, with the computer monitors and other equipment placed on it. The window is located behind the desk, and the reflection of the man can be seen in the window.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.48}, "power_stats": {"power_gpu_soc_mean_watts": 18.573, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 70.48}, "timestamp": "2026-01-28T11:20:01.956339"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3164.762, "latencies_ms": [3164.762], "images_per_second": 0.316, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man stands in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.769}, "power_stats": {"power_gpu_soc_mean_watts": 22.777, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 80.769}, "timestamp": "2026-01-28T11:20:07.176778"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3688.564, "latencies_ms": [3688.564], "images_per_second": 0.271, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming in through a window. The man is wearing a black suit and tie.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12537.1, "ram_available_mb": 50303.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.533}, "power_stats": {"power_gpu_soc_mean_watts": 21.851, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 77.533}, "timestamp": "2026-01-28T11:20:12.896943"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3717.908, "latencies_ms": [3717.908], "images_per_second": 0.269, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are sitting around a wooden table in a room with wooden walls and a wooden ceiling, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.323}, "power_stats": {"power_gpu_soc_mean_watts": 21.648, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 78.323}, "timestamp": "2026-01-28T11:20:18.651211"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5153.582, "latencies_ms": [5153.582], "images_per_second": 0.194, "prompt_tokens": 1113, "response_tokens_est": 49, "n_tiles": 1, "output_text": " table: 1\nclock: 1\nwindow: 1\ncurtain: 1\nbottle: 1\ncup: 1\nplate: 1\nbowl: 1\nteapot: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12536.6, "ram_available_mb": 50304.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.721}, "power_stats": {"power_gpu_soc_mean_watts": 19.323, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 73.721}, "timestamp": "2026-01-28T11:20:25.829763"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4638.744, "latencies_ms": [4638.744], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The window is in the background, and the clock is on the wall above the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.8, "ram_available_mb": 50304.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.35, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 73.385}, "timestamp": "2026-01-28T11:20:32.521945"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4390.809, "latencies_ms": [4390.809], "images_per_second": 0.228, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of friends are gathered around a wooden table in a cozy room with a large window. They are enjoying a meal together, with plates of food and drinks on the table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12537.0, "ram_available_mb": 50303.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.645, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 74.333}, "timestamp": "2026-01-28T11:20:38.941886"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3317.761, "latencies_ms": [3317.761], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is filled with warm light and the wooden table is adorned with a variety of colors.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12536.7, "ram_available_mb": 50304.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.618, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 79.519}, "timestamp": "2026-01-28T11:20:44.283021"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3677.582, "latencies_ms": [3677.582], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A red truck with a snowplow attached to the front is driving down a snowy street, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 12536.4, "ram_available_mb": 50304.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.967}, "power_stats": {"power_gpu_soc_mean_watts": 21.786, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 77.967}, "timestamp": "2026-01-28T11:20:49.997566"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4217.607, "latencies_ms": [4217.607], "images_per_second": 0.237, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. red truck\n2. snowplow\n3. snow\n4. house\n5. tree\n6. person\n7. street\n8. sidewalk", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.892, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 73.229}, "timestamp": "2026-01-28T11:20:56.235897"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5426.49, "latencies_ms": [5426.49], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The red truck is in the foreground, driving down the street. The snowplow is attached to the front of the truck, and it is in the middle of the image. The houses are in the background, and the trees are on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12536.1, "ram_available_mb": 50304.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.13}, "power_stats": {"power_gpu_soc_mean_watts": 19.109, "power_cpu_cv_mean_watts": 2.046, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 72.13}, "timestamp": "2026-01-28T11:21:03.679715"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4478.412, "latencies_ms": [4478.412], "images_per_second": 0.223, "prompt_tokens": 1111, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A red truck is driving down a snowy street with a snowplow attached to the front. There are houses on both sides of the street and a yellow fire hydrant on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.405}, "power_stats": {"power_gpu_soc_mean_watts": 20.596, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 75.405}, "timestamp": "2026-01-28T11:21:10.169128"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4648.311, "latencies_ms": [4648.311], "images_per_second": 0.215, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image depicts a red truck with a snowplow attached to the front, driving down a snowy street. The sky is overcast, and the snow is piled up on the sides of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.282}, "power_stats": {"power_gpu_soc_mean_watts": 20.18, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 74.282}, "timestamp": "2026-01-28T11:21:16.838409"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4633.935, "latencies_ms": [4633.935], "images_per_second": 0.216, "prompt_tokens": 1432, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a luxurious bathroom with a large mirror reflecting the person taking the photo, a marble countertop, and a television mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.605}, "power_stats": {"power_gpu_soc_mean_watts": 22.784, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 80.605}, "timestamp": "2026-01-28T11:21:23.504491"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6317.806, "latencies_ms": [6317.806], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. mirror: 1\n2. television: 1\n3. towel: 2\n4. bath tub: 1\n5. sink: 2\n6. counter: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.585}, "power_stats": {"power_gpu_soc_mean_watts": 20.901, "power_cpu_cv_mean_watts": 1.632, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 74.585}, "timestamp": "2026-01-28T11:21:31.844217"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6675.749, "latencies_ms": [6675.749], "images_per_second": 0.15, "prompt_tokens": 1450, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The mirror is positioned above the sink, reflecting the person taking the photo. The sink is located to the left of the mirror, and the person is standing in front of the mirror. The towel is hanging on the wall to the right of the sink, and the television is mounted on the wall above the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.625}, "power_stats": {"power_gpu_soc_mean_watts": 20.434, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 74.625}, "timestamp": "2026-01-28T11:21:40.559052"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3638.437, "latencies_ms": [3638.437], "images_per_second": 0.275, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A person is taking a picture of themselves in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.4}, "power_stats": {"power_gpu_soc_mean_watts": 25.27, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 85.4}, "timestamp": "2026-01-28T11:21:46.232654"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5290.018, "latencies_ms": [5290.018], "images_per_second": 0.189, "prompt_tokens": 1442, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The bathroom is well-lit with warm lighting, and the walls are adorned with a striped pattern. The marble countertop is a deep green color, and the floor is made of beige tiles.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.386}, "power_stats": {"power_gpu_soc_mean_watts": 22.264, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 78.386}, "timestamp": "2026-01-28T11:21:53.535702"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3472.627, "latencies_ms": [3472.627], "images_per_second": 0.288, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two men are unloading luggage from a car in a parking garage, with a white SUV parked nearby.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.276, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 77.724}, "timestamp": "2026-01-28T11:21:59.050811"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5516.768, "latencies_ms": [5516.768], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. luggage: 4\n2. luggage: 2\n3. luggage: 1\n4. luggage: 1\n5. luggage: 1\n6. luggage: 1\n7. luggage: 1\n8. luggage: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12535.0, "ram_available_mb": 50305.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.909, "power_cpu_cv_mean_watts": 2.089, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 71.804}, "timestamp": "2026-01-28T11:22:06.589184"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4692.097, "latencies_ms": [4692.097], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man with the luggage is positioned in the foreground, with the car and other luggage items in the background. The luggage cart is located to the left of the man, and the car is to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.103}, "power_stats": {"power_gpu_soc_mean_watts": 20.026, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 72.103}, "timestamp": "2026-01-28T11:22:13.309009"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3037.22, "latencies_ms": [3037.22], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two men are unloading their luggage from a car in a parking garage.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.293, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.868, "gpu_utilization_percent_mean": 79.56}, "timestamp": "2026-01-28T11:22:18.391182"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4599.138, "latencies_ms": [4599.138], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a man in a parking garage with a white SUV, a black suitcase, and a red luggage cart. The lighting is dim, and the man is wearing a brown shirt.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.577, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 76.324}, "timestamp": "2026-01-28T11:22:25.006028"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3522.779, "latencies_ms": [3522.779], "images_per_second": 0.284, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A plate with a sandwich, fries, and two small bowls of ketchup and mustard sits on a table.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.251, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 74.517}, "timestamp": "2026-01-28T11:22:30.569460"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5509.764, "latencies_ms": [5509.764], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. fries: 1\n3. onion: 1\n4. lettuce: 1\n5. sauce: 2\n6. sandwich: 2\n7. knife: 1\n8. bun: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.936}, "power_stats": {"power_gpu_soc_mean_watts": 18.899, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.936}, "timestamp": "2026-01-28T11:22:38.124043"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5161.272, "latencies_ms": [5161.272], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The plate is located in the foreground of the image, with the sandwich, fries, and ketchup in the foreground. The sandwich is in the center of the plate, with the fries to the right and the ketchup to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.674}, "power_stats": {"power_gpu_soc_mean_watts": 19.4, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 70.674}, "timestamp": "2026-01-28T11:22:45.299492"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3334.847, "latencies_ms": [3334.847], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A plate of food with a sandwich, fries, and ketchup is on a table.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.563, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 79.519}, "timestamp": "2026-01-28T11:22:50.656286"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3471.949, "latencies_ms": [3471.949], "images_per_second": 0.288, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The plate is white and the food is colorful. The lighting is bright and the food is well-lit.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12535.3, "ram_available_mb": 50305.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.137, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 79.552}, "timestamp": "2026-01-28T11:22:56.179532"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3899.552, "latencies_ms": [3899.552], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered by a green mosquito net, a wooden table with a candle, and a painting on the wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12536.3, "ram_available_mb": 50304.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.423, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 77.75}, "timestamp": "2026-01-28T11:23:02.111987"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5592.493, "latencies_ms": [5592.493], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. curtains: 2\n3. table: 1\n4. candle: 1\n5. floor: 1\n6. wall: 1\n7. ceiling: 1\n8. roof: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12536.2, "ram_available_mb": 50304.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.489}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 70.489}, "timestamp": "2026-01-28T11:23:09.739578"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4933.537, "latencies_ms": [4933.537], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the mosquito net draped over it. The table and chairs are located to the right of the bed, while the windows are on the left side of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12535.5, "ram_available_mb": 50305.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.634}, "power_stats": {"power_gpu_soc_mean_watts": 19.602, "power_cpu_cv_mean_watts": 2.07, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.634}, "timestamp": "2026-01-28T11:23:16.724608"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3180.354, "latencies_ms": [3180.354], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The room is a bedroom with a bed, a table, and a candle.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12535.2, "ram_available_mb": 50305.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.885}, "power_stats": {"power_gpu_soc_mean_watts": 22.826, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 78.885}, "timestamp": "2026-01-28T11:23:21.952872"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3603.37, "latencies_ms": [3603.37], "images_per_second": 0.278, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is painted yellow and has a thatched roof. The room is lit by natural light coming through the windows.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.2}, "power_stats": {"power_gpu_soc_mean_watts": 21.851, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 77.2}, "timestamp": "2026-01-28T11:23:27.605434"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3537.154, "latencies_ms": [3537.154], "images_per_second": 0.283, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A gray and black cat with a blue collar is standing on the hood of a black car in a garage.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.011, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 77.517}, "timestamp": "2026-01-28T11:23:33.191485"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5637.659, "latencies_ms": [5637.659], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. lamp: 1\n4. box: 1\n5. chair: 1\n6. bicycle: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.17}, "power_stats": {"power_gpu_soc_mean_watts": 18.693, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 71.17}, "timestamp": "2026-01-28T11:23:40.847858"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4283.079, "latencies_ms": [4283.079], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, near the front left corner of the car, while the lamp is located in the background, towards the left side of the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.514}, "power_stats": {"power_gpu_soc_mean_watts": 20.812, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 76.514}, "timestamp": "2026-01-28T11:23:47.153944"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3003.142, "latencies_ms": [3003.142], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is standing on the hood of a car in a garage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.245, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 80.56}, "timestamp": "2026-01-28T11:23:52.174038"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2985.24, "latencies_ms": [2985.24], "images_per_second": 0.335, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is gray and white, and the car is black.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.345, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 80.417}, "timestamp": "2026-01-28T11:23:57.177713"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3718.841, "latencies_ms": [3718.841], "images_per_second": 0.269, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A delicious plate of food with a knife on it is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12534.6, "ram_available_mb": 50306.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.033}, "power_stats": {"power_gpu_soc_mean_watts": 24.898, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 83.033}, "timestamp": "2026-01-28T11:24:02.944956"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6188.613, "latencies_ms": [6188.613], "images_per_second": 0.162, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. knife: 1\n3. food: 1\n4. table: 1\n5. fork: 1\n6. sandwich: 1\n7. sauce: 1\n8. bread: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.519}, "power_stats": {"power_gpu_soc_mean_watts": 21.059, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 75.519}, "timestamp": "2026-01-28T11:24:11.148186"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6199.847, "latencies_ms": [6199.847], "images_per_second": 0.161, "prompt_tokens": 1450, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The main object, the plate of food, is in the foreground and is the closest object to the camera. The knife is located near the plate, but not on it. The background is out of focus, indicating that the main object is the focal point of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.154}, "power_stats": {"power_gpu_soc_mean_watts": 20.827, "power_cpu_cv_mean_watts": 1.979, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 76.154}, "timestamp": "2026-01-28T11:24:19.376097"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3625.156, "latencies_ms": [3625.156], "images_per_second": 0.276, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A delicious looking meal is served on a plate with a knife.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12535.1, "ram_available_mb": 50305.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.2}, "power_stats": {"power_gpu_soc_mean_watts": 25.084, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.169, "gpu_utilization_percent_mean": 86.2}, "timestamp": "2026-01-28T11:24:25.014667"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6037.603, "latencies_ms": [6037.603], "images_per_second": 0.166, "prompt_tokens": 1442, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a plate of food with a brown sauce, white gravy, and a slice of bread. The food is placed on a white plate, and the background is a black metal table. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.627}, "power_stats": {"power_gpu_soc_mean_watts": 20.935, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 75.627}, "timestamp": "2026-01-28T11:24:33.081096"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3948.697, "latencies_ms": [3948.697], "images_per_second": 0.253, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, there are three men in a living room, one of them is holding a camera, and they are all sitting on a couch.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12534.8, "ram_available_mb": 50306.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12534.7, "ram_available_mb": 50306.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.251, "power_cpu_cv_mean_watts": 1.698, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 76.394}, "timestamp": "2026-01-28T11:24:39.080507"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4727.365, "latencies_ms": [4727.365], "images_per_second": 0.212, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " table: 1\nsofa: 1\nbed: 1\nwindow: 1\nlamp: 1\ntable: 1\ncouch: 1\nfloor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.7, "ram_available_mb": 50306.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.045, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 72.718}, "timestamp": "2026-01-28T11:24:45.830218"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8538.525, "latencies_ms": [8538.525], "images_per_second": 0.117, "prompt_tokens": 1117, "response_tokens_est": 102, "n_tiles": 1, "output_text": " The man in the white shirt is standing near the couch, while the man in the blue shirt is sitting on the couch. The man in the blue shirt is holding a can of beer, and the man in the white shirt is holding a phone. The man in the blue shirt is also holding a bag of chips. The man in the white shirt is standing near the table, which has a red tablecloth. The man in the blue shirt is sitting on the couch, which is next to the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.9, "ram_available_mb": 50306.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.986}, "power_stats": {"power_gpu_soc_mean_watts": 16.377, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.667, "gpu_utilization_percent_mean": 69.986}, "timestamp": "2026-01-28T11:24:56.380006"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3400.812, "latencies_ms": [3400.812], "images_per_second": 0.294, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Three men are sitting on a couch in a living room, drinking beer and having a good time.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.397, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.25}, "timestamp": "2026-01-28T11:25:01.799695"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3194.145, "latencies_ms": [3194.145], "images_per_second": 0.313, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The room is warmly lit with a yellow hue, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12534.0, "ram_available_mb": 50306.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.429, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 81.731}, "timestamp": "2026-01-28T11:25:07.028752"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3919.439, "latencies_ms": [3919.439], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A baseball catcher in a white and black uniform is squatting in the batter's box, wearing a black helmet and a black and yellow glove.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12534.0, "ram_available_mb": 50306.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.909}, "power_stats": {"power_gpu_soc_mean_watts": 21.287, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 74.909}, "timestamp": "2026-01-28T11:25:12.994531"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7399.013, "latencies_ms": [7399.013], "images_per_second": 0.135, "prompt_tokens": 1113, "response_tokens_est": 87, "n_tiles": 1, "output_text": " 1. catcher's mitt: 1\n2. catcher's mask: 1\n3. catcher's chest protector: 1\n4. catcher's leg guards: 1\n5. catcher's leg pads: 1\n6. catcher's shin guards: 1\n7. catcher's chest protector: 1\n8. catcher's chest protector: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.194}, "power_stats": {"power_gpu_soc_mean_watts": 17.441, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 70.194}, "timestamp": "2026-01-28T11:25:22.421934"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4915.583, "latencies_ms": [4915.583], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The catcher is positioned in the foreground, squatting in front of the batter, with the pitcher and umpire in the background. The catcher is closer to the camera than the batter, who is positioned further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12532.5, "ram_available_mb": 50308.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.756}, "power_stats": {"power_gpu_soc_mean_watts": 19.92, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 72.756}, "timestamp": "2026-01-28T11:25:29.362646"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3589.416, "latencies_ms": [3589.416], "images_per_second": 0.279, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A baseball catcher is squatting in the batter's box, wearing a black and white uniform and a black helmet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.5, "ram_available_mb": 50308.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.167}, "power_stats": {"power_gpu_soc_mean_watts": 22.017, "power_cpu_cv_mean_watts": 2.363, "power_sys_5v0_mean_watts": 7.856, "gpu_utilization_percent_mean": 78.167}, "timestamp": "2026-01-28T11:25:34.976822"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7543.922, "latencies_ms": [7543.922], "images_per_second": 0.133, "prompt_tokens": 1109, "response_tokens_est": 89, "n_tiles": 1, "output_text": " The image captures a moment of intense focus and concentration, with the catcher crouched in anticipation, his body poised in readiness to spring into action. The vibrant green of the field contrasts sharply with the brown dirt of the batter's box, while the catcher's black and white uniform stands out against the lush greenery. The lighting is natural and bright, casting sharp shadows and highlighting the textures of the catcher's gear and the grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.6, "ram_available_mb": 50308.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 12532.2, "ram_available_mb": 50308.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.016}, "power_stats": {"power_gpu_soc_mean_watts": 17.249, "power_cpu_cv_mean_watts": 2.734, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 69.016}, "timestamp": "2026-01-28T11:25:44.542119"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3945.897, "latencies_ms": [3945.897], "images_per_second": 0.253, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a bathroom with a pink and brown color scheme, featuring a bathtub, a toilet, and a wooden vanity with a mirror above it.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12532.2, "ram_available_mb": 50308.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12532.9, "ram_available_mb": 50308.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.442, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 74.594}, "timestamp": "2026-01-28T11:25:50.516592"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6258.296, "latencies_ms": [6258.296], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Toilet: 1\n3. Window: 1\n4. Shower curtain: 1\n5. Bathroom sink: 1\n6. Bathroom door: 1\n7. Bathroom cabinet: 1\n8. Bathroom floor: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12532.9, "ram_available_mb": 50308.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12532.8, "ram_available_mb": 50308.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.17}, "power_stats": {"power_gpu_soc_mean_watts": 18.19, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.17}, "timestamp": "2026-01-28T11:25:58.797499"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5053.483, "latencies_ms": [5053.483], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The toilet is located in the foreground, to the right of the sink. The bathtub is situated in the background, to the left of the sink. The shower curtain is hanging in the middle of the bathroom, between the bathtub and the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12532.8, "ram_available_mb": 50308.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12533.3, "ram_available_mb": 50307.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.209}, "power_stats": {"power_gpu_soc_mean_watts": 19.618, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 73.209}, "timestamp": "2026-01-28T11:26:05.888957"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3054.779, "latencies_ms": [3054.779], "images_per_second": 0.327, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A bathroom with pink tiles and a white toilet is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.3, "ram_available_mb": 50307.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12533.2, "ram_available_mb": 50307.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.165, "power_cpu_cv_mean_watts": 1.329, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 81.76}, "timestamp": "2026-01-28T11:26:10.977678"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3597.458, "latencies_ms": [3597.458], "images_per_second": 0.278, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The bathroom has pink and brown tiles, a white bathtub, and a wooden vanity. The lighting is bright and natural.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12533.2, "ram_available_mb": 50307.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.967}, "power_stats": {"power_gpu_soc_mean_watts": 21.894, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 75.967}, "timestamp": "2026-01-28T11:26:16.629789"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4186.97, "latencies_ms": [4186.97], "images_per_second": 0.239, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid blanket, a nightstand with a lamp on it, and a window with red curtains.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.857}, "power_stats": {"power_gpu_soc_mean_watts": 20.791, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 75.857}, "timestamp": "2026-01-28T11:26:22.868793"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5605.032, "latencies_ms": [5605.032], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bed: 1\n2. window: 1\n3. curtains: 2\n4. wall: 1\n5. lamp: 1\n6. bedside table: 1\n7. bed: 1\n8. blanket: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.354}, "power_stats": {"power_gpu_soc_mean_watts": 18.816, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 70.354}, "timestamp": "2026-01-28T11:26:30.489958"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4879.801, "latencies_ms": [4879.801], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The bed is located in the foreground of the image, with the window and curtains in the background. The lamp is positioned on the nightstand to the right of the bed, and the window is to the left of the bed.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12533.6, "ram_available_mb": 50307.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.707}, "power_stats": {"power_gpu_soc_mean_watts": 19.754, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 72.707}, "timestamp": "2026-01-28T11:26:37.398381"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4975.268, "latencies_ms": [4975.268], "images_per_second": 0.201, "prompt_tokens": 1111, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid blanket, positioned in the center of the room. The room is dimly lit, with a window on the left side allowing natural light to filter in.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.878}, "power_stats": {"power_gpu_soc_mean_watts": 19.703, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.878}, "timestamp": "2026-01-28T11:26:44.388272"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3497.773, "latencies_ms": [3497.773], "images_per_second": 0.286, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is dimly lit with a yellow and white plaid bedspread, and the window has red curtains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12533.9, "ram_available_mb": 50307.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.271, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-28T11:26:49.944825"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4415.865, "latencies_ms": [4415.865], "images_per_second": 0.226, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A woman in a black dress with a beaded bodice is adjusting a boutonniere on a man's lapel.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12534.4, "ram_available_mb": 50306.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.757}, "power_stats": {"power_gpu_soc_mean_watts": 22.98, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 81.757}, "timestamp": "2026-01-28T11:26:56.409243"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6802.008, "latencies_ms": [6802.008], "images_per_second": 0.147, "prompt_tokens": 1446, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. tie: 1\n2. suit: 1\n3. woman: 1\n4. man: 1\n5. woman's hand: 1\n6. woman's dress: 1\n7. woman's hair: 1\n8. woman's earring: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.3, "ram_available_mb": 50306.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.281}, "power_stats": {"power_gpu_soc_mean_watts": 20.4, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 73.281}, "timestamp": "2026-01-28T11:27:05.251171"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5829.722, "latencies_ms": [5829.722], "images_per_second": 0.172, "prompt_tokens": 1450, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, and she is closer to the camera than the man. The woman is wearing a black dress with a beige ribbon, and the man is wearing a black suit with a beige tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.449}, "power_stats": {"power_gpu_soc_mean_watts": 21.353, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 76.449}, "timestamp": "2026-01-28T11:27:13.124430"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4153.902, "latencies_ms": [4153.902], "images_per_second": 0.241, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman is helping a man put on a boutonniere. They are at a formal event.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.441}, "power_stats": {"power_gpu_soc_mean_watts": 24.186, "power_cpu_cv_mean_watts": 1.331, "power_sys_5v0_mean_watts": 8.136, "gpu_utilization_percent_mean": 84.441}, "timestamp": "2026-01-28T11:27:19.296560"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5479.193, "latencies_ms": [5479.193], "images_per_second": 0.183, "prompt_tokens": 1442, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is well-lit with natural light, and the colors are vibrant and bright. The man is wearing a black suit with a gold tie, and the woman is wearing a black dress with a gold belt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12533.7, "ram_available_mb": 50307.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.109}, "power_stats": {"power_gpu_soc_mean_watts": 21.664, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 78.109}, "timestamp": "2026-01-28T11:27:26.802527"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4064.611, "latencies_ms": [4064.611], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image features a chain-link fence with a stop sign attached to it, situated in a grassy area with palm trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12533.7, "ram_available_mb": 50307.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12534.0, "ram_available_mb": 50306.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.008, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 74.242}, "timestamp": "2026-01-28T11:27:32.909869"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4521.343, "latencies_ms": [4521.343], "images_per_second": 0.221, "prompt_tokens": 1113, "response_tokens_est": 38, "n_tiles": 1, "output_text": " 1. chain link fence\n2. stop sign\n3. palm trees\n4. building\n5. bushes\n6. trash\n7. sidewalk\n8. chain link fence", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12534.0, "ram_available_mb": 50306.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.919}, "power_stats": {"power_gpu_soc_mean_watts": 20.357, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 71.919}, "timestamp": "2026-01-28T11:27:39.471345"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5234.627, "latencies_ms": [5234.627], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The stop sign is located in the foreground of the image, on the left side, and is partially obscured by the chain link fence. The background of the image features a grassy area with palm trees and a building, which is far away from the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12534.5, "ram_available_mb": 50306.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.395}, "power_stats": {"power_gpu_soc_mean_watts": 19.458, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 73.395}, "timestamp": "2026-01-28T11:27:46.753396"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5617.306, "latencies_ms": [5617.306], "images_per_second": 0.178, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a scene of a chain-link fence with a stop sign attached to it, set against a backdrop of a grassy area and palm trees. The stop sign, with its bold red color and octagonal shape, stands out prominently against the green foliage and the blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12534.2, "ram_available_mb": 50306.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12547.9, "ram_available_mb": 50293.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.043}, "power_stats": {"power_gpu_soc_mean_watts": 19.054, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 73.043}, "timestamp": "2026-01-28T11:27:54.394625"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4845.052, "latencies_ms": [4845.052], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image depicts a chain-link fence with a stop sign attached to it, set against a backdrop of a grassy area with palm trees and a building in the distance. The sky is clear, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12547.9, "ram_available_mb": 50293.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12542.2, "ram_available_mb": 50298.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.796, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 72.775}, "timestamp": "2026-01-28T11:28:01.251030"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3954.393, "latencies_ms": [3954.393], "images_per_second": 0.253, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A man wearing a gray shirt and khaki shorts is standing next to a black bicycle with a basket on the back, while a motorcycle is parked nearby.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12542.2, "ram_available_mb": 50298.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.455}, "power_stats": {"power_gpu_soc_mean_watts": 21.408, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 7.82, "gpu_utilization_percent_mean": 75.455}, "timestamp": "2026-01-28T11:28:07.247333"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4287.582, "latencies_ms": [4287.582], "images_per_second": 0.233, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. yellow bicycle\n2. black bicycle\n3. motorcycle\n4. person\n5. tree\n6. fence\n7. trash bag\n8. graffiti", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.638, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-28T11:28:13.556570"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4342.783, "latencies_ms": [4342.783], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The yellow bicycle is positioned to the left of the black bicycle, which is in the foreground. The person is standing near the black bicycle, while the motorcycle is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.472}, "power_stats": {"power_gpu_soc_mean_watts": 20.684, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 74.472}, "timestamp": "2026-01-28T11:28:19.918147"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3284.59, "latencies_ms": [3284.59], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is standing next to a bike and a motorcycle. There is graffiti on the ground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12542.5, "ram_available_mb": 50298.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.074}, "power_stats": {"power_gpu_soc_mean_watts": 22.71, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 77.074}, "timestamp": "2026-01-28T11:28:25.243001"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5647.951, "latencies_ms": [5647.951], "images_per_second": 0.177, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a street scene with a yellow bicycle, a black bicycle, and a motorcycle parked on the side of the road. The sky is clear and blue, indicating a sunny day. The ground is covered with green grass and leaves, suggesting that it is either spring or summer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.5, "ram_available_mb": 50298.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.688}, "power_stats": {"power_gpu_soc_mean_watts": 18.708, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 71.688}, "timestamp": "2026-01-28T11:28:32.925354"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5254.11, "latencies_ms": [5254.11], "images_per_second": 0.19, "prompt_tokens": 1099, "response_tokens_est": 51, "n_tiles": 1, "output_text": " In the image, a man is standing on the sidewalk, looking at a street sign that reads \"PROCTER 2\" and \"PROCTER 3\". The street is busy with cars and people, and there are trees lining the sidewalk.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12540.2, "ram_available_mb": 50300.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.705}, "power_stats": {"power_gpu_soc_mean_watts": 19.324, "power_cpu_cv_mean_watts": 1.838, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 73.705}, "timestamp": "2026-01-28T11:28:40.222631"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4501.705, "latencies_ms": [4501.705], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 38, "n_tiles": 1, "output_text": " 1. black pole\n2. yellow sign\n3. black trash can\n4. traffic light\n5. street sign\n6. person\n7. bicycle\n8. car", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.2, "ram_available_mb": 50300.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12540.1, "ram_available_mb": 50300.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.289}, "power_stats": {"power_gpu_soc_mean_watts": 20.279, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 75.289}, "timestamp": "2026-01-28T11:28:46.747801"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5140.16, "latencies_ms": [5140.16], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The man is standing on the sidewalk, which is adjacent to the street. The traffic lights are positioned above the street, and the street signs are mounted on the poles. The man is closer to the camera than the traffic lights and street signs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12540.1, "ram_available_mb": 50300.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12540.8, "ram_available_mb": 50300.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.884}, "power_stats": {"power_gpu_soc_mean_watts": 19.227, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 71.884}, "timestamp": "2026-01-28T11:28:53.924953"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5434.212, "latencies_ms": [5434.212], "images_per_second": 0.184, "prompt_tokens": 1111, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a bustling city intersection, where pedestrians and vehicles coexist. The street is lined with buildings, and a traffic light hangs overhead, guiding the flow of traffic. A man stands on the sidewalk, perhaps waiting for the light to change or simply enjoying the urban scenery.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12540.8, "ram_available_mb": 50300.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12541.3, "ram_available_mb": 50299.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.348}, "power_stats": {"power_gpu_soc_mean_watts": 19.2, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 73.348}, "timestamp": "2026-01-28T11:29:01.384210"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4904.161, "latencies_ms": [4904.161], "images_per_second": 0.204, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a city street with a mix of colors, including the red of the car and the black of the street lamp. The lighting is natural, coming from the sky, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12541.3, "ram_available_mb": 50299.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12541.8, "ram_available_mb": 50299.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.366}, "power_stats": {"power_gpu_soc_mean_watts": 19.743, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 73.366}, "timestamp": "2026-01-28T11:29:08.316655"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5422.574, "latencies_ms": [5422.574], "images_per_second": 0.184, "prompt_tokens": 1099, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a bronze statue of two individuals seated on a stone bench, with a handbag resting beside them. The statue is situated on a sidewalk, and in the background, a group of people can be seen standing, possibly admiring the artwork or engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12541.6, "ram_available_mb": 50299.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.894, "power_cpu_cv_mean_watts": 2.621, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-28T11:29:15.788707"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5636.58, "latencies_ms": [5636.58], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. statue: 2\n2. bench: 1\n3. bag: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.34}, "power_stats": {"power_gpu_soc_mean_watts": 18.664, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.672, "gpu_utilization_percent_mean": 70.34}, "timestamp": "2026-01-28T11:29:23.462912"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5862.763, "latencies_ms": [5862.763], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The sculpture is located on the left side of the image, with the bench and bag placed in the foreground. The sculpture is positioned in the middle of the image, with the bench and bag placed in the foreground. The sculpture is located in the background, with the bench and bag placed in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12541.6, "ram_available_mb": 50299.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.701, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-28T11:29:31.336933"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5203.856, "latencies_ms": [5203.856], "images_per_second": 0.192, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a bronze statue of three individuals seated on a stone bench, with a handbag resting on the ground beside them. The setting appears to be an outdoor urban environment, possibly a park or a public square, with people walking in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12541.6, "ram_available_mb": 50299.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12541.6, "ram_available_mb": 50299.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.295}, "power_stats": {"power_gpu_soc_mean_watts": 19.234, "power_cpu_cv_mean_watts": 1.893, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 72.295}, "timestamp": "2026-01-28T11:29:38.565510"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3877.934, "latencies_ms": [3877.934], "images_per_second": 0.258, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The sculpture is made of bronze and is situated on a stone bench. The sculpture is bathed in sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12541.6, "ram_available_mb": 50299.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.25}, "power_stats": {"power_gpu_soc_mean_watts": 21.391, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 75.25}, "timestamp": "2026-01-28T11:29:44.469235"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5211.295, "latencies_ms": [5211.295], "images_per_second": 0.192, "prompt_tokens": 1100, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image shows a series of road signs, including a blue sign with white text and symbols, a green sign with white text and symbols, a red and white circular sign with a truck symbol, and a blue and white rectangular sign with a truck symbol.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12541.4, "ram_available_mb": 50299.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.302}, "power_stats": {"power_gpu_soc_mean_watts": 19.431, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 7.761, "gpu_utilization_percent_mean": 72.302}, "timestamp": "2026-01-28T11:29:51.729921"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4806.377, "latencies_ms": [4806.377], "images_per_second": 0.208, "prompt_tokens": 1114, "response_tokens_est": 44, "n_tiles": 1, "output_text": " 1. signpost\n2. blue sign\n3. green sign\n4. white sign\n5. red and white sign\n6. blue and white sign\n7. white arrow\n8. black arrow", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12542.2, "ram_available_mb": 50298.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.45}, "power_stats": {"power_gpu_soc_mean_watts": 20.077, "power_cpu_cv_mean_watts": 1.742, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 74.45}, "timestamp": "2026-01-28T11:29:58.567128"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5166.92, "latencies_ms": [5166.92], "images_per_second": 0.194, "prompt_tokens": 1118, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The blue sign is located to the left of the green sign, which is in turn positioned to the right of the red and blue circular signs. The red and blue circular signs are located in the foreground, while the blue sign is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.2, "ram_available_mb": 50298.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12542.9, "ram_available_mb": 50298.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.442}, "power_stats": {"power_gpu_soc_mean_watts": 19.476, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 73.442}, "timestamp": "2026-01-28T11:30:05.762081"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4453.715, "latencies_ms": [4453.715], "images_per_second": 0.225, "prompt_tokens": 1112, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a scene of a road signpost in a rural area, with a clear sky in the background. The signpost is adorned with multiple signs, each indicating different directions and destinations.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12542.3, "ram_available_mb": 50298.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12542.7, "ram_available_mb": 50298.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.541}, "power_stats": {"power_gpu_soc_mean_watts": 20.199, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 74.541}, "timestamp": "2026-01-28T11:30:12.232383"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5575.256, "latencies_ms": [5575.256], "images_per_second": 0.179, "prompt_tokens": 1110, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image depicts a collection of road signs with a mix of colors including blue, green, red, and white. The signs are attached to a pole and are positioned in an outdoor setting with trees in the background. The sky appears to be overcast, suggesting a cloudy day.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12542.7, "ram_available_mb": 50298.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12543.4, "ram_available_mb": 50297.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.043}, "power_stats": {"power_gpu_soc_mean_watts": 19.017, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 70.043}, "timestamp": "2026-01-28T11:30:19.825104"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4402.768, "latencies_ms": [4402.768], "images_per_second": 0.227, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, there are two women standing next to each other, with one of them holding a black suitcase. They are both smiling and appear to be enjoying their time together.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12543.4, "ram_available_mb": 50297.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.548, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 75.639}, "timestamp": "2026-01-28T11:30:26.254933"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5854.703, "latencies_ms": [5854.703], "images_per_second": 0.171, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. woman: 2\n3. girl: 1\n4. backpack: 1\n5. suitcase handle: 1\n6. suitcase strap: 1\n7. train: 1\n8. platform: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.469}, "power_stats": {"power_gpu_soc_mean_watts": 18.616, "power_cpu_cv_mean_watts": 2.133, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 72.469}, "timestamp": "2026-01-28T11:30:34.141563"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5020.396, "latencies_ms": [5020.396], "images_per_second": 0.199, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The woman on the left is standing closer to the camera than the woman on the right. The woman on the right is standing in front of the woman on the left. The woman on the right is standing in front of the luggage.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12543.9, "ram_available_mb": 50297.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.732}, "power_stats": {"power_gpu_soc_mean_watts": 19.783, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 73.732}, "timestamp": "2026-01-28T11:30:41.180720"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2760.993, "latencies_ms": [2760.993], "images_per_second": 0.362, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Two women are standing on a train platform with their luggage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.9, "ram_available_mb": 50297.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.783}, "power_stats": {"power_gpu_soc_mean_watts": 23.697, "power_cpu_cv_mean_watts": 1.34, "power_sys_5v0_mean_watts": 7.88, "gpu_utilization_percent_mean": 81.783}, "timestamp": "2026-01-28T11:30:45.979905"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4438.379, "latencies_ms": [4438.379], "images_per_second": 0.225, "prompt_tokens": 1110, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken during the day with natural light illuminating the scene. The colors in the image are vibrant, with the red of the train station and the blue of the sky standing out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12544.4, "ram_available_mb": 50296.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.425, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 74.838}, "timestamp": "2026-01-28T11:30:52.473563"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3418.632, "latencies_ms": [3418.632], "images_per_second": 0.293, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Three zebras with black and white stripes are walking on a dirt road in a forest with purple flowers.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12544.4, "ram_available_mb": 50296.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.321}, "power_stats": {"power_gpu_soc_mean_watts": 22.497, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 78.321}, "timestamp": "2026-01-28T11:30:57.926824"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2439.86, "latencies_ms": [2439.86], "images_per_second": 0.41, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.345, "power_cpu_cv_mean_watts": 1.181, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 84.25}, "timestamp": "2026-01-28T11:31:02.402757"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4641.904, "latencies_ms": [4641.904], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the trees and bushes serving as the background. The zebras are facing the camera, with the tree branches and purple flowers in the background.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.079}, "power_stats": {"power_gpu_soc_mean_watts": 20.242, "power_cpu_cv_mean_watts": 1.97, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 74.079}, "timestamp": "2026-01-28T11:31:09.056920"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3255.178, "latencies_ms": [3255.178], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three zebras are walking on a dirt road in a wooded area with purple flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.308, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 81.222}, "timestamp": "2026-01-28T11:31:14.350745"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4000.99, "latencies_ms": [4000.99], "images_per_second": 0.25, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The zebras are black and white striped, and the trees are green and purple. The sun is shining brightly, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.848}, "power_stats": {"power_gpu_soc_mean_watts": 20.967, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 76.848}, "timestamp": "2026-01-28T11:31:20.377544"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3618.486, "latencies_ms": [3618.486], "images_per_second": 0.276, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A tripod with a camera on it is in a room with a laptop and a vending machine in the background.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.767}, "power_stats": {"power_gpu_soc_mean_watts": 21.692, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 77.767}, "timestamp": "2026-01-28T11:31:26.034400"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2492.834, "latencies_ms": [2492.834], "images_per_second": 0.401, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " tripod: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.329, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 85.25}, "timestamp": "2026-01-28T11:31:30.578400"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5568.817, "latencies_ms": [5568.817], "images_per_second": 0.18, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The camera is positioned to the left of the laptop, which is placed on the tripod stand. The laptop is situated in the foreground, while the camera is in the background. The tripod stand is positioned near the laptop, and the camera is positioned far from the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.326}, "power_stats": {"power_gpu_soc_mean_watts": 18.899, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 72.326}, "timestamp": "2026-01-28T11:31:38.157770"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3910.269, "latencies_ms": [3910.269], "images_per_second": 0.256, "prompt_tokens": 1112, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In a room with a camera on a tripod, a laptop is open on a table, and a vending machine is visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.656}, "power_stats": {"power_gpu_soc_mean_watts": 21.288, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 72.656}, "timestamp": "2026-01-28T11:31:44.097769"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4104.435, "latencies_ms": [4104.435], "images_per_second": 0.244, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a blue and white color scheme. The camera on the tripod is black and the laptop is black.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.647}, "power_stats": {"power_gpu_soc_mean_watts": 21.226, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 74.647}, "timestamp": "2026-01-28T11:31:50.255763"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4160.611, "latencies_ms": [4160.611], "images_per_second": 0.24, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a sheep is seen grazing on a pile of wool, which is being sheared off by a person who is partially visible behind a metal fence.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.382}, "power_stats": {"power_gpu_soc_mean_watts": 20.979, "power_cpu_cv_mean_watts": 1.767, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 74.382}, "timestamp": "2026-01-28T11:31:56.446233"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6054.889, "latencies_ms": [6054.889], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. fence: 1\n3. metal: 1\n4. wool: 1\n5. sheep's head: 1\n6. wool's edge: 1\n7. wool's edge: 1\n8. wool's edge: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.157}, "power_stats": {"power_gpu_soc_mean_watts": 18.289, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 69.157}, "timestamp": "2026-01-28T11:32:04.519624"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5154.919, "latencies_ms": [5154.919], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The sheep is positioned in the foreground, with the metal fence serving as a boundary between the sheep and the background. The sheep is facing towards the camera, with its head lowered to the ground, indicating it is engaged in the act of shearing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.14}, "power_stats": {"power_gpu_soc_mean_watts": 19.465, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 70.14}, "timestamp": "2026-01-28T11:32:11.720708"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4547.448, "latencies_ms": [4547.448], "images_per_second": 0.22, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In a fenced enclosure, a sheep is seen eating a pile of wool, which is a common practice for shearing. The sheep is white and appears to be enjoying the fresh, clean wool.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.289}, "power_stats": {"power_gpu_soc_mean_watts": 20.309, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 70.289}, "timestamp": "2026-01-28T11:32:18.330549"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3377.772, "latencies_ms": [3377.772], "images_per_second": 0.296, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sheep is white and the wool is gray. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.239, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 76.143}, "timestamp": "2026-01-28T11:32:23.769856"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5916.692, "latencies_ms": [5916.692], "images_per_second": 0.169, "prompt_tokens": 1099, "response_tokens_est": 59, "n_tiles": 1, "output_text": " In the image, a tennis match is taking place on a blue court, with players dressed in red and purple uniforms, and a scoreboard displaying the scores of the players. The court is surrounded by a crowd of spectators, and various advertisements are visible on the walls and banners surrounding the court.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12543.2, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.347}, "power_stats": {"power_gpu_soc_mean_watts": 18.242, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.636, "gpu_utilization_percent_mean": 70.347}, "timestamp": "2026-01-28T11:32:31.728694"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4503.34, "latencies_ms": [4503.34], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. tennis court\n2. tennis ball\n3. tennis racket\n4. net\n5. ball boy\n6. net post\n7. scoreboard\n8. audience", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.2, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12543.0, "ram_available_mb": 50297.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.162}, "power_stats": {"power_gpu_soc_mean_watts": 20.523, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 71.162}, "timestamp": "2026-01-28T11:32:38.262340"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5316.282, "latencies_ms": [5316.282], "images_per_second": 0.188, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The tennis player is positioned near the net, with the ball in the air between her and the opposing team. The camera is positioned in the foreground, capturing the action from a low angle. The spectators are in the background, watching the match from their seats.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.0, "ram_available_mb": 50297.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.864}, "power_stats": {"power_gpu_soc_mean_watts": 19.516, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 70.864}, "timestamp": "2026-01-28T11:32:45.612129"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4784.737, "latencies_ms": [4784.737], "images_per_second": 0.209, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a tennis match in progress, with players on a blue court, surrounded by spectators in the stands. The scoreboard in the background displays the current score, indicating that the match is in progress.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.875}, "power_stats": {"power_gpu_soc_mean_watts": 19.635, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 73.875}, "timestamp": "2026-01-28T11:32:52.441319"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3806.6, "latencies_ms": [3806.6], "images_per_second": 0.263, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The court is blue with white lines, and the players are wearing red and purple. The lighting is bright and the weather is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.2, "ram_available_mb": 50297.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12543.1, "ram_available_mb": 50297.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.389, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.75}, "timestamp": "2026-01-28T11:32:58.285327"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3538.568, "latencies_ms": [3538.568], "images_per_second": 0.283, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is walking through a large, open, and empty airport terminal with a glass door in the foreground.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12543.1, "ram_available_mb": 50297.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.103}, "power_stats": {"power_gpu_soc_mean_watts": 21.919, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 80.103}, "timestamp": "2026-01-28T11:33:03.887208"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6345.607, "latencies_ms": [6345.607], "images_per_second": 0.158, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. person: 1\n2. suitcase: 1\n3. suitcase handle: 1\n4. suitcase wheels: 1\n5. suitcase wheels: 1\n6. suitcase wheels: 1\n7. suitcase wheels: 1\n8. suitcase wheels: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12543.6, "ram_available_mb": 50297.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.811}, "power_stats": {"power_gpu_soc_mean_watts": 18.129, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 70.811}, "timestamp": "2026-01-28T11:33:12.259404"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4823.808, "latencies_ms": [4823.808], "images_per_second": 0.207, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The main object is the glass door, which is located in the foreground of the image. The person is standing in the background, near the glass door. The escalator is located in the background, behind the person.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.6, "ram_available_mb": 50297.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.125}, "power_stats": {"power_gpu_soc_mean_watts": 19.987, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.125}, "timestamp": "2026-01-28T11:33:19.105132"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3029.007, "latencies_ms": [3029.007], "images_per_second": 0.33, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.523, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 79.8}, "timestamp": "2026-01-28T11:33:24.194379"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4443.672, "latencies_ms": [4443.672], "images_per_second": 0.225, "prompt_tokens": 1110, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a modern airport terminal with a glass door entrance, where a person is walking with luggage. The lighting is bright and natural, and the materials appear to be concrete and glass.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12543.4, "ram_available_mb": 50297.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.162}, "power_stats": {"power_gpu_soc_mean_watts": 20.543, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 73.162}, "timestamp": "2026-01-28T11:33:30.699932"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3949.385, "latencies_ms": [3949.385], "images_per_second": 0.253, "prompt_tokens": 1100, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image captures a cozy dining scene with a large pizza on a table, surrounded by empty glasses and a fork, with a television in the background.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12543.4, "ram_available_mb": 50297.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.419, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 73.97}, "timestamp": "2026-01-28T11:33:36.686198"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4251.925, "latencies_ms": [4251.925], "images_per_second": 0.235, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " pizza: 2, glasses: 2, forks: 2, knives: 1, spoons: 1, television: 1, tablecloth: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12542.7, "ram_available_mb": 50298.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.814, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-28T11:33:42.957040"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5032.332, "latencies_ms": [5032.332], "images_per_second": 0.199, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The pizza boxes are placed on the left side of the table, with the glasses of water positioned in the middle. The person sitting in the background is relatively far from the camera, while the television is in the background, closer to the camera.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 12542.7, "ram_available_mb": 50298.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.476}, "power_stats": {"power_gpu_soc_mean_watts": 19.672, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 72.476}, "timestamp": "2026-01-28T11:33:50.030963"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3118.147, "latencies_ms": [3118.147], "images_per_second": 0.321, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of people are sitting around a table with pizza boxes and glasses of soda.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.269}, "power_stats": {"power_gpu_soc_mean_watts": 22.58, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 82.269}, "timestamp": "2026-01-28T11:33:55.192474"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4847.663, "latencies_ms": [4847.663], "images_per_second": 0.206, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image is taken in a room with a warm and cozy atmosphere, with the colors of the pizza boxes and the tablecloth being the main focus. The lighting is soft and natural, coming from the window in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.675}, "power_stats": {"power_gpu_soc_mean_watts": 19.935, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 72.675}, "timestamp": "2026-01-28T11:34:02.077358"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3411.413, "latencies_ms": [3411.413], "images_per_second": 0.293, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young boy is standing at home plate in a baseball game, wearing a helmet and holding a bat.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.353, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 79.893}, "timestamp": "2026-01-28T11:34:07.532662"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5788.701, "latencies_ms": [5788.701], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. helmet: 1\n3. catcher's mitt: 1\n4. baseball: 1\n5. boy: 1\n6. grass: 1\n7. tree: 1\n8. bench: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12542.6, "ram_available_mb": 50298.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.438}, "power_stats": {"power_gpu_soc_mean_watts": 18.821, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 68.438}, "timestamp": "2026-01-28T11:34:15.360446"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4292.927, "latencies_ms": [4292.927], "images_per_second": 0.233, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12542.8, "ram_available_mb": 50298.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.611}, "power_stats": {"power_gpu_soc_mean_watts": 20.816, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 75.611}, "timestamp": "2026-01-28T11:34:21.692304"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3189.826, "latencies_ms": [3189.826], "images_per_second": 0.313, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young boy is playing baseball in a park with a catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.423}, "power_stats": {"power_gpu_soc_mean_watts": 22.815, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 80.423}, "timestamp": "2026-01-28T11:34:26.909579"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4304.479, "latencies_ms": [4304.479], "images_per_second": 0.232, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is taken during a sunny day with clear blue skies. The colors in the image are vibrant, with the green grass and trees providing a natural backdrop to the baseball game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.639, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 75.222}, "timestamp": "2026-01-28T11:34:33.247357"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3419.624, "latencies_ms": [3419.624], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A banana is placed on top of a black Philips phone, which is connected to a coiled cord.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12544.5, "ram_available_mb": 50296.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.541, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 79.714}, "timestamp": "2026-01-28T11:34:38.695025"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4322.017, "latencies_ms": [4322.017], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " banana: 1, phone: 1, pen: 1, paper: 1, computer: 1, coiled cord: 1, desk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.5, "ram_available_mb": 50296.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.914}, "power_stats": {"power_gpu_soc_mean_watts": 20.93, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 74.914}, "timestamp": "2026-01-28T11:34:45.032187"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4446.202, "latencies_ms": [4446.202], "images_per_second": 0.225, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is positioned to the right of the phone, which is placed on the left side of the desk. The notebook is located in the foreground, closer to the camera than the banana.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.378}, "power_stats": {"power_gpu_soc_mean_watts": 20.514, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 73.378}, "timestamp": "2026-01-28T11:34:51.489522"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3448.199, "latencies_ms": [3448.199], "images_per_second": 0.29, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A banana is on top of a phone and a piece of paper with writing on it is on the desk.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12543.9, "ram_available_mb": 50297.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.345}, "power_stats": {"power_gpu_soc_mean_watts": 22.33, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 76.345}, "timestamp": "2026-01-28T11:34:56.988259"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4296.932, "latencies_ms": [4296.932], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the left side. The banana is yellow and ripe, and the phone is black with a blue screen.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12543.9, "ram_available_mb": 50297.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.582, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 73.417}, "timestamp": "2026-01-28T11:35:03.342357"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4772.972, "latencies_ms": [4772.972], "images_per_second": 0.21, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a bustling scene of a crowd of people, with individuals of various ages and attires, including a person holding a large teddy bear, all engaged in different activities, creating a lively and dynamic atmosphere.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.2}, "power_stats": {"power_gpu_soc_mean_watts": 19.983, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-28T11:35:10.151217"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5861.197, "latencies_ms": [5861.197], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. crowd: 10\n2. person: 10\n3. backpack: 5\n4. handbag: 5\n5. purse: 5\n6. purse: 5\n7. handbag: 5\n8. handbag: 5", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.469}, "power_stats": {"power_gpu_soc_mean_watts": 18.931, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 71.469}, "timestamp": "2026-01-28T11:35:18.044814"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4270.048, "latencies_ms": [4270.048], "images_per_second": 0.234, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the crowd of people in the background. The people are standing close to each other, indicating a crowded environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12545.4, "ram_available_mb": 50295.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.389}, "power_stats": {"power_gpu_soc_mean_watts": 20.615, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 73.389}, "timestamp": "2026-01-28T11:35:24.337904"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2990.006, "latencies_ms": [2990.006], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large crowd of people are walking down a busy street in a city.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12545.4, "ram_available_mb": 50295.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.68}, "power_stats": {"power_gpu_soc_mean_watts": 23.567, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 81.68}, "timestamp": "2026-01-28T11:35:29.355041"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3307.782, "latencies_ms": [3307.782], "images_per_second": 0.302, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the colors are vibrant and varied.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.148}, "power_stats": {"power_gpu_soc_mean_watts": 22.741, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 77.148}, "timestamp": "2026-01-28T11:35:34.681736"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4317.619, "latencies_ms": [4317.619], "images_per_second": 0.232, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a man wearing a red shirt is holding a baby in his arms, while a brown horse is leaning its head over a wooden fence to nuzzle the man.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.083}, "power_stats": {"power_gpu_soc_mean_watts": 20.762, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 76.083}, "timestamp": "2026-01-28T11:35:41.036005"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6037.057, "latencies_ms": [6037.057], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. horse: 1\n2. man: 1\n3. child: 1\n4. brick wall: 1\n5. wooden beams: 1\n6. horse's nose: 1\n7. man's hand: 1\n8. child's hand: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.48}, "power_stats": {"power_gpu_soc_mean_watts": 18.417, "power_cpu_cv_mean_watts": 2.131, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 70.48}, "timestamp": "2026-01-28T11:35:49.089098"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4699.862, "latencies_ms": [4699.862], "images_per_second": 0.213, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is standing to the left of the horse, and the baby is in his arms, which are positioned in the foreground. The horse is in the background, and the man is in front of the horse.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.256}, "power_stats": {"power_gpu_soc_mean_watts": 20.394, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 74.256}, "timestamp": "2026-01-28T11:35:55.799858"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2949.436, "latencies_ms": [2949.436], "images_per_second": 0.339, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man and a child are petting a horse in a stable.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.208}, "power_stats": {"power_gpu_soc_mean_watts": 23.13, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 84.208}, "timestamp": "2026-01-28T11:36:00.779876"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6848.985, "latencies_ms": [6848.985], "images_per_second": 0.146, "prompt_tokens": 1110, "response_tokens_est": 77, "n_tiles": 1, "output_text": " The image features a brown horse with a white blaze on its face, standing in a stable with a man in a red shirt holding a baby. The horse is looking at the baby, who is wearing a white shirt with blue stars. The stable has a wooden roof and a brick wall. The lighting is natural, coming from the sun, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.053}, "power_stats": {"power_gpu_soc_mean_watts": 17.87, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 70.053}, "timestamp": "2026-01-28T11:36:09.641431"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2751.409, "latencies_ms": [2751.409], "images_per_second": 0.363, "prompt_tokens": 1100, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A banana and peanut butter are on a plate.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.409}, "power_stats": {"power_gpu_soc_mean_watts": 23.868, "power_cpu_cv_mean_watts": 1.238, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 84.409}, "timestamp": "2026-01-28T11:36:14.428156"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3037.641, "latencies_ms": [3037.641], "images_per_second": 0.329, "prompt_tokens": 1114, "response_tokens_est": 15, "n_tiles": 1, "output_text": " banana: 1, plate: 1, peanut butter: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.408, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 80.08}, "timestamp": "2026-01-28T11:36:19.497997"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4305.784, "latencies_ms": [4305.784], "images_per_second": 0.232, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The banana is on the left side of the plate, and the peanut butter is on the right side. The plate is in the foreground, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.771, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 75.972}, "timestamp": "2026-01-28T11:36:25.830783"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2870.026, "latencies_ms": [2870.026], "images_per_second": 0.348, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and peanut butter are on a plate on a table.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.213, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.838, "gpu_utilization_percent_mean": 84.667}, "timestamp": "2026-01-28T11:36:30.738974"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3573.949, "latencies_ms": [3573.949], "images_per_second": 0.28, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image shows a white plate with a banana and peanut butter on it. The plate is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12544.1, "ram_available_mb": 50296.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12543.6, "ram_available_mb": 50297.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.467}, "power_stats": {"power_gpu_soc_mean_watts": 22.134, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 77.467}, "timestamp": "2026-01-28T11:36:36.338974"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3519.253, "latencies_ms": [3519.253], "images_per_second": 0.284, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man in a green shirt and dark pants is working on a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12543.6, "ram_available_mb": 50297.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.276}, "power_stats": {"power_gpu_soc_mean_watts": 22.29, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 75.276}, "timestamp": "2026-01-28T11:36:41.890308"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5608.67, "latencies_ms": [5608.67], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. motorcycle: 1\n3. bicycle: 1\n4. scooter: 1\n5. wheel: 1\n6. tire: 1\n7. tool: 1\n8. pavement: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12543.5, "ram_available_mb": 50297.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.968, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 72.638}, "timestamp": "2026-01-28T11:36:49.518797"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5745.757, "latencies_ms": [5745.757], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The man is kneeling on the ground, which is in the foreground of the image. He is working on a bicycle wheel, which is near the center of the image. In the background, there are other bicycles and a motorcycle parked, suggesting that this is a busy area with multiple vehicles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12543.3, "ram_available_mb": 50297.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.938}, "power_stats": {"power_gpu_soc_mean_watts": 18.726, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 69.938}, "timestamp": "2026-01-28T11:36:57.279307"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3802.562, "latencies_ms": [3802.562], "images_per_second": 0.263, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a green shirt and blue pants is fixing a bicycle wheel on the ground. There are several motorcycles parked in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.935}, "power_stats": {"power_gpu_soc_mean_watts": 21.704, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 76.935}, "timestamp": "2026-01-28T11:37:03.107128"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6084.731, "latencies_ms": [6084.731], "images_per_second": 0.164, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image depicts a man wearing a green shirt and blue pants, kneeling on the ground while working on a bicycle wheel. The scene is set in an outdoor environment with a brick pavement and a motorcycle parked in the background. The lighting appears to be natural, possibly from the sun, and the weather seems to be clear.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12543.8, "ram_available_mb": 50297.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.487, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 71.804}, "timestamp": "2026-01-28T11:37:11.218310"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3370.181, "latencies_ms": [3370.181], "images_per_second": 0.297, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A skateboarder with dreadlocks is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12544.0, "ram_available_mb": 50296.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.107}, "power_stats": {"power_gpu_soc_mean_watts": 22.255, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 79.107}, "timestamp": "2026-01-28T11:37:16.637124"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5669.953, "latencies_ms": [5669.953], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. fence: 1\n4. grass: 1\n5. building: 1\n6. tree: 1\n7. wristband: 1\n8. camera: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.3, "ram_available_mb": 50296.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.213}, "power_stats": {"power_gpu_soc_mean_watts": 19.112, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 70.213}, "timestamp": "2026-01-28T11:37:24.320266"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5412.141, "latencies_ms": [5412.141], "images_per_second": 0.185, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on a ramp. The ramp is located in the middle ground, with the skateboarder's shadow visible on the ramp. The background features a fence and trees, indicating that the skatepark is outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.289}, "power_stats": {"power_gpu_soc_mean_watts": 19.04, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 72.289}, "timestamp": "2026-01-28T11:37:31.769337"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3026.464, "latencies_ms": [3026.464], "images_per_second": 0.33, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12543.7, "ram_available_mb": 50297.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.04}, "power_stats": {"power_gpu_soc_mean_watts": 22.765, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 83.04}, "timestamp": "2026-01-28T11:37:36.834111"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4735.885, "latencies_ms": [4735.885], "images_per_second": 0.211, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with the skateboarder wearing a black t-shirt and black pants. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12544.2, "ram_available_mb": 50296.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.154}, "power_stats": {"power_gpu_soc_mean_watts": 20.147, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.154}, "timestamp": "2026-01-28T11:37:43.611519"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9851.237, "latencies_ms": [9851.237], "images_per_second": 0.102, "prompt_tokens": 1099, "response_tokens_est": 128, "n_tiles": 1, "output_text": " In the image, a group of five individuals are gathered on a grassy field, each holding a frisbee. They are arranged in a line, with the person on the far left holding a white frisbee, followed by a person in a blue shirt, a person in a red shirt, a person in a white shirt, and finally a person in a blue shirt on the far right. The frisbees are of different colors, with the person in the blue shirt holding a green frisbee, the person in the red shirt holding a white frisbee, the person in the white shirt holding a red frisbee", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12544.6, "ram_available_mb": 50296.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12544.5, "ram_available_mb": 50296.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.238}, "power_stats": {"power_gpu_soc_mean_watts": 16.201, "power_cpu_cv_mean_watts": 2.264, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 69.238}, "timestamp": "2026-01-28T11:37:55.505385"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5832.604, "latencies_ms": [5832.604], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. frisbee: 5\n2. person: 5\n3. headband: 1\n4. shorts: 4\n5. shirt: 4\n6. shoes: 4\n7. grass: 1\n8. goal post: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.5, "ram_available_mb": 50296.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12545.4, "ram_available_mb": 50295.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.776}, "power_stats": {"power_gpu_soc_mean_watts": 18.381, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 71.776}, "timestamp": "2026-01-28T11:38:03.364358"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9588.194, "latencies_ms": [9588.194], "images_per_second": 0.104, "prompt_tokens": 1117, "response_tokens_est": 123, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the person on the left holding the frisbee closest to the camera, and the person on the right holding the frisbee farthest from the camera. The frisbees are arranged in a line, with the person on the left holding the first frisbee, and the person on the right holding the last frisbee. The frisbees are held at different heights, with the person on the left holding the frisbee closest to the ground, and the person on the right holding the frisbee closest to the person in front of them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12545.4, "ram_available_mb": 50295.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.111}, "power_stats": {"power_gpu_soc_mean_watts": 16.312, "power_cpu_cv_mean_watts": 2.081, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 67.111}, "timestamp": "2026-01-28T11:38:14.998660"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3139.685, "latencies_ms": [3139.685], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are posing for a picture on a grassy field at sunset.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.386, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.823, "gpu_utilization_percent_mean": 78.28}, "timestamp": "2026-01-28T11:38:20.159983"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5517.604, "latencies_ms": [5517.604], "images_per_second": 0.181, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a group of five people posing for a photo on a grassy field at sunset. The sky is painted with hues of orange and blue, and the sun is setting in the background. The people are holding frisbees, which are white with green and red designs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.37}, "power_stats": {"power_gpu_soc_mean_watts": 18.986, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.37}, "timestamp": "2026-01-28T11:38:27.718267"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9680.197, "latencies_ms": [9680.197], "images_per_second": 0.103, "prompt_tokens": 1099, "response_tokens_est": 125, "n_tiles": 1, "output_text": " The image captures a scene at an airport where a large white airplane adorned with red and black accents is parked at a gate, with a red and white logo prominently displayed on its side. The airplane is surrounded by various airport vehicles and equipment, including a luggage cart and a fuel truck, indicating ongoing preparations for a flight. The sky above is a clear blue, and the airport's surroundings are visible in the background, including a terminal building and a few other airplanes. The image also features a yellow arrow painted on the ground, pointing towards the airplane, possibly indicating the direction of the boarding process or the path to the airplane.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.024}, "power_stats": {"power_gpu_soc_mean_watts": 16.293, "power_cpu_cv_mean_watts": 2.099, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 67.024}, "timestamp": "2026-01-28T11:38:39.431714"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5876.451, "latencies_ms": [5876.451], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 1\n4. engine: 1\n5. jet bridge: 1\n6. luggage cart: 1\n7. ground crew: 1\n8. terminal building: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.531}, "power_stats": {"power_gpu_soc_mean_watts": 18.399, "power_cpu_cv_mean_watts": 2.068, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 70.531}, "timestamp": "2026-01-28T11:38:47.342345"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5231.455, "latencies_ms": [5231.455], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The airplane is positioned on the left side of the image, with the terminal building located on the right side. The airplane is in the foreground, while the terminal building is in the background. The airplane is closer to the viewer than the terminal building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.093}, "power_stats": {"power_gpu_soc_mean_watts": 19.336, "power_cpu_cv_mean_watts": 1.946, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 72.093}, "timestamp": "2026-01-28T11:38:54.586130"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7203.816, "latencies_ms": [7203.816], "images_per_second": 0.139, "prompt_tokens": 1111, "response_tokens_est": 83, "n_tiles": 1, "output_text": " The image captures a moment at an airport where a large white airplane with red and white accents is parked at a gate. The airplane is adorned with the logo of Japan Airlines, and the word \"JAL\" is prominently displayed on its side. The sky above is a clear blue, dotted with fluffy white clouds, and the airport tarmac is marked with yellow arrows and lines, guiding the flow of airport operations.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.833}, "power_stats": {"power_gpu_soc_mean_watts": 17.389, "power_cpu_cv_mean_watts": 2.189, "power_sys_5v0_mean_watts": 7.677, "gpu_utilization_percent_mean": 68.833}, "timestamp": "2026-01-28T11:39:03.812089"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3245.763, "latencies_ms": [3245.763], "images_per_second": 0.308, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The airplane is white with red and black accents, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.963}, "power_stats": {"power_gpu_soc_mean_watts": 22.991, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.856, "gpu_utilization_percent_mean": 79.963}, "timestamp": "2026-01-28T11:39:09.115419"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3442.407, "latencies_ms": [3442.407], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young man wearing a yellow shirt and black pants is skateboarding on a ramp with graffiti on it.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.31}, "power_stats": {"power_gpu_soc_mean_watts": 22.18, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 79.31}, "timestamp": "2026-01-28T11:39:14.608128"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5686.93, "latencies_ms": [5686.93], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. bench: 1\n4. trash can: 1\n5. fence: 1\n6. car: 1\n7. grass: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.708}, "power_stats": {"power_gpu_soc_mean_watts": 18.733, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 71.708}, "timestamp": "2026-01-28T11:39:22.307906"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4945.758, "latencies_ms": [4945.758], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The skateboarder is positioned to the right of the graffiti-covered ramp, with the ramp situated in the foreground of the image. The skateboarder is also relatively close to the camera, while the ramp is farther away.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12544.7, "ram_available_mb": 50296.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.659}, "power_stats": {"power_gpu_soc_mean_watts": 19.927, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 74.659}, "timestamp": "2026-01-28T11:39:29.273013"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3134.366, "latencies_ms": [3134.366], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12545.8, "ram_available_mb": 50295.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.577}, "power_stats": {"power_gpu_soc_mean_watts": 22.827, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 82.577}, "timestamp": "2026-01-28T11:39:34.442587"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5797.51, "latencies_ms": [5797.51], "images_per_second": 0.172, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with vibrant colors of the ramp and the skateboard contrasting against the natural green grass and the clear blue sky. The lighting is bright and sunny, casting sharp shadows on the ground and highlighting the skateboarder's movements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.8, "ram_available_mb": 50295.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.589, "power_cpu_cv_mean_watts": 2.086, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-28T11:39:42.263071"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3316.761, "latencies_ms": [3316.761], "images_per_second": 0.301, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle sits on a white plate with gold floral designs.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12545.5, "ram_available_mb": 50295.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.622, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 79.556}, "timestamp": "2026-01-28T11:39:47.606514"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5723.17, "latencies_ms": [5723.17], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 1\n2. cake: 1\n3. syrup: 1\n4. chocolate: 1\n5. plate's design: 1\n6. table: 1\n7. background: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12545.5, "ram_available_mb": 50295.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.688}, "power_stats": {"power_gpu_soc_mean_watts": 18.639, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 72.688}, "timestamp": "2026-01-28T11:39:55.354514"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4863.432, "latencies_ms": [4863.432], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The slice of chocolate cake is positioned on the right side of the plate, which is placed on a wooden table. The cake is in the foreground, with the plate and the table being the background elements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.7}, "power_stats": {"power_gpu_soc_mean_watts": 19.404, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.651, "gpu_utilization_percent_mean": 70.7}, "timestamp": "2026-01-28T11:40:02.250840"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3004.672, "latencies_ms": [3004.672], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A slice of chocolate cake is on a plate with a gold rim.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.578, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 79.333}, "timestamp": "2026-01-28T11:40:07.291287"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4430.976, "latencies_ms": [4430.976], "images_per_second": 0.226, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The slice of chocolate cake is on a white plate with gold designs, and the plate is on a wooden table. The lighting is bright and natural, and the cake is shiny and moist.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.973}, "power_stats": {"power_gpu_soc_mean_watts": 20.396, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 74.973}, "timestamp": "2026-01-28T11:40:13.763681"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4728.011, "latencies_ms": [4728.011], "images_per_second": 0.212, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a man is seated at a desk in a cluttered office space, surrounded by various electronic devices and equipment, while a group of people are gathered around a table, engaged in a discussion or activity.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.692}, "power_stats": {"power_gpu_soc_mean_watts": 20.403, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 74.692}, "timestamp": "2026-01-28T11:40:20.548434"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5494.076, "latencies_ms": [5494.076], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. laptop: 2\n2. chair: 3\n3. person: 3\n4. table: 2\n5. box: 1\n6. monitor: 1\n7. keyboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12545.5, "ram_available_mb": 50295.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.304}, "power_stats": {"power_gpu_soc_mean_watts": 19.352, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 72.304}, "timestamp": "2026-01-28T11:40:28.074995"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4641.426, "latencies_ms": [4641.426], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man is sitting in the foreground, working on his laptop. The other people are in the background, working on their laptops. The boxes are in the background, and the chairs are in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.5, "ram_available_mb": 50295.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.821}, "power_stats": {"power_gpu_soc_mean_watts": 20.393, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-28T11:40:34.769695"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3152.514, "latencies_ms": [3152.514], "images_per_second": 0.317, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are working in a cluttered office with computers and laptops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.462}, "power_stats": {"power_gpu_soc_mean_watts": 22.844, "power_cpu_cv_mean_watts": 1.324, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 80.462}, "timestamp": "2026-01-28T11:40:39.983438"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3508.793, "latencies_ms": [3508.793], "images_per_second": 0.285, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is lit with fluorescent lighting, and the walls are painted white. The floor is covered with yellow paint.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.331, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 76.207}, "timestamp": "2026-01-28T11:40:45.549994"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6617.601, "latencies_ms": [6617.601], "images_per_second": 0.151, "prompt_tokens": 1099, "response_tokens_est": 75, "n_tiles": 1, "output_text": " In the image, a group of people are gathered in a living room, engaging in a video game session. The room is furnished with a blue couch, a wooden coffee table, and a wooden entertainment center. The individuals are holding Wii remotes, indicating that they are playing a video game. The room is well-lit, with natural light coming from the windows.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.75}, "power_stats": {"power_gpu_soc_mean_watts": 17.866, "power_cpu_cv_mean_watts": 2.195, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 70.75}, "timestamp": "2026-01-28T11:40:54.205827"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5672.405, "latencies_ms": [5672.405], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. Wii remote: 1\n2. Woman: 1\n3. Man: 2\n4. Man: 1\n5. Woman: 1\n6. Woman: 1\n7. Woman: 1\n8. Woman: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.043}, "power_stats": {"power_gpu_soc_mean_watts": 19.054, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 72.043}, "timestamp": "2026-01-28T11:41:01.917276"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7466.2, "latencies_ms": [7466.2], "images_per_second": 0.134, "prompt_tokens": 1117, "response_tokens_est": 88, "n_tiles": 1, "output_text": " The woman is holding a Wii remote in her right hand and is standing to the left of the couch. The couch is located in the middle of the room, with the woman standing to its right. The man in the green shirt is standing to the right of the couch, while the man in the blue shirt is standing to the left of the couch. The woman is standing closer to the camera than the man in the green shirt.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12546.8, "ram_available_mb": 50294.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.429}, "power_stats": {"power_gpu_soc_mean_watts": 17.5, "power_cpu_cv_mean_watts": 2.161, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 69.429}, "timestamp": "2026-01-28T11:41:11.424015"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3042.957, "latencies_ms": [3042.957], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.8, "ram_available_mb": 50294.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.083, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 78.52}, "timestamp": "2026-01-28T11:41:16.492708"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3415.561, "latencies_ms": [3415.561], "images_per_second": 0.293, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is lit by natural light coming from the windows, and the carpet is a light grey color.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.511, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 76.5}, "timestamp": "2026-01-28T11:41:21.923954"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3355.635, "latencies_ms": [3355.635], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person stands on a beach at sunset, with a frisbee in the air above them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.074}, "power_stats": {"power_gpu_soc_mean_watts": 22.739, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 75.074}, "timestamp": "2026-01-28T11:41:27.326680"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5700.732, "latencies_ms": [5700.732], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. sun: 1\n3. water: 1\n4. ice: 1\n5. sky: 1\n6. sand: 1\n7. frisbee: 1\n8. reflection: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.298}, "power_stats": {"power_gpu_soc_mean_watts": 18.806, "power_cpu_cv_mean_watts": 1.976, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 70.298}, "timestamp": "2026-01-28T11:41:35.050842"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4778.949, "latencies_ms": [4778.949], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The person is standing on the left side of the image, with the sun in the center and the water on the right. The person is closer to the camera than the sun, and the water is farther away.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.95}, "power_stats": {"power_gpu_soc_mean_watts": 20.014, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 73.95}, "timestamp": "2026-01-28T11:41:41.863260"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5880.42, "latencies_ms": [5880.42], "images_per_second": 0.17, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a serene beach scene at sunset, where a lone figure stands on the shore, silhouetted against the vibrant orange and yellow hues of the setting sun. The water is calm, with gentle waves lapping at the shore, and the sky is a clear blue, dotted with a few clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.163}, "power_stats": {"power_gpu_soc_mean_watts": 18.633, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 71.163}, "timestamp": "2026-01-28T11:41:49.781961"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5264.965, "latencies_ms": [5264.965], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a serene beach scene during sunset, with the sun casting a warm glow over the water and sand. The sky is painted with hues of orange and yellow, while the water reflects the vibrant colors, creating a beautiful contrast with the surrounding landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12544.9, "ram_available_mb": 50296.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12544.8, "ram_available_mb": 50296.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.841}, "power_stats": {"power_gpu_soc_mean_watts": 19.132, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 70.841}, "timestamp": "2026-01-28T11:41:57.067990"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4979.178, "latencies_ms": [4979.178], "images_per_second": 0.201, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a modern living room with a white sofa, a black coffee table, a dining table with four chairs, a television on a stand, a floor lamp, a vase with flowers, and a variety of wall decorations.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12544.8, "ram_available_mb": 50296.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.707}, "power_stats": {"power_gpu_soc_mean_watts": 19.68, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 71.707}, "timestamp": "2026-01-28T11:42:04.095328"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6245.943, "latencies_ms": [6245.943], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. white sofa: 1\n2. red chairs: 2\n3. white table: 1\n4. black and white rug: 1\n5. television: 1\n6. vase with flowers: 1\n7. wall art: 4\n8. floor lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.577}, "power_stats": {"power_gpu_soc_mean_watts": 18.197, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 7.692, "gpu_utilization_percent_mean": 69.577}, "timestamp": "2026-01-28T11:42:12.369915"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6036.081, "latencies_ms": [6036.081], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The living room is situated in the foreground of the image, with the dining table and chairs placed in the center. The television is mounted on the wall in the background, and the sofa is positioned to the left of the television. The window is located behind the sofa, allowing natural light to flood the room.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.74}, "power_stats": {"power_gpu_soc_mean_watts": 18.606, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 69.74}, "timestamp": "2026-01-28T11:42:20.419190"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3549.324, "latencies_ms": [3549.324], "images_per_second": 0.282, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A living room with a white couch, a dining table, and a television set is shown in the image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12546.0, "ram_available_mb": 50294.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.483}, "power_stats": {"power_gpu_soc_mean_watts": 22.04, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 77.483}, "timestamp": "2026-01-28T11:42:26.013917"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3886.163, "latencies_ms": [3886.163], "images_per_second": 0.257, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the windows. The walls are painted white and the furniture is mostly black and white.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12546.0, "ram_available_mb": 50294.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12547.5, "ram_available_mb": 50293.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.479, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 75.562}, "timestamp": "2026-01-28T11:42:31.945883"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3200.194, "latencies_ms": [3200.194], "images_per_second": 0.312, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A cat is standing on top of a blue refrigerator, looking up at the camera.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12547.5, "ram_available_mb": 50293.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.192}, "power_stats": {"power_gpu_soc_mean_watts": 22.876, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 81.192}, "timestamp": "2026-01-28T11:42:37.185278"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5690.92, "latencies_ms": [5690.92], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cat: 1\n2. refrigerator: 1\n3. cabinet: 1\n4. door: 1\n5. light: 1\n6. shelf: 1\n7. cupboard: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.91, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 72.596}, "timestamp": "2026-01-28T11:42:44.915814"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5074.126, "latencies_ms": [5074.126], "images_per_second": 0.197, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, on top of the refrigerator, while the refrigerator is situated in the middle ground, between the cat and the wall. The wall is in the background, providing a sense of depth to the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.476}, "power_stats": {"power_gpu_soc_mean_watts": 19.388, "power_cpu_cv_mean_watts": 2.336, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 73.476}, "timestamp": "2026-01-28T11:42:52.002784"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2931.001, "latencies_ms": [2931.001], "images_per_second": 0.341, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A cat is standing on top of a refrigerator in a kitchen.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.292}, "power_stats": {"power_gpu_soc_mean_watts": 23.58, "power_cpu_cv_mean_watts": 2.152, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 82.292}, "timestamp": "2026-01-28T11:42:56.963206"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4503.511, "latencies_ms": [4503.511], "images_per_second": 0.222, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a cat standing on top of a blue refrigerator, with a white cabinet in the background. The lighting is natural, coming from a window on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.447}, "power_stats": {"power_gpu_soc_mean_watts": 20.027, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 75.447}, "timestamp": "2026-01-28T11:43:03.493762"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7510.257, "latencies_ms": [7510.257], "images_per_second": 0.133, "prompt_tokens": 1099, "response_tokens_est": 89, "n_tiles": 1, "output_text": " The image depicts a room with a variety of objects, including a refrigerator adorned with numerous photos and magnets, a wooden table with a microwave and a toaster oven, a bookshelf filled with books and decorative items, a bed with a blanket and pillows, and a wall decorated with framed pictures and a chandelier. The room also features balloons in different colors, such as blue, green, and yellow, and a rug on the floor.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.444}, "power_stats": {"power_gpu_soc_mean_watts": 17.472, "power_cpu_cv_mean_watts": 2.314, "power_sys_5v0_mean_watts": 7.679, "gpu_utilization_percent_mean": 70.444}, "timestamp": "2026-01-28T11:43:13.065487"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9056.096, "latencies_ms": [9056.096], "images_per_second": 0.11, "prompt_tokens": 1113, "response_tokens_est": 114, "n_tiles": 1, "output_text": " refrigerator: 1, microwave: 1, toaster: 1, oven: 1, television: 1, bookshelf: 1, chair: 1, table: 1, rug: 1, balloon: 4, wall: 1, mirror: 1, curtain: 1, light: 1, wall art: 1, plant: 1, wall: 1, door: 1, floor: 1, ceiling: 1, light fixture: 1, balloon string: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.597}, "power_stats": {"power_gpu_soc_mean_watts": 16.332, "power_cpu_cv_mean_watts": 2.095, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 68.597}, "timestamp": "2026-01-28T11:43:24.148272"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5229.278, "latencies_ms": [5229.278], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The refrigerator is on the left side of the room, the couch is on the right side, and the desk is in the middle. The balloons are in the foreground, the bookshelves are in the background, and the mirror is on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.773}, "power_stats": {"power_gpu_soc_mean_watts": 19.47, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.773}, "timestamp": "2026-01-28T11:43:31.399207"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2932.899, "latencies_ms": [2932.899], "images_per_second": 0.341, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A room with a fridge, a table, and a couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12546.9, "ram_available_mb": 50294.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.708}, "power_stats": {"power_gpu_soc_mean_watts": 23.697, "power_cpu_cv_mean_watts": 1.284, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 76.708}, "timestamp": "2026-01-28T11:43:36.393462"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3005.171, "latencies_ms": [3005.171], "images_per_second": 0.333, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The room is lit by a chandelier and has wooden floors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.9, "ram_available_mb": 50294.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.48}, "power_stats": {"power_gpu_soc_mean_watts": 22.906, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 82.48}, "timestamp": "2026-01-28T11:43:41.433291"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2942.574, "latencies_ms": [2942.574], "images_per_second": 0.34, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man wearing headphones is sitting in a train and using a laptop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.792}, "power_stats": {"power_gpu_soc_mean_watts": 23.614, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 78.792}, "timestamp": "2026-01-28T11:43:46.416972"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5670.369, "latencies_ms": [5670.369], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. laptop: 1\n3. headset: 1\n4. chair: 1\n5. window: 1\n6. train: 1\n7. table: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.83}, "power_stats": {"power_gpu_soc_mean_watts": 18.664, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 70.83}, "timestamp": "2026-01-28T11:43:54.101378"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4801.518, "latencies_ms": [4801.518], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The laptop is in the foreground, on the table, and the man is sitting in the middle of the image. The window is on the left side of the image, and the train tracks are in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12546.1, "ram_available_mb": 50294.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12547.0, "ram_available_mb": 50293.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.825}, "power_stats": {"power_gpu_soc_mean_watts": 19.797, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 71.825}, "timestamp": "2026-01-28T11:44:00.922183"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2966.006, "latencies_ms": [2966.006], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man wearing headphones is sitting in a train and using a laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12547.0, "ram_available_mb": 50293.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12547.5, "ram_available_mb": 50293.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.292}, "power_stats": {"power_gpu_soc_mean_watts": 23.546, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 83.292}, "timestamp": "2026-01-28T11:44:05.906790"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5276.434, "latencies_ms": [5276.434], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image depicts a man wearing headphones and using a laptop on a train. The train has a window with a view of the tracks outside. The lighting is natural, coming from the window, and the colors are muted due to the overcast weather.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12547.5, "ram_available_mb": 50293.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12547.3, "ram_available_mb": 50293.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.318}, "power_stats": {"power_gpu_soc_mean_watts": 19.287, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 72.318}, "timestamp": "2026-01-28T11:44:13.234126"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5360.68, "latencies_ms": [5360.68], "images_per_second": 0.187, "prompt_tokens": 1099, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a bustling train station with a striking white bridge arching gracefully over the tracks, while a sleek train glides smoothly along the tracks, and a red car is parked on the road, all under a clear blue sky dotted with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12547.3, "ram_available_mb": 50293.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12547.1, "ram_available_mb": 50293.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.215, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-28T11:44:20.636327"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5667.239, "latencies_ms": [5667.239], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. train tracks: 4\n3. train: 1\n4. train station: 1\n5. road: 1\n6. sky: 1\n7. clouds: 1\n8. buildings: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12547.1, "ram_available_mb": 50293.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12549.1, "ram_available_mb": 50291.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.75}, "power_stats": {"power_gpu_soc_mean_watts": 18.726, "power_cpu_cv_mean_watts": 2.086, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 72.75}, "timestamp": "2026-01-28T11:44:28.352143"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4887.934, "latencies_ms": [4887.934], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The train station is located in the foreground, with the bridge stretching across the image, and the city skyline is visible in the background. The train tracks are parallel to each other, and the bridge is positioned above them.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12549.1, "ram_available_mb": 50291.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12548.9, "ram_available_mb": 50292.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.902, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.976}, "timestamp": "2026-01-28T11:44:35.274954"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5596.685, "latencies_ms": [5596.685], "images_per_second": 0.179, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a bustling train station nestled amidst a serene landscape. The station, a marvel of modern engineering, boasts a striking white truss bridge that arches gracefully over the tracks. The sky above is a clear blue, dotted with fluffy white clouds, providing a beautiful backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12548.9, "ram_available_mb": 50292.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12549.1, "ram_available_mb": 50291.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.702}, "power_stats": {"power_gpu_soc_mean_watts": 18.741, "power_cpu_cv_mean_watts": 1.968, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.702}, "timestamp": "2026-01-28T11:44:42.903562"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3518.538, "latencies_ms": [3518.538], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image features a white bridge with a unique triangular design, and the sky is filled with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12549.1, "ram_available_mb": 50291.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12549.1, "ram_available_mb": 50291.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.016, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 78.724}, "timestamp": "2026-01-28T11:44:48.457176"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4324.286, "latencies_ms": [4324.286], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a group of people are enjoying a day at the park, with a kite flying high in the sky, and a man in a white shirt is flying it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12549.1, "ram_available_mb": 50291.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12548.3, "ram_available_mb": 50292.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.895, "power_cpu_cv_mean_watts": 1.899, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 72.8}, "timestamp": "2026-01-28T11:44:54.833267"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4509.482, "latencies_ms": [4509.482], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " kite: 1, person: 2, grass: 1, person: 2, person: 2, person: 2, person: 2, person: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12548.3, "ram_available_mb": 50292.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12549.5, "ram_available_mb": 50291.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.784}, "power_stats": {"power_gpu_soc_mean_watts": 20.31, "power_cpu_cv_mean_watts": 2.046, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 73.784}, "timestamp": "2026-01-28T11:45:01.371136"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5036.221, "latencies_ms": [5036.221], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the people are in the background, walking around the park. The kite is to the left of the people, and the park is to the right of the people.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12549.5, "ram_available_mb": 50291.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12547.8, "ram_available_mb": 50293.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.647, "power_cpu_cv_mean_watts": 2.237, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 71.244}, "timestamp": "2026-01-28T11:45:08.424486"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2971.77, "latencies_ms": [2971.77], "images_per_second": 0.336, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are flying a large kite in a park.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12547.8, "ram_available_mb": 50293.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12548.8, "ram_available_mb": 50292.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.195, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 83.667}, "timestamp": "2026-01-28T11:45:13.421714"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3107.671, "latencies_ms": [3107.671], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The kite is blue, purple, and yellow, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12548.8, "ram_available_mb": 50292.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12548.2, "ram_available_mb": 50292.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.97, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 82.5}, "timestamp": "2026-01-28T11:45:18.556310"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5125.309, "latencies_ms": [5125.309], "images_per_second": 0.195, "prompt_tokens": 1099, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a miniature model of a red and black train with the Virgin logo on its side, traveling on a track alongside a group of workers dressed in orange uniforms, all set against a backdrop of a green landscape with trees and a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12548.2, "ram_available_mb": 50292.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.302}, "power_stats": {"power_gpu_soc_mean_watts": 19.449, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 74.302}, "timestamp": "2026-01-28T11:45:25.717757"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4191.537, "latencies_ms": [4191.537], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " train: 1, workers: 4, railway: 2, tracks: 2, wires: 2, fence: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12548.2, "ram_available_mb": 50292.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.143}, "power_stats": {"power_gpu_soc_mean_watts": 20.885, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 76.143}, "timestamp": "2026-01-28T11:45:31.946362"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5109.82, "latencies_ms": [5109.82], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The red and black train is positioned on the left side of the image, with the workers on the right side. The train is in the foreground, while the workers are in the background. The train is closer to the viewer than the workers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12548.2, "ram_available_mb": 50292.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12545.8, "ram_available_mb": 50295.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.93}, "power_stats": {"power_gpu_soc_mean_watts": 19.42, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 73.93}, "timestamp": "2026-01-28T11:45:39.085748"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3924.214, "latencies_ms": [3924.214], "images_per_second": 0.255, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A model train is on a track with workers in orange uniforms. The train is red and black and has the word \"Virgin\" on it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12545.8, "ram_available_mb": 50295.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.438}, "power_stats": {"power_gpu_soc_mean_watts": 21.527, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.438}, "timestamp": "2026-01-28T11:45:45.033015"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6274.286, "latencies_ms": [6274.286], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image features a vibrant red and black model train with the Virgin logo on its side, traveling on a set of tracks. The train is surrounded by a lush green landscape with trees and bushes, and the sky is clear and blue. The lighting in the image is bright and natural, suggesting that the photo was taken during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.269}, "power_stats": {"power_gpu_soc_mean_watts": 18.086, "power_cpu_cv_mean_watts": 2.18, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 70.269}, "timestamp": "2026-01-28T11:45:53.333583"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3714.407, "latencies_ms": [3714.407], "images_per_second": 0.269, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image shows a close-up view of a cat's back, with its fur displaying a mix of brown and white colors.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12548.1, "ram_available_mb": 50292.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.467}, "power_stats": {"power_gpu_soc_mean_watts": 21.908, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 75.467}, "timestamp": "2026-01-28T11:45:59.074320"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5612.853, "latencies_ms": [5612.853], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. fur: 1\n3. tail: 1\n4. fabric: 1\n5. blanket: 1\n6. pattern: 1\n7. texture: 1\n8. color: 1", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12548.1, "ram_available_mb": 50292.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.745}, "power_stats": {"power_gpu_soc_mean_watts": 18.765, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 72.745}, "timestamp": "2026-01-28T11:46:06.756317"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4311.223, "latencies_ms": [4311.223], "images_per_second": 0.232, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The cat's tail is in the foreground, while the background is a textured beige blanket. The cat's fur is brown and white, and it appears to be lying down.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12546.9, "ram_available_mb": 50294.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.671, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 72.444}, "timestamp": "2026-01-28T11:46:13.117082"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3316.605, "latencies_ms": [3316.605], "images_per_second": 0.302, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cat's back is shown in a close-up photo, with a textured blanket in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12546.9, "ram_available_mb": 50294.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.575, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 77.593}, "timestamp": "2026-01-28T11:46:18.473012"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3922.135, "latencies_ms": [3922.135], "images_per_second": 0.255, "prompt_tokens": 1110, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image features a cat's fur with a mix of brown and white colors, and the lighting appears to be natural, possibly from a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.875}, "power_stats": {"power_gpu_soc_mean_watts": 21.378, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 73.875}, "timestamp": "2026-01-28T11:46:24.427168"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4541.751, "latencies_ms": [4541.751], "images_per_second": 0.22, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In the image, a cow is seen milking itself using a milking machine, with its udder being the main focus, and the machine is attached to the cow's udder.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12546.6, "ram_available_mb": 50294.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.433, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 74.868}, "timestamp": "2026-01-28T11:46:31.024385"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5619.818, "latencies_ms": [5619.818], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " cow: 1, cow's udder: 2, red cap: 2, white cap: 2, black and white cow: 1, black object: 1, yellow label: 1, black and white cow's udder: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.987, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 73.043}, "timestamp": "2026-01-28T11:46:38.663855"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5830.29, "latencies_ms": [5830.29], "images_per_second": 0.172, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The cow's udder is positioned in the foreground, with the black and white cow's body extending into the background. The red and white milking tubes are attached to the udder, with one tube on the left side and the other on the right side, both extending towards the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.545, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 70.49}, "timestamp": "2026-01-28T11:46:46.525513"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3118.973, "latencies_ms": [3118.973], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A cow is standing in a barn and milking herself using a milking machine.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12546.4, "ram_available_mb": 50294.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12546.8, "ram_available_mb": 50294.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.247, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 81.808}, "timestamp": "2026-01-28T11:46:51.677760"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4463.7, "latencies_ms": [4463.7], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a black and white cow with red and white udders, standing on a black and yellow mat. The lighting is natural and bright, illuminating the scene with a warm glow.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12546.8, "ram_available_mb": 50294.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12547.4, "ram_available_mb": 50293.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.456, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 76.351}, "timestamp": "2026-01-28T11:46:58.182004"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3970.864, "latencies_ms": [3970.864], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image features a plate with a sandwich cut in half, revealing its filling of red berries, placed on a green and white patterned tablecloth.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12547.4, "ram_available_mb": 50293.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.042, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.576}, "timestamp": "2026-01-28T11:47:04.213629"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3614.502, "latencies_ms": [3614.502], "images_per_second": 0.277, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " plate: 1, sandwich: 1, knife: 1, bread: 2, fruit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.7}, "power_stats": {"power_gpu_soc_mean_watts": 21.85, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 77.7}, "timestamp": "2026-01-28T11:47:09.843990"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4883.372, "latencies_ms": [4883.372], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the image, with the plate and knife placed to the right of it. The plate is positioned in the center of the image, with the sandwich and knife placed on top of it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.366}, "power_stats": {"power_gpu_soc_mean_watts": 19.642, "power_cpu_cv_mean_watts": 1.943, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 72.366}, "timestamp": "2026-01-28T11:47:16.756069"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3023.428, "latencies_ms": [3023.428], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate with a sandwich and a knife on a green tablecloth.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.226, "power_cpu_cv_mean_watts": 1.329, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 80.56}, "timestamp": "2026-01-28T11:47:21.815548"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4333.685, "latencies_ms": [4333.685], "images_per_second": 0.231, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sandwich is on a plate with a white and brown pattern, and the plate is on a green tablecloth. The lighting is dim and the sandwich is lit from the side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.361}, "power_stats": {"power_gpu_soc_mean_watts": 20.8, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 75.361}, "timestamp": "2026-01-28T11:47:28.180451"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4339.03, "latencies_ms": [4339.03], "images_per_second": 0.23, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a colorful and well-organized meal in a purple divided container, featuring a variety of food items including a salad, pasta with sauce, grapes, and carrots.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12545.3, "ram_available_mb": 50295.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.194}, "power_stats": {"power_gpu_soc_mean_watts": 20.591, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 75.194}, "timestamp": "2026-01-28T11:47:34.581957"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4778.823, "latencies_ms": [4778.823], "images_per_second": 0.209, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. purple tray\n2. orange tray\n3. green tray\n4. red tray\n5. purple container\n6. green container\n7. orange container\n8. blue container", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.443, "power_cpu_cv_mean_watts": 2.012, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 69.4}, "timestamp": "2026-01-28T11:47:41.381457"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7049.255, "latencies_ms": [7049.255], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 81, "n_tiles": 1, "output_text": " The main objects are arranged in a grid-like pattern, with the salad in the top left, the pasta in the bottom left, the carrots in the top right, and the grapes in the bottom right. The salad is positioned in the top left corner, while the pasta is in the bottom left corner. The carrots are in the top right corner, and the grapes are in the bottom right corner.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.898}, "power_stats": {"power_gpu_soc_mean_watts": 17.587, "power_cpu_cv_mean_watts": 2.253, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 70.898}, "timestamp": "2026-01-28T11:47:50.450817"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4045.897, "latencies_ms": [4045.897], "images_per_second": 0.247, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A colorful and healthy meal is served in a purple divided container. The meal includes a variety of foods such as pasta with sauce, a salad, and grapes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.094, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-28T11:47:56.516687"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5065.11, "latencies_ms": [5065.11], "images_per_second": 0.197, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a vibrant and colorful meal in a purple divided container, with a variety of food items including a salad, pasta with sauce, and grapes. The lighting is bright and even, and the container appears to be made of plastic.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12545.9, "ram_available_mb": 50295.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.262}, "power_stats": {"power_gpu_soc_mean_watts": 19.444, "power_cpu_cv_mean_watts": 2.069, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.262}, "timestamp": "2026-01-28T11:48:03.597625"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5198.001, "latencies_ms": [5198.001], "images_per_second": 0.192, "prompt_tokens": 1100, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a serene scene of a cherry blossom tree in full bloom, with its branches adorned with delicate pink and white flowers, while a traffic light with a red light hangs in the foreground, adding a touch of urban life to the tranquil setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12545.2, "ram_available_mb": 50295.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.909}, "power_stats": {"power_gpu_soc_mean_watts": 19.095, "power_cpu_cv_mean_watts": 2.02, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 71.909}, "timestamp": "2026-01-28T11:48:10.848406"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5938.635, "latencies_ms": [5938.635], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. traffic light: 4\n2. cherry blossoms: 1\n3. streetlight: 1\n4. building: 1\n5. tree branches: 1\n6. sky: 1\n7. ground: 1\n8. traffic light signal: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.7}, "power_stats": {"power_gpu_soc_mean_watts": 18.63, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 71.7}, "timestamp": "2026-01-28T11:48:18.803848"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4714.322, "latencies_ms": [4714.322], "images_per_second": 0.212, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The traffic light is positioned above the cherry blossoms, with the traffic light on the left and the cherry blossoms on the right. The traffic light is in the foreground, while the cherry blossoms are in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.923}, "power_stats": {"power_gpu_soc_mean_watts": 19.982, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 71.923}, "timestamp": "2026-01-28T11:48:25.535214"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5260.872, "latencies_ms": [5260.872], "images_per_second": 0.19, "prompt_tokens": 1112, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a serene scene of a cherry blossom tree in full bloom, with its branches adorned with delicate pink and white flowers. The tree stands in front of a traffic light, which is currently displaying a red signal, indicating a halt in the flow of traffic.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.614}, "power_stats": {"power_gpu_soc_mean_watts": 19.122, "power_cpu_cv_mean_watts": 1.956, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 72.614}, "timestamp": "2026-01-28T11:48:32.820097"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3540.925, "latencies_ms": [3540.925], "images_per_second": 0.282, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image features a cherry blossom tree with a traffic light hanging from its branches, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12546.2, "ram_available_mb": 50294.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.966}, "power_stats": {"power_gpu_soc_mean_watts": 22.438, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 7.824, "gpu_utilization_percent_mean": 77.966}, "timestamp": "2026-01-28T11:48:38.378917"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3752.184, "latencies_ms": [3752.184], "images_per_second": 0.267, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image shows a plate with a serving of broccoli and a piece of grilled salmon, both of which are placed on a white plate.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12546.7, "ram_available_mb": 50294.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.258}, "power_stats": {"power_gpu_soc_mean_watts": 21.795, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 77.258}, "timestamp": "2026-01-28T11:48:44.160735"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5866.835, "latencies_ms": [5866.835], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. plate: 1\n2. broccoli: 12\n3. salmon: 1\n4. sauce: 1\n5. seasoning: 1\n6. broccoli stem: 1\n7. broccoli floret: 1\n8. broccoli leaf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.5, "ram_available_mb": 50294.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.88}, "power_stats": {"power_gpu_soc_mean_watts": 18.708, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 70.88}, "timestamp": "2026-01-28T11:48:52.071821"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4035.908, "latencies_ms": [4035.908], "images_per_second": 0.248, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The broccoli is in the foreground, while the salmon is in the background. The broccoli is near the plate, while the salmon is far from the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12546.3, "ram_available_mb": 50294.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.211, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-28T11:48:58.131393"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5118.194, "latencies_ms": [5118.194], "images_per_second": 0.195, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " In the image, there is a plate of food that includes broccoli and salmon. The broccoli is green and appears to be cooked, while the salmon is orange and appears to be grilled. The plate is white and is placed on a table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12545.6, "ram_available_mb": 50295.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12547.5, "ram_available_mb": 50293.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.395}, "power_stats": {"power_gpu_soc_mean_watts": 19.344, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.696, "gpu_utilization_percent_mean": 73.395}, "timestamp": "2026-01-28T11:49:05.275305"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5584.808, "latencies_ms": [5584.808], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a plate of food with a vibrant green broccoli dish and a piece of grilled salmon. The broccoli is cooked to a bright green color, while the salmon has a golden-brown crust. The plate is white, and the food is placed on a white tablecloth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12547.5, "ram_available_mb": 50293.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.787}, "power_stats": {"power_gpu_soc_mean_watts": 18.746, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 73.787}, "timestamp": "2026-01-28T11:49:12.908830"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3312.411, "latencies_ms": [3312.411], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, with one person eating a sandwich.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12545.1, "ram_available_mb": 50295.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.882, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 81.593}, "timestamp": "2026-01-28T11:49:18.272368"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5538.751, "latencies_ms": [5538.751], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 3\n2. chair: 1\n3. table: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12545.0, "ram_available_mb": 50295.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12546.8, "ram_available_mb": 50294.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.826}, "power_stats": {"power_gpu_soc_mean_watts": 19.196, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.826}, "timestamp": "2026-01-28T11:49:25.843086"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5384.189, "latencies_ms": [5384.189], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The person in the middle is sitting between the two people on either side of them. The person on the left is sitting closer to the camera than the person on the right. The person on the right is sitting closer to the background than the person on the left.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12546.8, "ram_available_mb": 50294.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12547.0, "ram_available_mb": 50293.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.489}, "power_stats": {"power_gpu_soc_mean_watts": 19.304, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 71.489}, "timestamp": "2026-01-28T11:49:33.277285"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3276.612, "latencies_ms": [3276.612], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Three people are sitting at a table in a restaurant. One person is eating a sandwich.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12547.0, "ram_available_mb": 50293.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12547.0, "ram_available_mb": 50293.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.852}, "power_stats": {"power_gpu_soc_mean_watts": 22.632, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 76.852}, "timestamp": "2026-01-28T11:49:38.570287"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3460.2, "latencies_ms": [3460.2], "images_per_second": 0.289, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with warm lighting, and the subjects are wearing casual clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12547.0, "ram_available_mb": 50293.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12551.1, "ram_available_mb": 50289.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.288, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 78.103}, "timestamp": "2026-01-28T11:49:44.075964"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4525.694, "latencies_ms": [4525.694], "images_per_second": 0.221, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a bustling urban scene with a yellow bus parked on the side of a street, a white bus in the distance, and a modern building with a grid of windows in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12551.1, "ram_available_mb": 50289.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12551.2, "ram_available_mb": 50289.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.265, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 73.237}, "timestamp": "2026-01-28T11:49:50.631018"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5579.481, "latencies_ms": [5579.481], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. street: 1\n3. building: 1\n4. tree: 1\n5. pole: 1\n6. car: 1\n7. sidewalk: 1\n8. bench: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12551.2, "ram_available_mb": 50289.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12551.9, "ram_available_mb": 50289.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.543}, "power_stats": {"power_gpu_soc_mean_watts": 18.928, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 73.543}, "timestamp": "2026-01-28T11:49:58.229923"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4555.216, "latencies_ms": [4555.216], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The yellow bus is parked on the side of the road, with the white bus driving on the road in the background. The trees are located in the foreground, while the buildings are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12551.9, "ram_available_mb": 50289.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12552.4, "ram_available_mb": 50288.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.582, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 74.026}, "timestamp": "2026-01-28T11:50:04.815472"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5721.366, "latencies_ms": [5721.366], "images_per_second": 0.175, "prompt_tokens": 1111, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image captures a bustling urban scene with a yellow bus parked on the side of the road, a white bus driving down the street, and a large building in the background. The setting appears to be a city with a mix of modern architecture and greenery, suggesting a well-developed urban area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12552.4, "ram_available_mb": 50288.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12552.8, "ram_available_mb": 50288.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.898}, "power_stats": {"power_gpu_soc_mean_watts": 18.838, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 71.898}, "timestamp": "2026-01-28T11:50:12.596641"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4280.936, "latencies_ms": [4280.936], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a modern building with a glass facade, reflecting the sunlight and casting shadows on the ground. The sky is clear and blue, indicating a bright and sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12552.8, "ram_available_mb": 50288.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12552.0, "ram_available_mb": 50288.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.795, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 73.972}, "timestamp": "2026-01-28T11:50:18.915854"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4772.234, "latencies_ms": [4772.234], "images_per_second": 0.21, "prompt_tokens": 1100, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a serene street scene bathed in the warm glow of the setting sun, with a stop sign standing prominently in the foreground, its bold red color contrasting sharply with the muted tones of the surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12552.0, "ram_available_mb": 50288.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12555.8, "ram_available_mb": 50285.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.275}, "power_stats": {"power_gpu_soc_mean_watts": 20.014, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 73.275}, "timestamp": "2026-01-28T11:50:25.716952"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5681.467, "latencies_ms": [5681.467], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. stop sign: 1\n2. pole: 1\n3. railing: 1\n4. street: 1\n5. building: 1\n6. car: 1\n7. grass: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12555.8, "ram_available_mb": 50285.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12556.1, "ram_available_mb": 50284.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.553}, "power_stats": {"power_gpu_soc_mean_watts": 18.881, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 72.553}, "timestamp": "2026-01-28T11:50:33.414711"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4903.931, "latencies_ms": [4903.931], "images_per_second": 0.204, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The stop sign is positioned to the left of the metal fence, which is situated in the foreground of the image. In the background, there is a street with parked cars and buildings, which are relatively far from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.1, "ram_available_mb": 50284.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12556.0, "ram_available_mb": 50284.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.81, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 73.488}, "timestamp": "2026-01-28T11:50:40.355488"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5959.971, "latencies_ms": [5959.971], "images_per_second": 0.168, "prompt_tokens": 1112, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a serene street scene bathed in the warm glow of the setting sun. A stop sign stands prominently in the foreground, its bold red color contrasting sharply with the muted tones of the surroundings. In the distance, a row of apartment buildings rises against the skyline, their windows reflecting the fading light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.0, "ram_available_mb": 50284.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12555.8, "ram_available_mb": 50285.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.08}, "power_stats": {"power_gpu_soc_mean_watts": 18.311, "power_cpu_cv_mean_watts": 2.066, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 71.08}, "timestamp": "2026-01-28T11:50:48.337605"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4370.772, "latencies_ms": [4370.772], "images_per_second": 0.229, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a stop sign with a red octagonal shape and white letters, standing on a metal pole. The sun is shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12555.8, "ram_available_mb": 50285.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12555.8, "ram_available_mb": 50285.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.601, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 71.861}, "timestamp": "2026-01-28T11:50:54.767052"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3608.591, "latencies_ms": [3608.591], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A cat with a white and brown coat is lying on a black couch, with a white computer mouse next to it.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12555.8, "ram_available_mb": 50285.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12556.3, "ram_available_mb": 50284.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.033}, "power_stats": {"power_gpu_soc_mean_watts": 21.837, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 76.033}, "timestamp": "2026-01-28T11:51:00.400190"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4273.802, "latencies_ms": [4273.802], "images_per_second": 0.234, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " cat: 1, mouse: 1, cord: 1, black: 1, white: 1, brown: 1, black background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.3, "ram_available_mb": 50284.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.859, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 73.571}, "timestamp": "2026-01-28T11:51:06.695844"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4625.451, "latencies_ms": [4625.451], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The cat is in the foreground, lying on a black couch. The mouse is in the foreground, to the left of the cat. The cord is in the foreground, to the right of the cat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.139, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 73.974}, "timestamp": "2026-01-28T11:51:13.358008"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3083.196, "latencies_ms": [3083.196], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A cat is laying on a black couch with a computer mouse next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.199, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.843, "gpu_utilization_percent_mean": 79.12}, "timestamp": "2026-01-28T11:51:18.457856"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3182.566, "latencies_ms": [3182.566], "images_per_second": 0.314, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The cat is white and brown with green eyes, and the mouse is white.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.308}, "power_stats": {"power_gpu_soc_mean_watts": 22.675, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 78.308}, "timestamp": "2026-01-28T11:51:23.665483"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5015.575, "latencies_ms": [5015.575], "images_per_second": 0.199, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large bus terminal bustling with activity, surrounded by a variety of buildings, including a prominent white building with a distinctive red and white tower, and a clear blue sky dotted with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12557.4, "ram_available_mb": 50283.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.938, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 70.976}, "timestamp": "2026-01-28T11:51:30.727762"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5552.568, "latencies_ms": [5552.568], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Bus: 3\n2. Bus: 2\n3. Bus: 1\n4. Bus: 1\n5. Bus: 1\n6. Bus: 1\n7. Bus: 1\n8. Bus: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12557.4, "ram_available_mb": 50283.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12558.2, "ram_available_mb": 50282.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.968, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.695, "gpu_utilization_percent_mean": 72.851}, "timestamp": "2026-01-28T11:51:38.303233"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5270.921, "latencies_ms": [5270.921], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The buses are parked in the bus station, which is located in the foreground of the image. The buildings are in the background, with the skyline extending into the distance. The trees are in the foreground, providing a natural contrast to the urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.2, "ram_available_mb": 50282.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12558.4, "ram_available_mb": 50282.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.591}, "power_stats": {"power_gpu_soc_mean_watts": 19.39, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 73.591}, "timestamp": "2026-01-28T11:51:45.634451"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5434.377, "latencies_ms": [5434.377], "images_per_second": 0.184, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large bus terminal nestled amidst towering buildings. The sky above is a clear blue, dotted with fluffy white clouds, while the ground below is a mix of concrete and greenery, with trees and roads crisscrossing the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12558.4, "ram_available_mb": 50282.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.147, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 73.4}, "timestamp": "2026-01-28T11:51:53.080505"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3094.131, "latencies_ms": [3094.131], "images_per_second": 0.323, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The sky is blue with white clouds, and the buildings are white and gray.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12558.8, "ram_available_mb": 50282.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.424, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 79.56}, "timestamp": "2026-01-28T11:51:58.205503"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3597.015, "latencies_ms": [3597.015], "images_per_second": 0.278, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a cowboy hat and shorts is skateboarding on a ramp, with a tent in the background.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12558.8, "ram_available_mb": 50282.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.181, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 76.207}, "timestamp": "2026-01-28T11:52:03.826900"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5667.617, "latencies_ms": [5667.617], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. shorts: 1\n4. skateboard: 1\n5. ramp: 1\n6. tent: 2\n7. shadow: 1\n8. bicycle: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12558.2, "ram_available_mb": 50282.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.818, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 71.66}, "timestamp": "2026-01-28T11:52:11.520105"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5716.93, "latencies_ms": [5716.93], "images_per_second": 0.175, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, performing a trick on a ramp. The tents are located in the background, providing a contrast to the skateboarder's action. The shadow of the skateboarder is cast on the ramp, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12558.2, "ram_available_mb": 50282.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12558.5, "ram_available_mb": 50282.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.979}, "power_stats": {"power_gpu_soc_mean_watts": 18.651, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.69, "gpu_utilization_percent_mean": 73.979}, "timestamp": "2026-01-28T11:52:19.268176"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3036.258, "latencies_ms": [3036.258], "images_per_second": 0.329, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man is skateboarding on a ramp in a desert-like setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12558.5, "ram_available_mb": 50282.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12558.4, "ram_available_mb": 50282.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.751, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 79.6}, "timestamp": "2026-01-28T11:52:24.319006"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7390.011, "latencies_ms": [7390.011], "images_per_second": 0.135, "prompt_tokens": 1110, "response_tokens_est": 87, "n_tiles": 1, "output_text": " The image features a man wearing a cowboy hat and shorts, performing a skateboard trick on a ramp. The skateboarder is wearing a white cowboy hat and black shorts. The ramp is made of wood and has a red stripe painted on it. The skateboarder is in the middle of a trick, with his skateboard in the air. The background of the image shows a clear blue sky and a large tent.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12558.4, "ram_available_mb": 50282.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.597}, "power_stats": {"power_gpu_soc_mean_watts": 17.36, "power_cpu_cv_mean_watts": 2.125, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 69.597}, "timestamp": "2026-01-28T11:52:33.755081"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3112.921, "latencies_ms": [3112.921], "images_per_second": 0.321, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is windsurfing on the ocean with a kite in the sky.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.221, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 7.812, "gpu_utilization_percent_mean": 79.56}, "timestamp": "2026-01-28T11:52:38.898570"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5867.57, "latencies_ms": [5867.57], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 1\n2. windsurf board: 1\n3. kite: 2\n4. ocean: 1\n5. waves: 1\n6. sky: 1\n7. parachute: 1\n8. kite string: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.224}, "power_stats": {"power_gpu_soc_mean_watts": 18.453, "power_cpu_cv_mean_watts": 2.035, "power_sys_5v0_mean_watts": 7.675, "gpu_utilization_percent_mean": 70.224}, "timestamp": "2026-01-28T11:52:46.812326"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4887.854, "latencies_ms": [4887.854], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The kiteboarder is positioned in the foreground, with the ocean and kiteboarders in the background. The kiteboarder is near the water's edge, while the kiteboarders are further out in the water.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12559.3, "ram_available_mb": 50281.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.9}, "power_stats": {"power_gpu_soc_mean_watts": 19.789, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 73.9}, "timestamp": "2026-01-28T11:52:53.713737"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3363.334, "latencies_ms": [3363.334], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man is windsurfing in the ocean with a kite. The kite is yellow and black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12559.3, "ram_available_mb": 50281.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.929}, "power_stats": {"power_gpu_soc_mean_watts": 22.546, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 76.929}, "timestamp": "2026-01-28T11:52:59.108187"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4749.712, "latencies_ms": [4749.712], "images_per_second": 0.211, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a person windsurfing on the ocean with a clear blue sky and white clouds in the background. The water is a deep blue color, and the windsurfer is wearing a red shirt.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.846}, "power_stats": {"power_gpu_soc_mean_watts": 19.927, "power_cpu_cv_mean_watts": 2.013, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.846}, "timestamp": "2026-01-28T11:53:05.896520"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3755.18, "latencies_ms": [3755.18], "images_per_second": 0.266, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, there is a red fire hydrant situated in a grassy area, with a house and trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.936, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 7.82, "gpu_utilization_percent_mean": 73.6}, "timestamp": "2026-01-28T11:53:11.703163"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5801.091, "latencies_ms": [5801.091], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. Fire hydrant: 1\n2. Grass: 1\n3. Flowers: 1\n4. Tree: 1\n5. House: 1\n6. Window: 1\n7. Flowers: 1\n8. Dandelion: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.396}, "power_stats": {"power_gpu_soc_mean_watts": 18.685, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 70.396}, "timestamp": "2026-01-28T11:53:19.521178"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4801.642, "latencies_ms": [4801.642], "images_per_second": 0.208, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with the house and trees in the background. The hydrant is positioned to the left of the house, and the grass is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.925}, "power_stats": {"power_gpu_soc_mean_watts": 19.898, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 7.679, "gpu_utilization_percent_mean": 74.925}, "timestamp": "2026-01-28T11:53:26.344028"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3050.502, "latencies_ms": [3050.502], "images_per_second": 0.328, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A red fire hydrant is in the grass in front of a house.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.36}, "power_stats": {"power_gpu_soc_mean_watts": 22.99, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 78.36}, "timestamp": "2026-01-28T11:53:31.454235"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3450.03, "latencies_ms": [3450.03], "images_per_second": 0.29, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The fire hydrant is red and black, and it is in a grassy area with dandelions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.274, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 79.179}, "timestamp": "2026-01-28T11:53:36.948212"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3343.33, "latencies_ms": [3343.33], "images_per_second": 0.299, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A bird is flying over a roof with a blue hue, while other birds are on the roof.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.964}, "power_stats": {"power_gpu_soc_mean_watts": 22.373, "power_cpu_cv_mean_watts": 1.63, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 78.964}, "timestamp": "2026-01-28T11:53:42.334818"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5565.925, "latencies_ms": [5565.925], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 1\n2. roof: 1\n3. bird: 1\n4. roof: 1\n5. bird: 1\n6. roof: 1\n7. bird: 1\n8. roof: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12557.3, "ram_available_mb": 50283.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.435}, "power_stats": {"power_gpu_soc_mean_watts": 18.948, "power_cpu_cv_mean_watts": 2.02, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 70.435}, "timestamp": "2026-01-28T11:53:49.933298"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4811.083, "latencies_ms": [4811.083], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bird is flying towards the right side of the image, while the ducks are located in the background, near the edge of the roof. The bird is in the foreground, closer to the camera than the ducks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.3, "ram_available_mb": 50283.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.375}, "power_stats": {"power_gpu_soc_mean_watts": 19.716, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 73.375}, "timestamp": "2026-01-28T11:53:56.795656"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3495.254, "latencies_ms": [3495.254], "images_per_second": 0.286, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A bird is flying over a roof with a blue hue, while other birds are on the ground nearby.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.201, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 77.143}, "timestamp": "2026-01-28T11:54:02.313726"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5257.127, "latencies_ms": [5257.127], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a bird in flight, captured against a backdrop of a weathered wooden roof. The bird's wings are spread wide, showcasing the intricate patterns of its feathers, while the roof exhibits a rich blue hue with visible signs of wear and tear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.159}, "power_stats": {"power_gpu_soc_mean_watts": 19.088, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 7.686, "gpu_utilization_percent_mean": 71.159}, "timestamp": "2026-01-28T11:54:09.627427"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3813.598, "latencies_ms": [3813.598], "images_per_second": 0.262, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a woman is walking a horse in a barn, with a red door and a window visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.065}, "power_stats": {"power_gpu_soc_mean_watts": 21.524, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 74.065}, "timestamp": "2026-01-28T11:54:15.481565"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5576.188, "latencies_ms": [5576.188], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 1\n2. person: 1\n3. door: 1\n4. window: 1\n5. ladder: 1\n6. bucket: 1\n7. stool: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.319}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 71.319}, "timestamp": "2026-01-28T11:54:23.076198"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4273.56, "latencies_ms": [4273.56], "images_per_second": 0.234, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, with the woman walking towards it. The barn is located in the background, with the horse and woman positioned in the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.6, "ram_available_mb": 50283.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12558.1, "ram_available_mb": 50282.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.862, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 74.833}, "timestamp": "2026-01-28T11:54:29.369332"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2752.641, "latencies_ms": [2752.641], "images_per_second": 0.363, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is walking a horse in a barn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.1, "ram_available_mb": 50282.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.696}, "power_stats": {"power_gpu_soc_mean_watts": 23.945, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 85.696}, "timestamp": "2026-01-28T11:54:34.174188"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3757.001, "latencies_ms": [3757.001], "images_per_second": 0.266, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken in a stable with a wooden interior, the horse is brown and white, and the woman is wearing blue jeans.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.097}, "power_stats": {"power_gpu_soc_mean_watts": 21.914, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 76.097}, "timestamp": "2026-01-28T11:54:39.968865"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4113.986, "latencies_ms": [4113.986], "images_per_second": 0.243, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a group of zebras and a group of sheep are grazing on a grassy field, with a tree and a pond visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12558.3, "ram_available_mb": 50282.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12558.2, "ram_available_mb": 50282.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.441}, "power_stats": {"power_gpu_soc_mean_watts": 20.864, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 75.441}, "timestamp": "2026-01-28T11:54:46.152991"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5694.595, "latencies_ms": [5694.595], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. tree: 1\n2. zebras: 2\n3. rhinoceros: 1\n4. rocks: 1\n5. grass: 1\n6. water: 1\n7. trees: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.2, "ram_available_mb": 50282.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.723, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 70.596}, "timestamp": "2026-01-28T11:54:53.857600"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4862.849, "latencies_ms": [4862.849], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground, grazing on the grass, while the sheep are in the background, grazing on the grass as well. The trees are located in the background, providing a natural backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.61}, "power_stats": {"power_gpu_soc_mean_watts": 19.676, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 72.61}, "timestamp": "2026-01-28T11:55:00.781015"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3586.29, "latencies_ms": [3586.29], "images_per_second": 0.279, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " In this image, we can see a herd of animals grazing in a grassy field. There are trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.974, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 76.367}, "timestamp": "2026-01-28T11:55:06.398124"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4955.426, "latencies_ms": [4955.426], "images_per_second": 0.202, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features a vibrant green field with a variety of animals, including zebras, rhinos, and antelopes. The sky is a clear blue with a few clouds, and the trees in the background are tall and green.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.071}, "power_stats": {"power_gpu_soc_mean_watts": 19.656, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 74.071}, "timestamp": "2026-01-28T11:55:13.397062"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4330.254, "latencies_ms": [4330.254], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A horse-drawn trolley with a green and red body and gold accents is being pulled by a white horse in a park with trees and people in the background.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12556.6, "ram_available_mb": 50284.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.806}, "power_stats": {"power_gpu_soc_mean_watts": 20.027, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.625, "gpu_utilization_percent_mean": 74.806}, "timestamp": "2026-01-28T11:55:19.747591"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4240.291, "latencies_ms": [4240.291], "images_per_second": 0.236, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " trolley: 1, horse: 1, umbrella: 1, bench: 1, people: 1, trees: 1, sign: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12556.6, "ram_available_mb": 50284.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12555.7, "ram_available_mb": 50285.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.086}, "power_stats": {"power_gpu_soc_mean_watts": 20.785, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 76.086}, "timestamp": "2026-01-28T11:55:26.015289"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4857.942, "latencies_ms": [4857.942], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The horse-drawn trolley is positioned in the foreground, with the crowd of people in the background. The trolley is moving towards the right side of the image, while the people are standing on the left side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12555.7, "ram_available_mb": 50285.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12556.5, "ram_available_mb": 50284.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.22}, "power_stats": {"power_gpu_soc_mean_watts": 19.794, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 74.22}, "timestamp": "2026-01-28T11:55:32.931537"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3317.1, "latencies_ms": [3317.1], "images_per_second": 0.301, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A horse drawn trolley is being pulled by a white horse down a street in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.5, "ram_available_mb": 50284.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.111}, "power_stats": {"power_gpu_soc_mean_watts": 22.727, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 80.111}, "timestamp": "2026-01-28T11:55:38.264380"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5554.32, "latencies_ms": [5554.32], "images_per_second": 0.18, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a vibrant scene with a horse-drawn trolley in the foreground, with a clear blue sky and lush green trees in the background. The trolley is adorned with a green and gold color scheme, and the horse is white with a black mane and tail.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.174}, "power_stats": {"power_gpu_soc_mean_watts": 19.016, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 70.174}, "timestamp": "2026-01-28T11:55:45.835834"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4083.774, "latencies_ms": [4083.774], "images_per_second": 0.245, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there are several people sitting on benches in an outdoor area, with one person reading a newspaper, and a few others standing and talking.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.058, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 75.394}, "timestamp": "2026-01-28T11:55:51.964030"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5528.813, "latencies_ms": [5528.813], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. bench: 4\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.617}, "power_stats": {"power_gpu_soc_mean_watts": 18.825, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 73.617}, "timestamp": "2026-01-28T11:55:59.539811"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5648.471, "latencies_ms": [5648.471], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man on the left is sitting on a green bench, while the man on the right is sitting on a red bench. The man on the left is closer to the camera than the man on the right. The man on the left is sitting in front of the man on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12557.3, "ram_available_mb": 50283.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.213}, "power_stats": {"power_gpu_soc_mean_watts": 19.199, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 71.213}, "timestamp": "2026-01-28T11:56:07.216354"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4694.13, "latencies_ms": [4694.13], "images_per_second": 0.213, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In a busy city square, a group of people are enjoying a sunny day on a bench. The man in the foreground is reading a newspaper, while the man in the background is talking on his cell phone.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12557.3, "ram_available_mb": 50283.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.359}, "power_stats": {"power_gpu_soc_mean_watts": 20.023, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 74.359}, "timestamp": "2026-01-28T11:56:13.960140"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5546.999, "latencies_ms": [5546.999], "images_per_second": 0.18, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image depicts a group of people sitting on green metal benches in a sunny outdoor setting. The benches are lined up against a building with a maroon and white sign that reads \"SOCIAL CENTER\". The sky is clear and blue, indicating a bright and sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.37}, "power_stats": {"power_gpu_soc_mean_watts": 19.321, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 73.37}, "timestamp": "2026-01-28T11:56:21.537840"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3248.904, "latencies_ms": [3248.904], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A desk with a laptop, a lamp, and a glass of orange juice on it.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.757, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 78.556}, "timestamp": "2026-01-28T11:56:26.837396"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4814.483, "latencies_ms": [4814.483], "images_per_second": 0.208, "prompt_tokens": 1113, "response_tokens_est": 43, "n_tiles": 1, "output_text": " 1. black laptop\n2. black lamp\n3. glass of orange juice\n4. white telephone\n5. black trash can\n6. black drawer\n7. black book\n8. black pen", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.028, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 74.4}, "timestamp": "2026-01-28T11:56:33.715987"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5355.625, "latencies_ms": [5355.625], "images_per_second": 0.187, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The lamp is positioned to the right of the laptop, and the glass of orange juice is placed on the desk in front of the laptop. The telephone is located to the left of the laptop, and the framed picture is hanging on the wall above the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.311}, "power_stats": {"power_gpu_soc_mean_watts": 19.235, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 74.311}, "timestamp": "2026-01-28T11:56:41.113623"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2916.548, "latencies_ms": [2916.548], "images_per_second": 0.343, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A desk with a laptop, lamp, and phone on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12557.7, "ram_available_mb": 50283.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.598, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 7.854, "gpu_utilization_percent_mean": 82.042}, "timestamp": "2026-01-28T11:56:46.056975"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3416.795, "latencies_ms": [3416.795], "images_per_second": 0.293, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is well-lit with a warm yellow light, and the desk is made of wood.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12557.7, "ram_available_mb": 50283.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12558.0, "ram_available_mb": 50282.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.314, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 80.857}, "timestamp": "2026-01-28T11:56:51.503819"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5380.157, "latencies_ms": [5380.157], "images_per_second": 0.186, "prompt_tokens": 1432, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a blue and white striped towel, a blue surfboard, and a red cooler on the sand, with a person in the water and a beach umbrella in the background.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12558.0, "ram_available_mb": 50282.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.409}, "power_stats": {"power_gpu_soc_mean_watts": 21.72, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 78.409}, "timestamp": "2026-01-28T11:56:58.912514"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5175.994, "latencies_ms": [5175.994], "images_per_second": 0.193, "prompt_tokens": 1446, "response_tokens_est": 37, "n_tiles": 1, "output_text": " surfboard: 2, beach chair: 1, umbrella: 1, towel: 1, bag: 1, cooler: 1, beach umbrella: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12557.5, "ram_available_mb": 50283.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12557.4, "ram_available_mb": 50283.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.605}, "power_stats": {"power_gpu_soc_mean_watts": 22.297, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 78.605}, "timestamp": "2026-01-28T11:57:06.140728"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6764.599, "latencies_ms": [6764.599], "images_per_second": 0.148, "prompt_tokens": 1450, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The blue and white striped towel is to the left of the blue surfboard, which is in front of the red cooler. The pink and white surfboard is to the right of the blue surfboard, and the umbrella is behind the chairs. The beachgoers are in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12557.4, "ram_available_mb": 50283.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.386}, "power_stats": {"power_gpu_soc_mean_watts": 20.293, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 72.386}, "timestamp": "2026-01-28T11:57:14.951421"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6340.557, "latencies_ms": [6340.557], "images_per_second": 0.158, "prompt_tokens": 1444, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a clear blue sky and calm ocean waves. The beach is adorned with various beach items, including a blue and white striped towel, a blue surfboard, and a red cooler. A person can be seen enjoying the water in the distance.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.704}, "power_stats": {"power_gpu_soc_mean_watts": 20.684, "power_cpu_cv_mean_watts": 1.742, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 75.704}, "timestamp": "2026-01-28T11:57:23.346742"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3627.718, "latencies_ms": [3627.718], "images_per_second": 0.276, "prompt_tokens": 1442, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The beach is covered in sand and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.167}, "power_stats": {"power_gpu_soc_mean_watts": 25.163, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.159, "gpu_utilization_percent_mean": 83.167}, "timestamp": "2026-01-28T11:57:29.028458"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3461.344, "latencies_ms": [3461.344], "images_per_second": 0.289, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A sheep with a black face and white wool is standing on a rocky cliff, looking down at the ground.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.191, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 79.103}, "timestamp": "2026-01-28T11:57:34.536358"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5944.355, "latencies_ms": [5944.355], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. rock: 1\n3. grass: 1\n4. cloud: 1\n5. sky: 1\n6. sheep's head: 1\n7. sheep's body: 1\n8. sheep's legs: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12555.5, "ram_available_mb": 50285.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.04}, "power_stats": {"power_gpu_soc_mean_watts": 18.355, "power_cpu_cv_mean_watts": 2.17, "power_sys_5v0_mean_watts": 7.689, "gpu_utilization_percent_mean": 71.04}, "timestamp": "2026-01-28T11:57:42.519232"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5437.862, "latencies_ms": [5437.862], "images_per_second": 0.184, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The sheep is positioned on the left side of the image, with the sky occupying the majority of the background. The foreground features a rocky terrain with patches of green grass, while the sheep is standing on a higher elevation, providing a sense of depth and perspective to the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12555.5, "ram_available_mb": 50285.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.178}, "power_stats": {"power_gpu_soc_mean_watts": 19.213, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 72.178}, "timestamp": "2026-01-28T11:57:49.989202"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3453.12, "latencies_ms": [3453.12], "images_per_second": 0.29, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A sheep with a black face and white wool is standing on a rocky cliff, looking down at the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.607}, "power_stats": {"power_gpu_soc_mean_watts": 22.339, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 78.607}, "timestamp": "2026-01-28T11:57:55.466121"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3806.621, "latencies_ms": [3806.621], "images_per_second": 0.263, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The sheep is white with a black face and legs, standing on a rocky cliff with a blue sky and white clouds in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.414, "power_cpu_cv_mean_watts": 1.539, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 76.156}, "timestamp": "2026-01-28T11:58:01.304544"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3020.381, "latencies_ms": [3020.381], "images_per_second": 0.331, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person with blue hair is taking a selfie in a mirror.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.098, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 79.12}, "timestamp": "2026-01-28T11:58:06.358849"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5612.129, "latencies_ms": [5612.129], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. phone: 1\n3. shirt: 1\n4. tie: 1\n5. wall: 1\n6. mirror: 1\n7. ring: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.362}, "power_stats": {"power_gpu_soc_mean_watts": 18.745, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 71.362}, "timestamp": "2026-01-28T11:58:14.003706"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4263.282, "latencies_ms": [4263.282], "images_per_second": 0.235, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The person is in the foreground of the image, taking a selfie with a smartphone. The smartphone is held in their right hand, and the mirror is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.681, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 74.306}, "timestamp": "2026-01-28T11:58:20.284521"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3039.582, "latencies_ms": [3039.582], "images_per_second": 0.329, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person with blue hair is taking a selfie in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.64}, "power_stats": {"power_gpu_soc_mean_watts": 22.797, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.831, "gpu_utilization_percent_mean": 79.64}, "timestamp": "2026-01-28T11:58:25.335218"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4777.55, "latencies_ms": [4777.55], "images_per_second": 0.209, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is a selfie taken in a bathroom with a plain wall in the background. The lighting is natural, coming from the window outside the bathroom. The subject is wearing a blue shirt and a black tie.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.725, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 74.25}, "timestamp": "2026-01-28T11:58:32.139035"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4208.707, "latencies_ms": [4208.707], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden chair, a table, and a bookshelf, all arranged in a way that suggests a study or library.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12567.7, "ram_available_mb": 50273.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.744, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 73.676}, "timestamp": "2026-01-28T11:58:38.382349"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5636.981, "latencies_ms": [5636.981], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. fireplace: 1\n2. chair: 2\n3. table: 1\n4. bookshelf: 1\n5. painting: 2\n6. vase: 2\n7. lamp: 1\n8. rug: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.7, "ram_available_mb": 50273.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.784, "power_cpu_cv_mean_watts": 1.909, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 69.851}, "timestamp": "2026-01-28T11:58:46.079643"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4666.322, "latencies_ms": [4666.322], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The fireplace is located on the left side of the room, with the wooden chair positioned in the foreground. The wooden table is situated in the middle of the room, with the bookshelf in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.308}, "power_stats": {"power_gpu_soc_mean_watts": 19.966, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 73.308}, "timestamp": "2026-01-28T11:58:52.793581"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4376.426, "latencies_ms": [4376.426], "images_per_second": 0.228, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden chair, and a table. The room is decorated with various items, including vases, a painting, and a book.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.573, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 73.333}, "timestamp": "2026-01-28T11:58:59.183046"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4245.184, "latencies_ms": [4245.184], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white. The furniture is made of wood, and the floor is covered with a patterned carpet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12569.2, "ram_available_mb": 50271.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.314}, "power_stats": {"power_gpu_soc_mean_watts": 20.953, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.314}, "timestamp": "2026-01-28T11:59:05.474998"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3790.94, "latencies_ms": [3790.94], "images_per_second": 0.264, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black dog is jumping in the air to catch a red frisbee.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12569.2, "ram_available_mb": 50271.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.645}, "power_stats": {"power_gpu_soc_mean_watts": 24.428, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.173, "gpu_utilization_percent_mean": 82.645}, "timestamp": "2026-01-28T11:59:11.341977"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4769.951, "latencies_ms": [4769.951], "images_per_second": 0.21, "prompt_tokens": 1446, "response_tokens_est": 31, "n_tiles": 1, "output_text": " dog: 1, frisbee: 1, car: 2, tree: 1, grass: 1, mulch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.75}, "power_stats": {"power_gpu_soc_mean_watts": 23.001, "power_cpu_cv_mean_watts": 1.381, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 81.75}, "timestamp": "2026-01-28T11:59:18.154699"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5561.913, "latencies_ms": [5561.913], "images_per_second": 0.18, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The red frisbee is in the air, slightly to the left of the black dog, which is in the foreground of the image. The black car is in the background, parked on the street behind the dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.739}, "power_stats": {"power_gpu_soc_mean_watts": 21.817, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 77.739}, "timestamp": "2026-01-28T11:59:25.740426"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4060.21, "latencies_ms": [4060.21], "images_per_second": 0.246, "prompt_tokens": 1444, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A black dog is jumping in the air to catch a red frisbee in a grassy yard.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.97}, "power_stats": {"power_gpu_soc_mean_watts": 24.468, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 81.97}, "timestamp": "2026-01-28T11:59:31.830455"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6935.926, "latencies_ms": [6935.926], "images_per_second": 0.144, "prompt_tokens": 1442, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image is a vibrant depiction of a black dog in mid-air, leaping to catch a red frisbee. The scene is bathed in natural daylight, with the lush green grass and trees providing a serene backdrop. The dog's fur is a rich, dark brown, contrasting with the bright red of the frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.254}, "power_stats": {"power_gpu_soc_mean_watts": 20.334, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 75.254}, "timestamp": "2026-01-28T11:59:40.794887"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4138.134, "latencies_ms": [4138.134], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a giraffe with a brown and white coat stands in a lush green forest, its head turned towards the camera, its eyes wide and curious.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.647}, "power_stats": {"power_gpu_soc_mean_watts": 20.971, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 76.647}, "timestamp": "2026-01-28T11:59:46.968471"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6057.623, "latencies_ms": [6057.623], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. giraffe head: 1\n2. giraffe neck: 1\n3. giraffe ears: 2\n4. giraffe eyes: 2\n5. giraffe mouth: 1\n6. giraffe tongue: 1\n7. giraffe mane: 1\n8. giraffe horns: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 12569.3, "ram_available_mb": 50271.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.373}, "power_stats": {"power_gpu_soc_mean_watts": 18.41, "power_cpu_cv_mean_watts": 2.223, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 71.373}, "timestamp": "2026-01-28T11:59:55.049586"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4147.729, "latencies_ms": [4147.729], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The giraffe is in the foreground, with its head and neck prominently displayed. The background is filled with green foliage, suggesting that the giraffe is in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.3, "ram_available_mb": 50271.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.92, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 74.057}, "timestamp": "2026-01-28T12:00:01.251186"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5253.352, "latencies_ms": [5253.352], "images_per_second": 0.19, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " In the image, a giraffe is standing in a lush green forest, its head and neck prominently displayed as it gazes directly at the camera. The giraffe's brown and white spotted coat stands out against the verdant backdrop of the trees and foliage.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.523}, "power_stats": {"power_gpu_soc_mean_watts": 19.382, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.523}, "timestamp": "2026-01-28T12:00:08.560652"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3369.886, "latencies_ms": [3369.886], "images_per_second": 0.297, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The giraffe is brown and white with a black nose, and the background is green with trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.49, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 80.071}, "timestamp": "2026-01-28T12:00:13.963453"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4608.802, "latencies_ms": [4608.802], "images_per_second": 0.217, "prompt_tokens": 1100, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In the image, there are two zebras standing side by side, their black and white striped bodies facing away from the camera, with a chain link fence and a rocky ground in the background.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.079}, "power_stats": {"power_gpu_soc_mean_watts": 20.027, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.68, "gpu_utilization_percent_mean": 74.079}, "timestamp": "2026-01-28T12:00:20.615627"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2446.779, "latencies_ms": [2446.779], "images_per_second": 0.409, "prompt_tokens": 1114, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.1}, "power_stats": {"power_gpu_soc_mean_watts": 24.191, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 84.1}, "timestamp": "2026-01-28T12:00:25.113845"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4986.684, "latencies_ms": [4986.684], "images_per_second": 0.201, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The zebras are positioned on the left side of the image, with the fence serving as a boundary between them and the background. The zebras are in the foreground, with the fence and the background providing depth to the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.841, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 73.341}, "timestamp": "2026-01-28T12:00:32.131295"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3569.875, "latencies_ms": [3569.875], "images_per_second": 0.28, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two zebras are standing in a fenced enclosure, their black and white stripes contrasting against the brown dirt ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12569.3, "ram_available_mb": 50271.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.138}, "power_stats": {"power_gpu_soc_mean_watts": 21.878, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 77.138}, "timestamp": "2026-01-28T12:00:37.741274"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5506.181, "latencies_ms": [5506.181], "images_per_second": 0.182, "prompt_tokens": 1110, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features two zebras standing side by side in a fenced enclosure, with their distinctive black and white stripes clearly visible. The lighting is natural, suggesting daytime, and the zebras are standing on a patch of grass, with a fence and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.3, "ram_available_mb": 50271.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12569.0, "ram_available_mb": 50271.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.565}, "power_stats": {"power_gpu_soc_mean_watts": 19.184, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 71.565}, "timestamp": "2026-01-28T12:00:45.293580"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5453.307, "latencies_ms": [5453.307], "images_per_second": 0.183, "prompt_tokens": 1099, "response_tokens_est": 54, "n_tiles": 1, "output_text": " In the image, a silver sports car is parked on the right side of a narrow, tree-lined street, while a group of horses, including a brown and white one, are standing on the left side of the street, seemingly grazing or interacting with each other.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.889}, "power_stats": {"power_gpu_soc_mean_watts": 19.103, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 70.889}, "timestamp": "2026-01-28T12:00:52.773414"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5579.445, "latencies_ms": [5579.445], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 4\n2. horse: 3\n3. horse: 2\n4. horse: 1\n5. horse: 1\n6. horse: 1\n7. horse: 1\n8. horse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.587}, "power_stats": {"power_gpu_soc_mean_watts": 18.931, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 69.587}, "timestamp": "2026-01-28T12:01:00.404415"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5612.748, "latencies_ms": [5612.748], "images_per_second": 0.178, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The horses are positioned in the middle of the road, with the car parked on the right side of the street. The car is relatively close to the camera, while the horses are farther away. The horses are near the fence, which is located on the left side of the road.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12569.2, "ram_available_mb": 50271.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.277}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 71.277}, "timestamp": "2026-01-28T12:01:08.075064"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5646.167, "latencies_ms": [5646.167], "images_per_second": 0.177, "prompt_tokens": 1111, "response_tokens_est": 58, "n_tiles": 1, "output_text": " In a serene setting, a group of horses, their coats a mix of brown and black, are seen grazing on the lush grass along a tree-lined road. A silver car is parked on the side of the road, its presence adding a touch of modernity to the otherwise tranquil scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.2, "ram_available_mb": 50271.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.787}, "power_stats": {"power_gpu_soc_mean_watts": 18.921, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 71.787}, "timestamp": "2026-01-28T12:01:15.750302"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5442.945, "latencies_ms": [5442.945], "images_per_second": 0.184, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a silver car parked on the side of a road, with a group of horses standing on the road. The horses are brown and black, and the car is parked next to a wooden fence. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.109}, "power_stats": {"power_gpu_soc_mean_watts": 18.949, "power_cpu_cv_mean_watts": 2.351, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 72.109}, "timestamp": "2026-01-28T12:01:23.240180"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4011.742, "latencies_ms": [4011.742], "images_per_second": 0.249, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there is a wooden desk with a blackboard behind it, a bell on the desk, and a chair in front of the desk.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.424}, "power_stats": {"power_gpu_soc_mean_watts": 21.169, "power_cpu_cv_mean_watts": 2.209, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 72.424}, "timestamp": "2026-01-28T12:01:29.271836"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5729.383, "latencies_ms": [5729.383], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. wooden desk: 1\n2. bookshelf: 1\n3. chair: 1\n4. blackboard: 1\n5. bell: 1\n6. picture frame: 1\n7. wall: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.438}, "power_stats": {"power_gpu_soc_mean_watts": 18.827, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.438}, "timestamp": "2026-01-28T12:01:37.036407"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4694.156, "latencies_ms": [4694.156], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The desk is located in the foreground of the image, with the chalkboard and bookshelf in the background. The bell is positioned near the desk, while the chair is situated further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.282}, "power_stats": {"power_gpu_soc_mean_watts": 20.141, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 75.282}, "timestamp": "2026-01-28T12:01:43.754587"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3558.013, "latencies_ms": [3558.013], "images_per_second": 0.281, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A classroom with a blackboard, books, and a bell sits in a room with a picture on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.315, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 76.621}, "timestamp": "2026-01-28T12:01:49.328039"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3633.009, "latencies_ms": [3633.009], "images_per_second": 0.275, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from a window, and the walls are painted in a warm brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.3, "ram_available_mb": 50272.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.867}, "power_stats": {"power_gpu_soc_mean_watts": 22.014, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 76.867}, "timestamp": "2026-01-28T12:01:54.976328"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3280.15, "latencies_ms": [3280.15], "images_per_second": 0.305, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A yellow and white bus with a red and white license plate is driving down a busy street.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.148}, "power_stats": {"power_gpu_soc_mean_watts": 22.696, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 80.148}, "timestamp": "2026-01-28T12:02:00.309511"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5900.336, "latencies_ms": [5900.336], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. bus: 1\n2. white van: 1\n3. motor bike: 1\n4. road: 1\n5. white line: 1\n6. white sign: 1\n7. white text: 1\n8. red text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.482, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 72.49}, "timestamp": "2026-01-28T12:02:08.226665"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4895.222, "latencies_ms": [4895.222], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The bus is in the foreground, parked on the side of the road, with a white van in the background. The bus is parked on the left side of the road, while the white van is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.293}, "power_stats": {"power_gpu_soc_mean_watts": 19.643, "power_cpu_cv_mean_watts": 2.159, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 74.293}, "timestamp": "2026-01-28T12:02:15.175673"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3144.32, "latencies_ms": [3144.32], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A yellow bus is driving down a busy street with a white van behind it.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.885}, "power_stats": {"power_gpu_soc_mean_watts": 22.877, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 79.885}, "timestamp": "2026-01-28T12:02:20.342680"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4846.981, "latencies_ms": [4846.981], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image shows a yellow and white bus with red and green writing on the back, parked on a street with a white van behind it. The sky is overcast, and the street is wet, suggesting recent rain.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.646, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 73.25}, "timestamp": "2026-01-28T12:02:27.208049"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3945.975, "latencies_ms": [3945.975], "images_per_second": 0.253, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image depicts a bathroom with a large mirror reflecting a television screen showing a football game, two sinks with faucets, and a trash can.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.406}, "power_stats": {"power_gpu_soc_mean_watts": 21.404, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.406}, "timestamp": "2026-01-28T12:02:33.184927"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5722.13, "latencies_ms": [5722.13], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. television: 1\n2. sink: 2\n3. mirror: 1\n4. door: 1\n5. trash can: 1\n6. countertop: 1\n7. wall: 1\n8. tile: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.625}, "power_stats": {"power_gpu_soc_mean_watts": 18.598, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 70.625}, "timestamp": "2026-01-28T12:02:40.941643"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4651.17, "latencies_ms": [4651.17], "images_per_second": 0.215, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The television is positioned above the sinks, which are located on the right side of the mirror. The trash can is situated near the television, and the sinks are positioned on the left side of the mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.921}, "power_stats": {"power_gpu_soc_mean_watts": 20.323, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 73.921}, "timestamp": "2026-01-28T12:02:47.614961"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4595.367, "latencies_ms": [4595.367], "images_per_second": 0.218, "prompt_tokens": 1112, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a bathroom scene with a large mirror reflecting a television screen showing a football game. The bathroom features two sinks, one on each side of the mirror, and a trash can in the corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.895}, "power_stats": {"power_gpu_soc_mean_watts": 20.065, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 72.895}, "timestamp": "2026-01-28T12:02:54.244585"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3779.456, "latencies_ms": [3779.456], "images_per_second": 0.265, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The bathroom has a beige tiled wall and a brown granite countertop. The mirror reflects a television screen showing a football game.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.742}, "power_stats": {"power_gpu_soc_mean_watts": 21.759, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 74.742}, "timestamp": "2026-01-28T12:03:00.046378"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3781.267, "latencies_ms": [3781.267], "images_per_second": 0.264, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man sits on a bench in a park with a church in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12564.9, "ram_available_mb": 50276.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.484}, "power_stats": {"power_gpu_soc_mean_watts": 24.279, "power_cpu_cv_mean_watts": 1.162, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 82.484}, "timestamp": "2026-01-28T12:03:05.885224"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6425.368, "latencies_ms": [6425.368], "images_per_second": 0.156, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. bench: 1\n3. streetlamp: 1\n4. tree: 2\n5. building: 1\n6. clock: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.9, "ram_available_mb": 50276.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12564.6, "ram_available_mb": 50276.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.315}, "power_stats": {"power_gpu_soc_mean_watts": 20.615, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 73.315}, "timestamp": "2026-01-28T12:03:14.353131"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5158.043, "latencies_ms": [5158.043], "images_per_second": 0.194, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The man is sitting on the bench in the foreground, with the church in the background. The church is located behind the man, and there are trees in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12564.6, "ram_available_mb": 50276.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12564.6, "ram_available_mb": 50276.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.791}, "power_stats": {"power_gpu_soc_mean_watts": 21.304, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 7.911, "gpu_utilization_percent_mean": 75.791}, "timestamp": "2026-01-28T12:03:21.524665"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3792.025, "latencies_ms": [3792.025], "images_per_second": 0.264, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man sits on a bench in a park with a church in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.6, "ram_available_mb": 50276.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12564.0, "ram_available_mb": 50276.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.935}, "power_stats": {"power_gpu_soc_mean_watts": 25.027, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 84.935}, "timestamp": "2026-01-28T12:03:27.330708"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5035.628, "latencies_ms": [5035.628], "images_per_second": 0.199, "prompt_tokens": 1442, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the man and the background. The sky is cloudy, and the man is sitting on a bench in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.0, "ram_available_mb": 50276.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.452}, "power_stats": {"power_gpu_soc_mean_watts": 22.458, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 78.452}, "timestamp": "2026-01-28T12:03:34.401412"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4864.227, "latencies_ms": [4864.227], "images_per_second": 0.206, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a city, with a row of parked cars lining the street, including a black car, a white car, and a blue car, all parked in front of a large stone wall.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12562.9, "ram_available_mb": 50278.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.025}, "power_stats": {"power_gpu_soc_mean_watts": 19.878, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 74.025}, "timestamp": "2026-01-28T12:03:41.293363"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5606.361, "latencies_ms": [5606.361], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. car: 5\n2. street light: 1\n3. sign: 1\n4. building: 1\n5. wall: 1\n6. tree: 1\n7. street: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12562.9, "ram_available_mb": 50278.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12562.9, "ram_available_mb": 50278.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.34}, "power_stats": {"power_gpu_soc_mean_watts": 18.96, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 70.34}, "timestamp": "2026-01-28T12:03:48.928397"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5554.525, "latencies_ms": [5554.525], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The cars are parked on the side of the road, with the street curving to the left. The cars are parked in front of a large stone wall, which is in the background. The cars are parked near the street, with the street curving to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12562.9, "ram_available_mb": 50278.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12562.9, "ram_available_mb": 50278.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.652}, "power_stats": {"power_gpu_soc_mean_watts": 19.173, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 70.652}, "timestamp": "2026-01-28T12:03:56.508734"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5524.478, "latencies_ms": [5524.478], "images_per_second": 0.181, "prompt_tokens": 1111, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a city, with several cars parked on the side of the road. In the background, there is a large stone wall, possibly part of a historical or cultural site. The sky above is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12562.9, "ram_available_mb": 50278.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12563.0, "ram_available_mb": 50277.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.478}, "power_stats": {"power_gpu_soc_mean_watts": 19.137, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 73.478}, "timestamp": "2026-01-28T12:04:04.061430"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3477.422, "latencies_ms": [3477.422], "images_per_second": 0.288, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image features a clear blue sky with a few clouds, and the cars are parked on the street.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12563.0, "ram_available_mb": 50277.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.243, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 78.214}, "timestamp": "2026-01-28T12:04:09.557068"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9821.115, "latencies_ms": [9821.115], "images_per_second": 0.102, "prompt_tokens": 1099, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The image captures a serene breakfast scene set on a wooden table, bathed in the soft glow of sunlight. A white plate cradles a half-eaten omelette, its golden hue contrasting with the vibrant colors of the fruit and vegetables that accompany it. A cup of tea, its contents a deep red, sits next to the plate, while a small bowl of salt adds a touch of simplicity to the tableau. The table itself is a study in contrasts - the white tiles beneath it are pristine and clean, while the wooden table adds a rustic charm. The shadows cast by the objects on the table hint at the presence", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.744}, "power_stats": {"power_gpu_soc_mean_watts": 16.324, "power_cpu_cv_mean_watts": 2.119, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 67.744}, "timestamp": "2026-01-28T12:04:21.406642"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4634.727, "latencies_ms": [4634.727], "images_per_second": 0.216, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " plate: 1, cup: 1, fork: 1, knife: 1, banana: 1, watermelon: 1, cup of tea: 1, sugar: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.41}, "power_stats": {"power_gpu_soc_mean_watts": 20.026, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 73.41}, "timestamp": "2026-01-28T12:04:28.096278"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7019.125, "latencies_ms": [7019.125], "images_per_second": 0.142, "prompt_tokens": 1117, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The plate of food is located in the foreground, to the left of the cup of coffee, which is positioned in the middle of the table. The knife and fork are placed on the plate, with the knife on the left and the fork on the right. The shadow of the table is cast on the floor, indicating that the table is positioned in front of a light source, likely the sun.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.458}, "power_stats": {"power_gpu_soc_mean_watts": 17.63, "power_cpu_cv_mean_watts": 2.077, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 70.458}, "timestamp": "2026-01-28T12:04:37.128884"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6189.317, "latencies_ms": [6189.317], "images_per_second": 0.162, "prompt_tokens": 1111, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures a serene breakfast scene set on a wooden table with a white marble floor. A plate of food, including a slice of omelette and a bowl of fruit, is placed on the table. A cup of coffee and a small bowl of sugar are also present, suggesting a moment of quiet enjoyment before the day begins.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.261, "power_cpu_cv_mean_watts": 1.909, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 71.596}, "timestamp": "2026-01-28T12:04:45.354632"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5837.652, "latencies_ms": [5837.652], "images_per_second": 0.171, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a cup of coffee, and a bowl of fruit. The table is bathed in sunlight, casting shadows on the floor. The colors are vibrant, with the white plate of food contrasting against the brown table and the red and yellow fruit.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.061}, "power_stats": {"power_gpu_soc_mean_watts": 18.515, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 71.061}, "timestamp": "2026-01-28T12:04:53.238447"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4647.011, "latencies_ms": [4647.011], "images_per_second": 0.215, "prompt_tokens": 1100, "response_tokens_est": 41, "n_tiles": 1, "output_text": " An elderly woman wearing a green and white striped shirt and pink apron is preparing food on a table with a variety of baked goods, including cookies, bread, and pastries, while a child sits nearby.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.175, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 74.342}, "timestamp": "2026-01-28T12:04:59.934994"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5613.347, "latencies_ms": [5613.347], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. apron: 1\n3. table: 1\n4. glasses: 2\n5. food: 10\n6. mat: 1\n7. door: 1\n8. chair: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.787}, "power_stats": {"power_gpu_soc_mean_watts": 18.893, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 71.787}, "timestamp": "2026-01-28T12:05:07.584627"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4305.987, "latencies_ms": [4305.987], "images_per_second": 0.232, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The person is standing to the left of the table, with the table being in the foreground. The food items are placed on the table, with the person's hands reaching towards them.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.874, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.854, "gpu_utilization_percent_mean": 74.972}, "timestamp": "2026-01-28T12:05:13.938566"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3611.715, "latencies_ms": [3611.715], "images_per_second": 0.277, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " An elderly woman is preparing food in a kitchen. She is wearing a green and white striped shirt and a pink apron.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.133}, "power_stats": {"power_gpu_soc_mean_watts": 21.72, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 80.133}, "timestamp": "2026-01-28T12:05:19.580398"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5307.039, "latencies_ms": [5307.039], "images_per_second": 0.188, "prompt_tokens": 1110, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image depicts an elderly woman in a green and white striped shirt and pink apron, standing at a wooden table with a colorful placemat. The lighting in the room is natural, coming from a window in the background, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.178}, "power_stats": {"power_gpu_soc_mean_watts": 19.163, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 72.178}, "timestamp": "2026-01-28T12:05:26.918731"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4174.168, "latencies_ms": [4174.168], "images_per_second": 0.24, "prompt_tokens": 1100, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A man stands in front of a traffic light with a sign that says \"AUSTRALIA TRAFFIC LIGHT\" and a red traffic light on top.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.816, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 74.629}, "timestamp": "2026-01-28T12:05:33.133696"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4224.251, "latencies_ms": [4224.251], "images_per_second": 0.237, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " person: 1, traffic light: 1, sign: 1, pole: 1, ground: 1, rocks: 1, plants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.086}, "power_stats": {"power_gpu_soc_mean_watts": 21.046, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 75.086}, "timestamp": "2026-01-28T12:05:39.392427"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4514.243, "latencies_ms": [4514.243], "images_per_second": 0.222, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing to the left of the traffic light, which is positioned in the middle of the image. The traffic light is located in the background, while the man is in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12566.1, "ram_available_mb": 50274.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.632}, "power_stats": {"power_gpu_soc_mean_watts": 20.343, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 75.632}, "timestamp": "2026-01-28T12:05:45.948931"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3180.024, "latencies_ms": [3180.024], "images_per_second": 0.314, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man stands in front of a traffic light and a sign that says \"Australia Traffic Light\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.1, "ram_available_mb": 50274.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.615}, "power_stats": {"power_gpu_soc_mean_watts": 23.045, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.894, "gpu_utilization_percent_mean": 78.615}, "timestamp": "2026-01-28T12:05:51.143044"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3416.917, "latencies_ms": [3416.917], "images_per_second": 0.293, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The man is wearing a white t-shirt and khaki shorts, and the traffic light is red.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.456, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 78.857}, "timestamp": "2026-01-28T12:05:56.595785"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3890.814, "latencies_ms": [3890.814], "images_per_second": 0.257, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A large group of people are gathered in a park to fly a variety of kites, including a large red and black fish kite.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.212, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 77.375}, "timestamp": "2026-01-28T12:06:02.544891"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6420.99, "latencies_ms": [6420.99], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. Kites: 12\n2. People: 10\n3. Grass: 10\n4. Trees: 10\n5. Buildings: 1\n6. Kite tails: 10\n7. Kite strings: 10\n8. Kite tails: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.944}, "power_stats": {"power_gpu_soc_mean_watts": 18.006, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 68.944}, "timestamp": "2026-01-28T12:06:10.979866"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6264.323, "latencies_ms": [6264.323], "images_per_second": 0.16, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The kites are positioned in the foreground, with the largest and most prominent one being in the center. The kites are arranged in a loose formation, with some flying higher than others, creating a sense of depth and dimension. The background is filled with people and buildings, providing a sense of scale and context to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.377}, "power_stats": {"power_gpu_soc_mean_watts": 18.254, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 69.377}, "timestamp": "2026-01-28T12:06:19.280571"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3178.925, "latencies_ms": [3178.925], "images_per_second": 0.315, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are flying kites in a park on a cloudy day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.615}, "power_stats": {"power_gpu_soc_mean_watts": 22.81, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 82.615}, "timestamp": "2026-01-28T12:06:24.483010"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6500.928, "latencies_ms": [6500.928], "images_per_second": 0.154, "prompt_tokens": 1109, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a kite festival, with a multitude of kites soaring in the sky, predominantly in hues of red, blue, and purple. The sky is a canvas of overcast clouds, casting a soft light over the festivities below. The ground is a lush green, dotted with people and kites, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.722}, "power_stats": {"power_gpu_soc_mean_watts": 18.2, "power_cpu_cv_mean_watts": 1.95, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 71.722}, "timestamp": "2026-01-28T12:06:33.021057"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3497.5, "latencies_ms": [3497.5], "images_per_second": 0.286, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a blue hoodie is sitting on the floor with a child, sharing a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.655}, "power_stats": {"power_gpu_soc_mean_watts": 22.121, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 79.655}, "timestamp": "2026-01-28T12:06:38.569330"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5480.042, "latencies_ms": [5480.042], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. boy: 1\n3. pizza: 1\n4. box: 1\n5. blanket: 1\n6. chair: 1\n7. wall: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.196}, "power_stats": {"power_gpu_soc_mean_watts": 19.383, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 72.196}, "timestamp": "2026-01-28T12:06:46.104194"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4787.618, "latencies_ms": [4787.618], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, while the boy is sitting on the right side. The pizza is in the middle of the image, and the man is holding it with his right hand.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12566.1, "ram_available_mb": 50274.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.692}, "power_stats": {"power_gpu_soc_mean_watts": 20.037, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 72.692}, "timestamp": "2026-01-28T12:06:52.907068"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2921.995, "latencies_ms": [2921.995], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man and a boy are sitting on the floor eating pizza.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12566.1, "ram_available_mb": 50274.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.663, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 7.825, "gpu_utilization_percent_mean": 83.667}, "timestamp": "2026-01-28T12:06:57.852385"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4165.784, "latencies_ms": [4165.784], "images_per_second": 0.24, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is taken in a room with warm lighting and the colors are vibrant. The man is wearing a blue hoodie and the boy is wearing a blue shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.429}, "power_stats": {"power_gpu_soc_mean_watts": 20.916, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 75.429}, "timestamp": "2026-01-28T12:07:04.066602"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3308.642, "latencies_ms": [3308.642], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A woman wearing a striped shirt is eating a piece of pizza while sitting in a blue folding chair.", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12566.6, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.687, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 78.5}, "timestamp": "2026-01-28T12:07:09.425376"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5507.818, "latencies_ms": [5507.818], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. chair: 1\n3. plate: 1\n4. food: 1\n5. backpack: 1\n6. ground: 1\n7. fire: 1\n8. tree: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.6, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.957}, "power_stats": {"power_gpu_soc_mean_watts": 19.226, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 70.957}, "timestamp": "2026-01-28T12:07:16.959947"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5689.594, "latencies_ms": [5689.594], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The person is sitting on the left side of the image, with the plate of food placed in front of them on the right side. The plate of food is positioned closer to the camera than the person, and the background is darker, suggesting that the scene is taking place outdoors at night.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.208}, "power_stats": {"power_gpu_soc_mean_watts": 18.626, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 73.208}, "timestamp": "2026-01-28T12:07:24.665521"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3273.275, "latencies_ms": [3273.275], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman is sitting in a camping chair and eating a hotdog while sitting on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.741}, "power_stats": {"power_gpu_soc_mean_watts": 22.812, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.837, "gpu_utilization_percent_mean": 79.741}, "timestamp": "2026-01-28T12:07:29.964528"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4437.009, "latencies_ms": [4437.009], "images_per_second": 0.225, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken at night, with the subject illuminated by a dim light source, and the background is dark. The subject is wearing a striped shirt and is seated on a folding chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.73}, "power_stats": {"power_gpu_soc_mean_watts": 20.559, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 75.73}, "timestamp": "2026-01-28T12:07:36.447248"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4250.917, "latencies_ms": [4250.917], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A family of 12 is gathered around a long table at a dinner party, with the table filled with food and drinks, and the room decorated with various items.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.429}, "power_stats": {"power_gpu_soc_mean_watts": 20.817, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 76.429}, "timestamp": "2026-01-28T12:07:42.729598"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4133.24, "latencies_ms": [4133.24], "images_per_second": 0.242, "prompt_tokens": 1113, "response_tokens_est": 33, "n_tiles": 1, "output_text": " table: 1, chairs: 1, glasses: 10, plates: 10, food: 10, people: 10", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.118}, "power_stats": {"power_gpu_soc_mean_watts": 21.263, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 73.118}, "timestamp": "2026-01-28T12:07:48.895451"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5481.941, "latencies_ms": [5481.941], "images_per_second": 0.182, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The people are positioned in the middle of the image, with the table in front of them. The background includes a doorway and a painting on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.391}, "power_stats": {"power_gpu_soc_mean_watts": 18.938, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 72.391}, "timestamp": "2026-01-28T12:07:56.434987"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3385.211, "latencies_ms": [3385.211], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered around a long table in a dining room, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.358, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 80.214}, "timestamp": "2026-01-28T12:08:01.856994"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4190.966, "latencies_ms": [4190.966], "images_per_second": 0.239, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the windows. The colors in the image are vibrant and the materials are mostly wooden and fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.92, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 75.4}, "timestamp": "2026-01-28T12:08:08.078916"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3759.469, "latencies_ms": [3759.469], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A baseball game is taking place with a player sliding into a base, and the catcher and umpire are standing nearby.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.387}, "power_stats": {"power_gpu_soc_mean_watts": 21.718, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 78.387}, "timestamp": "2026-01-28T12:08:13.871061"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5997.756, "latencies_ms": [5997.756], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. catcher: 1\n3. umpire: 1\n4. baseball bat: 1\n5. baseball glove: 1\n6. baseball field: 1\n7. fence: 1\n8. bench: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.98}, "power_stats": {"power_gpu_soc_mean_watts": 18.553, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.683, "gpu_utilization_percent_mean": 73.98}, "timestamp": "2026-01-28T12:08:21.914957"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4605.921, "latencies_ms": [4605.921], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The baseball player is in the foreground, sliding into the base. The catcher is in the background, behind the batter. The umpire is also in the background, behind the catcher.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.364, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 73.789}, "timestamp": "2026-01-28T12:08:28.541906"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3113.522, "latencies_ms": [3113.522], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.074, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 81.808}, "timestamp": "2026-01-28T12:08:33.680760"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5277.354, "latencies_ms": [5277.354], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the vibrant green of the field contrasting against the brown dirt of the infield. The sun casts a warm glow on the scene, illuminating the players' uniforms and the white lines marking the base paths.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.932}, "power_stats": {"power_gpu_soc_mean_watts": 19.408, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 73.932}, "timestamp": "2026-01-28T12:08:40.981989"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4235.742, "latencies_ms": [4235.742], "images_per_second": 0.236, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A skateboarder wearing a black helmet and black clothing is performing a trick on a concrete ramp with graffiti on it.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.257}, "power_stats": {"power_gpu_soc_mean_watts": 23.439, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 8.149, "gpu_utilization_percent_mean": 79.257}, "timestamp": "2026-01-28T12:08:47.273154"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6410.82, "latencies_ms": [6410.82], "images_per_second": 0.156, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. knee pads: 2\n4. skateboard: 1\n5. rail: 1\n6. grass: 1\n7. fence: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.167}, "power_stats": {"power_gpu_soc_mean_watts": 20.775, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 76.167}, "timestamp": "2026-01-28T12:08:55.741105"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6436.924, "latencies_ms": [6436.924], "images_per_second": 0.155, "prompt_tokens": 1450, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, jumping over the concrete ledge of the skatepark. The shadow of the skateboarder is cast on the ground, indicating the direction of the light source. The skatepark is situated in the background, surrounded by a grassy area and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.778}, "power_stats": {"power_gpu_soc_mean_watts": 20.553, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 73.778}, "timestamp": "2026-01-28T12:09:04.220104"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4245.809, "latencies_ms": [4245.809], "images_per_second": 0.236, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A skateboarder wearing a black helmet and black clothing is performing a trick on a concrete ramp in a park.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.514}, "power_stats": {"power_gpu_soc_mean_watts": 24.189, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.137, "gpu_utilization_percent_mean": 82.514}, "timestamp": "2026-01-28T12:09:10.502188"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7370.981, "latencies_ms": [7370.981], "images_per_second": 0.136, "prompt_tokens": 1442, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The image captures a dynamic scene of a skateboarder in mid-air, executing a trick on a concrete ramp. The skateboarder is dressed in black attire, including a helmet and knee pads, and is surrounded by a vibrant green park setting. The sun casts a bright light on the scene, highlighting the skateboarder's shadow and the graffiti on the ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.532}, "power_stats": {"power_gpu_soc_mean_watts": 20.032, "power_cpu_cv_mean_watts": 2.035, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 74.532}, "timestamp": "2026-01-28T12:09:19.896053"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3796.659, "latencies_ms": [3796.659], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A plate of food is on a table with a glass of water, a glass of soda, and a bottle of ketchup.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.29}, "power_stats": {"power_gpu_soc_mean_watts": 21.615, "power_cpu_cv_mean_watts": 1.524, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 75.29}, "timestamp": "2026-01-28T12:09:25.719302"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4709.442, "latencies_ms": [4709.442], "images_per_second": 0.212, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " crab cake: 1, fries: 1, tomato: 1, lettuce: 1, pickles: 1, tartar sauce: 1, lemon: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.59}, "power_stats": {"power_gpu_soc_mean_watts": 20.106, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 74.59}, "timestamp": "2026-01-28T12:09:32.480138"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5562.335, "latencies_ms": [5562.335], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The plate of food is located in the foreground of the image, with the glass of water and condiments in the background. The plate of food is to the left of the glass of water, and the condiments are to the right of the glass of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12567.8, "ram_available_mb": 50273.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.37}, "power_stats": {"power_gpu_soc_mean_watts": 19.007, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 70.37}, "timestamp": "2026-01-28T12:09:40.085075"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3662.335, "latencies_ms": [3662.335], "images_per_second": 0.273, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A meal is served on a table with a glass of water, a glass of wine, and a plate of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.8, "ram_available_mb": 50273.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12567.8, "ram_available_mb": 50273.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.054, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 76.6}, "timestamp": "2026-01-28T12:09:45.763641"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6433.952, "latencies_ms": [6433.952], "images_per_second": 0.155, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a plate of food with a variety of colors, including the golden brown of the fries, the red of the tomato, and the green of the lettuce. The lighting is bright and even, illuminating the food and creating a warm and inviting atmosphere. The table is made of wood, and the overall setting suggests a casual dining experience.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12567.8, "ram_available_mb": 50273.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12567.6, "ram_available_mb": 50273.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.111}, "power_stats": {"power_gpu_soc_mean_watts": 17.986, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 71.111}, "timestamp": "2026-01-28T12:09:54.211079"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3223.749, "latencies_ms": [3223.749], "images_per_second": 0.31, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red motorcycle is parked on a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12567.6, "ram_available_mb": 50273.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.769}, "power_stats": {"power_gpu_soc_mean_watts": 22.473, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 79.769}, "timestamp": "2026-01-28T12:09:59.462444"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6847.825, "latencies_ms": [6847.825], "images_per_second": 0.146, "prompt_tokens": 1113, "response_tokens_est": 78, "n_tiles": 1, "output_text": " 1. Motorcycle: 1\n2. Motorcycle seat: 1\n3. Motorcycle windshield: 1\n4. Motorcycle handlebars: 1\n5. Motorcycle mirrors: 2\n6. Motorcycle saddlebags: 2\n7. Motorcycle rear fender: 1\n8. Motorcycle front fender: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12567.4, "ram_available_mb": 50273.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.414}, "power_stats": {"power_gpu_soc_mean_watts": 17.593, "power_cpu_cv_mean_watts": 2.106, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 70.414}, "timestamp": "2026-01-28T12:10:08.330189"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4667.708, "latencies_ms": [4667.708], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the beach and palm trees in the background. The motorcycle is in the foreground, with the beach and palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12567.4, "ram_available_mb": 50273.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.078, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.695, "gpu_utilization_percent_mean": 73.342}, "timestamp": "2026-01-28T12:10:15.022706"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3083.403, "latencies_ms": [3083.403], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red motorcycle is parked on a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.089, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 80.269}, "timestamp": "2026-01-28T12:10:20.152415"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3685.143, "latencies_ms": [3685.143], "images_per_second": 0.271, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The motorcycle is red and black, parked on a sandy beach with palm trees in the background. The sky is clear and blue.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12567.6, "ram_available_mb": 50273.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.742}, "power_stats": {"power_gpu_soc_mean_watts": 21.934, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 77.742}, "timestamp": "2026-01-28T12:10:25.863513"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3152.49, "latencies_ms": [3152.49], "images_per_second": 0.317, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man in a suit and tie is standing in front of a dark wall.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12567.6, "ram_available_mb": 50273.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.577}, "power_stats": {"power_gpu_soc_mean_watts": 22.721, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 81.577}, "timestamp": "2026-01-28T12:10:31.075189"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5628.195, "latencies_ms": [5628.195], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. suit: 1\n2. tie: 1\n3. shirt: 1\n4. tie clip: 1\n5. wall: 1\n6. door: 1\n7. light switch: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12569.0, "ram_available_mb": 50271.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.532}, "power_stats": {"power_gpu_soc_mean_watts": 19.097, "power_cpu_cv_mean_watts": 1.951, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 72.532}, "timestamp": "2026-01-28T12:10:38.713226"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5444.719, "latencies_ms": [5444.719], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is positioned in the foreground, with his face and upper body prominently displayed. The background is relatively dark, with a wall and a light switch visible. The man's tie is positioned to the right of his face, and his suit jacket is to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.0, "ram_available_mb": 50271.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.022}, "power_stats": {"power_gpu_soc_mean_watts": 18.974, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 72.022}, "timestamp": "2026-01-28T12:10:46.182021"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3049.61, "latencies_ms": [3049.61], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man in a suit and tie is standing in front of a door.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.242, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 7.835, "gpu_utilization_percent_mean": 81.16}, "timestamp": "2026-01-28T12:10:51.245823"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3944.994, "latencies_ms": [3944.994], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The man is wearing a dark suit with a white shirt and a patterned tie. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.788}, "power_stats": {"power_gpu_soc_mean_watts": 20.361, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.599, "gpu_utilization_percent_mean": 76.788}, "timestamp": "2026-01-28T12:10:57.228456"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2746.059, "latencies_ms": [2746.059], "images_per_second": 0.364, "prompt_tokens": 1099, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A cat is sleeping on a pair of shoes.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12568.5, "ram_available_mb": 50272.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.636}, "power_stats": {"power_gpu_soc_mean_watts": 23.936, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 83.636}, "timestamp": "2026-01-28T12:11:02.013302"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5732.63, "latencies_ms": [5732.63], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Cat: 1\n2. Shoes: 3\n3. Wall: 1\n4. Floor: 1\n5. Sneakers: 2\n6. White: 1\n7. Black: 1\n8. Blue: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.521}, "power_stats": {"power_gpu_soc_mean_watts": 18.672, "power_cpu_cv_mean_watts": 2.194, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 70.521}, "timestamp": "2026-01-28T12:11:09.763523"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4379.249, "latencies_ms": [4379.249], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The cat is sleeping on the left side of the shoe, which is on the right side of the image. The shoe is in the foreground, while the wall is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12568.9, "ram_available_mb": 50272.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.448, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 73.351}, "timestamp": "2026-01-28T12:11:16.192766"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2768.155, "latencies_ms": [2768.155], "images_per_second": 0.361, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A cat is sleeping on a pair of shoes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.9, "ram_available_mb": 50272.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12569.6, "ram_available_mb": 50271.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.217}, "power_stats": {"power_gpu_soc_mean_watts": 23.644, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 7.837, "gpu_utilization_percent_mean": 83.217}, "timestamp": "2026-01-28T12:11:21.010494"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3380.622, "latencies_ms": [3380.622], "images_per_second": 0.296, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The cat is brown and white, the shoes are blue and white, and the wall is white.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12569.6, "ram_available_mb": 50271.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12569.6, "ram_available_mb": 50271.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.426, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 79.214}, "timestamp": "2026-01-28T12:11:26.447083"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4341.112, "latencies_ms": [4341.112], "images_per_second": 0.23, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A green Isuzu truck with the number 213171 on the front is parked on the street, with a man in a green uniform standing next to it.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12569.6, "ram_available_mb": 50271.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.946}, "power_stats": {"power_gpu_soc_mean_watts": 20.574, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 72.946}, "timestamp": "2026-01-28T12:11:32.838972"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5344.99, "latencies_ms": [5344.99], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 53, "n_tiles": 1, "output_text": " 1. green truck\n2. yellow light\n3. red and white striped bar\n4. person in green uniform\n5. person in yellow vest\n6. person in green vest\n7. person in green uniform\n8. person in green vest", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.067}, "power_stats": {"power_gpu_soc_mean_watts": 19.161, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 72.067}, "timestamp": "2026-01-28T12:11:40.231927"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4792.642, "latencies_ms": [4792.642], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The green truck is in the foreground, parked on the street. The red and white striped barrier is in the middle ground, separating the truck from the sidewalk. The building in the background is far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.2}, "power_stats": {"power_gpu_soc_mean_watts": 19.938, "power_cpu_cv_mean_watts": 1.973, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 74.2}, "timestamp": "2026-01-28T12:11:47.060967"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3684.939, "latencies_ms": [3684.939], "images_per_second": 0.271, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A green truck with a white logo on the front is driving down a street. There are two people on top of the truck.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.767}, "power_stats": {"power_gpu_soc_mean_watts": 22.029, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 77.767}, "timestamp": "2026-01-28T12:11:52.767840"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3612.966, "latencies_ms": [3612.966], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The truck is green and white, and the license plate is yellow. The sky is blue and the sun is shining.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.967}, "power_stats": {"power_gpu_soc_mean_watts": 22.043, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 77.967}, "timestamp": "2026-01-28T12:11:58.398264"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3468.407, "latencies_ms": [3468.407], "images_per_second": 0.288, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is standing on a rocky riverbank, holding a fishing rod, and fishing in the river.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12569.7, "ram_available_mb": 50271.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.069}, "power_stats": {"power_gpu_soc_mean_watts": 22.069, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 80.069}, "timestamp": "2026-01-28T12:12:03.924318"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5608.315, "latencies_ms": [5608.315], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. rocks: 20\n3. water: 1\n4. bridge: 1\n5. vegetation: 1\n6. car: 1\n7. bridge: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12567.4, "ram_available_mb": 50273.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.489}, "power_stats": {"power_gpu_soc_mean_watts": 18.85, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 71.489}, "timestamp": "2026-01-28T12:12:11.578650"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5138.373, "latencies_ms": [5138.373], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The person is standing on the left side of the image, near the riverbank. The bridge is located in the background, far away from the person. The rocks are scattered throughout the river, with some closer to the person and others further away.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12567.4, "ram_available_mb": 50273.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.628}, "power_stats": {"power_gpu_soc_mean_watts": 19.456, "power_cpu_cv_mean_watts": 2.263, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 70.628}, "timestamp": "2026-01-28T12:12:18.732202"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2892.603, "latencies_ms": [2892.603], "images_per_second": 0.346, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is standing in a river with rocks and water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.917}, "power_stats": {"power_gpu_soc_mean_watts": 23.397, "power_cpu_cv_mean_watts": 1.318, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 79.917}, "timestamp": "2026-01-28T12:12:23.636501"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4413.094, "latencies_ms": [4413.094], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a person standing in a river with rocks and water, with a bridge in the background. The sky is clear and blue, and the water is a light blue color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.378}, "power_stats": {"power_gpu_soc_mean_watts": 20.284, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 73.378}, "timestamp": "2026-01-28T12:12:30.097516"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9873.644, "latencies_ms": [9873.644], "images_per_second": 0.101, "prompt_tokens": 1099, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The image captures a bustling street scene in Paris, France, where a row of parked motorcycles, adorned in various colors, lines the sidewalk in front of a row of shops. The motorcycles, each unique in design and color, are neatly aligned, creating a striking visual contrast against the backdrop of the city's architecture. The shops, with their vibrant red awnings and green shutters, add a splash of color to the scene. The buildings, with their ornate details and classic French architecture, stand tall, exuding an air of timeless elegance. The street itself is lined with cobblestones, adding to the charm of the scene.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.651}, "power_stats": {"power_gpu_soc_mean_watts": 15.956, "power_cpu_cv_mean_watts": 2.34, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 67.651}, "timestamp": "2026-01-28T12:12:42.000268"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5914.825, "latencies_ms": [5914.825], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Motorbikes: 12\n2. Street: 1\n3. Building: 1\n4. Sign: 1\n5. Window: 1\n6. Door: 1\n7. Streetlamp: 1\n8. Pedestrian: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.898}, "power_stats": {"power_gpu_soc_mean_watts": 18.544, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 69.898}, "timestamp": "2026-01-28T12:12:49.953097"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4132.067, "latencies_ms": [4132.067], "images_per_second": 0.242, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The motorcycles are parked on the left side of the street, while the buildings are on the right side. The motorcycles are closer to the viewer than the buildings.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12567.9, "ram_available_mb": 50273.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.441}, "power_stats": {"power_gpu_soc_mean_watts": 20.885, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 75.441}, "timestamp": "2026-01-28T12:12:56.109856"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6581.638, "latencies_ms": [6581.638], "images_per_second": 0.152, "prompt_tokens": 1111, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image captures a bustling street corner in Paris, France, where a row of parked motorcycles lines the sidewalk. The motorcycles, predominantly black and silver, are parked in front of a row of shops, including a bar and a caf\u00e9. The buildings are adorned with ornate details, and the street is lined with trees, adding a touch of greenery to the urban setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.327}, "power_stats": {"power_gpu_soc_mean_watts": 17.964, "power_cpu_cv_mean_watts": 2.199, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 68.327}, "timestamp": "2026-01-28T12:13:04.736539"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5498.707, "latencies_ms": [5498.707], "images_per_second": 0.182, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image depicts a vibrant street scene with a variety of motorcycles parked in front of a row of shops. The motorcycles are predominantly black and silver, with some featuring red and green accents. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.4, "ram_available_mb": 50272.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.109}, "power_stats": {"power_gpu_soc_mean_watts": 18.908, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.109}, "timestamp": "2026-01-28T12:13:12.276133"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2842.451, "latencies_ms": [2842.451], "images_per_second": 0.352, "prompt_tokens": 1099, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is holding a bunch of broccoli in their hand.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12568.1, "ram_available_mb": 50272.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12568.0, "ram_available_mb": 50272.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.739}, "power_stats": {"power_gpu_soc_mean_watts": 23.663, "power_cpu_cv_mean_watts": 1.305, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 82.739}, "timestamp": "2026-01-28T12:13:17.160102"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4598.875, "latencies_ms": [4598.875], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " broccoli: 1, hand: 1, broccoli bud: 1, broccoli stem: 1, broccoli leaves: 1, broccoli flower: 1, broccoli flower bud: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.0, "ram_available_mb": 50272.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.0, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 74.026}, "timestamp": "2026-01-28T12:13:23.795742"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3441.953, "latencies_ms": [3441.953], "images_per_second": 0.291, "prompt_tokens": 1117, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The broccoli is in the foreground, held by a hand, while the background is a tiled wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.401, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 79.536}, "timestamp": "2026-01-28T12:13:29.257788"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2903.245, "latencies_ms": [2903.245], "images_per_second": 0.344, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is holding a bunch of broccoli in their hand.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.75}, "power_stats": {"power_gpu_soc_mean_watts": 23.425, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 79.75}, "timestamp": "2026-01-28T12:13:34.175435"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2757.377, "latencies_ms": [2757.377], "images_per_second": 0.363, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The broccoli is green and the hand is pink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12568.7, "ram_available_mb": 50272.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.864}, "power_stats": {"power_gpu_soc_mean_watts": 23.885, "power_cpu_cv_mean_watts": 1.256, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 81.864}, "timestamp": "2026-01-28T12:13:38.944386"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4207.943, "latencies_ms": [4207.943], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " Two people are standing close to each other, one of them is wearing a black jacket with a hood and the other is wearing a black jacket with a red zipper.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.674, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 73.971}, "timestamp": "2026-01-28T12:13:45.215209"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5645.162, "latencies_ms": [5645.162], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. jacket: 2\n3. hood: 1\n4. hat: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.348}, "power_stats": {"power_gpu_soc_mean_watts": 18.942, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 71.348}, "timestamp": "2026-01-28T12:13:52.893523"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5704.07, "latencies_ms": [5704.07], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The person on the left is closer to the camera than the person on the right. The person on the right is in the background, while the person on the left is in the foreground. The person on the right is also farther away from the camera than the person on the left.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.771}, "power_stats": {"power_gpu_soc_mean_watts": 18.604, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 72.771}, "timestamp": "2026-01-28T12:14:00.644841"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3646.373, "latencies_ms": [3646.373], "images_per_second": 0.274, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two people are standing close together in a crowded area, one of them is laughing and the other is covering their face.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.6, "ram_available_mb": 50272.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.333}, "power_stats": {"power_gpu_soc_mean_watts": 21.944, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-28T12:14:06.327447"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3592.941, "latencies_ms": [3592.941], "images_per_second": 0.278, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a dimly lit environment with a yellowish hue, and the subjects are wearing winter clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12568.8, "ram_available_mb": 50272.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.7}, "power_stats": {"power_gpu_soc_mean_watts": 21.933, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 74.7}, "timestamp": "2026-01-28T12:14:11.962009"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2904.791, "latencies_ms": [2904.791], "images_per_second": 0.344, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man with long hair is playing tennis on a blue court.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12569.5, "ram_available_mb": 50271.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12569.0, "ram_available_mb": 50271.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.958}, "power_stats": {"power_gpu_soc_mean_watts": 23.625, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 7.847, "gpu_utilization_percent_mean": 82.958}, "timestamp": "2026-01-28T12:14:16.910681"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5981.915, "latencies_ms": [5981.915], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. chair: 1\n5. white chair: 1\n6. green chair: 1\n7. blue tennis court: 1\n8. white line: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.0, "ram_available_mb": 50271.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12569.2, "ram_available_mb": 50271.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.06}, "power_stats": {"power_gpu_soc_mean_watts": 18.542, "power_cpu_cv_mean_watts": 2.05, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 71.06}, "timestamp": "2026-01-28T12:14:24.949991"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5277.878, "latencies_ms": [5277.878], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball in the center and the empty chairs on the right side. The player is closer to the camera than the chairs, and the ball is in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12569.2, "ram_available_mb": 50271.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.386}, "power_stats": {"power_gpu_soc_mean_watts": 19.222, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 70.386}, "timestamp": "2026-01-28T12:14:32.246650"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2738.083, "latencies_ms": [2738.083], "images_per_second": 0.365, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A man is playing tennis on a blue court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.591}, "power_stats": {"power_gpu_soc_mean_watts": 24.157, "power_cpu_cv_mean_watts": 1.219, "power_sys_5v0_mean_watts": 7.845, "gpu_utilization_percent_mean": 82.591}, "timestamp": "2026-01-28T12:14:36.995427"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3411.709, "latencies_ms": [3411.709], "images_per_second": 0.293, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The tennis court is blue, the man is wearing a white shirt, and the ball is yellow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.244, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 80.714}, "timestamp": "2026-01-28T12:14:42.430891"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4010.914, "latencies_ms": [4010.914], "images_per_second": 0.249, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A red glass vase with a floral design sits on a glass coaster on a wooden shelf, flanked by a white candle and a string of lights.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.091}, "power_stats": {"power_gpu_soc_mean_watts": 21.253, "power_cpu_cv_mean_watts": 1.723, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 75.091}, "timestamp": "2026-01-28T12:14:48.460606"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5613.823, "latencies_ms": [5613.823], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. candle: 1\n2. glass: 1\n3. mirror: 1\n4. wood: 1\n5. string lights: 1\n6. vase: 1\n7. wall: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.553}, "power_stats": {"power_gpu_soc_mean_watts": 18.833, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 72.553}, "timestamp": "2026-01-28T12:14:56.101301"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5216.774, "latencies_ms": [5216.774], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The red glass vase is positioned in the center of the image, with the white candle to its left and the string of lights to its right. The vase is placed on a round glass coaster, which is positioned in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.455}, "power_stats": {"power_gpu_soc_mean_watts": 19.324, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 73.455}, "timestamp": "2026-01-28T12:15:03.362770"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3779.282, "latencies_ms": [3779.282], "images_per_second": 0.265, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A red glass vase sits on a glass coaster on a wooden shelf, with a white candle and string lights in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12566.5, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.903}, "power_stats": {"power_gpu_soc_mean_watts": 21.613, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 77.903}, "timestamp": "2026-01-28T12:15:09.175252"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2773.097, "latencies_ms": [2773.097], "images_per_second": 0.361, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The vase is red and the candle is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.5, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12566.5, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.043}, "power_stats": {"power_gpu_soc_mean_watts": 23.734, "power_cpu_cv_mean_watts": 1.184, "power_sys_5v0_mean_watts": 7.85, "gpu_utilization_percent_mean": 79.043}, "timestamp": "2026-01-28T12:15:13.984277"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3895.027, "latencies_ms": [3895.027], "images_per_second": 0.257, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man in a gray shirt is standing in front of a mirror, while another man in a green shirt is standing in front of a couch.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.5, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.455, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 76.156}, "timestamp": "2026-01-28T12:15:19.909267"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5683.918, "latencies_ms": [5683.918], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. jacket: 1\n3. laptop: 1\n4. man: 2\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.784, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 70.851}, "timestamp": "2026-01-28T12:15:27.607593"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4348.06, "latencies_ms": [4348.06], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The man in the foreground is bending over, while the man in the background is standing upright. The man in the foreground is closer to the camera than the man in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12566.1, "ram_available_mb": 50274.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.25}, "power_stats": {"power_gpu_soc_mean_watts": 20.516, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 71.25}, "timestamp": "2026-01-28T12:15:33.983133"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3126.549, "latencies_ms": [3126.549], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is filming another man in a room with a couch and a laptop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12566.1, "ram_available_mb": 50274.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12566.4, "ram_available_mb": 50274.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.216, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.812, "gpu_utilization_percent_mean": 82.76}, "timestamp": "2026-01-28T12:15:39.120947"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3463.59, "latencies_ms": [3463.59], "images_per_second": 0.289, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken in a room with a brown couch, a silver suitcase, and a white light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12566.4, "ram_available_mb": 50274.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.414}, "power_stats": {"power_gpu_soc_mean_watts": 22.337, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 79.414}, "timestamp": "2026-01-28T12:15:44.618670"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3776.629, "latencies_ms": [3776.629], "images_per_second": 0.265, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman wearing a hat and a striped shirt is holding a cigarette in her hand.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.677}, "power_stats": {"power_gpu_soc_mean_watts": 24.511, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 83.677}, "timestamp": "2026-01-28T12:15:50.449486"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6347.577, "latencies_ms": [6347.577], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. hat: 1\n2. cigarette: 1\n3. woman: 1\n4. necklace: 1\n5. bracelet: 1\n6. shirt: 1\n7. tie: 1\n8. earring: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.962}, "power_stats": {"power_gpu_soc_mean_watts": 20.782, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 74.962}, "timestamp": "2026-01-28T12:15:58.809663"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5428.701, "latencies_ms": [5428.701], "images_per_second": 0.184, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The woman is positioned in the foreground of the image, with her hat and cigarette in the foreground. The background is a plain white wall, which provides a stark contrast to the woman's dark attire and hair.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.444}, "power_stats": {"power_gpu_soc_mean_watts": 22.01, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 79.444}, "timestamp": "2026-01-28T12:16:06.254563"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3826.052, "latencies_ms": [3826.052], "images_per_second": 0.261, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a hat and a striped shirt is holding a cigarette and smiling.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12566.2, "ram_available_mb": 50274.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.484}, "power_stats": {"power_gpu_soc_mean_watts": 24.906, "power_cpu_cv_mean_watts": 1.266, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 85.484}, "timestamp": "2026-01-28T12:16:12.095929"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4955.677, "latencies_ms": [4955.677], "images_per_second": 0.202, "prompt_tokens": 1442, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is in black and white, with a high contrast and a soft focus. The lighting is natural, and the subject is wearing a black hat and a striped shirt.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.829}, "power_stats": {"power_gpu_soc_mean_watts": 22.673, "power_cpu_cv_mean_watts": 1.514, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 79.829}, "timestamp": "2026-01-28T12:16:19.071240"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3192.077, "latencies_ms": [3192.077], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two zebras are grazing in a grassy enclosure with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.016, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 79.808}, "timestamp": "2026-01-28T12:16:24.288268"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3352.976, "latencies_ms": [3352.976], "images_per_second": 0.298, "prompt_tokens": 1113, "response_tokens_est": 20, "n_tiles": 1, "output_text": " zebra: 2\ngrass: 1\nrocks: 2\ntrees: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12564.4, "ram_available_mb": 50276.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.643, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 79.357}, "timestamp": "2026-01-28T12:16:29.698830"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4581.904, "latencies_ms": [4581.904], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the rocky wall and trees in the background. The zebras are grazing on the grass, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12564.4, "ram_available_mb": 50276.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12564.5, "ram_available_mb": 50276.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.949}, "power_stats": {"power_gpu_soc_mean_watts": 20.26, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 73.949}, "timestamp": "2026-01-28T12:16:36.334690"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3201.451, "latencies_ms": [3201.451], "images_per_second": 0.312, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two zebras are grazing in a grassy enclosure with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12564.5, "ram_available_mb": 50276.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12564.8, "ram_available_mb": 50276.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.846}, "power_stats": {"power_gpu_soc_mean_watts": 22.95, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 80.846}, "timestamp": "2026-01-28T12:16:41.551771"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5271.547, "latencies_ms": [5271.547], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features two zebras grazing in a grassy enclosure with a rocky wall in the background. The zebras are black and white with distinctive stripes, and the grass is green with patches of moss. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12564.8, "ram_available_mb": 50276.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.409}, "power_stats": {"power_gpu_soc_mean_watts": 19.218, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 72.409}, "timestamp": "2026-01-28T12:16:48.857476"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3319.438, "latencies_ms": [3319.438], "images_per_second": 0.301, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " An old, rusted fire hydrant with a chain attached to it is sitting on a sidewalk.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.671, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 78.179}, "timestamp": "2026-01-28T12:16:54.212091"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3508.866, "latencies_ms": [3508.866], "images_per_second": 0.285, "prompt_tokens": 1114, "response_tokens_est": 22, "n_tiles": 1, "output_text": " hydrant: 1\nstone: 1\nchain: 1\npink flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.966}, "power_stats": {"power_gpu_soc_mean_watts": 22.234, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 77.966}, "timestamp": "2026-01-28T12:16:59.748725"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5496.799, "latencies_ms": [5496.799], "images_per_second": 0.182, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with a concrete sidewalk and a stone wall in the background. The fire hydrant is positioned to the left of the stone wall, and there are some plants and flowers to the left of the hydrant.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.937, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-28T12:17:07.291099"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3587.182, "latencies_ms": [3587.182], "images_per_second": 0.279, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A rusted fire hydrant sits on the ground next to a stone wall, surrounded by a garden with flowers and plants.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12564.5, "ram_available_mb": 50276.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.733}, "power_stats": {"power_gpu_soc_mean_watts": 21.868, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 75.733}, "timestamp": "2026-01-28T12:17:12.917008"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3224.252, "latencies_ms": [3224.252], "images_per_second": 0.31, "prompt_tokens": 1110, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The fire hydrant is rusted and chained, with a faded pink color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.5, "ram_available_mb": 50276.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12564.4, "ram_available_mb": 50276.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.679, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 82.815}, "timestamp": "2026-01-28T12:17:18.175650"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3905.122, "latencies_ms": [3905.122], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In the image, there are two brown bears walking on a rocky path, with one bear in the foreground and the other in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12564.4, "ram_available_mb": 50276.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.25}, "power_stats": {"power_gpu_soc_mean_watts": 21.503, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 75.25}, "timestamp": "2026-01-28T12:17:24.108275"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5707.901, "latencies_ms": [5707.901], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 2\n2. road: 1\n3. grass: 1\n4. dirt: 1\n5. rocks: 1\n6. dirt road: 1\n7. bear: 1\n8. bear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.532}, "power_stats": {"power_gpu_soc_mean_watts": 18.765, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 70.532}, "timestamp": "2026-01-28T12:17:31.842898"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4808.898, "latencies_ms": [4808.898], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The main bear is in the foreground, walking towards the camera, while the second bear is in the background, walking away from the camera. The bears are on a gravel road, with the road stretching out behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.55}, "power_stats": {"power_gpu_soc_mean_watts": 20.114, "power_cpu_cv_mean_watts": 1.742, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 74.55}, "timestamp": "2026-01-28T12:17:38.680842"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4314.57, "latencies_ms": [4314.57], "images_per_second": 0.232, "prompt_tokens": 1111, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, two brown bears are walking on a gravel road. The bear in the foreground is walking towards the camera, while the other bear is walking away from it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.889}, "power_stats": {"power_gpu_soc_mean_watts": 20.693, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 73.889}, "timestamp": "2026-01-28T12:17:45.057116"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3572.79, "latencies_ms": [3572.79], "images_per_second": 0.28, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The bears are brown with a white underbelly, and the image is taken in natural daylight with a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.167}, "power_stats": {"power_gpu_soc_mean_watts": 22.028, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 77.167}, "timestamp": "2026-01-28T12:17:50.669431"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4073.283, "latencies_ms": [4073.283], "images_per_second": 0.246, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A young child with curly blonde hair is kneeling on the ground next to a metal bowl filled with soil, wearing a white shirt and a colorful tie.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.735}, "power_stats": {"power_gpu_soc_mean_watts": 20.886, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 74.735}, "timestamp": "2026-01-28T12:17:56.772909"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5603.477, "latencies_ms": [5603.477], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. child: 1\n2. shirt: 1\n3. tie: 1\n4. pants: 1\n5. shoes: 1\n6. bowl: 1\n7. gravel: 1\n8. leaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.935}, "power_stats": {"power_gpu_soc_mean_watts": 18.717, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 70.935}, "timestamp": "2026-01-28T12:18:04.392264"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5698.385, "latencies_ms": [5698.385], "images_per_second": 0.175, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The child is in the foreground of the image, kneeling on the ground next to a bucket of soil. The bucket is placed on the ground, which is covered with gravel. The child is holding a handful of soil in their hand, and there is a plant in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.723}, "power_stats": {"power_gpu_soc_mean_watts": 18.637, "power_cpu_cv_mean_watts": 2.07, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 70.723}, "timestamp": "2026-01-28T12:18:12.111711"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2910.178, "latencies_ms": [2910.178], "images_per_second": 0.344, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A young child is playing in a dirt area with a bucket.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.435}, "power_stats": {"power_gpu_soc_mean_watts": 23.297, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 7.895, "gpu_utilization_percent_mean": 78.435}, "timestamp": "2026-01-28T12:18:17.069705"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4547.018, "latencies_ms": [4547.018], "images_per_second": 0.22, "prompt_tokens": 1110, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image is in black and white, with the exception of the child's tie, which is colorful. The child is wearing a white shirt and beige pants. The ground is covered with gravel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.211}, "power_stats": {"power_gpu_soc_mean_watts": 20.279, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 73.211}, "timestamp": "2026-01-28T12:18:23.631406"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3583.474, "latencies_ms": [3583.474], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A table with bottles and flowers sits in the middle of a dirt field with stuffed animals and a red cross on it.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.001, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 75.6}, "timestamp": "2026-01-28T12:18:29.268699"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3990.566, "latencies_ms": [3990.566], "images_per_second": 0.251, "prompt_tokens": 1113, "response_tokens_est": 31, "n_tiles": 1, "output_text": " teddy bear: 2\nbottle: 3\nflowers: 1\ntable: 1\nbench: 1\ncloth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.7, "ram_available_mb": 50276.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12564.1, "ram_available_mb": 50276.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.385, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T12:18:35.296598"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4816.27, "latencies_ms": [4816.27], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The teddy bears are positioned to the left of the table, which is located in the foreground of the image. The table is situated near the center of the image, with the teddy bears and other objects arranged around it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12563.0, "ram_available_mb": 50277.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.855, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 72.25}, "timestamp": "2026-01-28T12:18:42.128553"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4468.504, "latencies_ms": [4468.504], "images_per_second": 0.224, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In a barren, dry landscape, a makeshift memorial is set up. A makeshift bed, adorned with a red cross, holds stuffed animals and bottles of alcohol, suggesting a poignant tribute.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12563.0, "ram_available_mb": 50277.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.205, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 73.351}, "timestamp": "2026-01-28T12:18:48.653730"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5928.609, "latencies_ms": [5928.609], "images_per_second": 0.169, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image depicts a barren, dry landscape with a makeshift table made of wood and metal. The table is adorned with a variety of stuffed animals, including teddy bears and a lion, and a vase filled with yellow flowers. The sky is clear, and the sun is shining brightly, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.58}, "power_stats": {"power_gpu_soc_mean_watts": 18.758, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 70.58}, "timestamp": "2026-01-28T12:18:56.619993"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 10552.818, "latencies_ms": [10552.818], "images_per_second": 0.095, "prompt_tokens": 1432, "response_tokens_est": 123, "n_tiles": 1, "output_text": " The image captures a serene harbor scene, where several fishing boats are docked at a pier. The boats, painted in hues of green and white, are adorned with orange buoys and life jackets, hinting at their purpose and the safety measures in place. The harbor is nestled amidst lush green hills, providing a picturesque backdrop to the scene. The sky overhead is overcast, casting a soft light over the entire setting. In the distance, other boats can be seen, adding to the sense of a bustling harbor. The image exudes a sense of tranquility and the quiet beauty of a day at the harbor.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.389}, "power_stats": {"power_gpu_soc_mean_watts": 17.131, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 70.389}, "timestamp": "2026-01-28T12:19:09.219476"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4855.339, "latencies_ms": [4855.339], "images_per_second": 0.206, "prompt_tokens": 1446, "response_tokens_est": 34, "n_tiles": 1, "output_text": " boat: 1, dock: 1, water: 1, mountains: 1, people: 1, ropes: 1, metal: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.317}, "power_stats": {"power_gpu_soc_mean_watts": 22.934, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 80.317}, "timestamp": "2026-01-28T12:19:16.108420"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5404.957, "latencies_ms": [5404.957], "images_per_second": 0.185, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The fishing boats are positioned on the left side of the image, with the nearest boat being closest to the viewer. The background features a calm body of water, with hills and other boats visible in the distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.511}, "power_stats": {"power_gpu_soc_mean_watts": 22.259, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 76.511}, "timestamp": "2026-01-28T12:19:23.548376"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6706.41, "latencies_ms": [6706.41], "images_per_second": 0.149, "prompt_tokens": 1444, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a serene harbor scene where several fishing boats are docked at a pier. The boats, painted in hues of green and white, are adorned with orange buoys and life jackets, indicating their readiness for the sea. The harbor is nestled amidst lush green hills, providing a picturesque backdrop to this tranquil setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.821}, "power_stats": {"power_gpu_soc_mean_watts": 20.53, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 74.821}, "timestamp": "2026-01-28T12:19:32.280869"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4298.416, "latencies_ms": [4298.416], "images_per_second": 0.233, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image features a harbor with boats docked at the pier, the water is calm and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12563.6, "ram_available_mb": 50277.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12564.1, "ram_available_mb": 50276.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.594, "power_cpu_cv_mean_watts": 1.312, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 82.222}, "timestamp": "2026-01-28T12:19:38.595666"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3048.196, "latencies_ms": [3048.196], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is eating a hot dog with mustard and has her tongue out.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12564.1, "ram_available_mb": 50276.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12563.4, "ram_available_mb": 50277.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.92}, "power_stats": {"power_gpu_soc_mean_watts": 23.082, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 7.835, "gpu_utilization_percent_mean": 81.92}, "timestamp": "2026-01-28T12:19:43.683769"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5535.156, "latencies_ms": [5535.156], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. food: 1\n3. hand: 1\n4. mouth: 1\n5. nose: 1\n6. eyes: 1\n7. hair: 1\n8. scarf: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12563.4, "ram_available_mb": 50277.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12563.5, "ram_available_mb": 50277.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.872}, "power_stats": {"power_gpu_soc_mean_watts": 19.153, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.872}, "timestamp": "2026-01-28T12:19:51.260344"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4892.397, "latencies_ms": [4892.397], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The woman is in the foreground of the image, with the hot dog in her mouth being the main object in the foreground. The background is blurred, indicating that the focus is on the woman and the hot dog.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.902}, "power_stats": {"power_gpu_soc_mean_watts": 19.193, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 73.902}, "timestamp": "2026-01-28T12:19:58.187238"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2739.414, "latencies_ms": [2739.414], "images_per_second": 0.365, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is eating a hot dog at night.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 12563.2, "ram_available_mb": 50277.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12563.3, "ram_available_mb": 50277.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.409}, "power_stats": {"power_gpu_soc_mean_watts": 24.121, "power_cpu_cv_mean_watts": 1.237, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 84.409}, "timestamp": "2026-01-28T12:20:02.943400"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4046.28, "latencies_ms": [4046.28], "images_per_second": 0.247, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken at night, with the subject's face illuminated by a warm light source. The subject is wearing a black jacket and has short dark hair.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12563.3, "ram_available_mb": 50277.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.294}, "power_stats": {"power_gpu_soc_mean_watts": 21.379, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 75.294}, "timestamp": "2026-01-28T12:20:09.037330"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3852.099, "latencies_ms": [3852.099], "images_per_second": 0.26, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man and a woman are standing in a room, the man is holding a glass of champagne and the woman is looking at him.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.603, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 76.344}, "timestamp": "2026-01-28T12:20:14.923045"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5546.413, "latencies_ms": [5546.413], "images_per_second": 0.18, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. glass: 1\n4. curtain: 1\n5. door: 1\n6. wall: 1\n7. floor: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.191}, "power_stats": {"power_gpu_soc_mean_watts": 18.968, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 72.191}, "timestamp": "2026-01-28T12:20:22.520010"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4207.521, "latencies_ms": [4207.521], "images_per_second": 0.238, "prompt_tokens": 1118, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The man is standing to the right of the woman, and they are both standing in the foreground of the image. The woman is closer to the camera than the man.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12563.8, "ram_available_mb": 50277.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12564.5, "ram_available_mb": 50276.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.257}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 77.257}, "timestamp": "2026-01-28T12:20:28.758798"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3799.729, "latencies_ms": [3799.729], "images_per_second": 0.263, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man and a woman are standing in a room, the man is holding a glass of champagne and the woman is looking at him.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12564.5, "ram_available_mb": 50276.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12564.2, "ram_available_mb": 50276.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.742}, "power_stats": {"power_gpu_soc_mean_watts": 21.484, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.824, "gpu_utilization_percent_mean": 76.742}, "timestamp": "2026-01-28T12:20:34.588746"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4873.746, "latencies_ms": [4873.746], "images_per_second": 0.205, "prompt_tokens": 1110, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the window. The man is wearing a black suit with a white shirt and a black tie, while the woman is dressed in a black dress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.2, "ram_available_mb": 50276.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12564.2, "ram_available_mb": 50276.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.797, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 75.463}, "timestamp": "2026-01-28T12:20:41.494944"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8705.306, "latencies_ms": [8705.306], "images_per_second": 0.115, "prompt_tokens": 1099, "response_tokens_est": 108, "n_tiles": 1, "output_text": " The image depicts a blue wooden cabinet with a white top, which is situated in a room with a concrete floor. The cabinet has two open shelves and a closed cabinet door. On the top shelf, there are several items including a silver teapot, a silver pitcher, and a few small metal objects. The bottom shelf contains a few items such as a green plate and a white bowl. The cabinet is positioned in front of a white wall, and there are other items visible in the background, including a wooden chair and a basket.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12564.2, "ram_available_mb": 50276.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12564.8, "ram_available_mb": 50276.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.822}, "power_stats": {"power_gpu_soc_mean_watts": 16.876, "power_cpu_cv_mean_watts": 2.271, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 68.822}, "timestamp": "2026-01-28T12:20:52.240518"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4647.188, "latencies_ms": [4647.188], "images_per_second": 0.215, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. blue cabinet\n2. silver vase\n3. silver bowl\n4. silver cup\n5. silver spoon\n6. silver knife\n7. silver fork\n8. silver spoon", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.8, "ram_available_mb": 50276.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.795}, "power_stats": {"power_gpu_soc_mean_watts": 20.024, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 73.795}, "timestamp": "2026-01-28T12:20:58.905606"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4604.326, "latencies_ms": [4604.326], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The blue cabinet is positioned in the foreground, with the green and white table to its left. The green and white table is situated in the background, while the blue cabinet is in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.579}, "power_stats": {"power_gpu_soc_mean_watts": 20.108, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 71.579}, "timestamp": "2026-01-28T12:21:05.549884"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9477.334, "latencies_ms": [9477.334], "images_per_second": 0.106, "prompt_tokens": 1111, "response_tokens_est": 121, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a flea market, where a blue wooden cabinet stands as the centerpiece. The cabinet, adorned with a green and white striped top, is brimming with an array of items, each with its own story to tell. Amidst the clutter, a silver teapot and a white vase add a touch of elegance, while a green and white striped plate and a blue and white striped bowl add a dash of color. The background is a blur of other stalls and people, each with their own tales to tell, creating a lively atmosphere that is quintessentially flea market.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 66.55}, "power_stats": {"power_gpu_soc_mean_watts": 16.281, "power_cpu_cv_mean_watts": 2.368, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 66.55}, "timestamp": "2026-01-28T12:21:17.050248"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5892.619, "latencies_ms": [5892.619], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image depicts a blue wooden cabinet with a white top, situated in a room with a concrete floor. The cabinet is adorned with various items, including a silver teapot, a silver pitcher, and a green vase. The lighting in the room is natural, coming from a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12566.5, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.776}, "power_stats": {"power_gpu_soc_mean_watts": 18.879, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 70.776}, "timestamp": "2026-01-28T12:21:24.995529"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3350.513, "latencies_ms": [3350.513], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A plate of cheese and butter sandwiches is on a desk with a keyboard and mouse in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12566.5, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.889}, "power_stats": {"power_gpu_soc_mean_watts": 22.619, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 80.889}, "timestamp": "2026-01-28T12:21:30.374352"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4308.266, "latencies_ms": [4308.266], "images_per_second": 0.232, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " plate: 1, butter: 1, bread: 4, butter knife: 1, keyboard: 1, mouse: 1, mousepad: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.658, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 74.278}, "timestamp": "2026-01-28T12:21:36.700828"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5532.398, "latencies_ms": [5532.398], "images_per_second": 0.181, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The plate is located in the foreground, with the sandwich slices placed on top of it. The sandwich slices are positioned in a diagonal arrangement, with the top left slice being the closest to the camera. The plate is situated on a desk, which is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.217}, "power_stats": {"power_gpu_soc_mean_watts": 18.661, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 71.217}, "timestamp": "2026-01-28T12:21:44.287130"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3144.57, "latencies_ms": [3144.57], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A plate of cheese and butter sandwiches is on a desk with a keyboard and mouse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.615}, "power_stats": {"power_gpu_soc_mean_watts": 23.015, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.82, "gpu_utilization_percent_mean": 78.615}, "timestamp": "2026-01-28T12:21:49.479803"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4482.122, "latencies_ms": [4482.122], "images_per_second": 0.223, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image shows a plate of cheese and butter sandwiches on a white plate, with a keyboard and mouse in the background. The lighting is natural, and the sandwiches are placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.921}, "power_stats": {"power_gpu_soc_mean_watts": 20.259, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 73.921}, "timestamp": "2026-01-28T12:21:56.006070"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4277.622, "latencies_ms": [4277.622], "images_per_second": 0.234, "prompt_tokens": 1432, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man in a suit and tie is adjusting his tie, which has a pattern of red, green, and yellow lights.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.086}, "power_stats": {"power_gpu_soc_mean_watts": 23.427, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 76.086}, "timestamp": "2026-01-28T12:22:02.321048"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4318.522, "latencies_ms": [4318.522], "images_per_second": 0.232, "prompt_tokens": 1446, "response_tokens_est": 24, "n_tiles": 1, "output_text": " tie: 1, glasses: 1, suit: 1, shirt: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.639}, "power_stats": {"power_gpu_soc_mean_watts": 23.706, "power_cpu_cv_mean_watts": 1.29, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 79.639}, "timestamp": "2026-01-28T12:22:08.655147"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5538.615, "latencies_ms": [5538.615], "images_per_second": 0.181, "prompt_tokens": 1450, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The man is standing in the foreground, with the tie being the main object in the image. The tie is positioned in the middle of the image, with the man's face and glasses being the closest objects to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.064}, "power_stats": {"power_gpu_soc_mean_watts": 21.797, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 78.064}, "timestamp": "2026-01-28T12:22:16.230712"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3699.486, "latencies_ms": [3699.486], "images_per_second": 0.27, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is adjusting his tie with a glowing red light on it.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.29}, "power_stats": {"power_gpu_soc_mean_watts": 24.859, "power_cpu_cv_mean_watts": 1.279, "power_sys_5v0_mean_watts": 8.166, "gpu_utilization_percent_mean": 85.29}, "timestamp": "2026-01-28T12:22:21.964421"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4640.86, "latencies_ms": [4640.86], "images_per_second": 0.215, "prompt_tokens": 1442, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The man is wearing a black suit with a tie that has a pattern of red and green lights. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.369, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 78.5}, "timestamp": "2026-01-28T12:22:28.620328"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3513.376, "latencies_ms": [3513.376], "images_per_second": 0.285, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man is walking across the street in front of a building with a sign that says \"TABU\".", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.112, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 77.207}, "timestamp": "2026-01-28T12:22:34.192008"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5648.503, "latencies_ms": [5648.503], "images_per_second": 0.177, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. traffic light: 1\n3. street light: 1\n4. building: 2\n5. sign: 1\n6. car: 1\n7. sidewalk: 1\n8. street: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.713, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-28T12:22:41.864411"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4892.182, "latencies_ms": [4892.182], "images_per_second": 0.204, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is walking on the sidewalk in front of the building, which is located on the corner of the street. The traffic light is positioned on the street corner, and the building is situated on the opposite side of the street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.707}, "power_stats": {"power_gpu_soc_mean_watts": 19.753, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 73.707}, "timestamp": "2026-01-28T12:22:48.786718"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3554.031, "latencies_ms": [3554.031], "images_per_second": 0.281, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man is walking across the street at night in front of a building with a sign that says \"TABU\".", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12564.8, "ram_available_mb": 50276.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.724}, "power_stats": {"power_gpu_soc_mean_watts": 21.986, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 77.724}, "timestamp": "2026-01-28T12:22:54.373675"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4106.538, "latencies_ms": [4106.538], "images_per_second": 0.244, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken at night, with the sky being dark blue and the street being lit by streetlights. The building is white and has a curved facade.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12564.8, "ram_available_mb": 50276.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.206}, "power_stats": {"power_gpu_soc_mean_watts": 21.013, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 76.206}, "timestamp": "2026-01-28T12:23:00.512355"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4769.045, "latencies_ms": [4769.045], "images_per_second": 0.21, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a young girl is skillfully riding a wave on a blue surfboard, while a group of people are enjoying the ocean, with one person holding a blue surfboard and another person swimming in the water.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.2}, "power_stats": {"power_gpu_soc_mean_watts": 19.876, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-28T12:23:07.347383"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5865.74, "latencies_ms": [5865.74], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. surfboard: 1\n2. person: 3\n3. surfboard: 1\n4. person: 1\n5. surfboard: 1\n6. person: 1\n7. surfboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.612}, "power_stats": {"power_gpu_soc_mean_watts": 18.603, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 71.612}, "timestamp": "2026-01-28T12:23:15.251950"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6346.246, "latencies_ms": [6346.246], "images_per_second": 0.158, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The main object, a girl, is in the foreground, riding a wave on a blue surfboard. The surfboard is in the middle ground, with the girl positioned slightly to the left of it. The background features other people, including a man in a black wetsuit, who are swimming and paddling on their surfboards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.1, "ram_available_mb": 50275.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.377}, "power_stats": {"power_gpu_soc_mean_watts": 18.03, "power_cpu_cv_mean_watts": 2.244, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 69.377}, "timestamp": "2026-01-28T12:23:23.614977"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7211.244, "latencies_ms": [7211.244], "images_per_second": 0.139, "prompt_tokens": 1111, "response_tokens_est": 84, "n_tiles": 1, "output_text": " In the vast expanse of the ocean, a group of people are enjoying a day of surfing. The surfer in the foreground, clad in a blue wetsuit, is skillfully riding a wave on a blue surfboard. In the background, other surfers can be seen paddling and waiting for their turn to catch a wave. The scene is a vibrant display of the ocean's power and the thrill of surfing.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.361}, "power_stats": {"power_gpu_soc_mean_watts": 17.616, "power_cpu_cv_mean_watts": 2.035, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 70.361}, "timestamp": "2026-01-28T12:23:32.838220"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6303.041, "latencies_ms": [6303.041], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a group of people enjoying a day at the beach. The sky is a clear blue, and the sun is shining brightly, casting a warm glow on the water. The waves are a beautiful shade of blue, and the surfers are wearing colorful swimwear, adding a splash of color to the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12565.5, "ram_available_mb": 50275.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.755}, "power_stats": {"power_gpu_soc_mean_watts": 18.267, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 70.755}, "timestamp": "2026-01-28T12:23:41.169102"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4477.169, "latencies_ms": [4477.169], "images_per_second": 0.223, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the image, a man wearing a white shirt and beige pants is feeding an elephant with his hand, while the elephant is standing on a concrete platform with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.5, "ram_available_mb": 50275.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.27}, "power_stats": {"power_gpu_soc_mean_watts": 20.385, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 72.27}, "timestamp": "2026-01-28T12:23:47.696758"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5158.218, "latencies_ms": [5158.218], "images_per_second": 0.194, "prompt_tokens": 1113, "response_tokens_est": 49, "n_tiles": 1, "output_text": " elephant: 1, man: 1, fence: 1, elephant's trunk: 1, man's hand: 1, man's pants: 1, man's shirt: 1, man's belt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.837}, "power_stats": {"power_gpu_soc_mean_watts": 19.644, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 70.837}, "timestamp": "2026-01-28T12:23:54.892294"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4808.269, "latencies_ms": [4808.269], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, while the elephant is on the right side. The man is closer to the camera than the elephant. The elephant is in the background, behind the fence.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12565.2, "ram_available_mb": 50275.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.625}, "power_stats": {"power_gpu_soc_mean_watts": 19.875, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 73.625}, "timestamp": "2026-01-28T12:24:01.733111"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3264.526, "latencies_ms": [3264.526], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is feeding an elephant in a fenced area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.148}, "power_stats": {"power_gpu_soc_mean_watts": 22.428, "power_cpu_cv_mean_watts": 1.275, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 79.148}, "timestamp": "2026-01-28T12:24:07.035874"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3222.536, "latencies_ms": [3222.536], "images_per_second": 0.31, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephant is gray, the man is wearing white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12565.7, "ram_available_mb": 50275.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12566.2, "ram_available_mb": 50274.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.926}, "power_stats": {"power_gpu_soc_mean_watts": 22.517, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 82.926}, "timestamp": "2026-01-28T12:24:12.303665"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3449.267, "latencies_ms": [3449.267], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown and white dog sits on a bed covered in clothes and a box, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12566.2, "ram_available_mb": 50274.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12564.9, "ram_available_mb": 50276.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.607}, "power_stats": {"power_gpu_soc_mean_watts": 22.544, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 74.607}, "timestamp": "2026-01-28T12:24:17.784326"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4235.934, "latencies_ms": [4235.934], "images_per_second": 0.236, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " dog: 1, box: 1, clothes: 1, pillow: 1, blanket: 1, bag: 1, window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.9, "ram_available_mb": 50276.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.457}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 75.457}, "timestamp": "2026-01-28T12:24:24.029071"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4266.744, "latencies_ms": [4266.744], "images_per_second": 0.234, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The dog is sitting on the bed, which is in the foreground of the image. The bed is located near the window, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.848, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 71.229}, "timestamp": "2026-01-28T12:24:30.323841"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3157.213, "latencies_ms": [3157.213], "images_per_second": 0.317, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A brown and white dog sits on a bed covered in clothes and a box.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.885}, "power_stats": {"power_gpu_soc_mean_watts": 22.932, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 80.885}, "timestamp": "2026-01-28T12:24:35.528952"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3404.933, "latencies_ms": [3404.933], "images_per_second": 0.294, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The dog is brown and white, and the room is lit by natural light coming through a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.252, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 78.071}, "timestamp": "2026-01-28T12:24:40.961077"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3783.233, "latencies_ms": [3783.233], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a blue tie and white shirt is sitting at a desk with a laptop and a pen in his hand, looking thoughtful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12565.5, "ram_available_mb": 50275.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.29}, "power_stats": {"power_gpu_soc_mean_watts": 21.767, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 77.29}, "timestamp": "2026-01-28T12:24:46.773865"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3649.714, "latencies_ms": [3649.714], "images_per_second": 0.274, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " laptop: 1, pen: 1, glasses: 1, notebook: 1, man: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12565.5, "ram_available_mb": 50275.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12565.5, "ram_available_mb": 50275.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.803, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 75.6}, "timestamp": "2026-01-28T12:24:52.443397"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5151.06, "latencies_ms": [5151.06], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The laptop is on the left side of the man, the pen is on the right side of the man, and the glasses are on the man's head. The man is in the foreground, and the background is a blurred image of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.5, "ram_available_mb": 50275.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.75}, "power_stats": {"power_gpu_soc_mean_watts": 19.354, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 72.75}, "timestamp": "2026-01-28T12:24:59.629721"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3567.719, "latencies_ms": [3567.719], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man in a blue tie and white shirt is sitting at a desk with a laptop and a pen in his hand.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.201, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 76.667}, "timestamp": "2026-01-28T12:25:05.227433"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3477.077, "latencies_ms": [3477.077], "images_per_second": 0.288, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The man is wearing a blue tie and a white shirt. The laptop is black and the pen is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.069}, "power_stats": {"power_gpu_soc_mean_watts": 22.304, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 79.069}, "timestamp": "2026-01-28T12:25:10.732368"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3732.729, "latencies_ms": [3732.729], "images_per_second": 0.268, "prompt_tokens": 1432, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large airplane is flying in the sky with a moon in the background.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.161}, "power_stats": {"power_gpu_soc_mean_watts": 24.354, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.149, "gpu_utilization_percent_mean": 86.161}, "timestamp": "2026-01-28T12:25:16.515434"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4057.059, "latencies_ms": [4057.059], "images_per_second": 0.246, "prompt_tokens": 1446, "response_tokens_est": 19, "n_tiles": 1, "output_text": " airplane: 1, moon: 1, clouds: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12566.3, "ram_available_mb": 50274.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.059}, "power_stats": {"power_gpu_soc_mean_watts": 24.027, "power_cpu_cv_mean_watts": 1.26, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 83.059}, "timestamp": "2026-01-28T12:25:22.595822"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4575.561, "latencies_ms": [4575.561], "images_per_second": 0.219, "prompt_tokens": 1450, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The airplane is flying in the sky, which is in the background. The moon is in the foreground, and the airplane is flying above it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.3, "ram_available_mb": 50274.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12566.4, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.842}, "power_stats": {"power_gpu_soc_mean_watts": 23.502, "power_cpu_cv_mean_watts": 2.066, "power_sys_5v0_mean_watts": 8.122, "gpu_utilization_percent_mean": 80.842}, "timestamp": "2026-01-28T12:25:29.180329"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3645.56, "latencies_ms": [3645.56], "images_per_second": 0.274, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plane is flying in the sky with the moon in the background.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12566.4, "ram_available_mb": 50274.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.2}, "power_stats": {"power_gpu_soc_mean_watts": 25.328, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 86.2}, "timestamp": "2026-01-28T12:25:34.864084"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4608.03, "latencies_ms": [4608.03], "images_per_second": 0.217, "prompt_tokens": 1442, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The airplane is white with red and blue stripes on the tail, and the moon is orange. The sky is blue and the lighting is bright.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12565.6, "ram_available_mb": 50275.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.395}, "power_stats": {"power_gpu_soc_mean_watts": 23.282, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 77.395}, "timestamp": "2026-01-28T12:25:41.504688"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4204.064, "latencies_ms": [4204.064], "images_per_second": 0.238, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A young man wearing a tie-dye shirt and black pants is performing a skateboard trick in a skate park.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12566.0, "ram_available_mb": 50274.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.2}, "power_stats": {"power_gpu_soc_mean_watts": 23.539, "power_cpu_cv_mean_watts": 2.609, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 81.2}, "timestamp": "2026-01-28T12:25:47.742637"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5035.867, "latencies_ms": [5035.867], "images_per_second": 0.199, "prompt_tokens": 1446, "response_tokens_est": 36, "n_tiles": 1, "output_text": " skateboard: 1, person: 1, palm tree: 1, building: 1, bench: 1, sky: 1, clouds: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12565.0, "ram_available_mb": 50275.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.524, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 77.071}, "timestamp": "2026-01-28T12:25:54.807051"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5004.012, "latencies_ms": [5004.012], "images_per_second": 0.2, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the middle of the image. The skate park is in the background, with palm trees and buildings visible beyond it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.738}, "power_stats": {"power_gpu_soc_mean_watts": 22.507, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 77.738}, "timestamp": "2026-01-28T12:26:01.853070"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3760.707, "latencies_ms": [3760.707], "images_per_second": 0.266, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young man wearing a tie dye shirt is skateboarding in a skate park.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.194}, "power_stats": {"power_gpu_soc_mean_watts": 25.128, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 85.194}, "timestamp": "2026-01-28T12:26:07.650626"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4572.581, "latencies_ms": [4572.581], "images_per_second": 0.219, "prompt_tokens": 1442, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The skateboarder is wearing a tie-dye shirt and black pants, and the skate park is surrounded by palm trees and buildings.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12565.4, "ram_available_mb": 50275.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.895}, "power_stats": {"power_gpu_soc_mean_watts": 23.232, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 78.895}, "timestamp": "2026-01-28T12:26:14.248583"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4426.688, "latencies_ms": [4426.688], "images_per_second": 0.226, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the image, a sheep with a fluffy white coat is standing in a grassy field, looking directly at the camera, while a wire fence with a metal gate is visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12565.3, "ram_available_mb": 50275.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.083}, "power_stats": {"power_gpu_soc_mean_watts": 20.718, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 75.083}, "timestamp": "2026-01-28T12:26:20.700673"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5972.279, "latencies_ms": [5972.279], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. wire fence: 1\n3. grass: 1\n4. trees: 1\n5. wire: 1\n6. sheep's wool: 1\n7. sheep's face: 1\n8. sheep's body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.9, "ram_available_mb": 50275.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.039}, "power_stats": {"power_gpu_soc_mean_watts": 18.394, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.683, "gpu_utilization_percent_mean": 71.039}, "timestamp": "2026-01-28T12:26:28.705816"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4292.768, "latencies_ms": [4292.768], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sheep is in the foreground, behind a wire fence, and the trees are in the background. The sheep is looking directly at the camera, while the trees are behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12565.8, "ram_available_mb": 50275.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.111}, "power_stats": {"power_gpu_soc_mean_watts": 20.673, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 73.111}, "timestamp": "2026-01-28T12:26:35.045617"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3140.519, "latencies_ms": [3140.519], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A sheep is standing in a field behind a fence, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.423}, "power_stats": {"power_gpu_soc_mean_watts": 22.983, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 81.423}, "timestamp": "2026-01-28T12:26:40.215144"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2989.828, "latencies_ms": [2989.828], "images_per_second": 0.334, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The sheep is white and fluffy, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.3, "ram_available_mb": 50273.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12567.5, "ram_available_mb": 50273.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.375}, "power_stats": {"power_gpu_soc_mean_watts": 23.265, "power_cpu_cv_mean_watts": 1.218, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 80.375}, "timestamp": "2026-01-28T12:26:45.232918"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3800.629, "latencies_ms": [3800.629], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image shows a close-up of a white electronic device with a red logo and a circular button with a red symbol on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.5, "ram_available_mb": 50273.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.677}, "power_stats": {"power_gpu_soc_mean_watts": 21.734, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 75.677}, "timestamp": "2026-01-28T12:26:51.075955"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5632.183, "latencies_ms": [5632.183], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. iPod: 1\n2. Screen: 1\n3. Buttons: 5\n4. Silver: 1\n5. Red: 1\n6. White: 1\n7. Black: 1\n8. Green: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12567.1, "ram_available_mb": 50273.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.681}, "power_stats": {"power_gpu_soc_mean_watts": 18.965, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 72.681}, "timestamp": "2026-01-28T12:26:58.728087"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4835.523, "latencies_ms": [4835.523], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main object is located in the foreground, with the buttons and the logo being the focal point of the image. The buttons are positioned on the left side of the device, while the logo is located on the right side.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.951}, "power_stats": {"power_gpu_soc_mean_watts": 19.815, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 72.951}, "timestamp": "2026-01-28T12:27:05.600789"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5098.415, "latencies_ms": [5098.415], "images_per_second": 0.196, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a close-up view of a white electronic device, possibly a portable media player, with a prominent red logo on its side. The device features a circular button with a red outline and a white center, surrounded by a green ring.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.721}, "power_stats": {"power_gpu_soc_mean_watts": 19.555, "power_cpu_cv_mean_watts": 2.012, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 72.721}, "timestamp": "2026-01-28T12:27:12.713831"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4007.302, "latencies_ms": [4007.302], "images_per_second": 0.25, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The device is white with green accents and has a glossy finish. It is illuminated by a bright light source, casting a shadow on the surface.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12566.6, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.265}, "power_stats": {"power_gpu_soc_mean_watts": 21.231, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 72.265}, "timestamp": "2026-01-28T12:27:18.762426"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4006.963, "latencies_ms": [4006.963], "images_per_second": 0.25, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman wearing a black dress and black shoes is standing in a kitchen holding a glass of champagne.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12566.6, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.879}, "power_stats": {"power_gpu_soc_mean_watts": 24.155, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 81.879}, "timestamp": "2026-01-28T12:27:24.802819"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6306.774, "latencies_ms": [6306.774], "images_per_second": 0.159, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. dress: 1\n3. shoes: 1\n4. refrigerator: 1\n5. counter: 1\n6. cabinet: 1\n7. bottle: 1\n8. mop: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.6, "ram_available_mb": 50274.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.585}, "power_stats": {"power_gpu_soc_mean_watts": 21.012, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 73.585}, "timestamp": "2026-01-28T12:27:33.161626"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5345.635, "latencies_ms": [5345.635], "images_per_second": 0.187, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the refrigerator in the background. The woman is positioned to the left of the refrigerator, and the sink is located to the right of the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.978}, "power_stats": {"power_gpu_soc_mean_watts": 22.097, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 76.978}, "timestamp": "2026-01-28T12:27:40.555822"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4073.106, "latencies_ms": [4073.106], "images_per_second": 0.246, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman wearing a black dress is standing in a kitchen holding a glass of champagne.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12566.2, "ram_available_mb": 50274.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.676}, "power_stats": {"power_gpu_soc_mean_watts": 23.871, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 84.676}, "timestamp": "2026-01-28T12:27:46.673828"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4373.538, "latencies_ms": [4373.538], "images_per_second": 0.229, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The woman is wearing a black dress with sparkles and black shoes. The kitchen has wooden cabinets and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12566.2, "ram_available_mb": 50274.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12592.8, "ram_available_mb": 50248.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.972}, "power_stats": {"power_gpu_soc_mean_watts": 23.843, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 80.972}, "timestamp": "2026-01-28T12:27:53.076842"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4284.526, "latencies_ms": [4284.526], "images_per_second": 0.233, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image captures a round convex mirror mounted on a pole, reflecting the scene of a yellow school bus and a silver car on a street with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12592.8, "ram_available_mb": 50248.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.63, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 73.222}, "timestamp": "2026-01-28T12:27:59.410608"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4406.031, "latencies_ms": [4406.031], "images_per_second": 0.227, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " mirror: 1\nbus: 1\ntraffic light: 1\npole: 1\nbuilding: 1\ncar: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.083}, "power_stats": {"power_gpu_soc_mean_watts": 20.44, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 75.083}, "timestamp": "2026-01-28T12:28:05.831862"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6176.752, "latencies_ms": [6176.752], "images_per_second": 0.162, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The mirror is positioned in the foreground, reflecting the yellow school bus and the surrounding environment. The reflection of the school bus is prominently displayed in the mirror, which is mounted on a pole. The background of the image features a building with a sign, indicating that the mirror is likely located near a commercial or public area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.51}, "power_stats": {"power_gpu_soc_mean_watts": 18.318, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.677, "gpu_utilization_percent_mean": 72.51}, "timestamp": "2026-01-28T12:28:14.021497"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5161.902, "latencies_ms": [5161.902], "images_per_second": 0.194, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a scene of a school bus parked on the side of a road, with its reflection visible in a convex mirror mounted on a pole. The background reveals a commercial area with various signs and advertisements, suggesting a busy urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.256}, "power_stats": {"power_gpu_soc_mean_watts": 19.191, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 71.256}, "timestamp": "2026-01-28T12:28:21.227607"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4568.654, "latencies_ms": [4568.654], "images_per_second": 0.219, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a yellow school bus with a red roof, parked on the side of a road. The sky is overcast, and the lighting is dim, casting a soft glow on the scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.262, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 73.026}, "timestamp": "2026-01-28T12:28:27.841972"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4829.278, "latencies_ms": [4829.278], "images_per_second": 0.207, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the image, a gray cat is sitting on a wooden table, looking at a dog that is standing outside the window. The dog is brown and black, and there are several potted plants on the table.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.1}, "power_stats": {"power_gpu_soc_mean_watts": 19.94, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 75.1}, "timestamp": "2026-01-28T12:28:34.708711"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5671.632, "latencies_ms": [5671.632], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. cat: 1\n2. dog: 2\n3. potted plant: 3\n4. can: 1\n5. window: 1\n6. table: 1\n7. grass: 1\n8. fence: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.489}, "power_stats": {"power_gpu_soc_mean_watts": 19.058, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 72.489}, "timestamp": "2026-01-28T12:28:42.426296"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4259.203, "latencies_ms": [4259.203], "images_per_second": 0.235, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at the dog, which is in the background. The dog is standing on the grass, while the cat is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.673, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-28T12:28:48.724117"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3288.047, "latencies_ms": [3288.047], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A gray cat is sitting on a table next to a window, looking outside at a dog.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.444}, "power_stats": {"power_gpu_soc_mean_watts": 22.757, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 79.444}, "timestamp": "2026-01-28T12:28:54.029676"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3663.399, "latencies_ms": [3663.399], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is taken during the day with natural light coming through the window, and the cat is sitting on a wooden table.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.018, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 78.033}, "timestamp": "2026-01-28T12:28:59.709481"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4780.524, "latencies_ms": [4780.524], "images_per_second": 0.209, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " A female soccer player in a blue jersey with the number 10 and the name \"Marilyn\" on it is dribbling the ball while being closely followed by a player in a yellow jersey.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.45}, "power_stats": {"power_gpu_soc_mean_watts": 20.088, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 72.45}, "timestamp": "2026-01-28T12:29:06.510769"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5717.032, "latencies_ms": [5717.032], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. soccer ball: 1\n3. jersey: 1\n4. shorts: 1\n5. headband: 1\n6. hair: 1\n7. background: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12588.5, "ram_available_mb": 50252.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.104}, "power_stats": {"power_gpu_soc_mean_watts": 18.876, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 74.104}, "timestamp": "2026-01-28T12:29:14.245247"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6155.885, "latencies_ms": [6155.885], "images_per_second": 0.162, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The main object is a woman wearing a blue jersey, positioned in the foreground of the image. The woman is holding a soccer ball in her hands, which is located in the middle of the image. In the background, there is another woman wearing a yellow jersey, positioned to the right of the woman in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.5, "ram_available_mb": 50252.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.356, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-28T12:29:22.413902"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3295.156, "latencies_ms": [3295.156], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A female soccer player in a blue jersey is dribbling the ball on a field.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.711, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 79.593}, "timestamp": "2026-01-28T12:29:27.748380"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5838.625, "latencies_ms": [5838.625], "images_per_second": 0.171, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a grassy field, where a female athlete in a vibrant blue jersey is in the midst of a powerful kick, her body language suggesting intense focus and determination. The lighting is natural and bright, casting soft shadows and highlighting the texture of the grass beneath her feet.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.612}, "power_stats": {"power_gpu_soc_mean_watts": 18.344, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 70.612}, "timestamp": "2026-01-28T12:29:35.635201"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3902.337, "latencies_ms": [3902.337], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In the image, there are two giraffes standing in a grassy area, one of them eating grass while the other is standing near a fence.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.875}, "power_stats": {"power_gpu_soc_mean_watts": 21.257, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 72.875}, "timestamp": "2026-01-28T12:29:41.564942"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5789.649, "latencies_ms": [5789.649], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. giraffe: 2\n2. fence: 1\n3. grass: 1\n4. tree: 1\n5. tree trunk: 1\n6. tree leaves: 1\n7. tree branches: 1\n8. tree trunk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.98}, "power_stats": {"power_gpu_soc_mean_watts": 18.664, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 70.98}, "timestamp": "2026-01-28T12:29:49.410126"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6361.368, "latencies_ms": [6361.368], "images_per_second": 0.157, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The giraffe on the left is positioned closer to the camera than the one on the right, which is farther away. The giraffe on the right is standing near the fence, while the one on the left is grazing near the fence. The giraffe on the right is also positioned in the background, while the one on the left is in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12588.5, "ram_available_mb": 50252.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.434}, "power_stats": {"power_gpu_soc_mean_watts": 18.412, "power_cpu_cv_mean_watts": 2.086, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 70.434}, "timestamp": "2026-01-28T12:29:57.828143"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3625.212, "latencies_ms": [3625.212], "images_per_second": 0.276, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two giraffes are standing in a grassy area with a fence in the background, one eating grass and the other looking around.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12588.5, "ram_available_mb": 50252.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.046, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-28T12:30:03.478613"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3731.409, "latencies_ms": [3731.409], "images_per_second": 0.268, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The giraffes are brown and white, and the grass is green. The giraffes are standing in a grassy area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.258}, "power_stats": {"power_gpu_soc_mean_watts": 21.93, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 77.258}, "timestamp": "2026-01-28T12:30:09.259275"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3850.67, "latencies_ms": [3850.67], "images_per_second": 0.26, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A suitcase and two bags are on the floor in front of a curtain.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.062}, "power_stats": {"power_gpu_soc_mean_watts": 23.932, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 84.062}, "timestamp": "2026-01-28T12:30:15.177134"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3178.375, "latencies_ms": [3178.375], "images_per_second": 0.315, "prompt_tokens": 1446, "response_tokens_est": 5, "n_tiles": 1, "output_text": " suitcase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.846}, "power_stats": {"power_gpu_soc_mean_watts": 25.866, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.176, "gpu_utilization_percent_mean": 86.846}, "timestamp": "2026-01-28T12:30:20.389798"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4213.636, "latencies_ms": [4213.636], "images_per_second": 0.237, "prompt_tokens": 1450, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The suitcase is on the left, the bag is on the right, and the books are in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.571}, "power_stats": {"power_gpu_soc_mean_watts": 24.067, "power_cpu_cv_mean_watts": 1.293, "power_sys_5v0_mean_watts": 8.137, "gpu_utilization_percent_mean": 82.571}, "timestamp": "2026-01-28T12:30:26.664003"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3834.878, "latencies_ms": [3834.878], "images_per_second": 0.261, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A suitcase and two bags are on the floor in front of a curtain.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12588.2, "ram_available_mb": 50252.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.581}, "power_stats": {"power_gpu_soc_mean_watts": 24.923, "power_cpu_cv_mean_watts": 1.162, "power_sys_5v0_mean_watts": 8.132, "gpu_utilization_percent_mean": 84.581}, "timestamp": "2026-01-28T12:30:32.520147"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4199.492, "latencies_ms": [4199.492], "images_per_second": 0.238, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is in black and white, and the lighting is dim. The materials of the luggage are not clear.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 12588.2, "ram_available_mb": 50252.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12588.2, "ram_available_mb": 50252.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.343}, "power_stats": {"power_gpu_soc_mean_watts": 23.988, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.145, "gpu_utilization_percent_mean": 83.343}, "timestamp": "2026-01-28T12:30:38.754417"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4136.532, "latencies_ms": [4136.532], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a man wearing a blue shirt and an orange bandana is standing on a rocky trail in a forest, observing a group of people riding horses.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12588.2, "ram_available_mb": 50252.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.257}, "power_stats": {"power_gpu_soc_mean_watts": 21.024, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 76.257}, "timestamp": "2026-01-28T12:30:44.940368"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5822.764, "latencies_ms": [5822.764], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. horse: 2\n3. saddle: 1\n4. saddle blanket: 1\n5. backpack: 1\n6. rock: 1\n7. tree: 1\n8. person's hand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.388}, "power_stats": {"power_gpu_soc_mean_watts": 18.497, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 71.388}, "timestamp": "2026-01-28T12:30:52.820021"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4508.521, "latencies_ms": [4508.521], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing to the left of the horses, which are positioned in the middle of the image. The horses are walking on a rocky trail that is located in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.737}, "power_stats": {"power_gpu_soc_mean_watts": 20.396, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 74.737}, "timestamp": "2026-01-28T12:30:59.356881"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4535.48, "latencies_ms": [4535.48], "images_per_second": 0.22, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A man wearing a blue shirt and an orange bandana is standing on a rocky trail in the woods, watching two horses with saddles on their backs as they walk away from him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.27}, "power_stats": {"power_gpu_soc_mean_watts": 20.384, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 73.27}, "timestamp": "2026-01-28T12:31:05.905277"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4309.976, "latencies_ms": [4309.976], "images_per_second": 0.232, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is a photograph taken in a sunny forest with a blue sky and green trees. The ground is covered with rocks and dirt, and the horses are brown and white.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.943, "power_cpu_cv_mean_watts": 1.98, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 74.657}, "timestamp": "2026-01-28T12:31:12.247766"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3022.181, "latencies_ms": [3022.181], "images_per_second": 0.331, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is riding a horse with a blurred background of a building.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.52}, "power_stats": {"power_gpu_soc_mean_watts": 22.926, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 82.52}, "timestamp": "2026-01-28T12:31:17.323688"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5531.519, "latencies_ms": [5531.519], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. horse: 1\n3. saddle: 1\n4. bridle: 1\n5. reins: 1\n6. jacket: 1\n7. building: 1\n8. tent: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12588.0, "ram_available_mb": 50252.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.426}, "power_stats": {"power_gpu_soc_mean_watts": 18.954, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 72.426}, "timestamp": "2026-01-28T12:31:24.918024"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4268.009, "latencies_ms": [4268.009], "images_per_second": 0.234, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The man is positioned on the left side of the image, with the horse on the right side. The man is in the foreground, while the building is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12588.0, "ram_available_mb": 50252.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.697, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.306}, "timestamp": "2026-01-28T12:31:31.218845"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2924.538, "latencies_ms": [2924.538], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is riding a horse in a black and white photo.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.75}, "power_stats": {"power_gpu_soc_mean_watts": 23.432, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 80.75}, "timestamp": "2026-01-28T12:31:36.158926"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3796.973, "latencies_ms": [3796.973], "images_per_second": 0.263, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is in black and white, with the subject in motion, and the background is blurred, suggesting a fast-moving subject.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.906}, "power_stats": {"power_gpu_soc_mean_watts": 21.615, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 77.906}, "timestamp": "2026-01-28T12:31:42.000719"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3066.131, "latencies_ms": [3066.131], "images_per_second": 0.326, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of geese are swimming in a pond surrounded by tall grass and trees.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.359, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.867, "gpu_utilization_percent_mean": 83.16}, "timestamp": "2026-01-28T12:31:47.108130"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2927.454, "latencies_ms": [2927.454], "images_per_second": 0.342, "prompt_tokens": 1113, "response_tokens_est": 14, "n_tiles": 1, "output_text": " goose: 4\nwater: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12585.9, "ram_available_mb": 50255.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.208}, "power_stats": {"power_gpu_soc_mean_watts": 23.812, "power_cpu_cv_mean_watts": 1.435, "power_sys_5v0_mean_watts": 7.897, "gpu_utilization_percent_mean": 82.208}, "timestamp": "2026-01-28T12:31:52.064112"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4713.513, "latencies_ms": [4713.513], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The geese are positioned in the middle of the pond, with the vegetation on the far side of the pond providing a natural backdrop. The geese are relatively close to the camera, while the vegetation is farther away.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12585.9, "ram_available_mb": 50255.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.641}, "power_stats": {"power_gpu_soc_mean_watts": 19.992, "power_cpu_cv_mean_watts": 1.961, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 73.641}, "timestamp": "2026-01-28T12:31:58.815791"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3072.718, "latencies_ms": [3072.718], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of geese are swimming in a pond surrounded by tall grass and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.64}, "power_stats": {"power_gpu_soc_mean_watts": 23.453, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 76.64}, "timestamp": "2026-01-28T12:32:03.920711"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5330.817, "latencies_ms": [5330.817], "images_per_second": 0.188, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a serene scene of a group of geese swimming in a calm body of water, with the sun casting a warm glow on the scene. The geese are surrounded by lush green vegetation, and the water reflects the sunlight, creating a peaceful and tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.378}, "power_stats": {"power_gpu_soc_mean_watts": 19.191, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 72.378}, "timestamp": "2026-01-28T12:32:11.280259"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3665.311, "latencies_ms": [3665.311], "images_per_second": 0.273, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A cat is lying on the hood of a black Mercedes-Benz car, which is parked in front of a house.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.083, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 75.1}, "timestamp": "2026-01-28T12:32:16.965747"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5575.466, "latencies_ms": [5575.466], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. house: 1\n4. window: 1\n5. fence: 1\n6. plant: 1\n7. flower: 1\n8. reflection: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.766}, "power_stats": {"power_gpu_soc_mean_watts": 18.96, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 71.766}, "timestamp": "2026-01-28T12:32:24.576742"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4504.608, "latencies_ms": [4504.608], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The cat is positioned to the left of the car, which is in the foreground of the image. The cat is resting on the hood of the car, which is in front of the house.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.947}, "power_stats": {"power_gpu_soc_mean_watts": 20.416, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 74.947}, "timestamp": "2026-01-28T12:32:31.101810"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3472.083, "latencies_ms": [3472.083], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A cat is laying on top of a black car, and the car is parked in front of a house.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.069}, "power_stats": {"power_gpu_soc_mean_watts": 22.359, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 79.069}, "timestamp": "2026-01-28T12:32:36.629197"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4092.091, "latencies_ms": [4092.091], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The car is black and the cat is orange and white. The car is parked in front of a house and the cat is laying on the hood of the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.706}, "power_stats": {"power_gpu_soc_mean_watts": 21.108, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 74.706}, "timestamp": "2026-01-28T12:32:42.748528"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3843.339, "latencies_ms": [3843.339], "images_per_second": 0.26, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A snowboarder is captured mid-air against a clear blue sky, wearing a brown jacket, yellow pants, and a black helmet.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.389, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 76.125}, "timestamp": "2026-01-28T12:32:48.618678"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6099.576, "latencies_ms": [6099.576], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " snowboard: 1, snowboarder: 1, snowboarder's pants: 1, snowboarder's jacket: 1, snowboarder's gloves: 1, snowboarder's helmet: 1, snowboarder's goggles: 1, snowboarder's boots: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.385}, "power_stats": {"power_gpu_soc_mean_watts": 18.317, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 70.385}, "timestamp": "2026-01-28T12:32:56.775692"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4318.417, "latencies_ms": [4318.417], "images_per_second": 0.232, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The snowboarder is in the foreground, jumping over a snow-covered slope. The snowboarder is in the middle of the image, with the sky in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.361}, "power_stats": {"power_gpu_soc_mean_watts": 20.627, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 73.361}, "timestamp": "2026-01-28T12:33:03.131171"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3146.641, "latencies_ms": [3146.641], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air against a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12585.5, "ram_available_mb": 50255.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.124, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 79.923}, "timestamp": "2026-01-28T12:33:08.293805"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4010.681, "latencies_ms": [4010.681], "images_per_second": 0.249, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The snowboarder is wearing a brown jacket and yellow pants, and the snow is white. The sky is blue and the snow is white.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12585.5, "ram_available_mb": 50255.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12585.4, "ram_available_mb": 50255.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.485}, "power_stats": {"power_gpu_soc_mean_watts": 20.743, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 76.485}, "timestamp": "2026-01-28T12:33:14.351405"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3598.934, "latencies_ms": [3598.934], "images_per_second": 0.278, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white bathtub, a white toilet, and a white pipe running along the wall.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12585.4, "ram_available_mb": 50255.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.033}, "power_stats": {"power_gpu_soc_mean_watts": 21.989, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 77.033}, "timestamp": "2026-01-28T12:33:19.988304"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5572.508, "latencies_ms": [5572.508], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. toilet: 1\n2. bathtub: 1\n3. pipes: 1\n4. door: 1\n5. towel: 1\n6. wall: 1\n7. floor: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.826}, "power_stats": {"power_gpu_soc_mean_watts": 19.252, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 71.826}, "timestamp": "2026-01-28T12:33:27.591217"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4317.217, "latencies_ms": [4317.217], "images_per_second": 0.232, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The toilet is located to the left of the bathtub, which is situated in the background. The towel is hanging from the pipes above the toilet, which are positioned near the bathtub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12586.0, "ram_available_mb": 50254.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.694, "power_cpu_cv_mean_watts": 1.757, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-28T12:33:33.927821"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2931.244, "latencies_ms": [2931.244], "images_per_second": 0.341, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A bathroom with a toilet and a bathtub is shown in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12585.7, "ram_available_mb": 50255.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12585.1, "ram_available_mb": 50255.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.708}, "power_stats": {"power_gpu_soc_mean_watts": 23.259, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.846, "gpu_utilization_percent_mean": 83.708}, "timestamp": "2026-01-28T12:33:38.887175"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3086.348, "latencies_ms": [3086.348], "images_per_second": 0.324, "prompt_tokens": 1110, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bathroom is painted white with a brown floor, and the lighting is dim.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12585.1, "ram_available_mb": 50255.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12585.0, "ram_available_mb": 50255.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.104, "power_cpu_cv_mean_watts": 2.125, "power_sys_5v0_mean_watts": 7.87, "gpu_utilization_percent_mean": 80.462}, "timestamp": "2026-01-28T12:33:44.019953"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3793.6, "latencies_ms": [3793.6], "images_per_second": 0.264, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In the image, there is a statue of two people holding a kite, standing on a pedestal, with a building in the background.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 12585.0, "ram_available_mb": 50255.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12584.5, "ram_available_mb": 50256.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.564, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 77.344}, "timestamp": "2026-01-28T12:33:49.855478"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5763.774, "latencies_ms": [5763.774], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. statue: 2\n2. kite: 1\n3. building: 1\n4. clouds: 1\n5. sky: 1\n6. ground: 1\n7. statue's hand: 1\n8. statue's foot: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12584.5, "ram_available_mb": 50256.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12583.3, "ram_available_mb": 50257.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.286}, "power_stats": {"power_gpu_soc_mean_watts": 18.595, "power_cpu_cv_mean_watts": 2.068, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.286}, "timestamp": "2026-01-28T12:33:57.663214"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4485.113, "latencies_ms": [4485.113], "images_per_second": 0.223, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the statue is in the background, standing on a pedestal. The statue is closer to the viewer than the kite.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12583.3, "ram_available_mb": 50257.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12583.1, "ram_available_mb": 50257.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.027}, "power_stats": {"power_gpu_soc_mean_watts": 20.632, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 73.027}, "timestamp": "2026-01-28T12:34:04.207305"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5445.533, "latencies_ms": [5445.533], "images_per_second": 0.184, "prompt_tokens": 1112, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a scene of a kite flying high in the sky, with a statue of two people standing on a pedestal in the foreground. The statue is positioned on a corner of a building, with the kite soaring above it, creating a sense of height and distance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12583.1, "ram_available_mb": 50257.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12582.8, "ram_available_mb": 50258.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.174}, "power_stats": {"power_gpu_soc_mean_watts": 18.921, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 73.174}, "timestamp": "2026-01-28T12:34:11.679152"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6223.873, "latencies_ms": [6223.873], "images_per_second": 0.161, "prompt_tokens": 1110, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image features a statue of two people holding a kite, with the kite being the most prominent object in the scene. The kite is colorful and appears to be made of fabric, while the statue is made of metal and has a shiny, reflective surface. The sky is overcast, and the overall lighting is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12582.8, "ram_available_mb": 50258.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12583.1, "ram_available_mb": 50257.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.635}, "power_stats": {"power_gpu_soc_mean_watts": 18.24, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.696, "gpu_utilization_percent_mean": 70.635}, "timestamp": "2026-01-28T12:34:19.937949"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3936.501, "latencies_ms": [3936.501], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image displays a variety of fresh vegetables, including strawberries, broccoli, radishes, carrots, and potatoes, arranged in a visually appealing manner.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12583.1, "ram_available_mb": 50257.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12583.2, "ram_available_mb": 50257.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.906}, "power_stats": {"power_gpu_soc_mean_watts": 21.389, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 76.906}, "timestamp": "2026-01-28T12:34:25.922648"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5808.852, "latencies_ms": [5808.852], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. broccoli: 4\n2. radishes: 12\n3. carrots: 4\n4. strawberries: 12\n5. peas: 12\n6. potatoes: 4\n7. asparagus: 1\n8. celery: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12583.2, "ram_available_mb": 50257.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12583.4, "ram_available_mb": 50257.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.082}, "power_stats": {"power_gpu_soc_mean_watts": 18.66, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 72.082}, "timestamp": "2026-01-28T12:34:33.746718"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4426.721, "latencies_ms": [4426.721], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The strawberries are located in the foreground, while the broccoli is situated in the middle ground. The carrots are positioned in the background, and the radishes are placed near the broccoli.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12583.4, "ram_available_mb": 50257.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12583.9, "ram_available_mb": 50257.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.111}, "power_stats": {"power_gpu_soc_mean_watts": 20.541, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 75.111}, "timestamp": "2026-01-28T12:34:40.189360"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5209.929, "latencies_ms": [5209.929], "images_per_second": 0.192, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce at a market stall, with a variety of fruits and vegetables arranged in a visually appealing manner. The stall is situated in a bustling market setting, surrounded by other stalls and customers, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12583.9, "ram_available_mb": 50257.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12583.9, "ram_available_mb": 50257.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.545}, "power_stats": {"power_gpu_soc_mean_watts": 19.482, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 72.545}, "timestamp": "2026-01-28T12:34:47.425041"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5308.625, "latencies_ms": [5308.625], "images_per_second": 0.188, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a vibrant display of fresh produce, with a variety of colors including red, green, and orange. The lighting is bright and natural, highlighting the freshness of the vegetables. The materials are organic and natural, with the produce appearing fresh and healthy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12583.9, "ram_available_mb": 50257.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12583.6, "ram_available_mb": 50257.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.409}, "power_stats": {"power_gpu_soc_mean_watts": 19.237, "power_cpu_cv_mean_watts": 1.966, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 71.409}, "timestamp": "2026-01-28T12:34:54.751799"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3262.371, "latencies_ms": [3262.371], "images_per_second": 0.307, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Three people are sitting on a couch playing video games with a projector on top of the couch.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12583.6, "ram_available_mb": 50257.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12583.5, "ram_available_mb": 50257.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.037}, "power_stats": {"power_gpu_soc_mean_watts": 22.697, "power_cpu_cv_mean_watts": 1.572, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 79.037}, "timestamp": "2026-01-28T12:35:00.072121"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3000.434, "latencies_ms": [3000.434], "images_per_second": 0.333, "prompt_tokens": 1113, "response_tokens_est": 14, "n_tiles": 1, "output_text": " projector: 1, couch: 1, person: 3", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12583.5, "ram_available_mb": 50257.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12583.1, "ram_available_mb": 50257.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.182, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 82.4}, "timestamp": "2026-01-28T12:35:05.118632"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6145.632, "latencies_ms": [6145.632], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The person on the left is in the foreground, the person in the middle is in the background, and the person on the right is in the foreground. The person on the left is closer to the camera than the person in the middle, and the person on the right is closer to the camera than the person in the middle.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12583.1, "ram_available_mb": 50257.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12583.5, "ram_available_mb": 50257.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.585}, "power_stats": {"power_gpu_soc_mean_watts": 18.176, "power_cpu_cv_mean_watts": 2.078, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 68.585}, "timestamp": "2026-01-28T12:35:13.308454"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2792.94, "latencies_ms": [2792.94], "images_per_second": 0.358, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " Three people are sitting on a couch playing video games.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12583.2, "ram_available_mb": 50257.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12582.6, "ram_available_mb": 50258.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.87}, "power_stats": {"power_gpu_soc_mean_watts": 23.82, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 81.87}, "timestamp": "2026-01-28T12:35:18.148304"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3436.11, "latencies_ms": [3436.11], "images_per_second": 0.291, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is dimly lit with a projector on the bed, and the people are wearing casual clothes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12582.6, "ram_available_mb": 50258.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12583.2, "ram_available_mb": 50257.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.179, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 77.448}, "timestamp": "2026-01-28T12:35:23.631674"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3952.388, "latencies_ms": [3952.388], "images_per_second": 0.253, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, a sheep is resting on the grass near a tree, while in the background, a group of cows are grazing in a field.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12583.2, "ram_available_mb": 50257.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12582.3, "ram_available_mb": 50258.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.212}, "power_stats": {"power_gpu_soc_mean_watts": 21.193, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 75.212}, "timestamp": "2026-01-28T12:35:29.645133"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5825.457, "latencies_ms": [5825.457], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tree: 1\n2. grass: 1\n3. sheep: 2\n4. cow: 2\n5. cow: 2\n6. cow: 2\n7. cow: 2\n8. cow: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12582.3, "ram_available_mb": 50258.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12582.2, "ram_available_mb": 50258.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.286}, "power_stats": {"power_gpu_soc_mean_watts": 17.673, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.581, "gpu_utilization_percent_mean": 69.286}, "timestamp": "2026-01-28T12:35:37.487188"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3819.695, "latencies_ms": [3819.695], "images_per_second": 0.262, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The sheep is in the foreground, lying on the grass near a tree. In the background, there are other sheep grazing in the field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12582.2, "ram_available_mb": 50258.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12582.6, "ram_available_mb": 50258.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.592, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 76.125}, "timestamp": "2026-01-28T12:35:43.366443"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4679.864, "latencies_ms": [4679.864], "images_per_second": 0.214, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In a serene rural setting, a white sheep lies peacefully on a lush green field, while a tree stands nearby. In the distance, other sheep and cows graze on the grass, adding to the tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12582.6, "ram_available_mb": 50258.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12582.4, "ram_available_mb": 50258.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.171, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 74.385}, "timestamp": "2026-01-28T12:35:50.065178"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5148.71, "latencies_ms": [5148.71], "images_per_second": 0.194, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a pastoral scene with a lush green field, a tree with a rough bark, and a herd of cows grazing peacefully. The lighting is natural and soft, suggesting a sunny day, and the colors are vibrant and true to life.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12582.4, "ram_available_mb": 50258.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12581.5, "ram_available_mb": 50259.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.81}, "power_stats": {"power_gpu_soc_mean_watts": 19.474, "power_cpu_cv_mean_watts": 1.926, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 71.81}, "timestamp": "2026-01-28T12:35:57.228376"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5356.741, "latencies_ms": [5356.741], "images_per_second": 0.187, "prompt_tokens": 1099, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image is a black and white photograph of a large group of boys sitting on the ground in front of a building, with the text \"GOODMAYES BOYS' SCHOOL APRIL 1929\" visible at the bottom.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12581.5, "ram_available_mb": 50259.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12581.5, "ram_available_mb": 50259.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.886}, "power_stats": {"power_gpu_soc_mean_watts": 19.255, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-28T12:36:04.611803"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7458.308, "latencies_ms": [7458.308], "images_per_second": 0.134, "prompt_tokens": 1113, "response_tokens_est": 87, "n_tiles": 1, "output_text": " 1. group of boys: 100\n2. boys' school: 10\n3. boys' school building: 1\n4. boys' school building windows: 1\n5. boys' school building doors: 1\n6. boys' school building roof: 1\n7. boys' school building chimney: 1\n8. boys' school building chimney roof: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12581.5, "ram_available_mb": 50259.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12579.4, "ram_available_mb": 50261.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.726}, "power_stats": {"power_gpu_soc_mean_watts": 17.425, "power_cpu_cv_mean_watts": 1.976, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 67.726}, "timestamp": "2026-01-28T12:36:14.088107"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4163.418, "latencies_ms": [4163.418], "images_per_second": 0.24, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The boys are standing in front of the building, with the building being in the background. The boys are in the foreground, with the building being in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12579.4, "ram_available_mb": 50261.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12579.1, "ram_available_mb": 50261.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.075, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-28T12:36:20.264355"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3194.564, "latencies_ms": [3194.564], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A large group of boys are posing for a picture in front of a building.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12579.1, "ram_available_mb": 50261.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12579.3, "ram_available_mb": 50261.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.615}, "power_stats": {"power_gpu_soc_mean_watts": 22.599, "power_cpu_cv_mean_watts": 1.278, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 82.615}, "timestamp": "2026-01-28T12:36:25.487960"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4326.475, "latencies_ms": [4326.475], "images_per_second": 0.231, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is in black and white, and the lighting is even, with no shadows or highlights. The material of the photograph is paper, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12579.3, "ram_available_mb": 50261.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12579.0, "ram_available_mb": 50261.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.627, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 74.278}, "timestamp": "2026-01-28T12:36:31.849760"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3604.566, "latencies_ms": [3604.566], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A colorful kite with a long tail is flying high in the sky, with a park and some buildings in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12579.0, "ram_available_mb": 50261.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12578.7, "ram_available_mb": 50262.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.1}, "power_stats": {"power_gpu_soc_mean_watts": 21.788, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 77.1}, "timestamp": "2026-01-28T12:36:37.523801"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5724.737, "latencies_ms": [5724.737], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Kite: 1\n2. Buildings: 1\n3. Trees: 2\n4. People: 1\n5. Clouds: 2\n6. Sky: 1\n7. Kite string: 1\n8. Grass: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12578.7, "ram_available_mb": 50262.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12577.8, "ram_available_mb": 50263.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.438}, "power_stats": {"power_gpu_soc_mean_watts": 18.658, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 72.438}, "timestamp": "2026-01-28T12:36:45.285102"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4091.95, "latencies_ms": [4091.95], "images_per_second": 0.244, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The kite is in the sky, which is above the buildings and trees. The kite is in the foreground, while the buildings and trees are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.8, "ram_available_mb": 50263.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12577.9, "ram_available_mb": 50263.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.971}, "power_stats": {"power_gpu_soc_mean_watts": 21.076, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.971}, "timestamp": "2026-01-28T12:36:51.417027"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3514.159, "latencies_ms": [3514.159], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A colorful kite with a long tail flies high in the sky over a park with trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.9, "ram_available_mb": 50263.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12578.1, "ram_available_mb": 50262.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.237, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 76.379}, "timestamp": "2026-01-28T12:36:56.974444"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3918.39, "latencies_ms": [3918.39], "images_per_second": 0.255, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The kite is a vibrant rainbow of colors, with a long tail that trails behind it. The sky is a clear blue with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12578.1, "ram_available_mb": 50262.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.188}, "power_stats": {"power_gpu_soc_mean_watts": 21.504, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 77.188}, "timestamp": "2026-01-28T12:37:02.922005"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3367.452, "latencies_ms": [3367.452], "images_per_second": 0.297, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A large pizza with a generous amount of cheese and tomato sauce is sitting in a cardboard box.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12578.3, "ram_available_mb": 50262.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.652, "power_cpu_cv_mean_watts": 1.78, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 78.556}, "timestamp": "2026-01-28T12:37:08.325223"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5848.337, "latencies_ms": [5848.337], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. pizza: 1\n2. cardboard box: 1\n3. pizza crust: 1\n4. cheese: 1\n5. sauce: 1\n6. pepperoni: 1\n7. black pepper: 1\n8. sauce can: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.3, "ram_available_mb": 50262.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12578.4, "ram_available_mb": 50262.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.623, "power_cpu_cv_mean_watts": 2.722, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-28T12:37:16.230632"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4215.492, "latencies_ms": [4215.492], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the cardboard box in the background. The pizza is on the left side of the box, and the box is on the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12578.4, "ram_available_mb": 50262.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12578.0, "ram_available_mb": 50262.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.314}, "power_stats": {"power_gpu_soc_mean_watts": 20.989, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 74.314}, "timestamp": "2026-01-28T12:37:22.489398"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2934.767, "latencies_ms": [2934.767], "images_per_second": 0.341, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A pizza with cheese and tomato sauce is in a cardboard box.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12578.0, "ram_available_mb": 50262.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.625}, "power_stats": {"power_gpu_soc_mean_watts": 23.465, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 83.625}, "timestamp": "2026-01-28T12:37:27.465801"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3859.01, "latencies_ms": [3859.01], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The pizza is in a cardboard box with a white and red color scheme. The lighting is dim and the pizza is in a dark environment.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12577.6, "ram_available_mb": 50263.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.719}, "power_stats": {"power_gpu_soc_mean_watts": 21.363, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 76.719}, "timestamp": "2026-01-28T12:37:33.366532"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4040.581, "latencies_ms": [4040.581], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A woman in a brown jacket is sitting on the edge of an open refrigerator, talking on her cell phone, while another woman sits on the sidewalk nearby.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12577.6, "ram_available_mb": 50263.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12577.6, "ram_available_mb": 50263.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.853}, "power_stats": {"power_gpu_soc_mean_watts": 20.952, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 74.853}, "timestamp": "2026-01-28T12:37:39.466881"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5557.789, "latencies_ms": [5557.789], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. jacket: 1\n3. pants: 1\n4. shoes: 1\n5. refrigerator: 1\n6. cup: 2\n7. glass: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12577.6, "ram_available_mb": 50263.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12577.6, "ram_available_mb": 50263.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.435}, "power_stats": {"power_gpu_soc_mean_watts": 19.169, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 72.435}, "timestamp": "2026-01-28T12:37:47.037070"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5271.331, "latencies_ms": [5271.331], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The woman sitting on the refrigerator is positioned to the right of the woman sitting on the bench, with the refrigerator being in the foreground and the bench being in the background. The woman on the bench is closer to the camera than the woman on the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.6, "ram_available_mb": 50263.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12577.8, "ram_available_mb": 50263.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.295}, "power_stats": {"power_gpu_soc_mean_watts": 19.358, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.295}, "timestamp": "2026-01-28T12:37:54.320196"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2857.073, "latencies_ms": [2857.073], "images_per_second": 0.35, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A woman sits in an open refrigerator on a city street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.8, "ram_available_mb": 50263.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12577.8, "ram_available_mb": 50263.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.565}, "power_stats": {"power_gpu_soc_mean_watts": 24.013, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 83.565}, "timestamp": "2026-01-28T12:37:59.201256"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5129.514, "latencies_ms": [5129.514], "images_per_second": 0.195, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image depicts a woman sitting in an open refrigerator on a street, with a brown jacket and blue jeans. The refrigerator is white and has a yellow interior. The weather appears to be overcast, and the street is wet, suggesting recent rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.8, "ram_available_mb": 50263.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.492, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 70.07}, "timestamp": "2026-01-28T12:38:06.372104"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3577.332, "latencies_ms": [3577.332], "images_per_second": 0.28, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a straw hat and a green shirt is holding a tray of hot dogs with a red sauce on top.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.091, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.85, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-28T12:38:11.994991"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5660.039, "latencies_ms": [5660.039], "images_per_second": 0.177, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. hat: 1\n3. shirt: 1\n4. chair: 1\n5. hotdogs: 12\n6. foil: 1\n7. grass: 1\n8. white: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.208}, "power_stats": {"power_gpu_soc_mean_watts": 18.917, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 72.208}, "timestamp": "2026-01-28T12:38:19.713654"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4621.17, "latencies_ms": [4621.17], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is standing in the foreground, wearing a straw hat and a green shirt. The hot dogs are placed on a tray in the middle of the image, and the white chair is located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.7, "ram_available_mb": 50263.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12577.9, "ram_available_mb": 50263.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.154}, "power_stats": {"power_gpu_soc_mean_watts": 20.158, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 74.154}, "timestamp": "2026-01-28T12:38:26.367992"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3581.434, "latencies_ms": [3581.434], "images_per_second": 0.279, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing a straw hat and a green shirt is standing in a grassy area and looking at a tray of hot dogs.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12577.9, "ram_available_mb": 50263.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12577.9, "ram_available_mb": 50263.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.3}, "power_stats": {"power_gpu_soc_mean_watts": 21.815, "power_cpu_cv_mean_watts": 2.136, "power_sys_5v0_mean_watts": 7.836, "gpu_utilization_percent_mean": 76.3}, "timestamp": "2026-01-28T12:38:31.988333"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4711.54, "latencies_ms": [4711.54], "images_per_second": 0.212, "prompt_tokens": 1110, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a man wearing a straw hat and a green shirt, standing outdoors on a sunny day. The hot dogs are placed on a tray covered with aluminum foil, and the man is holding a white plastic chair.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12577.9, "ram_available_mb": 50263.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.625}, "power_stats": {"power_gpu_soc_mean_watts": 20.226, "power_cpu_cv_mean_watts": 2.843, "power_sys_5v0_mean_watts": 7.825, "gpu_utilization_percent_mean": 72.625}, "timestamp": "2026-01-28T12:38:38.722580"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3924.382, "latencies_ms": [3924.382], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a room with a desk, a chair, a bookshelf, and a couch, all of which are cluttered with various items.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12578.3, "ram_available_mb": 50262.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.515}, "power_stats": {"power_gpu_soc_mean_watts": 21.435, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 75.515}, "timestamp": "2026-01-28T12:38:44.686854"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4555.545, "latencies_ms": [4555.545], "images_per_second": 0.22, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " chair: 1, laptop: 1, bookshelf: 1, books: 1, blanket: 1, couch: 1, wall: 1, star: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12578.3, "ram_available_mb": 50262.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12578.8, "ram_available_mb": 50262.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.289}, "power_stats": {"power_gpu_soc_mean_watts": 20.142, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 74.289}, "timestamp": "2026-01-28T12:38:51.269982"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4963.424, "latencies_ms": [4963.424], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The laptop is on the left side of the room, the bookshelf is in the middle, and the couch is on the right side. The bookshelf is closer to the camera than the laptop, and the couch is farther away.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12578.8, "ram_available_mb": 50262.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12578.2, "ram_available_mb": 50262.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.833}, "power_stats": {"power_gpu_soc_mean_watts": 19.584, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 72.833}, "timestamp": "2026-01-28T12:38:58.255535"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3361.287, "latencies_ms": [3361.287], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A room with a blue couch, a bookshelf, and a desk with a laptop on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12578.2, "ram_available_mb": 50262.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12578.4, "ram_available_mb": 50262.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.453, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 77.357}, "timestamp": "2026-01-28T12:39:03.640397"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4150.101, "latencies_ms": [4150.101], "images_per_second": 0.241, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The room is lit by a single light bulb and has a warm yellow light. The walls are painted a light beige color and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12578.4, "ram_available_mb": 50262.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12578.7, "ram_available_mb": 50262.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.676}, "power_stats": {"power_gpu_soc_mean_watts": 21.106, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 75.676}, "timestamp": "2026-01-28T12:39:09.832683"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3964.513, "latencies_ms": [3964.513], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, two elephants are seen in a grassy field, their trunks intertwined as they face each other, with a bird flying in the background.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12578.7, "ram_available_mb": 50262.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12578.5, "ram_available_mb": 50262.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.719}, "power_stats": {"power_gpu_soc_mean_watts": 21.524, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 72.719}, "timestamp": "2026-01-28T12:39:15.823115"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4196.771, "latencies_ms": [4196.771], "images_per_second": 0.238, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 2, grass: 1, tree: 1, bird: 1, bush: 1, hill: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12578.5, "ram_available_mb": 50262.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12578.5, "ram_available_mb": 50262.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.833, "power_cpu_cv_mean_watts": 2.528, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 75.629}, "timestamp": "2026-01-28T12:39:22.048921"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6926.252, "latencies_ms": [6926.252], "images_per_second": 0.144, "prompt_tokens": 1117, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The two elephants are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the one on the right. The elephants are facing each other, with the one on the left appearing to be slightly larger in size. The background of the image features a hazy, misty landscape with a few trees and bushes, providing a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.5, "ram_available_mb": 50262.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12578.7, "ram_available_mb": 50262.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.695}, "power_stats": {"power_gpu_soc_mean_watts": 17.579, "power_cpu_cv_mean_watts": 2.613, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 70.695}, "timestamp": "2026-01-28T12:39:31.002627"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5123.821, "latencies_ms": [5123.821], "images_per_second": 0.195, "prompt_tokens": 1111, "response_tokens_est": 49, "n_tiles": 1, "output_text": " In the heart of a verdant savanna, two majestic elephants engage in a tender moment of affection. The elephants, their skin a rich brown, stand side by side in the lush green grass, their trunks intertwined in a display of affection.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.7, "ram_available_mb": 50262.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12579.1, "ram_available_mb": 50261.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.463, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 72.07}, "timestamp": "2026-01-28T12:39:38.161022"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3209.55, "latencies_ms": [3209.55], "images_per_second": 0.312, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephants are brown, the grass is green, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12579.1, "ram_available_mb": 50261.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12579.1, "ram_available_mb": 50261.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.038}, "power_stats": {"power_gpu_soc_mean_watts": 22.884, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 79.038}, "timestamp": "2026-01-28T12:39:43.395283"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3833.413, "latencies_ms": [3833.413], "images_per_second": 0.261, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A shirtless man wearing a baseball cap and sunglasses is holding a frisbee and a bottle of beer while standing on a grassy field.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12579.1, "ram_available_mb": 50261.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12578.9, "ram_available_mb": 50262.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.462, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 78.344}, "timestamp": "2026-01-28T12:39:49.275268"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5672.379, "latencies_ms": [5672.379], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. cap: 1\n3. shirt: 1\n4. shorts: 1\n5. frisbee: 1\n6. bottle: 1\n7. grass: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.9, "ram_available_mb": 50262.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12579.4, "ram_available_mb": 50261.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.042}, "power_stats": {"power_gpu_soc_mean_watts": 18.995, "power_cpu_cv_mean_watts": 1.943, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 73.042}, "timestamp": "2026-01-28T12:39:56.984101"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5401.391, "latencies_ms": [5401.391], "images_per_second": 0.185, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee and a bottle, while the other man is in the background, walking on the field. The frisbee is held in the man's right hand, and the bottle is in his left hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12579.4, "ram_available_mb": 50261.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.067}, "power_stats": {"power_gpu_soc_mean_watts": 18.927, "power_cpu_cv_mean_watts": 2.038, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 72.067}, "timestamp": "2026-01-28T12:40:04.404841"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3372.489, "latencies_ms": [3372.489], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A shirtless man is playing frisbee in a park with a bottle in his hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.502, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 80.815}, "timestamp": "2026-01-28T12:40:09.796213"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4282.92, "latencies_ms": [4282.92], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a man in a grassy field, wearing a white baseball cap, sunglasses, and khaki shorts. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12578.4, "ram_available_mb": 50262.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.836, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 72.657}, "timestamp": "2026-01-28T12:40:16.096328"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4157.8, "latencies_ms": [4157.8], "images_per_second": 0.241, "prompt_tokens": 1100, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A young boy wearing a blue sports jersey is cutting a large chocolate cake decorated with red and yellow icing and chocolate logs on a table with a colorful tablecloth.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12578.4, "ram_available_mb": 50262.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12578.3, "ram_available_mb": 50262.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.343}, "power_stats": {"power_gpu_soc_mean_watts": 20.959, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 73.343}, "timestamp": "2026-01-28T12:40:22.298736"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5591.403, "latencies_ms": [5591.403], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. boy: 1\n2. knife: 1\n3. cake: 1\n4. tablecloth: 1\n5. plate: 1\n6. toy: 1\n7. candle: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12578.3, "ram_available_mb": 50262.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12578.2, "ram_available_mb": 50262.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.085}, "power_stats": {"power_gpu_soc_mean_watts": 18.823, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.085}, "timestamp": "2026-01-28T12:40:29.919745"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4565.415, "latencies_ms": [4565.415], "images_per_second": 0.219, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The boy is in the foreground, leaning over the table with a knife in his hand. The cake is in the middle of the table, and the plate is on the right side of the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.2, "ram_available_mb": 50262.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12578.2, "ram_available_mb": 50262.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.711}, "power_stats": {"power_gpu_soc_mean_watts": 20.401, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 73.711}, "timestamp": "2026-01-28T12:40:36.500381"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3752.246, "latencies_ms": [3752.246], "images_per_second": 0.267, "prompt_tokens": 1112, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A young boy wearing a blue sports jersey is cutting a large chocolate cake shaped like a log on a table covered with a colorful tablecloth.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12578.2, "ram_available_mb": 50262.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12578.4, "ram_available_mb": 50262.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.857, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 75.71}, "timestamp": "2026-01-28T12:40:42.290114"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4164.914, "latencies_ms": [4164.914], "images_per_second": 0.24, "prompt_tokens": 1110, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a room with a brown wall and a table covered with a colorful tablecloth. The lighting is natural, coming from a window out of frame.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12578.4, "ram_available_mb": 50262.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.771}, "power_stats": {"power_gpu_soc_mean_watts": 20.949, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 74.771}, "timestamp": "2026-01-28T12:40:48.505371"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4606.743, "latencies_ms": [4606.743], "images_per_second": 0.217, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a close-up view of a zebra's face, showcasing its distinctive black and white stripes, with a blurred background that hints at the presence of other zebras and a natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.526}, "power_stats": {"power_gpu_soc_mean_watts": 20.033, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 72.526}, "timestamp": "2026-01-28T12:40:55.137012"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4499.974, "latencies_ms": [4499.974], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " zebra: 1, eye: 1, nose: 1, ear: 1, mouth: 1, tail: 1, fence: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12578.6, "ram_available_mb": 50262.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12576.5, "ram_available_mb": 50264.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.193, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 73.184}, "timestamp": "2026-01-28T12:41:01.656138"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4824.965, "latencies_ms": [4824.965], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The zebra's head is in the foreground, with its body partially visible in the background. The zebra's eye is in the upper left corner of the image, while the zebra's nose is in the lower right corner.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12576.5, "ram_available_mb": 50264.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12576.2, "ram_available_mb": 50264.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.675}, "power_stats": {"power_gpu_soc_mean_watts": 19.755, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 73.675}, "timestamp": "2026-01-28T12:41:08.493751"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4999.967, "latencies_ms": [4999.967], "images_per_second": 0.2, "prompt_tokens": 1111, "response_tokens_est": 45, "n_tiles": 1, "output_text": " In the image, there are two zebras standing close to each other, with one zebra's face prominently displayed in the foreground. The zebras are in a zoo enclosure, with a white fence separating them from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12576.2, "ram_available_mb": 50264.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12577.4, "ram_available_mb": 50263.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.122}, "power_stats": {"power_gpu_soc_mean_watts": 19.505, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 74.122}, "timestamp": "2026-01-28T12:41:15.504372"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6167.188, "latencies_ms": [6167.188], "images_per_second": 0.162, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image features a close-up of a zebra's face, with its distinctive black and white stripes standing out against the natural colors of the environment. The lighting is natural and soft, casting gentle shadows on the zebra's face, and the zebra appears to be in a natural setting, possibly a zoo or wildlife reserve.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12577.4, "ram_available_mb": 50263.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12576.8, "ram_available_mb": 50264.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.549}, "power_stats": {"power_gpu_soc_mean_watts": 18.201, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 7.645, "gpu_utilization_percent_mean": 71.549}, "timestamp": "2026-01-28T12:41:23.691631"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4026.706, "latencies_ms": [4026.706], "images_per_second": 0.248, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The black and white photo captures a train station with a sign that reads \"La Spezia Centrale\" and a train on the tracks.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12576.8, "ram_available_mb": 50264.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12576.5, "ram_available_mb": 50264.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.485}, "power_stats": {"power_gpu_soc_mean_watts": 21.031, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 72.485}, "timestamp": "2026-01-28T12:41:29.789557"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5609.291, "latencies_ms": [5609.291], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sign: 1\n2. train: 1\n3. platform: 1\n4. bench: 1\n5. train tracks: 2\n6. train station: 1\n7. mountain: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12576.5, "ram_available_mb": 50264.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12576.7, "ram_available_mb": 50264.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.914, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 71.511}, "timestamp": "2026-01-28T12:41:37.422749"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4351.025, "latencies_ms": [4351.025], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The train station platform is located in the foreground, with the train tracks extending into the background. The sign is positioned above the platform, indicating the direction to the center of the station.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12576.7, "ram_available_mb": 50264.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12576.7, "ram_available_mb": 50264.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.028}, "power_stats": {"power_gpu_soc_mean_watts": 20.66, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 74.028}, "timestamp": "2026-01-28T12:41:43.815201"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3521.564, "latencies_ms": [3521.564], "images_per_second": 0.284, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white photo of a train station with a sign that says La Spezia Centrale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12576.7, "ram_available_mb": 50264.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12576.6, "ram_available_mb": 50264.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.481, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 78.536}, "timestamp": "2026-01-28T12:41:49.355938"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4544.103, "latencies_ms": [4544.103], "images_per_second": 0.22, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image is in black and white, with the station platform and train tracks being the main focus. The lighting is natural, coming from the sky, and the materials are mostly concrete and metal.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12576.6, "ram_available_mb": 50264.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.097, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 74.474}, "timestamp": "2026-01-28T12:41:55.942047"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3436.496, "latencies_ms": [3436.496], "images_per_second": 0.291, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is sitting on a red surfboard in the ocean, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12576.5, "ram_available_mb": 50264.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.255, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 78.714}, "timestamp": "2026-01-28T12:42:01.419980"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5640.646, "latencies_ms": [5640.646], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. ocean: 1\n4. sky: 1\n5. clouds: 1\n6. sun: 1\n7. waves: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12576.5, "ram_available_mb": 50264.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12576.7, "ram_available_mb": 50264.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.234}, "power_stats": {"power_gpu_soc_mean_watts": 18.702, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 72.234}, "timestamp": "2026-01-28T12:42:09.107944"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4333.295, "latencies_ms": [4333.295], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The person is sitting on the surfboard, which is in the foreground of the image. The ocean is in the background, and the sky is above the person and the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12576.7, "ram_available_mb": 50264.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12576.9, "ram_available_mb": 50264.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.389}, "power_stats": {"power_gpu_soc_mean_watts": 20.78, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 75.389}, "timestamp": "2026-01-28T12:42:15.462438"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3075.942, "latencies_ms": [3075.942], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is sitting on a red surfboard in the ocean at sunset.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12576.9, "ram_available_mb": 50264.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.036, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 80.84}, "timestamp": "2026-01-28T12:42:20.571829"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6421.466, "latencies_ms": [6421.466], "images_per_second": 0.156, "prompt_tokens": 1109, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a solitary figure clad in a black wetsuit, poised on a vibrant red surfboard, as they gaze out at the tranquil ocean. The sky above is a canvas of dark clouds, casting an ominous tone over the scene, while the sun's warm glow casts a golden hue on the water's surface, creating a striking contrast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.759}, "power_stats": {"power_gpu_soc_mean_watts": 17.99, "power_cpu_cv_mean_watts": 2.031, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 70.759}, "timestamp": "2026-01-28T12:42:29.014235"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3341.757, "latencies_ms": [3341.757], "images_per_second": 0.299, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man and a woman are sitting at a table on a train, eating sushi and other food.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.467, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 77.214}, "timestamp": "2026-01-28T12:42:34.387797"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5622.059, "latencies_ms": [5622.059], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. chopsticks: 2\n4. tray: 1\n5. food: 1\n6. seat: 1\n7. window: 1\n8. bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.6, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.666, "power_cpu_cv_mean_watts": 2.52, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 70.021}, "timestamp": "2026-01-28T12:42:42.056563"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5652.326, "latencies_ms": [5652.326], "images_per_second": 0.177, "prompt_tokens": 1118, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, while the woman is on the right side. The tray of food is in the middle of the image, and the man is holding chopsticks in his right hand. The woman is holding a bag of chips in her left hand.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12577.1, "ram_available_mb": 50263.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12577.5, "ram_available_mb": 50263.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.234}, "power_stats": {"power_gpu_soc_mean_watts": 19.029, "power_cpu_cv_mean_watts": 2.871, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 71.234}, "timestamp": "2026-01-28T12:42:49.744733"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3446.635, "latencies_ms": [3446.635], "images_per_second": 0.29, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A couple is enjoying a meal on a train, with a window in the background showing a cityscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.5, "ram_available_mb": 50263.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12577.5, "ram_available_mb": 50263.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.084, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 76.143}, "timestamp": "2026-01-28T12:42:55.241042"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4295.312, "latencies_ms": [4295.312], "images_per_second": 0.233, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a well-lit train carriage with natural light coming through the windows. The colors in the image are vibrant and the materials are mostly plastic and metal.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12577.5, "ram_available_mb": 50263.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.591, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-28T12:43:01.580605"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3958.842, "latencies_ms": [3958.842], "images_per_second": 0.253, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " Two men are walking down the street at night, one in a white shirt and black tie, and the other in a pink shirt and black tie.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.364}, "power_stats": {"power_gpu_soc_mean_watts": 21.334, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 74.364}, "timestamp": "2026-01-28T12:43:07.562035"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5747.493, "latencies_ms": [5747.493], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. tie: 1\n3. shirt: 1\n4. pants: 2\n5. shoes: 2\n6. building: 1\n7. street: 1\n8. sign: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.413, "power_cpu_cv_mean_watts": 1.843, "power_sys_5v0_mean_watts": 7.642, "gpu_utilization_percent_mean": 70.25}, "timestamp": "2026-01-28T12:43:15.351232"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5686.347, "latencies_ms": [5686.347], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The two men are standing on the sidewalk, with the man on the left being closer to the camera and the man on the right being farther away. The man on the left is standing in front of the man on the right, and the man on the right is standing on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.617}, "power_stats": {"power_gpu_soc_mean_watts": 19.121, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 72.617}, "timestamp": "2026-01-28T12:43:23.066601"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2747.66, "latencies_ms": [2747.66], "images_per_second": 0.364, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " Two men are walking down a street at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.783}, "power_stats": {"power_gpu_soc_mean_watts": 23.819, "power_cpu_cv_mean_watts": 1.236, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 83.783}, "timestamp": "2026-01-28T12:43:27.865762"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4209.755, "latencies_ms": [4209.755], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken at night, with the two men walking on the sidewalk. The street is lit by streetlights and the building behind them is lit by a yellow light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.883, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 75.571}, "timestamp": "2026-01-28T12:43:34.088275"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4044.076, "latencies_ms": [4044.076], "images_per_second": 0.247, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man in glasses and a gray sweater is pouring wine into a glass at a bar, while a person in a blue shirt is holding a wine glass.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.287, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 73.576}, "timestamp": "2026-01-28T12:43:40.184489"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6039.315, "latencies_ms": [6039.315], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. person: 1\n2. glasses: 2\n3. wine bottle: 1\n4. wine glass: 1\n5. wine rack: 1\n6. wooden table: 1\n7. wine glass holder: 1\n8. wine bottle holder: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.784}, "power_stats": {"power_gpu_soc_mean_watts": 18.273, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 70.784}, "timestamp": "2026-01-28T12:43:48.262500"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5553.544, "latencies_ms": [5553.544], "images_per_second": 0.18, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, with the wine glass in his hand on the right side. The wine bottle is on the left side of the image, and the glasses are on the right side. The man is closer to the camera than the wine bottle.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.787}, "power_stats": {"power_gpu_soc_mean_watts": 19.145, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 72.787}, "timestamp": "2026-01-28T12:43:55.855826"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3898.325, "latencies_ms": [3898.325], "images_per_second": 0.257, "prompt_tokens": 1112, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A man in glasses and a gray sweater is standing behind a bar, pouring wine into a glass. There are wine bottles on the shelves behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.503, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 74.594}, "timestamp": "2026-01-28T12:44:01.789762"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3722.365, "latencies_ms": [3722.365], "images_per_second": 0.269, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with warm lighting, and the wooden wine rack is filled with bottles of wine.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.548}, "power_stats": {"power_gpu_soc_mean_watts": 21.615, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 74.548}, "timestamp": "2026-01-28T12:44:07.573322"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3887.477, "latencies_ms": [3887.477], "images_per_second": 0.257, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A tennis player is in the middle of a powerful swing with his racket, attempting to hit a tennis ball that is in the air.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12577.2, "ram_available_mb": 50263.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.3, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.844}, "timestamp": "2026-01-28T12:44:13.502043"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6093.238, "latencies_ms": [6093.238], "images_per_second": 0.164, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. tennis racket: 1\n2. tennis ball: 1\n3. tennis player: 1\n4. grass court: 1\n5. white lines: 1\n6. white shorts: 1\n7. white shirt: 1\n8. white wristband: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12577.2, "ram_available_mb": 50263.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.558}, "power_stats": {"power_gpu_soc_mean_watts": 18.5, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 70.558}, "timestamp": "2026-01-28T12:44:21.625189"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6034.418, "latencies_ms": [6034.418], "images_per_second": 0.166, "prompt_tokens": 1118, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the tennis ball in the background. The player is holding the tennis racket in his right hand, and the ball is in his left hand. The player is positioned to the left of the image, and the ball is to the right of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.569}, "power_stats": {"power_gpu_soc_mean_watts": 18.499, "power_cpu_cv_mean_watts": 1.939, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 72.569}, "timestamp": "2026-01-28T12:44:29.699963"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3547.503, "latencies_ms": [3547.503], "images_per_second": 0.282, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A tennis player is playing on a grass court, wearing white clothes and holding a blue and green tennis racket.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.517}, "power_stats": {"power_gpu_soc_mean_watts": 21.915, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 77.517}, "timestamp": "2026-01-28T12:44:35.289517"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5861.319, "latencies_ms": [5861.319], "images_per_second": 0.171, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a grass court, where a tennis player is in the midst of a powerful swing with his racket. The vibrant green of the grass contrasts with the player's white attire, and the bright blue of the tennis ball stands out against the backdrop of the overcast sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.327}, "power_stats": {"power_gpu_soc_mean_watts": 18.675, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 70.327}, "timestamp": "2026-01-28T12:44:43.163082"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3159.813, "latencies_ms": [3159.813], "images_per_second": 0.316, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A white and orange cat is walking on a wooden shelf next to a television.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12574.1, "ram_available_mb": 50266.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.154}, "power_stats": {"power_gpu_soc_mean_watts": 22.826, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.806, "gpu_utilization_percent_mean": 82.154}, "timestamp": "2026-01-28T12:44:48.372752"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5673.62, "latencies_ms": [5673.62], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. television: 1\n2. cat: 2\n3. shelf: 1\n4. bookshelf: 1\n5. cup: 1\n6. remote: 1\n7. digital clock: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12574.1, "ram_available_mb": 50266.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.625}, "power_stats": {"power_gpu_soc_mean_watts": 18.671, "power_cpu_cv_mean_watts": 2.144, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 71.625}, "timestamp": "2026-01-28T12:44:56.072967"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5032.833, "latencies_ms": [5032.833], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The cat is in the foreground, on the right side of the TV, and the TV is on the left side of the shelf. The shelf is in the middle of the room, and the cat is in front of the TV.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.19}, "power_stats": {"power_gpu_soc_mean_watts": 19.707, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 75.19}, "timestamp": "2026-01-28T12:45:03.155919"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3277.232, "latencies_ms": [3277.232], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A cat is on top of a TV stand, and a TV is on the stand.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12574.4, "ram_available_mb": 50266.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.529, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-28T12:45:08.451485"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3544.832, "latencies_ms": [3544.832], "images_per_second": 0.282, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the window, and the cat is white with orange stripes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12574.4, "ram_available_mb": 50266.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.862}, "power_stats": {"power_gpu_soc_mean_watts": 22.386, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 78.862}, "timestamp": "2026-01-28T12:45:14.021783"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4888.807, "latencies_ms": [4888.807], "images_per_second": 0.205, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a street sign with a blue circle and a bicycle symbol, and a white sign with Chinese characters, all mounted on a metal pole against a backdrop of a clear blue sky with a few trees in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.375}, "power_stats": {"power_gpu_soc_mean_watts": 20.054, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 74.375}, "timestamp": "2026-01-28T12:45:20.958007"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4306.786, "latencies_ms": [4306.786], "images_per_second": 0.232, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. signpost\n2. blue circle\n3. white sign\n4. tree\n5. bicycle\n6. road\n7. sky\n8. sun", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.478, "power_cpu_cv_mean_watts": 2.013, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 72.444}, "timestamp": "2026-01-28T12:45:27.294539"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5159.324, "latencies_ms": [5159.324], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, with the bicycle symbol and the Chinese characters being the main focus. The sign is positioned to the left of the pole, and the background consists of a clear blue sky with some trees visible.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.791}, "power_stats": {"power_gpu_soc_mean_watts": 19.464, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 74.791}, "timestamp": "2026-01-28T12:45:34.483911"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7450.622, "latencies_ms": [7450.622], "images_per_second": 0.134, "prompt_tokens": 1111, "response_tokens_est": 87, "n_tiles": 1, "output_text": " The image captures a street scene in China, where a blue circular sign with a white bicycle symbol and the words \"\u4eba\u884c\u9053\" (pedestrian road) is mounted on a metal pole. Below it, a white rectangular sign with the Chinese characters \"\u6c5f\u82cf\u7701\u6dee\u5317\u5e02\" (Jiangsu Province, Hubei City) is visible, indicating the location.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.952}, "power_stats": {"power_gpu_soc_mean_watts": 17.223, "power_cpu_cv_mean_watts": 2.25, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 67.952}, "timestamp": "2026-01-28T12:45:43.981885"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4357.322, "latencies_ms": [4357.322], "images_per_second": 0.229, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a blue circular sign with a white bicycle symbol and a white rectangular sign with black Chinese characters. The sky is clear and blue, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.647, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 75.972}, "timestamp": "2026-01-28T12:45:50.379624"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3705.072, "latencies_ms": [3705.072], "images_per_second": 0.27, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young girl with black hair and a black dress is sitting at a table in a restaurant, eating a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.599, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 78.71}, "timestamp": "2026-01-28T12:45:56.140801"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4218.166, "latencies_ms": [4218.166], "images_per_second": 0.237, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " table: 1, chair: 1, pizza: 1, glass: 1, book: 1, person: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12572.7, "ram_available_mb": 50268.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.829}, "power_stats": {"power_gpu_soc_mean_watts": 20.973, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 73.829}, "timestamp": "2026-01-28T12:46:02.394161"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4625.03, "latencies_ms": [4625.03], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The girl is sitting at a table in the foreground, with a glass of water and a book on the table. The pizza is on the table in the background, and the chairs are behind the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12572.7, "ram_available_mb": 50268.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12573.9, "ram_available_mb": 50267.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.605}, "power_stats": {"power_gpu_soc_mean_watts": 20.467, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 72.605}, "timestamp": "2026-01-28T12:46:09.037038"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3221.478, "latencies_ms": [3221.478], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl is sitting at a table in a restaurant, eating a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.9, "ram_available_mb": 50267.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.06, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 82.462}, "timestamp": "2026-01-28T12:46:14.291886"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4470.417, "latencies_ms": [4470.417], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image is taken in a dimly lit restaurant with warm lighting. The colors in the image are mostly muted with the exception of the girl's yellow hair and the green of the salad.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12573.9, "ram_available_mb": 50267.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.105}, "power_stats": {"power_gpu_soc_mean_watts": 20.511, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 75.105}, "timestamp": "2026-01-28T12:46:20.800070"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4804.556, "latencies_ms": [4804.556], "images_per_second": 0.208, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image captures a meal spread out on a kitchen counter, featuring a variety of dishes including a bowl of broccoli, a plate of rice, and a plate of bread, all set against the backdrop of a wooden wall.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12573.9, "ram_available_mb": 50267.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.1}, "power_stats": {"power_gpu_soc_mean_watts": 20.034, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 74.1}, "timestamp": "2026-01-28T12:46:27.642147"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4544.806, "latencies_ms": [4544.806], "images_per_second": 0.22, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " bowl: 1, plate: 2, glass: 1, bowl: 1, plate: 1, bowl: 1, plate: 1, bowl: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.865}, "power_stats": {"power_gpu_soc_mean_watts": 20.433, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 74.865}, "timestamp": "2026-01-28T12:46:34.201308"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5792.041, "latencies_ms": [5792.041], "images_per_second": 0.173, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the plates of food are placed in the foreground, with the bowls of vegetables and the glass of water in the background. The plates of food are positioned to the left of the bowls, and the glass of water is placed to the right of the bowls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12573.2, "ram_available_mb": 50267.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.735}, "power_stats": {"power_gpu_soc_mean_watts": 18.601, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 70.735}, "timestamp": "2026-01-28T12:46:42.034290"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3497.661, "latencies_ms": [3497.661], "images_per_second": 0.286, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A meal is set on a table with a variety of food items, including broccoli, cauliflower, and rice.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12573.2, "ram_available_mb": 50267.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.139, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 76.552}, "timestamp": "2026-01-28T12:46:47.553356"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4042.508, "latencies_ms": [4042.508], "images_per_second": 0.247, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in a kitchen with a wooden table and a stainless steel countertop. The lighting is natural, coming from the window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.971}, "power_stats": {"power_gpu_soc_mean_watts": 21.015, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 76.971}, "timestamp": "2026-01-28T12:46:53.637123"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4876.89, "latencies_ms": [4876.89], "images_per_second": 0.205, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, where a green bus is navigating through the traffic, while a white truck and a red car are parked on the side of the road, and a black car is driving down the street.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.756}, "power_stats": {"power_gpu_soc_mean_watts": 19.789, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 71.756}, "timestamp": "2026-01-28T12:47:00.559587"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5627.805, "latencies_ms": [5627.805], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. street sign: 1\n2. bus: 1\n3. car: 4\n4. truck: 1\n5. person: 1\n6. tree: 2\n7. building: 2\n8. pole: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.809}, "power_stats": {"power_gpu_soc_mean_watts": 18.753, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 70.809}, "timestamp": "2026-01-28T12:47:08.201200"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5574.643, "latencies_ms": [5574.643], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The bus is positioned in the middle of the street, with the cars on the right side and the truck on the left. The bus is closer to the camera than the cars, and the truck is farther away. The bus is also closer to the street sign than the cars.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.783}, "power_stats": {"power_gpu_soc_mean_watts": 19.318, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 71.783}, "timestamp": "2026-01-28T12:47:15.792857"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7199.924, "latencies_ms": [7199.924], "images_per_second": 0.139, "prompt_tokens": 1111, "response_tokens_est": 83, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, teeming with life and activity. A green bus, adorned with a yellow sign, is in motion, navigating through the traffic. The street is lined with towering buildings, their windows reflecting the city's hustle and bustle. Cars, including a black one, a red one, and a white one, are parked along the curb, adding to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.517}, "power_stats": {"power_gpu_soc_mean_watts": 17.976, "power_cpu_cv_mean_watts": 1.975, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 69.517}, "timestamp": "2026-01-28T12:47:25.014471"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6815.794, "latencies_ms": [6815.794], "images_per_second": 0.147, "prompt_tokens": 1109, "response_tokens_est": 77, "n_tiles": 1, "output_text": " The image depicts a bustling city street with a variety of vehicles, including cars and buses, and buildings of different heights and designs. The sky is overcast, casting a soft light over the scene. The colors in the image are predominantly muted, with the gray of the buildings and the black of the vehicles standing out against the green of the trees and the blue of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.5, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.07}, "power_stats": {"power_gpu_soc_mean_watts": 17.727, "power_cpu_cv_mean_watts": 2.473, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 69.07}, "timestamp": "2026-01-28T12:47:33.892282"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3875.698, "latencies_ms": [3875.698], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A laptop computer with a Toshiba brand name on it is sitting on a table with a cell phone and a remote control next to it.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12573.1, "ram_available_mb": 50267.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.406}, "power_stats": {"power_gpu_soc_mean_watts": 21.75, "power_cpu_cv_mean_watts": 2.102, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 77.406}, "timestamp": "2026-01-28T12:47:39.813095"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4525.532, "latencies_ms": [4525.532], "images_per_second": 0.221, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " laptop: 1, phone: 1, remote: 1, phone: 1, remote: 1, phone: 1, remote: 1, phone: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.1, "ram_available_mb": 50267.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.514}, "power_stats": {"power_gpu_soc_mean_watts": 20.489, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 74.514}, "timestamp": "2026-01-28T12:47:46.349449"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3954.99, "latencies_ms": [3954.99], "images_per_second": 0.253, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the cell phone is on the right side, and the remote is in front of the laptop.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.788}, "power_stats": {"power_gpu_soc_mean_watts": 21.309, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 7.812, "gpu_utilization_percent_mean": 75.788}, "timestamp": "2026-01-28T12:47:52.353856"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3356.029, "latencies_ms": [3356.029], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A laptop computer is open on a table with a cell phone and a remote control next to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12573.4, "ram_available_mb": 50267.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.397, "power_cpu_cv_mean_watts": 1.63, "power_sys_5v0_mean_watts": 7.82, "gpu_utilization_percent_mean": 78.071}, "timestamp": "2026-01-28T12:47:57.759112"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3352.871, "latencies_ms": [3352.871], "images_per_second": 0.298, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The laptop is black and silver, the phone is black, and the remote is silver.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12573.4, "ram_available_mb": 50267.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.012, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 81.143}, "timestamp": "2026-01-28T12:48:03.160453"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4044.326, "latencies_ms": [4044.326], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a cluttered desk with a computer monitor, keyboard, mouse, and laptop, surrounded by books, papers, and other office supplies.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12573.4, "ram_available_mb": 50267.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.788}, "power_stats": {"power_gpu_soc_mean_watts": 21.078, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 74.788}, "timestamp": "2026-01-28T12:48:09.243300"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5609.144, "latencies_ms": [5609.144], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. monitor: 2\n2. keyboard: 1\n3. mouse: 1\n4. laptop: 1\n5. books: 10\n6. pen: 1\n7. paper: 1\n8. bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.4, "ram_available_mb": 50267.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12573.8, "ram_available_mb": 50267.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.766}, "power_stats": {"power_gpu_soc_mean_watts": 18.78, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 71.766}, "timestamp": "2026-01-28T12:48:16.881872"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4723.537, "latencies_ms": [4723.537], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The laptop is positioned to the right of the monitor, while the books are stacked on the left side of the desk. The water bottle is placed near the laptop, and the window is located behind the desk.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12573.8, "ram_available_mb": 50267.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.066, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-28T12:48:23.660934"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3041.37, "latencies_ms": [3041.37], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A desk with a computer, books, and a laptop on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.021, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 79.84}, "timestamp": "2026-01-28T12:48:28.753515"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3479.19, "latencies_ms": [3479.19], "images_per_second": 0.287, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.152, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 79.379}, "timestamp": "2026-01-28T12:48:34.281705"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3353.737, "latencies_ms": [3353.737], "images_per_second": 0.298, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A skateboarder is performing a trick in the air while being filmed by a group of people.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12572.2, "ram_available_mb": 50268.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.34, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 80.179}, "timestamp": "2026-01-28T12:48:39.674574"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4474.82, "latencies_ms": [4474.82], "images_per_second": 0.223, "prompt_tokens": 1114, "response_tokens_est": 38, "n_tiles": 1, "output_text": " skateboard: 1, helmet: 1, knee pads: 1, skateboarder: 1, crowd: 1, camera: 1, banner: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12572.0, "ram_available_mb": 50268.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.568}, "power_stats": {"power_gpu_soc_mean_watts": 20.479, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.568}, "timestamp": "2026-01-28T12:48:46.187529"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4435.846, "latencies_ms": [4435.846], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the air, while the spectators are in the background. The skateboarder is closer to the camera than the spectators.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.522, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 73.838}, "timestamp": "2026-01-28T12:48:52.667360"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3316.957, "latencies_ms": [3316.957], "images_per_second": 0.301, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A skateboarder is performing a trick in the air while being filmed by a group of people.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.385, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 79.63}, "timestamp": "2026-01-28T12:48:58.009414"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4765.107, "latencies_ms": [4765.107], "images_per_second": 0.21, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick in an indoor arena with a crowd of spectators. The lighting is artificial, and the skateboarder is wearing protective gear, including a helmet and knee pads.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.895, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 72.775}, "timestamp": "2026-01-28T12:49:04.792587"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4426.318, "latencies_ms": [4426.318], "images_per_second": 0.226, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a vibrant red fire hydrant with a smiley face painted on it, standing on a sidewalk next to a street with a yellow line, and a tree in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.811}, "power_stats": {"power_gpu_soc_mean_watts": 20.444, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 72.811}, "timestamp": "2026-01-28T12:49:11.247957"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4533.258, "latencies_ms": [4533.258], "images_per_second": 0.221, "prompt_tokens": 1114, "response_tokens_est": 38, "n_tiles": 1, "output_text": " fire hydrant: 1\nsmiley face: 1\ntree: 1\ncar: 1\nbuilding: 1\nstreet: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12571.0, "ram_available_mb": 50269.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.595}, "power_stats": {"power_gpu_soc_mean_watts": 20.197, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.695, "gpu_utilization_percent_mean": 73.595}, "timestamp": "2026-01-28T12:49:17.805128"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3875.66, "latencies_ms": [3875.66], "images_per_second": 0.258, "prompt_tokens": 1118, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The fire hydrant is located on the right side of the image, in the foreground, and is positioned near a tree and a building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12571.0, "ram_available_mb": 50269.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12571.0, "ram_available_mb": 50269.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.688}, "power_stats": {"power_gpu_soc_mean_watts": 21.451, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 75.688}, "timestamp": "2026-01-28T12:49:23.715750"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3312.38, "latencies_ms": [3312.38], "images_per_second": 0.302, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A red fire hydrant with a smiley face painted on it stands on a city street corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12571.0, "ram_available_mb": 50269.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12570.8, "ram_available_mb": 50270.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.518, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 78.296}, "timestamp": "2026-01-28T12:49:29.053465"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4817.193, "latencies_ms": [4817.193], "images_per_second": 0.208, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The fire hydrant is painted in a vibrant shade of orange, with a black nozzle and a smiley face drawn on it. The scene is bathed in natural light, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12570.8, "ram_available_mb": 50270.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12570.7, "ram_available_mb": 50270.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.3}, "power_stats": {"power_gpu_soc_mean_watts": 19.823, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 74.3}, "timestamp": "2026-01-28T12:49:35.904805"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4369.808, "latencies_ms": [4369.808], "images_per_second": 0.229, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A green trolley is filled with old suitcases of various colors and sizes, including brown, blue, and green, and is parked in front of a building with a green door.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12570.7, "ram_available_mb": 50270.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12571.0, "ram_available_mb": 50269.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.722, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 73.444}, "timestamp": "2026-01-28T12:49:42.333979"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5827.88, "latencies_ms": [5827.88], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. suitcase: 6\n2. cart: 1\n3. door: 1\n4. wall: 1\n5. window: 1\n6. green door: 1\n7. green cart: 1\n8. green trolley: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12571.0, "ram_available_mb": 50269.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12570.7, "ram_available_mb": 50270.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.643, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 69.49}, "timestamp": "2026-01-28T12:49:50.192383"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6204.178, "latencies_ms": [6204.178], "images_per_second": 0.161, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The green trolley is positioned in the foreground, with the stack of luggage placed on top of it. The luggage is stacked in a haphazard manner, with some pieces leaning against each other and others stacked on top of one another. The trolley is parked in front of a green door, which is located in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12570.7, "ram_available_mb": 50270.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.346}, "power_stats": {"power_gpu_soc_mean_watts": 18.299, "power_cpu_cv_mean_watts": 2.094, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 70.346}, "timestamp": "2026-01-28T12:49:58.414953"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3262.125, "latencies_ms": [3262.125], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A green cart is filled with old suitcases and a green cart is parked outside a building.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12572.4, "ram_available_mb": 50268.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.827, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-28T12:50:03.737887"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6337.887, "latencies_ms": [6337.887], "images_per_second": 0.158, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a green trolley with a stack of old suitcases on it, with the suitcases being brown, blue, and green. The suitcases are placed on a green trolley, which is positioned in front of a building with a green door. The lighting in the image is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12572.4, "ram_available_mb": 50268.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.038}, "power_stats": {"power_gpu_soc_mean_watts": 18.137, "power_cpu_cv_mean_watts": 2.199, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 70.038}, "timestamp": "2026-01-28T12:50:12.144629"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3274.396, "latencies_ms": [3274.396], "images_per_second": 0.305, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl in a pink dress is playing a video game on a Wii console.", "error": null, "sys_before": {"cpu_percent": 19.0, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12571.7, "ram_available_mb": 50269.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.529, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 76.259}, "timestamp": "2026-01-28T12:50:17.438912"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5654.29, "latencies_ms": [5654.29], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. girl: 1\n2. dress: 1\n3. couch: 1\n4. remote: 1\n5. window: 1\n6. blinds: 1\n7. curtain: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12571.7, "ram_available_mb": 50269.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12571.4, "ram_available_mb": 50269.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.553}, "power_stats": {"power_gpu_soc_mean_watts": 18.669, "power_cpu_cv_mean_watts": 1.976, "power_sys_5v0_mean_watts": 7.711, "gpu_utilization_percent_mean": 71.553}, "timestamp": "2026-01-28T12:50:25.110652"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4834.826, "latencies_ms": [4834.826], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The girl is standing to the left of the couch, which is positioned in the middle of the image. The window blinds are located behind the couch, and the red curtain is on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12571.4, "ram_available_mb": 50269.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.293}, "power_stats": {"power_gpu_soc_mean_watts": 19.752, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 72.293}, "timestamp": "2026-01-28T12:50:31.963491"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3245.503, "latencies_ms": [3245.503], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl is playing a video game on a Wii console in her living room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12573.0, "ram_available_mb": 50267.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.037}, "power_stats": {"power_gpu_soc_mean_watts": 22.692, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 78.037}, "timestamp": "2026-01-28T12:50:37.263371"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5135.193, "latencies_ms": [5135.193], "images_per_second": 0.195, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image depicts a young girl in a pink dress with a floral pattern, standing in front of a brown couch. The lighting in the room is natural, coming from a window with white blinds, and the overall atmosphere is warm and inviting.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12573.0, "ram_available_mb": 50267.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12573.1, "ram_available_mb": 50267.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.953}, "power_stats": {"power_gpu_soc_mean_watts": 19.548, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.953}, "timestamp": "2026-01-28T12:50:44.438305"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3739.576, "latencies_ms": [3739.576], "images_per_second": 0.267, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A cluttered desk with a laptop, keyboard, and headphones sits in front of a window with a trash can beside it.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12573.1, "ram_available_mb": 50267.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12573.0, "ram_available_mb": 50267.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.387}, "power_stats": {"power_gpu_soc_mean_watts": 21.328, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 79.387}, "timestamp": "2026-01-28T12:50:50.219104"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5904.046, "latencies_ms": [5904.046], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. chair: 1\n2. laptop: 1\n3. keyboard: 1\n4. mouse: 1\n5. monitor: 1\n6. trash can: 1\n7. window: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12573.0, "ram_available_mb": 50267.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12573.0, "ram_available_mb": 50267.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.653}, "power_stats": {"power_gpu_soc_mean_watts": 17.694, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.579, "gpu_utilization_percent_mean": 72.653}, "timestamp": "2026-01-28T12:50:58.155974"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5049.451, "latencies_ms": [5049.451], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The laptop is on the left side of the desk, the chair is on the right side, and the trash can is in the middle of the desk. The desk is in the foreground, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.0, "ram_available_mb": 50267.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12572.9, "ram_available_mb": 50268.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.31}, "power_stats": {"power_gpu_soc_mean_watts": 19.489, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 74.31}, "timestamp": "2026-01-28T12:51:05.247378"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3594.931, "latencies_ms": [3594.931], "images_per_second": 0.278, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A computer desk with a laptop, keyboard, and mouse is in a room with a window and a trash can.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12572.9, "ram_available_mb": 50268.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.167}, "power_stats": {"power_gpu_soc_mean_watts": 21.811, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 75.167}, "timestamp": "2026-01-28T12:51:10.886898"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3639.89, "latencies_ms": [3639.89], "images_per_second": 0.275, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the windows. The walls are painted white and the floor is wooden.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12572.8, "ram_available_mb": 50268.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.067, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 72.6}, "timestamp": "2026-01-28T12:51:16.554733"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3555.842, "latencies_ms": [3555.842], "images_per_second": 0.281, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is cutting a pizza with a knife and fork on a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12571.9, "ram_available_mb": 50269.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.846, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 82.0}, "timestamp": "2026-01-28T12:51:22.153150"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6239.982, "latencies_ms": [6239.982], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. plate: 1\n2. pizza: 1\n3. fork: 1\n4. person's hand: 1\n5. red and white checkered tablecloth: 1\n6. green peppers: 2\n7. mushrooms: 2\n8. red peppers: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12571.6, "ram_available_mb": 50269.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12571.8, "ram_available_mb": 50269.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.943}, "power_stats": {"power_gpu_soc_mean_watts": 18.225, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 7.693, "gpu_utilization_percent_mean": 71.943}, "timestamp": "2026-01-28T12:51:30.433146"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4210.47, "latencies_ms": [4210.47], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The pizza is in the foreground, on a white plate, with a fork and knife in the background. The person's hand is near the pizza, holding a fork.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12571.8, "ram_available_mb": 50269.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12572.1, "ram_available_mb": 50268.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.057}, "timestamp": "2026-01-28T12:51:36.657999"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3474.653, "latencies_ms": [3474.653], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is cutting a pizza with a knife and fork on a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12572.1, "ram_available_mb": 50268.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.191, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 78.379}, "timestamp": "2026-01-28T12:51:42.152260"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3322.03, "latencies_ms": [3322.03], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The pizza is on a white plate with red and white checkered tablecloth in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.5, "ram_available_mb": 50267.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.737, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 77.63}, "timestamp": "2026-01-28T12:51:47.486850"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4147.819, "latencies_ms": [4147.819], "images_per_second": 0.241, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A white and red bus with the words \"Metropolitan Transit System\" on it is parked in front of a building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12573.1, "ram_available_mb": 50267.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.765}, "power_stats": {"power_gpu_soc_mean_watts": 23.921, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 8.179, "gpu_utilization_percent_mean": 81.765}, "timestamp": "2026-01-28T12:51:53.673944"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6327.849, "latencies_ms": [6327.849], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bus: 1\n2. windows: 4\n3. doors: 2\n4. wheels: 2\n5. seats: 2\n6. passengers: 2\n7. bus number: 1\n8. bus route: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12573.1, "ram_available_mb": 50267.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.585}, "power_stats": {"power_gpu_soc_mean_watts": 20.855, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 75.585}, "timestamp": "2026-01-28T12:52:02.032702"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5002.418, "latencies_ms": [5002.418], "images_per_second": 0.2, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is parked on the left side of the image, with the sidewalk and trees in the background. The bus is in the foreground, with the building and street in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.548}, "power_stats": {"power_gpu_soc_mean_watts": 22.854, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 77.548}, "timestamp": "2026-01-28T12:52:09.085567"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3630.294, "latencies_ms": [3630.294], "images_per_second": 0.275, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A white and red bus is parked in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12573.8, "ram_available_mb": 50267.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.333}, "power_stats": {"power_gpu_soc_mean_watts": 25.153, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 85.333}, "timestamp": "2026-01-28T12:52:14.768911"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4317.426, "latencies_ms": [4317.426], "images_per_second": 0.232, "prompt_tokens": 1442, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The bus is white with red and blue stripes, and it is parked in front of a building with a glass facade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.8, "ram_available_mb": 50267.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.028}, "power_stats": {"power_gpu_soc_mean_watts": 23.908, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 81.028}, "timestamp": "2026-01-28T12:52:21.144820"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3745.606, "latencies_ms": [3745.606], "images_per_second": 0.267, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball glove and cap are resting on the ground next to a metal pole.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.065}, "power_stats": {"power_gpu_soc_mean_watts": 24.404, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.144, "gpu_utilization_percent_mean": 83.065}, "timestamp": "2026-01-28T12:52:26.917116"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5531.668, "latencies_ms": [5531.668], "images_per_second": 0.181, "prompt_tokens": 1446, "response_tokens_est": 43, "n_tiles": 1, "output_text": " baseball cap: 1, baseball glove: 1, baseball: 1, baseball bat: 0, baseball bat handle: 0, baseball bat barrel: 0, baseball bat tip: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12573.3, "ram_available_mb": 50267.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.674}, "power_stats": {"power_gpu_soc_mean_watts": 21.635, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 76.674}, "timestamp": "2026-01-28T12:52:34.487095"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5146.153, "latencies_ms": [5146.153], "images_per_second": 0.194, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The baseball cap is positioned to the left of the glove, which is resting on the ground. The glove is in the foreground of the image, while the cap is in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12573.6, "ram_available_mb": 50267.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.419}, "power_stats": {"power_gpu_soc_mean_watts": 22.175, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 78.419}, "timestamp": "2026-01-28T12:52:41.672255"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3850.942, "latencies_ms": [3850.942], "images_per_second": 0.26, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball glove and cap are resting on the ground next to a metal pole.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.554, "power_cpu_cv_mean_watts": 1.189, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 81.5}, "timestamp": "2026-01-28T12:52:47.576607"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6647.605, "latencies_ms": [6647.605], "images_per_second": 0.15, "prompt_tokens": 1442, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a baseball glove and cap resting on the ground, with the glove being brown and the cap being blue. The glove is positioned on the ground, and the cap is placed on top of it. The image was taken during the day, and the lighting appears to be natural, possibly from the sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.25}, "power_stats": {"power_gpu_soc_mean_watts": 20.633, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 76.25}, "timestamp": "2026-01-28T12:52:56.248577"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3039.604, "latencies_ms": [3039.604], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a red shirt is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.307, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.835, "gpu_utilization_percent_mean": 84.0}, "timestamp": "2026-01-28T12:53:01.318007"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5647.743, "latencies_ms": [5647.743], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. cloud: 0\n7. land: 0\n8. surfboard: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12575.8, "ram_available_mb": 50265.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.687, "power_cpu_cv_mean_watts": 2.352, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.021}, "timestamp": "2026-01-28T12:53:09.007839"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4760.66, "latencies_ms": [4760.66], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, riding a wave that is in the middle ground. The surfer is facing towards the right side of the image, with the wave moving towards the left.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.575}, "power_stats": {"power_gpu_soc_mean_watts": 19.971, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 74.575}, "timestamp": "2026-01-28T12:53:15.786709"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2841.929, "latencies_ms": [2841.929], "images_per_second": 0.352, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.174}, "power_stats": {"power_gpu_soc_mean_watts": 23.867, "power_cpu_cv_mean_watts": 1.218, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 82.174}, "timestamp": "2026-01-28T12:53:20.648654"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3464.111, "latencies_ms": [3464.111], "images_per_second": 0.289, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The surfer is wearing a red shirt and black shorts, and the water is a bright turquoise color.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12573.7, "ram_available_mb": 50267.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12574.4, "ram_available_mb": 50266.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.039, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 76.379}, "timestamp": "2026-01-28T12:53:26.149811"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3624.265, "latencies_ms": [3624.265], "images_per_second": 0.276, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A black and white photo of a bathroom with a toilet, sink, and a stack of toilet paper under the sink.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12574.4, "ram_available_mb": 50266.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.867}, "power_stats": {"power_gpu_soc_mean_watts": 21.998, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 77.867}, "timestamp": "2026-01-28T12:53:31.826831"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4476.922, "latencies_ms": [4476.922], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " toilet: 1, sink: 1, toilet paper: 1, mirror: 1, faucet: 1, soap dispenser: 1, cabinet: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.865}, "power_stats": {"power_gpu_soc_mean_watts": 20.345, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 74.865}, "timestamp": "2026-01-28T12:53:38.339216"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5385.697, "latencies_ms": [5385.697], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the sink is on the right side. The toilet is positioned closer to the camera than the sink. The sink is situated in the foreground of the image, while the toilet is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.133, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 73.244}, "timestamp": "2026-01-28T12:53:45.769138"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3307.212, "latencies_ms": [3307.212], "images_per_second": 0.302, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A black and white photo of a bathroom with a toilet, sink, and toilet paper.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12575.5, "ram_available_mb": 50265.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.619, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 81.222}, "timestamp": "2026-01-28T12:53:51.105769"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3270.249, "latencies_ms": [3270.249], "images_per_second": 0.306, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The bathroom is black and white, with a granite countertop and a tiled wall.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.678, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 76.296}, "timestamp": "2026-01-28T12:53:56.389302"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4740.474, "latencies_ms": [4740.474], "images_per_second": 0.211, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a picturesque scene of a white clock tower with a blue dome, standing tall against a clear blue sky, surrounded by a vibrant red-tiled roof and adorned with intricate white and gold decorations.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.769}, "power_stats": {"power_gpu_soc_mean_watts": 20.012, "power_cpu_cv_mean_watts": 1.838, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 74.769}, "timestamp": "2026-01-28T12:54:03.158082"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5700.637, "latencies_ms": [5700.637], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. clock: 1\n2. roof: 1\n3. tower: 1\n4. gazebo: 1\n5. light: 1\n6. tree: 1\n7. sky: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12574.7, "ram_available_mb": 50266.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.809}, "power_stats": {"power_gpu_soc_mean_watts": 19.016, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 7.693, "gpu_utilization_percent_mean": 71.809}, "timestamp": "2026-01-28T12:54:10.872318"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5210.794, "latencies_ms": [5210.794], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The clock tower is located in the background, behind the ornate gazebo. The gazebo is situated to the left of the clock tower. The clock tower is near the gazebo, as they are both part of the same architectural structure.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12574.7, "ram_available_mb": 50266.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12575.0, "ram_available_mb": 50265.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.568}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 71.568}, "timestamp": "2026-01-28T12:54:18.126546"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5765.798, "latencies_ms": [5765.798], "images_per_second": 0.173, "prompt_tokens": 1111, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a picturesque scene of a white clock tower with a blue dome, standing tall against the backdrop of a clear blue sky. The tower is adorned with a white clock face and is surrounded by a vibrant red-tiled roof, adding a warm contrast to the cool blue of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.0, "ram_available_mb": 50265.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.327}, "power_stats": {"power_gpu_soc_mean_watts": 18.544, "power_cpu_cv_mean_watts": 2.051, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 70.327}, "timestamp": "2026-01-28T12:54:25.925340"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6196.736, "latencies_ms": [6196.736], "images_per_second": 0.161, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a white clock tower with a blue dome, set against a clear blue sky. The tower is adorned with intricate white trim and has a white clock face with black numbers and hands. The roof of the building is covered in terracotta tiles, and there is a decorative wrought iron gazebo in the foreground.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12574.4, "ram_available_mb": 50266.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.404}, "power_stats": {"power_gpu_soc_mean_watts": 18.098, "power_cpu_cv_mean_watts": 1.909, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 69.404}, "timestamp": "2026-01-28T12:54:34.173836"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4190.733, "latencies_ms": [4190.733], "images_per_second": 0.239, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, a group of elephants is seen walking on a dirt path in a natural setting, with one elephant in the foreground prominently displayed and the others in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12574.4, "ram_available_mb": 50266.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.995, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 75.571}, "timestamp": "2026-01-28T12:54:40.415682"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4278.108, "latencies_ms": [4278.108], "images_per_second": 0.234, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " elephant: 1, trunk: 1, tusk: 1, ear: 1, eye: 1, trunk: 1, tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.457}, "power_stats": {"power_gpu_soc_mean_watts": 20.859, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 73.457}, "timestamp": "2026-01-28T12:54:46.730048"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4154.554, "latencies_ms": [4154.554], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking on a dirt path, with trees and bushes on either side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.765, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 74.4}, "timestamp": "2026-01-28T12:54:52.928673"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3237.772, "latencies_ms": [3237.772], "images_per_second": 0.309, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of elephants are walking in a line on a dirt path in a forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.0, "ram_available_mb": 50266.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12574.2, "ram_available_mb": 50266.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.538}, "power_stats": {"power_gpu_soc_mean_watts": 22.655, "power_cpu_cv_mean_watts": 1.524, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 77.538}, "timestamp": "2026-01-28T12:54:58.185291"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3181.16, "latencies_ms": [3181.16], "images_per_second": 0.314, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The elephants are gray, the ground is brown, and the trees are green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.2, "ram_available_mb": 50266.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.846}, "power_stats": {"power_gpu_soc_mean_watts": 22.902, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 77.846}, "timestamp": "2026-01-28T12:55:03.407978"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3895.157, "latencies_ms": [3895.157], "images_per_second": 0.257, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts an open refrigerator with its door open, revealing the interior with empty shelves and a bottle of mustard placed on the top shelf.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12574.9, "ram_available_mb": 50266.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.625}, "power_stats": {"power_gpu_soc_mean_watts": 21.424, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 76.625}, "timestamp": "2026-01-28T12:55:09.358997"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6114.707, "latencies_ms": [6114.707], "images_per_second": 0.164, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Refrigerator: 1\n2. Shelves: 4\n3. Drawers: 2\n4. Door: 1\n5. Door handle: 1\n6. Door hinge: 1\n7. Door latch: 1\n8. Door lock: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12575.7, "ram_available_mb": 50265.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12575.9, "ram_available_mb": 50265.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.412}, "power_stats": {"power_gpu_soc_mean_watts": 18.326, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 7.669, "gpu_utilization_percent_mean": 69.412}, "timestamp": "2026-01-28T12:55:17.490965"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5193.209, "latencies_ms": [5193.209], "images_per_second": 0.193, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The refrigerator is located in the kitchen, with the left side of the refrigerator being closer to the camera than the right side. The bottle of mustard is placed on the top shelf of the refrigerator, which is positioned in the middle of the refrigerator.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12575.9, "ram_available_mb": 50265.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.186}, "power_stats": {"power_gpu_soc_mean_watts": 19.206, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 73.186}, "timestamp": "2026-01-28T12:55:24.713882"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6600.29, "latencies_ms": [6600.29], "images_per_second": 0.152, "prompt_tokens": 1112, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image captures a moment in a kitchen, where an open refrigerator stands on a wooden floor. The refrigerator, with its white exterior and black interior, is filled with various items. On the top shelf, there's a bottle of orange juice, while the middle shelf holds a carton of eggs. The bottom shelf is empty, waiting to be filled with more groceries.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12575.6, "ram_available_mb": 50265.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.125}, "power_stats": {"power_gpu_soc_mean_watts": 17.837, "power_cpu_cv_mean_watts": 1.916, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 71.125}, "timestamp": "2026-01-28T12:55:33.339999"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2812.915, "latencies_ms": [2812.915], "images_per_second": 0.356, "prompt_tokens": 1110, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The refrigerator is white and has a brown floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.696}, "power_stats": {"power_gpu_soc_mean_watts": 23.522, "power_cpu_cv_mean_watts": 1.236, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 79.696}, "timestamp": "2026-01-28T12:55:38.177092"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3738.052, "latencies_ms": [3738.052], "images_per_second": 0.268, "prompt_tokens": 1432, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A bunch of bananas are lined up on a shelf with a purple background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12575.4, "ram_available_mb": 50265.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.226}, "power_stats": {"power_gpu_soc_mean_watts": 24.248, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 84.226}, "timestamp": "2026-01-28T12:55:43.965576"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3078.402, "latencies_ms": [3078.402], "images_per_second": 0.325, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 8", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 91.56}, "power_stats": {"power_gpu_soc_mean_watts": 26.382, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 91.56}, "timestamp": "2026-01-28T12:55:49.079455"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5100.428, "latencies_ms": [5100.428], "images_per_second": 0.196, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bananas are in the foreground, with the purple object in the background. The bananas are stacked on top of each other, with the top banana being the closest to the viewer.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12575.1, "ram_available_mb": 50265.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.762}, "power_stats": {"power_gpu_soc_mean_watts": 22.426, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 79.762}, "timestamp": "2026-01-28T12:55:56.196687"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3578.359, "latencies_ms": [3578.359], "images_per_second": 0.279, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A bunch of bananas are on a shelf in a store.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12575.1, "ram_available_mb": 50265.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.5}, "power_stats": {"power_gpu_soc_mean_watts": 25.002, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 82.5}, "timestamp": "2026-01-28T12:56:01.819447"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3789.211, "latencies_ms": [3789.211], "images_per_second": 0.264, "prompt_tokens": 1442, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and they are sitting on a black surface.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12574.6, "ram_available_mb": 50266.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.812}, "power_stats": {"power_gpu_soc_mean_watts": 24.967, "power_cpu_cv_mean_watts": 1.163, "power_sys_5v0_mean_watts": 8.179, "gpu_utilization_percent_mean": 82.812}, "timestamp": "2026-01-28T12:56:07.637013"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4627.896, "latencies_ms": [4627.896], "images_per_second": 0.216, "prompt_tokens": 1432, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there are four orange cylindrical objects with valves on top, placed on a sidewalk in a city, with a building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.308}, "power_stats": {"power_gpu_soc_mean_watts": 22.849, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.146, "gpu_utilization_percent_mean": 78.308}, "timestamp": "2026-01-28T12:56:14.309486"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6642.055, "latencies_ms": [6642.055], "images_per_second": 0.151, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. metal bollards: 4\n2. trees: 2\n3. buildings: 3\n4. windows: 10\n5. street lights: 2\n6. traffic lights: 1\n7. snow: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12575.0, "ram_available_mb": 50265.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.339}, "power_stats": {"power_gpu_soc_mean_watts": 20.531, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 74.339}, "timestamp": "2026-01-28T12:56:22.992702"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5258.334, "latencies_ms": [5258.334], "images_per_second": 0.19, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The orange cylindrical objects are positioned in the foreground, with the city buildings in the background. The objects are located on the left side of the image, while the buildings are on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.0, "ram_available_mb": 50265.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.144, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-28T12:56:30.290966"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4941.098, "latencies_ms": [4941.098], "images_per_second": 0.202, "prompt_tokens": 1444, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image captures a city square with a row of orange cylindrical bollards in the foreground, while in the background, a large building with a clock tower stands tall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.61}, "power_stats": {"power_gpu_soc_mean_watts": 22.623, "power_cpu_cv_mean_watts": 1.426, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 78.61}, "timestamp": "2026-01-28T12:56:37.268379"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4540.166, "latencies_ms": [4540.166], "images_per_second": 0.22, "prompt_tokens": 1442, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a city square with a row of orange metal bollards, a snow-covered ground, and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.737}, "power_stats": {"power_gpu_soc_mean_watts": 23.311, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 81.737}, "timestamp": "2026-01-28T12:56:43.829898"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5160.961, "latencies_ms": [5160.961], "images_per_second": 0.194, "prompt_tokens": 1432, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In the image, a person is riding a horse in a race, wearing a helmet and a yellow shirt, with a sign in the background that reads \"WINSTONE AGGREGATES.\"", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12574.8, "ram_available_mb": 50266.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.279}, "power_stats": {"power_gpu_soc_mean_watts": 21.904, "power_cpu_cv_mean_watts": 2.188, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 77.279}, "timestamp": "2026-01-28T12:56:51.047177"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6892.881, "latencies_ms": [6892.881], "images_per_second": 0.145, "prompt_tokens": 1446, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. horse: 1\n2. rider: 1\n3. cart: 1\n4. horse's leg: 2\n5. horse's hoof: 1\n6. horse's mane: 1\n7. horse's tail: 1\n8. horse's ear: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.276}, "power_stats": {"power_gpu_soc_mean_watts": 20.268, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 74.276}, "timestamp": "2026-01-28T12:56:59.978034"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5231.918, "latencies_ms": [5231.918], "images_per_second": 0.191, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, with the rider and carriage in the middle ground. The horse is moving towards the right side of the image, while the rider is looking towards the left.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12574.5, "ram_available_mb": 50266.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12574.7, "ram_available_mb": 50266.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.091}, "power_stats": {"power_gpu_soc_mean_watts": 22.227, "power_cpu_cv_mean_watts": 1.538, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 77.091}, "timestamp": "2026-01-28T12:57:07.256126"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3947.5, "latencies_ms": [3947.5], "images_per_second": 0.253, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a helmet and a yellow shirt is riding a horse in a dirt track.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12574.7, "ram_available_mb": 50266.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12574.7, "ram_available_mb": 50266.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.667}, "power_stats": {"power_gpu_soc_mean_watts": 24.319, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 83.667}, "timestamp": "2026-01-28T12:57:13.227003"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8983.923, "latencies_ms": [8983.923], "images_per_second": 0.111, "prompt_tokens": 1442, "response_tokens_est": 102, "n_tiles": 1, "output_text": " The image captures a moment of intense competition on a dirt track, where a horse and carriage are in motion. The horse, a majestic creature with a coat of rich brown, is adorned with a harness that gleams under the bright sunlight. The rider, clad in a vibrant yellow shirt and a protective helmet, sits firmly in the carriage, guiding the horse with a calm and focused demeanor. The track itself is a testament to the sport, with its smooth surface and the presence of a fence marking the boundary.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12574.7, "ram_available_mb": 50266.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.467}, "power_stats": {"power_gpu_soc_mean_watts": 18.924, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 71.467}, "timestamp": "2026-01-28T12:57:24.223678"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3187.504, "latencies_ms": [3187.504], "images_per_second": 0.314, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A brown dog stands on a wooden platform in a backyard with a tree bearing lemons.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12575.3, "ram_available_mb": 50265.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.538}, "power_stats": {"power_gpu_soc_mean_watts": 22.902, "power_cpu_cv_mean_watts": 1.324, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 80.538}, "timestamp": "2026-01-28T12:57:29.453275"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5564.314, "latencies_ms": [5564.314], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. dog: 1\n2. fence: 1\n3. tree: 1\n4. grass: 1\n5. house: 1\n6. bench: 1\n7. wall: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.3, "ram_available_mb": 50265.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12575.1, "ram_available_mb": 50265.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.838, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 71.851}, "timestamp": "2026-01-28T12:57:37.064076"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4488.718, "latencies_ms": [4488.718], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The dog is standing on the left side of the image, with the tree and fence in the background. The dog is in the foreground, with the house and grass in the background.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12575.1, "ram_available_mb": 50265.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.216}, "power_stats": {"power_gpu_soc_mean_watts": 20.164, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 75.216}, "timestamp": "2026-01-28T12:57:43.592553"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3160.113, "latencies_ms": [3160.113], "images_per_second": 0.316, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A brown dog stands on a wooden platform in a backyard with a tree bearing lemons.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12575.2, "ram_available_mb": 50265.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12575.1, "ram_available_mb": 50265.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.183, "power_cpu_cv_mean_watts": 1.247, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 77.538}, "timestamp": "2026-01-28T12:57:48.795606"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3425.492, "latencies_ms": [3425.492], "images_per_second": 0.292, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The dog is brown, the fence is wooden, the tree is green, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12575.1, "ram_available_mb": 50265.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12598.6, "ram_available_mb": 50242.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.321}, "power_stats": {"power_gpu_soc_mean_watts": 22.343, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 80.321}, "timestamp": "2026-01-28T12:57:54.245577"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3342.892, "latencies_ms": [3342.892], "images_per_second": 0.299, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person is standing on a wooden bench with a blue sign on the left side of the bench.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12598.6, "ram_available_mb": 50242.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12594.7, "ram_available_mb": 50246.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.708, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 76.556}, "timestamp": "2026-01-28T12:57:59.619632"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5576.468, "latencies_ms": [5576.468], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. bench: 1\n3. paper: 1\n4. wall: 1\n5. bricks: 1\n6. shoes: 1\n7. pants: 1\n8. feet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.7, "ram_available_mb": 50246.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12594.6, "ram_available_mb": 50246.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.447}, "power_stats": {"power_gpu_soc_mean_watts": 18.795, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 71.447}, "timestamp": "2026-01-28T12:58:07.235011"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5197.797, "latencies_ms": [5197.797], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The bench is positioned in the foreground, with the person's feet on it, and the sign is placed on the left side of the bench. The wall is in the background, and the person's legs are positioned in the middle of the bench.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12594.6, "ram_available_mb": 50246.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12594.9, "ram_available_mb": 50246.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.12, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 72.341}, "timestamp": "2026-01-28T12:58:14.457030"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3152.431, "latencies_ms": [3152.431], "images_per_second": 0.317, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is standing on a wooden bench with a sign on the left side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12594.9, "ram_available_mb": 50246.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.038}, "power_stats": {"power_gpu_soc_mean_watts": 22.84, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 81.038}, "timestamp": "2026-01-28T12:58:19.666191"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3500.537, "latencies_ms": [3500.537], "images_per_second": 0.286, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bench is made of wood and has a red brick floor. The person is wearing red pants and blue shoes.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.506, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 79.517}, "timestamp": "2026-01-28T12:58:25.205639"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3975.831, "latencies_ms": [3975.831], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a red sofa, a round table with a white tablecloth, and a television mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12593.9, "ram_available_mb": 50247.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.283, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 75.273}, "timestamp": "2026-01-28T12:58:31.227295"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5708.427, "latencies_ms": [5708.427], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. red sofa: 1\n2. lamp: 2\n3. vase: 1\n4. table: 1\n5. chair: 1\n6. television: 1\n7. curtains: 2\n8. painting: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.9, "ram_available_mb": 50247.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.938}, "power_stats": {"power_gpu_soc_mean_watts": 18.612, "power_cpu_cv_mean_watts": 2.06, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 73.938}, "timestamp": "2026-01-28T12:58:38.957294"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6025.593, "latencies_ms": [6025.593], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The red sofa is located on the left side of the room, with the white table and chairs positioned in the center. The television is situated on the right side of the room, with the lamp and vase on the left side. The window is located behind the table, and the curtains are drawn to the side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.294}, "power_stats": {"power_gpu_soc_mean_watts": 18.547, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 71.294}, "timestamp": "2026-01-28T12:58:47.028253"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3282.151, "latencies_ms": [3282.151], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The room is furnished with a red sofa, a dining table, and a television.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12594.8, "ram_available_mb": 50246.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.675, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 79.519}, "timestamp": "2026-01-28T12:58:52.344916"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3664.951, "latencies_ms": [3664.951], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted in a warm yellow color.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12594.8, "ram_available_mb": 50246.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.067}, "power_stats": {"power_gpu_soc_mean_watts": 21.943, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 77.067}, "timestamp": "2026-01-28T12:58:58.030556"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3528.212, "latencies_ms": [3528.212], "images_per_second": 0.283, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A black frying pan filled with a mixture of broccoli, carrots, and meat is being stirred with a metal spatula.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.424, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 78.379}, "timestamp": "2026-01-28T12:59:03.602595"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6038.666, "latencies_ms": [6038.666], "images_per_second": 0.166, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. broccoli: 12\n2. carrots: 10\n3. meat: 12\n4. broccoli: 12\n5. meat: 12\n6. carrots: 10\n7. broccoli: 12\n8. meat: 12", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12594.2, "ram_available_mb": 50246.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.3}, "power_stats": {"power_gpu_soc_mean_watts": 18.381, "power_cpu_cv_mean_watts": 2.042, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 70.3}, "timestamp": "2026-01-28T12:59:11.668364"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4845.644, "latencies_ms": [4845.644], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The broccoli is in the middle of the pan, the meat is on the left side, and the vegetables are on the right side. The pan is on the stove, and the broccoli is in the middle of the pan.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12594.2, "ram_available_mb": 50246.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12594.0, "ram_available_mb": 50246.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.759, "power_cpu_cv_mean_watts": 1.767, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 72.976}, "timestamp": "2026-01-28T12:59:18.540970"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4800.442, "latencies_ms": [4800.442], "images_per_second": 0.208, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In a black frying pan on a stove, a colorful mixture of broccoli, carrots, and meat is being cooked. The broccoli is bright green, the carrots are orange, and the meat is pink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12594.0, "ram_available_mb": 50246.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 18.952, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.621, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-28T12:59:25.376501"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5934.813, "latencies_ms": [5934.813], "images_per_second": 0.168, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a black frying pan with a variety of vegetables and meat being cooked. The vegetables are in shades of green, orange, and red, while the meat appears to be pink and white. The lighting in the image is bright and even, suggesting that the photo was taken in a well-lit kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.502, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 70.02}, "timestamp": "2026-01-28T12:59:33.349446"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3004.508, "latencies_ms": [3004.508], "images_per_second": 0.333, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three hot dogs with mustard on a plate are on a dark countertop.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12593.5, "ram_available_mb": 50247.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.531, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 7.883, "gpu_utilization_percent_mean": 82.28}, "timestamp": "2026-01-28T12:59:38.383428"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3620.839, "latencies_ms": [3620.839], "images_per_second": 0.276, "prompt_tokens": 1114, "response_tokens_est": 25, "n_tiles": 1, "output_text": " hotdog: 4, mustard: 4, bun: 4, plate: 1, book: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12593.5, "ram_available_mb": 50247.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.146, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-28T12:59:44.036451"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4407.668, "latencies_ms": [4407.668], "images_per_second": 0.227, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The hot dogs are placed on the left side of the plate, with the mustard being spread on the right side. The plate is positioned in the foreground, with the book in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12593.0, "ram_available_mb": 50247.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.946}, "power_stats": {"power_gpu_soc_mean_watts": 20.684, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 74.946}, "timestamp": "2026-01-28T12:59:50.492010"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3038.778, "latencies_ms": [3038.778], "images_per_second": 0.329, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three hot dogs with mustard on a plate are on a dark countertop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12593.0, "ram_available_mb": 50247.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12593.6, "ram_available_mb": 50247.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.72}, "power_stats": {"power_gpu_soc_mean_watts": 22.935, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.823, "gpu_utilization_percent_mean": 81.72}, "timestamp": "2026-01-28T12:59:55.572209"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5288.428, "latencies_ms": [5288.428], "images_per_second": 0.189, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a plate with three hot dogs, each topped with mustard, placed on a dark green countertop. The lighting in the image is bright, highlighting the vibrant colors of the food and the contrast between the dark countertop and the lighter hot dogs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.6, "ram_available_mb": 50247.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12593.6, "ram_available_mb": 50247.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.636}, "power_stats": {"power_gpu_soc_mean_watts": 19.486, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 73.636}, "timestamp": "2026-01-28T13:00:02.881231"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4799.741, "latencies_ms": [4799.741], "images_per_second": 0.208, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, there are four people swimming in the ocean, with a green umbrella and two chairs placed on the beach, and a bird standing on the sand.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12593.6, "ram_available_mb": 50247.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12593.6, "ram_available_mb": 50247.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.475, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 79.2}, "timestamp": "2026-01-28T13:00:09.737371"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3715.724, "latencies_ms": [3715.724], "images_per_second": 0.269, "prompt_tokens": 1446, "response_tokens_est": 14, "n_tiles": 1, "output_text": " umbrella: 1\nchairs: 2\npeople: 4", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12593.6, "ram_available_mb": 50247.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12595.6, "ram_available_mb": 50245.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.677}, "power_stats": {"power_gpu_soc_mean_watts": 24.777, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 84.677}, "timestamp": "2026-01-28T13:00:15.485314"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6388.669, "latencies_ms": [6388.669], "images_per_second": 0.157, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The green umbrella is positioned to the right of the chairs, which are situated in the foreground of the image. The people are swimming in the water, which is located in the middle ground of the image, while the beach chairs are placed on the sandy shore, which is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.6, "ram_available_mb": 50245.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.472}, "power_stats": {"power_gpu_soc_mean_watts": 20.786, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 75.472}, "timestamp": "2026-01-28T13:00:23.887994"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5389.478, "latencies_ms": [5389.478], "images_per_second": 0.186, "prompt_tokens": 1444, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a lively beach scene where a group of people are enjoying a swim in the ocean. A green umbrella provides shade for a pair of colorful beach chairs, adding a pop of color to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.08, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 77.667}, "timestamp": "2026-01-28T13:00:31.336112"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5381.292, "latencies_ms": [5381.292], "images_per_second": 0.186, "prompt_tokens": 1442, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image depicts a beach scene with a group of people swimming in the ocean, under a green umbrella with a floral pattern. The sky is clear, and the water is a deep blue, reflecting the sunlight.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12593.8, "ram_available_mb": 50247.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.778}, "power_stats": {"power_gpu_soc_mean_watts": 21.972, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 76.778}, "timestamp": "2026-01-28T13:00:38.768458"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4153.964, "latencies_ms": [4153.964], "images_per_second": 0.241, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a vintage kitchen with green wallpaper, a white table, a sink, a refrigerator, and a stove, all arranged in a cozy and functional manner.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12593.8, "ram_available_mb": 50247.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.265}, "power_stats": {"power_gpu_soc_mean_watts": 20.928, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 73.265}, "timestamp": "2026-01-28T13:00:44.953184"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4581.856, "latencies_ms": [4581.856], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " table: 1, chair: 1, sink: 1, refrigerator: 1, oven: 1, stove: 1, cabinet: 1, cupboard: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.52, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-28T13:00:51.576767"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5821.267, "latencies_ms": [5821.267], "images_per_second": 0.172, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The white sink is located near the center of the image, with the white refrigerator to its right. The green table is positioned in the foreground, with the green and white cabinet to its left. The green and white stove is located behind the table, with the green and white oven to its right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.188}, "power_stats": {"power_gpu_soc_mean_watts": 18.979, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 72.188}, "timestamp": "2026-01-28T13:00:59.429605"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4046.999, "latencies_ms": [4046.999], "images_per_second": 0.247, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a vintage kitchen with green wallpaper and a white table in the center. The kitchen is equipped with a sink, a stove, and a refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.706}, "power_stats": {"power_gpu_soc_mean_watts": 21.272, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 75.706}, "timestamp": "2026-01-28T13:01:05.502270"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4903.204, "latencies_ms": [4903.204], "images_per_second": 0.204, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a floral wallpaper and a green and white color scheme. The floor is covered with a floral-patterned carpet, and the walls are adorned with a green and white wallpaper.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.5}, "power_stats": {"power_gpu_soc_mean_watts": 19.823, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 71.5}, "timestamp": "2026-01-28T13:01:12.423264"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3457.169, "latencies_ms": [3457.169], "images_per_second": 0.289, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white dog is walking on a dirt path next to a tree with green moss on its trunk.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.138}, "power_stats": {"power_gpu_soc_mean_watts": 22.275, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.825, "gpu_utilization_percent_mean": 77.138}, "timestamp": "2026-01-28T13:01:17.939429"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4230.808, "latencies_ms": [4230.808], "images_per_second": 0.236, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " dog: 1, tree: 1, leaves: 1, shadow: 1, ground: 1, bark: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.686}, "power_stats": {"power_gpu_soc_mean_watts": 20.7, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 75.686}, "timestamp": "2026-01-28T13:01:24.199273"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4641.527, "latencies_ms": [4641.527], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The dog is in the foreground, walking towards the right side of the image. The tree is in the background, to the left of the dog. The dog is closer to the camera than the tree.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.156, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-28T13:01:30.871873"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3530.193, "latencies_ms": [3530.193], "images_per_second": 0.283, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white dog is walking on a dirt path in a wooded area, sniffing around a tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.022, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 77.103}, "timestamp": "2026-01-28T13:01:36.436716"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4395.618, "latencies_ms": [4395.618], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a black and white dog with a blue collar, walking on a dirt path surrounded by fallen leaves. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.583}, "power_stats": {"power_gpu_soc_mean_watts": 20.637, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 74.583}, "timestamp": "2026-01-28T13:01:42.856530"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3169.888, "latencies_ms": [3169.888], "images_per_second": 0.315, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill, wearing a backpack and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.185, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 78.462}, "timestamp": "2026-01-28T13:01:48.089554"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5641.718, "latencies_ms": [5641.718], "images_per_second": 0.177, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. skis: 2\n2. ski poles: 2\n3. backpack: 1\n4. helmet: 1\n5. gloves: 2\n6. jacket: 1\n7. pants: 1\n8. snow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.1, "ram_available_mb": 50246.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.292}, "power_stats": {"power_gpu_soc_mean_watts": 19.009, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 72.292}, "timestamp": "2026-01-28T13:01:55.787391"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5208.818, "latencies_ms": [5208.818], "images_per_second": 0.192, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the snowy mountain landscape and trees in the background. The skier is facing towards the left side of the image, with the ski poles in their hands and the ski poles in the snow.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.523}, "power_stats": {"power_gpu_soc_mean_watts": 19.414, "power_cpu_cv_mean_watts": 2.13, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 73.523}, "timestamp": "2026-01-28T13:02:03.025985"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2905.854, "latencies_ms": [2905.854], "images_per_second": 0.344, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.833}, "power_stats": {"power_gpu_soc_mean_watts": 23.413, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.864, "gpu_utilization_percent_mean": 77.833}, "timestamp": "2026-01-28T13:02:07.951760"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5353.841, "latencies_ms": [5353.841], "images_per_second": 0.187, "prompt_tokens": 1110, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a person skiing down a snowy hill, wearing a white helmet and black pants. The sky is clear and blue, indicating a sunny day. The snow is pristine white, and the person's skis are green and orange, contrasting with the white snow.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12594.3, "ram_available_mb": 50246.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12591.9, "ram_available_mb": 50249.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.222}, "power_stats": {"power_gpu_soc_mean_watts": 19.172, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 70.222}, "timestamp": "2026-01-28T13:02:15.328078"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4265.629, "latencies_ms": [4265.629], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A vibrant orange and black train with the number 639 on its side is moving along a track, with a clear blue sky and leafless trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12591.9, "ram_available_mb": 50249.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12591.5, "ram_available_mb": 50249.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.678, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-28T13:02:21.652537"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5620.926, "latencies_ms": [5620.926], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. train: 1\n2. tracks: 1\n3. trees: 1\n4. sky: 1\n5. bushes: 1\n6. fence: 1\n7. gravel: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12591.5, "ram_available_mb": 50249.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.447}, "power_stats": {"power_gpu_soc_mean_watts": 18.704, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 72.447}, "timestamp": "2026-01-28T13:02:29.332204"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4698.9, "latencies_ms": [4698.9], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The orange and black train is positioned on the left side of the image, with the clear blue sky and leafless trees in the background. The train is in the foreground, with the gravel track beneath it.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12592.3, "ram_available_mb": 50248.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.082, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-28T13:02:36.068957"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4067.675, "latencies_ms": [4067.675], "images_per_second": 0.246, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A vibrant orange and black train with the number 639 on the front is moving along a track, surrounded by trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.3, "ram_available_mb": 50248.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.176, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 73.273}, "timestamp": "2026-01-28T13:02:42.156477"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4380.235, "latencies_ms": [4380.235], "images_per_second": 0.228, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The locomotive is painted in vibrant shades of orange and yellow, with black and white accents. The sky is a clear blue, and the trees are bare, suggesting a cold season.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12591.4, "ram_available_mb": 50249.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.616, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.278}, "timestamp": "2026-01-28T13:02:48.596383"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4408.357, "latencies_ms": [4408.357], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a wooden table with a plate containing a serving of avocado spread on a slice of whole grain bread, a bowl of steamed broccoli, and a side of white dip.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12591.4, "ram_available_mb": 50249.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12591.3, "ram_available_mb": 50249.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.401, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 73.324}, "timestamp": "2026-01-28T13:02:55.053119"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4361.998, "latencies_ms": [4361.998], "images_per_second": 0.229, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " plate: 1, bread: 2, broccoli: 1, guacamole: 1, bowl: 1, spoon: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12591.3, "ram_available_mb": 50249.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.784}, "power_stats": {"power_gpu_soc_mean_watts": 20.66, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.784, "gpu_utilization_percent_mean": 74.784}, "timestamp": "2026-01-28T13:03:01.429412"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6434.674, "latencies_ms": [6434.674], "images_per_second": 0.155, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The plate is located in the foreground, with the bread, bowl of broccoli, and bowl of guacamole arranged in a left-right-left pattern. The bread is positioned on the left side of the plate, while the bowl of broccoli is on the right side, and the bowl of guacamole is in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12592.0, "ram_available_mb": 50248.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.778}, "power_stats": {"power_gpu_soc_mean_watts": 17.983, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 70.778}, "timestamp": "2026-01-28T13:03:09.905908"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4458.355, "latencies_ms": [4458.355], "images_per_second": 0.224, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a meal set on a wooden table, featuring a plate with a serving of broccoli, a slice of bread topped with guacamole, and a bowl of quinoa.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.0, "ram_available_mb": 50248.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12592.0, "ram_available_mb": 50248.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.541}, "power_stats": {"power_gpu_soc_mean_watts": 20.523, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.689, "gpu_utilization_percent_mean": 75.541}, "timestamp": "2026-01-28T13:03:16.401109"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5881.855, "latencies_ms": [5881.855], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a wooden table with a plate of food on it, including a bowl of broccoli and a slice of bread topped with guacamole. The lighting is natural, and the colors are vibrant, with the green of the broccoli contrasting against the brown of the bread and the blue of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.0, "ram_available_mb": 50248.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12592.3, "ram_available_mb": 50248.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.88}, "power_stats": {"power_gpu_soc_mean_watts": 18.695, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 72.88}, "timestamp": "2026-01-28T13:03:24.300375"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3529.25, "latencies_ms": [3529.25], "images_per_second": 0.283, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is sleeping on a bench covered with an orange blanket, with a blue bag and a red bag nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.966}, "power_stats": {"power_gpu_soc_mean_watts": 22.316, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 76.966}, "timestamp": "2026-01-28T13:03:29.861376"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5057.263, "latencies_ms": [5057.263], "images_per_second": 0.198, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " bench: 1\npark bench: 1\npark bench blanket: 1\npark bench bag: 1\npark bench bag strap: 1\npark bench lamp: 2\npark bench parking meter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12592.8, "ram_available_mb": 50248.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.857}, "power_stats": {"power_gpu_soc_mean_watts": 19.672, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 73.857}, "timestamp": "2026-01-28T13:03:36.961606"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4380.205, "latencies_ms": [4380.205], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bench is located in the foreground of the image, with the parking meters and fence in the background. The person is lying on the bench, with the backpack and blanket near them.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12592.8, "ram_available_mb": 50248.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12593.2, "ram_available_mb": 50247.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.62, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.486}, "timestamp": "2026-01-28T13:03:43.365695"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2843.447, "latencies_ms": [2843.447], "images_per_second": 0.352, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A person is sleeping on a bench in a park.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12593.2, "ram_available_mb": 50247.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12592.9, "ram_available_mb": 50248.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.786, "power_cpu_cv_mean_watts": 1.236, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-28T13:03:48.221319"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4061.393, "latencies_ms": [4061.393], "images_per_second": 0.246, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The bench is made of wood and is covered with an orange blanket. The scene is bathed in natural light, and the grass is a vibrant green.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12592.9, "ram_available_mb": 50248.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12592.9, "ram_available_mb": 50248.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.969, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 76.029}, "timestamp": "2026-01-28T13:03:54.319208"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4286.183, "latencies_ms": [4286.183], "images_per_second": 0.233, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A tall, colorful vase with a twisted design is placed on a white pedestal in front of a brown wall, with a red vase and a decorative plate in the background.", "error": null, "sys_before": {"cpu_percent": 14.8, "ram_used_mb": 12592.8, "ram_available_mb": 50248.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.371}, "power_stats": {"power_gpu_soc_mean_watts": 20.875, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 72.371}, "timestamp": "2026-01-28T13:04:00.671307"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4294.998, "latencies_ms": [4294.998], "images_per_second": 0.233, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " vase: 1, pot: 1, wall: 1, wall art: 1, paper: 1, tag: 1, flower: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.686}, "power_stats": {"power_gpu_soc_mean_watts": 20.744, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 75.686}, "timestamp": "2026-01-28T13:04:07.009057"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4486.835, "latencies_ms": [4486.835], "images_per_second": 0.223, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The vase is positioned in the foreground, with the wall and other objects in the background. The vase is placed on a white pedestal, which is situated in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.7, "ram_available_mb": 50247.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12593.0, "ram_available_mb": 50247.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.297}, "power_stats": {"power_gpu_soc_mean_watts": 20.535, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 72.297}, "timestamp": "2026-01-28T13:04:13.531533"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6254.8, "latencies_ms": [6254.8], "images_per_second": 0.16, "prompt_tokens": 1112, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image captures a vibrant display of ceramic art in a gallery setting. A tall, twisted vase filled with dried flowers and twigs stands out against the brown wall, its colors ranging from deep purple to bright yellow and green. The vase is placed on a white pedestal, drawing attention to its unique design and the intricate details of the dried flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.0, "ram_available_mb": 50247.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.264}, "power_stats": {"power_gpu_soc_mean_watts": 18.084, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 72.264}, "timestamp": "2026-01-28T13:04:21.841926"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4513.616, "latencies_ms": [4513.616], "images_per_second": 0.222, "prompt_tokens": 1110, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The vase is a vibrant mix of colors, with shades of green, yellow, and brown. The lighting is bright and even, highlighting the textures and colors of the vase and the surrounding objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12593.1, "ram_available_mb": 50247.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12592.9, "ram_available_mb": 50248.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.684}, "power_stats": {"power_gpu_soc_mean_watts": 20.393, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 74.684}, "timestamp": "2026-01-28T13:04:28.381253"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3568.499, "latencies_ms": [3568.499], "images_per_second": 0.28, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A skateboarder wearing a helmet and knee pads is performing a trick on a skateboard in a concrete skate park.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12592.9, "ram_available_mb": 50248.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12592.5, "ram_available_mb": 50248.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.867}, "power_stats": {"power_gpu_soc_mean_watts": 21.988, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 78.867}, "timestamp": "2026-01-28T13:04:33.991330"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6438.125, "latencies_ms": [6438.125], "images_per_second": 0.155, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. helmet: 1\n3. knee pads: 1\n4. skateboard wheels: 2\n5. skateboard deck: 1\n6. skateboard trucks: 1\n7. skateboard deck grip tape: 1\n8. skateboard deck trucks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.5, "ram_available_mb": 50248.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12593.2, "ram_available_mb": 50247.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.855}, "power_stats": {"power_gpu_soc_mean_watts": 18.169, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 71.855}, "timestamp": "2026-01-28T13:04:42.474522"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4347.864, "latencies_ms": [4347.864], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the center of the image. The skatepark is in the background, with ramps and other skateboarders visible.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12593.2, "ram_available_mb": 50247.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12594.2, "ram_available_mb": 50246.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.806}, "power_stats": {"power_gpu_soc_mean_watts": 20.718, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 73.806}, "timestamp": "2026-01-28T13:04:48.856124"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3214.153, "latencies_ms": [3214.153], "images_per_second": 0.311, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a concrete bowl at a skatepark.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12594.2, "ram_available_mb": 50246.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12591.9, "ram_available_mb": 50249.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.766, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 81.5}, "timestamp": "2026-01-28T13:04:54.084965"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3793.81, "latencies_ms": [3793.81], "images_per_second": 0.264, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The skateboarder is wearing a helmet and knee pads, and the skate park is lit by natural light during the golden hour.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12591.9, "ram_available_mb": 50249.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12591.9, "ram_available_mb": 50249.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.774}, "power_stats": {"power_gpu_soc_mean_watts": 21.579, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 78.774}, "timestamp": "2026-01-28T13:04:59.910936"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4943.041, "latencies_ms": [4943.041], "images_per_second": 0.202, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a lively night scene in a bustling city square, where a majestic clock tower stands tall, adorned with a festive Christmas tree and twinkling lights, while the surrounding buildings are illuminated, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12591.9, "ram_available_mb": 50249.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12591.7, "ram_available_mb": 50249.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.268}, "power_stats": {"power_gpu_soc_mean_watts": 19.402, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 73.268}, "timestamp": "2026-01-28T13:05:06.916615"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4256.382, "latencies_ms": [4256.382], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " clock: 1, tower: 1, lights: 1, tree: 1, building: 1, people: 1, street: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12591.7, "ram_available_mb": 50249.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12591.7, "ram_available_mb": 50249.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.743}, "power_stats": {"power_gpu_soc_mean_watts": 20.873, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 75.743}, "timestamp": "2026-01-28T13:05:13.203135"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5053.523, "latencies_ms": [5053.523], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The clock tower is located in the center of the image, with the Christmas tree to its right. The street is in the foreground, with the buildings in the background. The clock tower is closer to the viewer than the Christmas tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12591.7, "ram_available_mb": 50249.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.595}, "power_stats": {"power_gpu_soc_mean_watts": 19.713, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 73.595}, "timestamp": "2026-01-28T13:05:20.295255"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5938.725, "latencies_ms": [5938.725], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a lively night scene in a bustling city square, where a majestic clock tower stands tall, adorned with twinkling lights that add a magical touch to the urban landscape. The square is alive with people, some strolling leisurely, others gathered around a beautifully decorated Christmas tree, creating a festive atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12592.1, "ram_available_mb": 50248.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12592.4, "ram_available_mb": 50248.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.08}, "power_stats": {"power_gpu_soc_mean_watts": 18.393, "power_cpu_cv_mean_watts": 2.05, "power_sys_5v0_mean_watts": 7.682, "gpu_utilization_percent_mean": 71.08}, "timestamp": "2026-01-28T13:05:28.262737"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7363.194, "latencies_ms": [7363.194], "images_per_second": 0.136, "prompt_tokens": 1109, "response_tokens_est": 86, "n_tiles": 1, "output_text": " The image captures a vibrant night scene in a bustling city square, where a majestic clock tower stands tall, its white face and black hands glowing under the artificial lights. The square is adorned with a festive Christmas tree, its branches heavy with twinkling lights and ornaments, and a crowd of people can be seen enjoying the festive atmosphere. The sky above is a deep, dark blue, providing a stark contrast to the illuminated cityscape below.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12592.4, "ram_available_mb": 50248.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12591.5, "ram_available_mb": 50249.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.492}, "power_stats": {"power_gpu_soc_mean_watts": 17.356, "power_cpu_cv_mean_watts": 2.034, "power_sys_5v0_mean_watts": 7.686, "gpu_utilization_percent_mean": 70.492}, "timestamp": "2026-01-28T13:05:37.647739"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3199.088, "latencies_ms": [3199.088], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young man is playing tennis on a court with a tennis ball in the air.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12591.5, "ram_available_mb": 50249.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12591.0, "ram_available_mb": 50249.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.923}, "power_stats": {"power_gpu_soc_mean_watts": 22.675, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 80.923}, "timestamp": "2026-01-28T13:05:42.877963"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6208.265, "latencies_ms": [6208.265], "images_per_second": 0.161, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. chain link fence: 1\n5. tennis court: 1\n6. chain link fence post: 1\n7. tennis court line: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12591.0, "ram_available_mb": 50249.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12590.9, "ram_available_mb": 50250.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.923}, "power_stats": {"power_gpu_soc_mean_watts": 18.431, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 70.923}, "timestamp": "2026-01-28T13:05:51.144597"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5761.596, "latencies_ms": [5761.596], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The tennis player is in the foreground of the image, holding a tennis racket and preparing to hit a tennis ball. The tennis ball is in the middle ground, slightly to the right of the player. The tennis court is in the background, with a chain link fence and trees surrounding it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12590.9, "ram_available_mb": 50250.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12590.8, "ram_available_mb": 50250.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.896}, "power_stats": {"power_gpu_soc_mean_watts": 18.666, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 71.896}, "timestamp": "2026-01-28T13:05:58.932680"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3252.832, "latencies_ms": [3252.832], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young man is playing tennis on a court with a green fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12590.8, "ram_available_mb": 50250.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12591.1, "ram_available_mb": 50249.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.115}, "power_stats": {"power_gpu_soc_mean_watts": 22.875, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 78.115}, "timestamp": "2026-01-28T13:06:04.202055"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3582.52, "latencies_ms": [3582.52], "images_per_second": 0.279, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the tennis court is made of concrete with white lines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12591.1, "ram_available_mb": 50249.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12590.2, "ram_available_mb": 50250.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.154, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 76.621}, "timestamp": "2026-01-28T13:06:09.819708"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3983.439, "latencies_ms": [3983.439], "images_per_second": 0.251, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a fireplace, a comfortable armchair, and a bookshelf filled with books, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12590.2, "ram_available_mb": 50250.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12589.8, "ram_available_mb": 50251.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.152}, "power_stats": {"power_gpu_soc_mean_watts": 21.361, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 74.152}, "timestamp": "2026-01-28T13:06:15.859357"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5781.861, "latencies_ms": [5781.861], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. sofa: 1\n2. bookshelves: 2\n3. lamp: 2\n4. fireplace: 1\n5. painting: 1\n6. plant: 2\n7. chair: 1\n8. table: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12589.8, "ram_available_mb": 50251.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12590.0, "ram_available_mb": 50250.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.479}, "power_stats": {"power_gpu_soc_mean_watts": 18.563, "power_cpu_cv_mean_watts": 1.969, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 72.479}, "timestamp": "2026-01-28T13:06:23.681625"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6589.387, "latencies_ms": [6589.387], "images_per_second": 0.152, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The beige armchair is positioned in the foreground, to the right of the fireplace, with the green plant to its left. The white bookshelves are located behind the armchair, with the framed picture hanging above the fireplace. The beige sofa is situated in the background, to the left of the fireplace, with the green plant to its right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12590.0, "ram_available_mb": 50250.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12591.0, "ram_available_mb": 50249.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.836}, "power_stats": {"power_gpu_soc_mean_watts": 18.176, "power_cpu_cv_mean_watts": 2.075, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 69.836}, "timestamp": "2026-01-28T13:06:32.312077"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3277.818, "latencies_ms": [3277.818], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A living room with a fireplace, two lamps, a chair, and a bookshelf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12590.5, "ram_available_mb": 50250.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12590.5, "ram_available_mb": 50250.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.606, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 78.519}, "timestamp": "2026-01-28T13:06:37.627385"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3606.319, "latencies_ms": [3606.319], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from the windows, and the walls are painted in a light color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12590.5, "ram_available_mb": 50250.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12590.5, "ram_available_mb": 50250.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.4}, "power_stats": {"power_gpu_soc_mean_watts": 21.882, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-28T13:06:43.250042"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4269.531, "latencies_ms": [4269.531], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, a group of zebras is seen grazing on the lush green grass in a field, with one zebra standing out due to its unique black and white stripes.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12590.2, "ram_available_mb": 50250.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12589.8, "ram_available_mb": 50251.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.723, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 75.629}, "timestamp": "2026-01-28T13:06:49.569417"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3623.164, "latencies_ms": [3623.164], "images_per_second": 0.276, "prompt_tokens": 1113, "response_tokens_est": 25, "n_tiles": 1, "output_text": " zebra: 4\ngrass: 1\ntree: 1\ndirt: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12589.8, "ram_available_mb": 50251.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12590.2, "ram_available_mb": 50250.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.067}, "power_stats": {"power_gpu_soc_mean_watts": 22.093, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 76.067}, "timestamp": "2026-01-28T13:06:55.214307"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4921.495, "latencies_ms": [4921.495], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the dirt mound and grass in the background. The zebras are facing towards the left side of the image, with the dirt mound located to the right of them.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12590.2, "ram_available_mb": 50250.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12590.2, "ram_available_mb": 50250.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.571}, "power_stats": {"power_gpu_soc_mean_watts": 19.595, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 73.571}, "timestamp": "2026-01-28T13:07:02.161959"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4640.352, "latencies_ms": [4640.352], "images_per_second": 0.216, "prompt_tokens": 1111, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a group of zebras are grazing on a grassy hillside under a clear blue sky. The zebras are standing close to each other, with one of them bending down to eat grass.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12590.2, "ram_available_mb": 50250.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12590.0, "ram_available_mb": 50250.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.842}, "power_stats": {"power_gpu_soc_mean_watts": 20.215, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 73.842}, "timestamp": "2026-01-28T13:07:08.816262"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4932.74, "latencies_ms": [4932.74], "images_per_second": 0.203, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a group of zebras in a grassy field with a clear blue sky in the background. The zebras are grazing on the grass, with their black and white stripes standing out against the green backdrop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12590.0, "ram_available_mb": 50250.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12589.7, "ram_available_mb": 50251.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.805}, "power_stats": {"power_gpu_soc_mean_watts": 18.943, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 7.646, "gpu_utilization_percent_mean": 71.805}, "timestamp": "2026-01-28T13:07:15.758223"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3961.492, "latencies_ms": [3961.492], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, with a man wearing a hat and a woman wearing a hat sitting at the table.", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 12589.7, "ram_available_mb": 50251.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12589.5, "ram_available_mb": 50251.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.636}, "power_stats": {"power_gpu_soc_mean_watts": 21.518, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 75.636}, "timestamp": "2026-01-28T13:07:21.753204"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6587.421, "latencies_ms": [6587.421], "images_per_second": 0.152, "prompt_tokens": 1113, "response_tokens_est": 73, "n_tiles": 1, "output_text": " object: chair, count: 12\nobject: table, count: 1\nobject: person, count: 12\nobject: wall, count: 1\nobject: floor, count: 1\nobject: wall, count: 1\nobject: wall, count: 1\nobject: wall, count: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12589.5, "ram_available_mb": 50251.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12589.5, "ram_available_mb": 50251.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.455}, "power_stats": {"power_gpu_soc_mean_watts": 18.123, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-28T13:07:30.363956"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5628.16, "latencies_ms": [5628.16], "images_per_second": 0.178, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The people are positioned in the middle of the image, with the table being the central focus. The background features the restaurant's interior, including the kitchen and other patrons.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12589.5, "ram_available_mb": 50251.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.438}, "power_stats": {"power_gpu_soc_mean_watts": 18.768, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 72.438}, "timestamp": "2026-01-28T13:07:38.007739"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2922.067, "latencies_ms": [2922.067], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12589.4, "ram_available_mb": 50251.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.579, "power_cpu_cv_mean_watts": 1.318, "power_sys_5v0_mean_watts": 7.847, "gpu_utilization_percent_mean": 82.5}, "timestamp": "2026-01-28T13:07:42.953247"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5034.896, "latencies_ms": [5034.896], "images_per_second": 0.199, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere, characterized by the rich brown color of the wooden floor and the warm lighting that illuminates the space. The walls are adorned with brick, adding a rustic charm to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12589.4, "ram_available_mb": 50251.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12589.0, "ram_available_mb": 50251.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.024}, "power_stats": {"power_gpu_soc_mean_watts": 19.719, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 71.024}, "timestamp": "2026-01-28T13:07:50.001902"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4270.211, "latencies_ms": [4270.211], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, a group of white swans are swimming in a body of water near a marina, where several boats are docked and covered with purple tarps.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12589.0, "ram_available_mb": 50251.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.528}, "power_stats": {"power_gpu_soc_mean_watts": 20.727, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 76.528}, "timestamp": "2026-01-28T13:07:56.321451"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4064.172, "latencies_ms": [4064.172], "images_per_second": 0.246, "prompt_tokens": 1113, "response_tokens_est": 31, "n_tiles": 1, "output_text": " 1. swans: 14\n2. boats: 10\n3. dock: 1\n4. water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.42, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 75.182}, "timestamp": "2026-01-28T13:08:02.410900"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4992.173, "latencies_ms": [4992.173], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The swans are positioned in the foreground of the image, with the boats in the background. The boats are docked on the left side of the image, while the swans are swimming in the water on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.881}, "power_stats": {"power_gpu_soc_mean_watts": 19.348, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 73.881}, "timestamp": "2026-01-28T13:08:09.458290"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3531.398, "latencies_ms": [3531.398], "images_per_second": 0.283, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A group of swans are swimming in the water near a marina with boats docked in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12589.7, "ram_available_mb": 50251.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.276}, "power_stats": {"power_gpu_soc_mean_watts": 22.191, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 76.276}, "timestamp": "2026-01-28T13:08:15.026652"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5594.615, "latencies_ms": [5594.615], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a serene harbor scene with a group of swans swimming in the water, their white feathers contrasting with the dark blue-gray of the water. The sky is a clear blue, and the sun is shining brightly, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12589.7, "ram_available_mb": 50251.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12589.7, "ram_available_mb": 50251.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.196}, "power_stats": {"power_gpu_soc_mean_watts": 18.673, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 7.677, "gpu_utilization_percent_mean": 72.196}, "timestamp": "2026-01-28T13:08:22.657094"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3530.72, "latencies_ms": [3530.72], "images_per_second": 0.283, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man and woman are cutting a wedding cake in a tent with a tablecloth and a guitar in the background.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12589.3, "ram_available_mb": 50251.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.26, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 76.103}, "timestamp": "2026-01-28T13:08:28.215511"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4166.049, "latencies_ms": [4166.049], "images_per_second": 0.24, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " 1. Tent\n2. Table\n3. Cake\n4. People\n5. Chair\n6. Speaker\n7. Guitar\n8. Flags", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.343}, "power_stats": {"power_gpu_soc_mean_watts": 20.974, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 74.343}, "timestamp": "2026-01-28T13:08:34.409043"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5832.292, "latencies_ms": [5832.292], "images_per_second": 0.171, "prompt_tokens": 1118, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The bride and groom are standing close to each other, with the bride on the left and the groom on the right. The cake is placed in the middle of the table, which is positioned in the foreground. The tent is located in the background, with the guests standing near the edge of the tent.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12589.4, "ram_available_mb": 50251.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.6}, "power_stats": {"power_gpu_soc_mean_watts": 18.597, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 71.6}, "timestamp": "2026-01-28T13:08:42.258677"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3091.204, "latencies_ms": [3091.204], "images_per_second": 0.323, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A wedding is taking place in a tent with a table with a cake on it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12589.4, "ram_available_mb": 50251.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12589.6, "ram_available_mb": 50251.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.077}, "power_stats": {"power_gpu_soc_mean_watts": 22.732, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.856, "gpu_utilization_percent_mean": 80.077}, "timestamp": "2026-01-28T13:08:47.371475"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3928.533, "latencies_ms": [3928.533], "images_per_second": 0.255, "prompt_tokens": 1110, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The wedding is taking place in a tent with white walls and a wooden floor. The lighting is dim, and the tent is decorated with colorful flags.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12589.6, "ram_available_mb": 50251.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12589.8, "ram_available_mb": 50251.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.3, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 75.394}, "timestamp": "2026-01-28T13:08:53.344137"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4448.297, "latencies_ms": [4448.297], "images_per_second": 0.225, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a blue sofa, a coffee table, and a red patterned rug, all set against a backdrop of red walls adorned with various paintings and framed pictures.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12589.8, "ram_available_mb": 50251.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12589.6, "ram_available_mb": 50251.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.421}, "power_stats": {"power_gpu_soc_mean_watts": 20.447, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 72.421}, "timestamp": "2026-01-28T13:08:59.839465"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4238.723, "latencies_ms": [4238.723], "images_per_second": 0.236, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " sofa: 1, table: 2, lamp: 1, plant: 2, rug: 1, painting: 1, window: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12589.6, "ram_available_mb": 50251.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12589.3, "ram_available_mb": 50251.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.78, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 74.861}, "timestamp": "2026-01-28T13:09:06.121820"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5403.079, "latencies_ms": [5403.079], "images_per_second": 0.185, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The sofa is positioned in the center of the room, with the coffee table in front of it and the side table to its left. The painting is hung on the wall above the sofa, while the rug is placed on the floor in front of the sofa.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12589.3, "ram_available_mb": 50251.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12589.3, "ram_available_mb": 50251.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.37}, "power_stats": {"power_gpu_soc_mean_watts": 19.371, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 72.37}, "timestamp": "2026-01-28T13:09:13.573630"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3286.377, "latencies_ms": [3286.377], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A living room with red walls and a blue couch, a coffee table and a rug.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12589.3, "ram_available_mb": 50251.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12589.0, "ram_available_mb": 50251.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.444}, "power_stats": {"power_gpu_soc_mean_watts": 22.53, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 80.444}, "timestamp": "2026-01-28T13:09:18.883310"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3974.758, "latencies_ms": [3974.758], "images_per_second": 0.252, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The room is painted red with white curtains and a red and yellow rug. The room is well-lit with natural light coming in from the windows.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12589.0, "ram_available_mb": 50251.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12588.9, "ram_available_mb": 50252.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.121}, "power_stats": {"power_gpu_soc_mean_watts": 21.26, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 77.121}, "timestamp": "2026-01-28T13:09:24.889512"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5250.869, "latencies_ms": [5250.869], "images_per_second": 0.19, "prompt_tokens": 1432, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image depicts a surreal scene where a doll with red hair and a black dress is seated at a table, with a clock on its head that is showing the time as 10:10.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12588.9, "ram_available_mb": 50252.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-28T13:09:32.187803"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4228.722, "latencies_ms": [4228.722], "images_per_second": 0.236, "prompt_tokens": 1446, "response_tokens_est": 24, "n_tiles": 1, "output_text": " clock: 1, doll: 1, table: 1, wall: 1, shadow: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.629}, "power_stats": {"power_gpu_soc_mean_watts": 24.317, "power_cpu_cv_mean_watts": 2.094, "power_sys_5v0_mean_watts": 8.173, "gpu_utilization_percent_mean": 83.629}, "timestamp": "2026-01-28T13:09:38.456268"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5506.634, "latencies_ms": [5506.634], "images_per_second": 0.182, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The clock is positioned to the left of the doll, which is situated in the foreground of the image. The doll is positioned in front of the clock, with the clock's face slightly obscured by the doll's head.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.83}, "power_stats": {"power_gpu_soc_mean_watts": 21.713, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 76.83}, "timestamp": "2026-01-28T13:09:46.006633"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4133.714, "latencies_ms": [4133.714], "images_per_second": 0.242, "prompt_tokens": 1444, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A doll with a clock on its face is sitting at a table with a red object in front of it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.235}, "power_stats": {"power_gpu_soc_mean_watts": 24.432, "power_cpu_cv_mean_watts": 1.295, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 83.235}, "timestamp": "2026-01-28T13:09:52.153829"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5949.646, "latencies_ms": [5949.646], "images_per_second": 0.168, "prompt_tokens": 1442, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a doll with a clock face on its head, set against a white background. The lighting is soft and diffused, creating a warm and inviting atmosphere. The doll's hair is a vibrant red, and it is dressed in a black outfit.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.3}, "power_stats": {"power_gpu_soc_mean_watts": 21.257, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 77.3}, "timestamp": "2026-01-28T13:10:00.122230"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3020.757, "latencies_ms": [3020.757], "images_per_second": 0.331, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a helmet and a jacket is sitting on a scooter.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.278, "power_cpu_cv_mean_watts": 1.441, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 79.56}, "timestamp": "2026-01-28T13:10:05.201867"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5651.794, "latencies_ms": [5651.794], "images_per_second": 0.177, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. scooter: 1\n4. jacket: 1\n5. pants: 1\n6. shoes: 1\n7. seat: 1\n8. seatbelt: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 2.437, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 72.596}, "timestamp": "2026-01-28T13:10:12.883534"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4588.599, "latencies_ms": [4588.599], "images_per_second": 0.218, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The person is sitting on the left side of the scooter, which is positioned in the foreground of the image. The person is wearing a helmet, which is located near the top of the scooter.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.468, "power_cpu_cv_mean_watts": 2.55, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 72.789}, "timestamp": "2026-01-28T13:10:19.504010"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2873.413, "latencies_ms": [2873.413], "images_per_second": 0.348, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A man wearing a helmet is sitting on a scooter.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.304}, "power_stats": {"power_gpu_soc_mean_watts": 23.471, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 7.85, "gpu_utilization_percent_mean": 81.304}, "timestamp": "2026-01-28T13:10:24.417195"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3768.372, "latencies_ms": [3768.372], "images_per_second": 0.265, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a red background. The person is wearing a beige jacket and black shoes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.258}, "power_stats": {"power_gpu_soc_mean_watts": 21.732, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 76.258}, "timestamp": "2026-01-28T13:10:30.222571"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3086.558, "latencies_ms": [3086.558], "images_per_second": 0.324, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large pizza with cheese and herbs is being prepared on a wooden table.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 12588.7, "ram_available_mb": 50252.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12589.1, "ram_available_mb": 50251.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.149, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 79.76}, "timestamp": "2026-01-28T13:10:35.358523"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5586.314, "latencies_ms": [5586.314], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. pizza: 1\n2. person: 1\n3. spatula: 1\n4. table: 1\n5. counter: 1\n6. oven: 1\n7. pan: 1\n8. cheese: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12589.1, "ram_available_mb": 50251.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12589.6, "ram_available_mb": 50251.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.383}, "power_stats": {"power_gpu_soc_mean_watts": 18.771, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 70.383}, "timestamp": "2026-01-28T13:10:43.010120"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4418.912, "latencies_ms": [4418.912], "images_per_second": 0.226, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the person's hand in the background. The pizza is on the left side of the image, while the person's hand is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12589.6, "ram_available_mb": 50251.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.243}, "power_stats": {"power_gpu_soc_mean_watts": 20.501, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.784, "gpu_utilization_percent_mean": 74.243}, "timestamp": "2026-01-28T13:10:49.466150"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3165.264, "latencies_ms": [3165.264], "images_per_second": 0.316, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A large pizza with cheese and herbs is being prepared on a wooden table in a kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12589.2, "ram_available_mb": 50251.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12588.9, "ram_available_mb": 50252.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.038}, "power_stats": {"power_gpu_soc_mean_watts": 22.704, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 81.038}, "timestamp": "2026-01-28T13:10:54.657780"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3638.341, "latencies_ms": [3638.341], "images_per_second": 0.275, "prompt_tokens": 1110, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The pizza is golden brown and has a creamy white sauce. The lighting is dim and the pizza is on a wooden table.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12588.9, "ram_available_mb": 50252.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.081, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.846, "gpu_utilization_percent_mean": 77.8}, "timestamp": "2026-01-28T13:11:00.337503"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3107.384, "latencies_ms": [3107.384], "images_per_second": 0.322, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman in a white dress and white shoes is playing tennis on a grass court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.077}, "power_stats": {"power_gpu_soc_mean_watts": 23.26, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 81.077}, "timestamp": "2026-01-28T13:11:05.483809"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5921.689, "latencies_ms": [5921.689], "images_per_second": 0.169, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. tennis racket: 1\n2. woman: 1\n3. grass: 1\n4. white: 1\n5. white skirt: 1\n6. white shoes: 1\n7. white visor: 1\n8. white dress: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.18}, "power_stats": {"power_gpu_soc_mean_watts": 18.456, "power_cpu_cv_mean_watts": 2.09, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 70.18}, "timestamp": "2026-01-28T13:11:13.450523"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4847.528, "latencies_ms": [4847.528], "images_per_second": 0.206, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the tennis net and grass court in the background. The player is reaching up with her racket, indicating she is in the process of serving the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.375}, "power_stats": {"power_gpu_soc_mean_watts": 19.917, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 73.375}, "timestamp": "2026-01-28T13:11:20.327787"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2965.476, "latencies_ms": [2965.476], "images_per_second": 0.337, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman in a white dress is playing tennis on a grass court.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.792}, "power_stats": {"power_gpu_soc_mean_watts": 23.159, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 80.792}, "timestamp": "2026-01-28T13:11:25.307550"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3572.463, "latencies_ms": [3572.463], "images_per_second": 0.28, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The tennis player is wearing a white outfit and white shoes, and the grass on the tennis court is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.379}, "power_stats": {"power_gpu_soc_mean_watts": 21.919, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 76.379}, "timestamp": "2026-01-28T13:11:30.898149"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3795.043, "latencies_ms": [3795.043], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white toilet, a bathtub with a shower curtain, and a wire shelf with folded towels.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12588.0, "ram_available_mb": 50252.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.677}, "power_stats": {"power_gpu_soc_mean_watts": 21.551, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 76.677}, "timestamp": "2026-01-28T13:11:36.750647"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6206.804, "latencies_ms": [6206.804], "images_per_second": 0.161, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Shower curtain: 1\n3. Towel: 1\n4. Bathtub: 1\n5. Sink: 1\n6. Shower rod: 1\n7. Towel rack: 1\n8. Shelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.0, "ram_available_mb": 50252.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.346}, "power_stats": {"power_gpu_soc_mean_watts": 18.447, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 71.346}, "timestamp": "2026-01-28T13:11:44.975810"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4679.385, "latencies_ms": [4679.385], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the shower curtain is on the right side. The closet is positioned in the background, and the towel is hanging on the wall above the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.795}, "power_stats": {"power_gpu_soc_mean_watts": 19.964, "power_cpu_cv_mean_watts": 2.249, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 72.795}, "timestamp": "2026-01-28T13:11:51.691516"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3023.121, "latencies_ms": [3023.121], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A bathroom with a toilet, bathtub, and shower curtain is shown.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.8}, "power_stats": {"power_gpu_soc_mean_watts": 23.116, "power_cpu_cv_mean_watts": 2.403, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 79.8}, "timestamp": "2026-01-28T13:11:56.734241"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2893.166, "latencies_ms": [2893.166], "images_per_second": 0.346, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The bathroom is painted yellow, and the toilet is white.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.652}, "power_stats": {"power_gpu_soc_mean_watts": 23.735, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 77.652}, "timestamp": "2026-01-28T13:12:01.642388"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3213.543, "latencies_ms": [3213.543], "images_per_second": 0.311, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two men are standing in a room, holding wine glasses, and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.231}, "power_stats": {"power_gpu_soc_mean_watts": 22.996, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 78.231}, "timestamp": "2026-01-28T13:12:06.889691"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5526.778, "latencies_ms": [5526.778], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. glasses: 2\n2. wine: 1\n3. man: 2\n4. woman: 1\n5. shirt: 2\n6. table: 1\n7. chair: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.152}, "power_stats": {"power_gpu_soc_mean_watts": 18.946, "power_cpu_cv_mean_watts": 2.115, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 71.152}, "timestamp": "2026-01-28T13:12:14.444090"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5891.434, "latencies_ms": [5891.434], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The two men are standing close to each other, with the man on the left holding a glass of red wine and the man on the right holding a glass of white wine. The man on the left is positioned slightly in front of the man on the right, and the glasses are held in front of their faces.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.918}, "power_stats": {"power_gpu_soc_mean_watts": 18.706, "power_cpu_cv_mean_watts": 2.182, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 72.918}, "timestamp": "2026-01-28T13:12:22.360863"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3288.57, "latencies_ms": [3288.57], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two men are standing in a room with wine glasses in their hands, smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.593}, "power_stats": {"power_gpu_soc_mean_watts": 22.872, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.823, "gpu_utilization_percent_mean": 76.593}, "timestamp": "2026-01-28T13:12:27.694023"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4288.036, "latencies_ms": [4288.036], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming in from the windows. The colors in the image are vibrant and the materials are mostly wooden and glass.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.543}, "power_stats": {"power_gpu_soc_mean_watts": 20.834, "power_cpu_cv_mean_watts": 1.956, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 73.543}, "timestamp": "2026-01-28T13:12:34.011133"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3385.666, "latencies_ms": [3385.666], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, with a beach and clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.573, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 77.893}, "timestamp": "2026-01-28T13:12:39.449930"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5660.318, "latencies_ms": [5660.318], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. surfboard: 1\n3. wave: 1\n4. ocean: 1\n5. beach: 1\n6. sky: 1\n7. sand: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.271}, "power_stats": {"power_gpu_soc_mean_watts": 19.072, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.271}, "timestamp": "2026-01-28T13:12:47.153986"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4430.562, "latencies_ms": [4430.562], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the middle ground, with the beach and sky visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.632, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 75.324}, "timestamp": "2026-01-28T13:12:53.615776"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3443.929, "latencies_ms": [3443.929], "images_per_second": 0.29, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, with a beach and palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.75}, "power_stats": {"power_gpu_soc_mean_watts": 22.5, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 75.75}, "timestamp": "2026-01-28T13:12:59.076535"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5357.197, "latencies_ms": [5357.197], "images_per_second": 0.187, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a surfer riding a wave with a vibrant blue and green color palette, with the sun shining brightly in the background. The surfer is wearing a black wetsuit and is positioned on a white surfboard, skillfully navigating the wave.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.356}, "power_stats": {"power_gpu_soc_mean_watts": 18.94, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.67, "gpu_utilization_percent_mean": 73.356}, "timestamp": "2026-01-28T13:13:06.469141"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3580.184, "latencies_ms": [3580.184], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A collection of laptops, tablets, and a backpack are scattered on the floor, with cables strewn about.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.276}, "power_stats": {"power_gpu_soc_mean_watts": 21.807, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 79.276}, "timestamp": "2026-01-28T13:13:12.102755"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6215.072, "latencies_ms": [6215.072], "images_per_second": 0.161, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. black laptop: 3\n2. red and black backpack: 1\n3. black laptop: 2\n4. black tablet: 1\n5. black monitor: 2\n6. black keyboard: 1\n7. black mouse: 1\n8. black mousepad: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.808}, "power_stats": {"power_gpu_soc_mean_watts": 18.239, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 70.808}, "timestamp": "2026-01-28T13:13:20.353566"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3724.474, "latencies_ms": [3724.474], "images_per_second": 0.268, "prompt_tokens": 1117, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The backpack is located to the left of the laptop, the cables are in the middle, and the laptop is on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.757, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 75.71}, "timestamp": "2026-01-28T13:13:26.117946"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3189.526, "latencies_ms": [3189.526], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A collection of laptops and a backpack are scattered on the floor in a room.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.308}, "power_stats": {"power_gpu_soc_mean_watts": 22.78, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 81.308}, "timestamp": "2026-01-28T13:13:31.351311"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4927.924, "latencies_ms": [4927.924], "images_per_second": 0.203, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image is taken in a room with a carpeted floor and a white wall. The lighting is natural, coming from a window out of frame. The objects in the image are made of metal, plastic, and fabric.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.623, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 73.195}, "timestamp": "2026-01-28T13:13:38.320336"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4309.516, "latencies_ms": [4309.516], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A skier in a vibrant red and green suit is captured mid-air, performing a jump on a snowy mountain, while a second skier stands in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.619, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 75.657}, "timestamp": "2026-01-28T13:13:44.667621"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6540.47, "latencies_ms": [6540.47], "images_per_second": 0.153, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. skier: 1\n2. skis: 2\n3. poles: 2\n4. snowboard: 1\n5. skier's helmet: 1\n6. skier's goggles: 1\n7. skier's gloves: 1\n8. skier's pants: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.87}, "power_stats": {"power_gpu_soc_mean_watts": 18.076, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 69.87}, "timestamp": "2026-01-28T13:13:53.223604"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4934.637, "latencies_ms": [4934.637], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The skier is in the foreground, with the snowboarder in the background. The skier is to the left of the snowboarder. The skier is closer to the camera than the snowboarder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.628, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 74.341}, "timestamp": "2026-01-28T13:14:00.213013"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4495.279, "latencies_ms": [4495.279], "images_per_second": 0.222, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A skier in a vibrant orange and green suit is captured mid-air, performing a jump on a snowy mountain. In the background, another skier is seen walking on the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.595}, "power_stats": {"power_gpu_soc_mean_watts": 20.338, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 72.595}, "timestamp": "2026-01-28T13:14:06.724205"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4206.318, "latencies_ms": [4206.318], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The skier is wearing a vibrant red and green outfit, and the snow is a pristine white. The sun is shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.686}, "power_stats": {"power_gpu_soc_mean_watts": 20.834, "power_cpu_cv_mean_watts": 1.727, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 73.686}, "timestamp": "2026-01-28T13:14:12.968037"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3243.028, "latencies_ms": [3243.028], "images_per_second": 0.308, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird is standing on the edge of a boat window, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.926}, "power_stats": {"power_gpu_soc_mean_watts": 22.666, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 79.926}, "timestamp": "2026-01-28T13:14:18.260553"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6285.131, "latencies_ms": [6285.131], "images_per_second": 0.159, "prompt_tokens": 1114, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. Bird: 1\n2. Window: 1\n3. Bird's beak: 1\n4. Bird's eye: 1\n5. Bird's legs: 1\n6. Bird's feet: 1\n7. Bird's wing: 1\n8. Bird's tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.1, "ram_available_mb": 50252.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.481}, "power_stats": {"power_gpu_soc_mean_watts": 18.541, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 72.481}, "timestamp": "2026-01-28T13:14:26.562287"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4154.208, "latencies_ms": [4154.208], "images_per_second": 0.241, "prompt_tokens": 1118, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The bird is positioned in the foreground, looking out of the window, while the door is located in the background. The bird is closer to the camera than the door.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.257}, "power_stats": {"power_gpu_soc_mean_watts": 21.114, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 77.257}, "timestamp": "2026-01-28T13:14:32.760856"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3156.168, "latencies_ms": [3156.168], "images_per_second": 0.317, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird is standing on the edge of a boat window, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.769}, "power_stats": {"power_gpu_soc_mean_watts": 22.844, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 79.769}, "timestamp": "2026-01-28T13:14:37.959945"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5797.561, "latencies_ms": [5797.561], "images_per_second": 0.172, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a bird perched on a window sill, with a view of a body of water in the background. The bird is black, and the window sill is made of wood. The lighting in the image is natural, coming from the outside, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12588.3, "ram_available_mb": 50252.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12588.0, "ram_available_mb": 50252.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.375}, "power_stats": {"power_gpu_soc_mean_watts": 18.972, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 72.375}, "timestamp": "2026-01-28T13:14:45.778099"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3807.933, "latencies_ms": [3807.933], "images_per_second": 0.263, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " Two men are cleaning a bathroom with a bucket and a mop, and there is a black trash can with a white cloth on it.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12588.0, "ram_available_mb": 50252.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.719}, "power_stats": {"power_gpu_soc_mean_watts": 21.524, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 75.719}, "timestamp": "2026-01-28T13:14:51.619121"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4540.09, "latencies_ms": [4540.09], "images_per_second": 0.22, "prompt_tokens": 1114, "response_tokens_est": 41, "n_tiles": 1, "output_text": " toilet: 1, trash can: 1, broom: 1, bucket: 1, shelf: 1, person: 2, bottle: 1, trash bag: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.395}, "power_stats": {"power_gpu_soc_mean_watts": 20.448, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 74.395}, "timestamp": "2026-01-28T13:14:58.183892"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4983.558, "latencies_ms": [4983.558], "images_per_second": 0.201, "prompt_tokens": 1118, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The man in the orange hat is standing to the left of the toilet, while the man in the gray shirt is standing to the right of the toilet. The trash can is located in the foreground, while the bucket is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.214}, "power_stats": {"power_gpu_soc_mean_watts": 19.718, "power_cpu_cv_mean_watts": 2.05, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 73.214}, "timestamp": "2026-01-28T13:15:05.181518"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2858.23, "latencies_ms": [2858.23], "images_per_second": 0.35, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Two men are cleaning a bathroom with a bucket and mop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.277, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 7.851, "gpu_utilization_percent_mean": 84.042}, "timestamp": "2026-01-28T13:15:10.077982"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3365.719, "latencies_ms": [3365.719], "images_per_second": 0.297, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is dimly lit with a blue tint, and the floor is covered in blue paint.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.411, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 78.714}, "timestamp": "2026-01-28T13:15:15.472291"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4602.005, "latencies_ms": [4602.005], "images_per_second": 0.217, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the image, a person is seen walking down a hallway, holding an umbrella with the words \"Pour moi\" written on it, as rain pours down around them.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.333}, "power_stats": {"power_gpu_soc_mean_watts": 19.654, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 7.672, "gpu_utilization_percent_mean": 72.333}, "timestamp": "2026-01-28T13:15:22.127530"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5511.595, "latencies_ms": [5511.595], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. umbrella: 1\n3. door: 1\n4. wall: 2\n5. window: 1\n6. floor: 1\n7. light: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.66}, "power_stats": {"power_gpu_soc_mean_watts": 19.027, "power_cpu_cv_mean_watts": 1.899, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 72.66}, "timestamp": "2026-01-28T13:15:29.680962"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3998.966, "latencies_ms": [3998.966], "images_per_second": 0.25, "prompt_tokens": 1118, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, holding the umbrella in the middle of the image, and the door is located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.485}, "power_stats": {"power_gpu_soc_mean_watts": 21.368, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 74.485}, "timestamp": "2026-01-28T13:15:35.717656"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3600.59, "latencies_ms": [3600.59], "images_per_second": 0.278, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A person is walking down a hallway with a blue umbrella that has the words \"God's mood\" written on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.729, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 77.5}, "timestamp": "2026-01-28T13:15:41.367806"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5149.835, "latencies_ms": [5149.835], "images_per_second": 0.194, "prompt_tokens": 1110, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a person holding an umbrella with the words \"God's mood\" written on it, walking down a hallway with red walls and a white door. The lighting is dim, and the rain is falling outside, creating a gloomy atmosphere.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.349}, "power_stats": {"power_gpu_soc_mean_watts": 19.364, "power_cpu_cv_mean_watts": 2.561, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 73.349}, "timestamp": "2026-01-28T13:15:48.545995"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4405.142, "latencies_ms": [4405.142], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man wearing a red shirt and blue jeans is walking on a path in the woods, holding a walking stick, while another man in a yellow jacket stands on a bridge in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.216}, "power_stats": {"power_gpu_soc_mean_watts": 20.481, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 73.216}, "timestamp": "2026-01-28T13:15:55.011299"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6193.858, "latencies_ms": [6193.858], "images_per_second": 0.161, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. man: 1\n2. backpack: 1\n3. walking stick: 1\n4. man's legs: 1\n5. man's feet: 1\n6. man's hands: 1\n7. man's head: 1\n8. man's face: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.115}, "power_stats": {"power_gpu_soc_mean_watts": 18.194, "power_cpu_cv_mean_watts": 2.033, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 70.115}, "timestamp": "2026-01-28T13:16:03.262223"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5397.765, "latencies_ms": [5397.765], "images_per_second": 0.185, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, with the signpost in the middle and the other man on the right side. The man is in the foreground, while the signpost is in the middle ground, and the other man is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.435}, "power_stats": {"power_gpu_soc_mean_watts": 19.196, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 73.435}, "timestamp": "2026-01-28T13:16:10.691897"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3825.826, "latencies_ms": [3825.826], "images_per_second": 0.261, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man wearing a red shirt and blue jeans is walking on a path in the woods, carrying a backpack and holding a walking stick.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.341, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-28T13:16:16.543921"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4740.848, "latencies_ms": [4740.848], "images_per_second": 0.211, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a man wearing a red shirt and blue jeans, with a backpack on his back, standing on a rocky path in a forest. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.966, "power_cpu_cv_mean_watts": 2.182, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 73.95}, "timestamp": "2026-01-28T13:16:23.308932"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3942.05, "latencies_ms": [3942.05], "images_per_second": 0.254, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Five men are standing together in a room with a red chair and a table with wine bottles.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.719}, "power_stats": {"power_gpu_soc_mean_watts": 24.207, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 8.138, "gpu_utilization_percent_mean": 80.719}, "timestamp": "2026-01-28T13:16:29.294690"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6242.441, "latencies_ms": [6242.441], "images_per_second": 0.16, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. chair: 2\n2. man: 5\n3. bottle: 1\n4. wall: 1\n5. table: 1\n6. ring: 1\n7. tie: 1\n8. suit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.442}, "power_stats": {"power_gpu_soc_mean_watts": 20.86, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 74.442}, "timestamp": "2026-01-28T13:16:37.554038"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6338.346, "latencies_ms": [6338.346], "images_per_second": 0.158, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man in the middle is standing between the two men on the left and the two men on the right. The man on the left is standing closer to the camera than the man on the right. The man on the right is standing closer to the camera than the man on the left.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.962}, "power_stats": {"power_gpu_soc_mean_watts": 20.948, "power_cpu_cv_mean_watts": 1.723, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 75.962}, "timestamp": "2026-01-28T13:16:45.915711"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3587.987, "latencies_ms": [3587.987], "images_per_second": 0.279, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Five men are standing in a room with chairs and a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.767}, "power_stats": {"power_gpu_soc_mean_watts": 25.389, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.18, "gpu_utilization_percent_mean": 86.767}, "timestamp": "2026-01-28T13:16:51.536402"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4265.888, "latencies_ms": [4265.888], "images_per_second": 0.234, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well lit with natural light coming from the windows. The chairs are red and the walls are white.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.086}, "power_stats": {"power_gpu_soc_mean_watts": 23.995, "power_cpu_cv_mean_watts": 1.258, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 82.086}, "timestamp": "2026-01-28T13:16:57.825393"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6733.65, "latencies_ms": [6733.65], "images_per_second": 0.149, "prompt_tokens": 1100, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The image captures a bustling street corner in a city, where a yellow traffic signal is mounted on a black pole, standing out against the backdrop of a red traffic light and a blue bus. The street is lined with buildings, their facades adorned with various signs and advertisements, adding to the urban atmosphere. The sky overhead is overcast, casting a soft light over the scene.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.259}, "power_stats": {"power_gpu_soc_mean_watts": 17.878, "power_cpu_cv_mean_watts": 2.023, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.259}, "timestamp": "2026-01-28T13:17:06.593069"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4588.691, "latencies_ms": [4588.691], "images_per_second": 0.218, "prompt_tokens": 1114, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. black pole\n2. yellow sign\n3. black box\n4. traffic light\n5. street lamp\n6. brick building\n7. blue bus\n8. white car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.947}, "power_stats": {"power_gpu_soc_mean_watts": 20.152, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 71.947}, "timestamp": "2026-01-28T13:17:13.225368"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4774.353, "latencies_ms": [4774.353], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The yellow sign is positioned to the right of the black pole, which is situated in the foreground of the image. In the background, there are several cars and buildings, with the traffic light positioned above the sign.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.825}, "power_stats": {"power_gpu_soc_mean_watts": 19.915, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 73.825}, "timestamp": "2026-01-28T13:17:20.059815"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5594.513, "latencies_ms": [5594.513], "images_per_second": 0.179, "prompt_tokens": 1112, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, where a yellow traffic signal stands out against the backdrop of a red bus and a blue car. The street is lined with buildings, their facades adorned with various signs and advertisements, and the sky overhead is a canvas of overcast clouds.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.362}, "power_stats": {"power_gpu_soc_mean_watts": 18.834, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 72.362}, "timestamp": "2026-01-28T13:17:27.711649"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4315.887, "latencies_ms": [4315.887], "images_per_second": 0.232, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a street corner with a yellow traffic signal, a black pole, and a black box. The sky is cloudy, and the street is wet, suggesting recent rain.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.691, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-28T13:17:34.060143"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3860.758, "latencies_ms": [3860.758], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man is playing tennis on a court at night, wearing a white shirt and black shorts, and holding a red and black tennis racket.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12586.0, "ram_available_mb": 50254.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.969}, "power_stats": {"power_gpu_soc_mean_watts": 21.55, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 72.969}, "timestamp": "2026-01-28T13:17:39.951670"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5800.601, "latencies_ms": [5800.601], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. fence: 1\n5. sign: 1\n6. net: 1\n7. court: 1\n8. ball boy: 0", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.0, "ram_available_mb": 50254.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12586.0, "ram_available_mb": 50254.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.878}, "power_stats": {"power_gpu_soc_mean_watts": 18.506, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 69.878}, "timestamp": "2026-01-28T13:17:47.776451"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4960.895, "latencies_ms": [4960.895], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main object, the tennis player, is in the foreground of the image, with the tennis court and fence in the background. The player is positioned to the left of the image, while the fence is to the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12586.0, "ram_available_mb": 50254.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.664, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 75.244}, "timestamp": "2026-01-28T13:17:54.771405"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2849.526, "latencies_ms": [2849.526], "images_per_second": 0.351, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is playing tennis on a court at night.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.609}, "power_stats": {"power_gpu_soc_mean_watts": 23.559, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 82.609}, "timestamp": "2026-01-28T13:17:59.654862"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5315.362, "latencies_ms": [5315.362], "images_per_second": 0.188, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a tennis court bathed in the soft glow of artificial lighting. The court, a vibrant shade of green, contrasts sharply with the red clay surface, while the surrounding fence and advertisements add a touch of urbanity to the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.066, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 71.244}, "timestamp": "2026-01-28T13:18:07.032681"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4676.896, "latencies_ms": [4676.896], "images_per_second": 0.214, "prompt_tokens": 1432, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A group of people, including a man in a black jacket and a woman in a white helmet, are standing near a blue fence on a snowy day.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.846}, "power_stats": {"power_gpu_soc_mean_watts": 22.543, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 76.846}, "timestamp": "2026-01-28T13:18:13.749484"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6366.716, "latencies_ms": [6366.716], "images_per_second": 0.157, "prompt_tokens": 1446, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skis: 4\n2. skiers: 4\n3. helmet: 4\n4. goggles: 4\n5. gloves: 4\n6. ski poles: 4\n7. net: 1\n8. fence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.593}, "power_stats": {"power_gpu_soc_mean_watts": 20.967, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 76.593}, "timestamp": "2026-01-28T13:18:22.141603"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6017.322, "latencies_ms": [6017.322], "images_per_second": 0.166, "prompt_tokens": 1450, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The skier in the white helmet and goggles is positioned in the foreground, while the skier in the black jacket is in the background. The skier in the white helmet and goggles is standing closer to the camera than the skier in the black jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.38}, "power_stats": {"power_gpu_soc_mean_watts": 21.182, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 76.38}, "timestamp": "2026-01-28T13:18:30.176801"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4459.858, "latencies_ms": [4459.858], "images_per_second": 0.224, "prompt_tokens": 1444, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A group of people are standing on a snowy slope, some of them wearing helmets and goggles, and they are talking to each other.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.27}, "power_stats": {"power_gpu_soc_mean_watts": 23.48, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 81.27}, "timestamp": "2026-01-28T13:18:36.672803"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6956.021, "latencies_ms": [6956.021], "images_per_second": 0.144, "prompt_tokens": 1442, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image captures a lively scene on a snowy mountain where a group of skiers and snowboarders are gathered. The skiers are clad in vibrant winter gear, including helmets and goggles, while the snowboarders sport colorful attire. The sky is a clear blue, and the sun casts a bright glow on the snow-covered landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.312, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-28T13:18:45.665447"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4098.139, "latencies_ms": [4098.139], "images_per_second": 0.244, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A blue truck with the text \"HUISMANGROUP.COM\" on the front is driving down a wet road with houses and trees on either side.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.029}, "power_stats": {"power_gpu_soc_mean_watts": 21.075, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 75.029}, "timestamp": "2026-01-28T13:18:51.803995"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4253.089, "latencies_ms": [4253.089], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " 1. blue truck\n2. road\n3. street\n4. sidewalk\n5. grass\n6. trees\n7. houses\n8. street lamp", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12585.9, "ram_available_mb": 50255.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.801, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 74.229}, "timestamp": "2026-01-28T13:18:58.075996"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4199.711, "latencies_ms": [4199.711], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The blue truck is on the left side of the road, while the white car is on the right side. The truck is closer to the camera than the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12585.9, "ram_available_mb": 50255.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.914}, "power_stats": {"power_gpu_soc_mean_watts": 20.989, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 73.914}, "timestamp": "2026-01-28T13:19:04.316462"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3049.727, "latencies_ms": [3049.727], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A blue truck is driving down a wet road in a residential area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.458}, "power_stats": {"power_gpu_soc_mean_watts": 23.612, "power_cpu_cv_mean_watts": 1.268, "power_sys_5v0_mean_watts": 7.846, "gpu_utilization_percent_mean": 77.458}, "timestamp": "2026-01-28T13:19:09.385943"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3035.016, "latencies_ms": [3035.016], "images_per_second": 0.329, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The truck is blue and the road is wet, indicating recent rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.07, "power_cpu_cv_mean_watts": 1.233, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 77.52}, "timestamp": "2026-01-28T13:19:14.472077"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4321.055, "latencies_ms": [4321.055], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a large commercial airplane is taxiing on a wet runway, with a clear view of the runway and surrounding landscape, including distant mountains and a hazy sky.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.882, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 74.639}, "timestamp": "2026-01-28T13:19:20.830189"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3506.042, "latencies_ms": [3506.042], "images_per_second": 0.285, "prompt_tokens": 1113, "response_tokens_est": 22, "n_tiles": 1, "output_text": " airplane: 1\nrunway: 1\nlight poles: 4\nmountains: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.247, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.784, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-28T13:19:26.392006"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4819.77, "latencies_ms": [4819.77], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The airplane is in the foreground, with the runway extending into the background. The runway is surrounded by a variety of objects, including lights, poles, and vegetation, which are positioned at different distances from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.225}, "power_stats": {"power_gpu_soc_mean_watts": 19.828, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 75.225}, "timestamp": "2026-01-28T13:19:33.268726"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3268.028, "latencies_ms": [3268.028], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " An airplane is on the runway, and there are lights on the side of the runway.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.556}, "power_stats": {"power_gpu_soc_mean_watts": 22.534, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 79.556}, "timestamp": "2026-01-28T13:19:38.551928"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4530.448, "latencies_ms": [4530.448], "images_per_second": 0.221, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a large airplane on a runway with a hazy sky in the background. The airplane is white with blue and red stripes, and the runway is wet, reflecting the light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.1, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 74.342}, "timestamp": "2026-01-28T13:19:45.120054"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3824.186, "latencies_ms": [3824.186], "images_per_second": 0.261, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A woman in an orange shirt is holding a tennis racket in the air while a man in a black jacket stands next to her.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.677}, "power_stats": {"power_gpu_soc_mean_watts": 21.797, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 74.677}, "timestamp": "2026-01-28T13:19:50.984532"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5954.122, "latencies_ms": [5954.122], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. flag: 2\n2. beach: 1\n3. mountain: 1\n4. people: 10\n5. beach umbrella: 1\n6. beach chair: 1\n7. beach ball: 1\n8. beach ball net: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.96}, "power_stats": {"power_gpu_soc_mean_watts": 18.562, "power_cpu_cv_mean_watts": 1.962, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 71.96}, "timestamp": "2026-01-28T13:19:58.963161"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5092.361, "latencies_ms": [5092.361], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The person in the foreground is holding a tennis racket, while the person in the background is walking away from the camera. The person in the foreground is standing on the beach, while the person in the background is walking on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.048}, "power_stats": {"power_gpu_soc_mean_watts": 19.35, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.048}, "timestamp": "2026-01-28T13:20:06.089468"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3904.721, "latencies_ms": [3904.721], "images_per_second": 0.256, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A group of people are on a beach with mountains in the background. One person is holding a tennis racket and another is holding a bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.337, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-28T13:20:12.042536"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3957.82, "latencies_ms": [3957.82], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image is taken during the day with clear skies and the sun shining brightly. The sand is light beige and the sky is a light blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.314, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 76.273}, "timestamp": "2026-01-28T13:20:18.027159"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3543.416, "latencies_ms": [3543.416], "images_per_second": 0.282, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A tennis player is standing on a blue tennis court, holding a tennis racket and looking down at the ground.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12586.4, "ram_available_mb": 50254.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12585.9, "ram_available_mb": 50255.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.113, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 78.379}, "timestamp": "2026-01-28T13:20:23.590797"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5906.405, "latencies_ms": [5906.405], "images_per_second": 0.169, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. tennis shoes: 2\n5. shorts: 1\n6. shirt: 1\n7. headband: 1\n8. wristband: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12585.9, "ram_available_mb": 50255.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12585.8, "ram_available_mb": 50255.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.041}, "power_stats": {"power_gpu_soc_mean_watts": 18.53, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 70.041}, "timestamp": "2026-01-28T13:20:31.526906"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5651.293, "latencies_ms": [5651.293], "images_per_second": 0.177, "prompt_tokens": 1118, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis court taking up the majority of the space in the background. The player is standing near the center of the court, with the shadow of the player and the court extending towards the bottom right corner of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12585.8, "ram_available_mb": 50255.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12585.8, "ram_available_mb": 50255.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.896}, "power_stats": {"power_gpu_soc_mean_watts": 18.783, "power_cpu_cv_mean_watts": 1.852, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 71.896}, "timestamp": "2026-01-28T13:20:39.189882"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4169.214, "latencies_ms": [4169.214], "images_per_second": 0.24, "prompt_tokens": 1112, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A tennis player is standing on a blue court with a white line on it. He is holding a tennis racket and appears to be wiping his face with his hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12585.8, "ram_available_mb": 50255.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12585.8, "ram_available_mb": 50255.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.088}, "power_stats": {"power_gpu_soc_mean_watts": 20.829, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 72.088}, "timestamp": "2026-01-28T13:20:45.410278"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3830.338, "latencies_ms": [3830.338], "images_per_second": 0.261, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The tennis player is wearing a blue shirt and white shorts, and the court is blue. The lighting is bright and the shadows are long.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12585.8, "ram_available_mb": 50255.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.406}, "power_stats": {"power_gpu_soc_mean_watts": 21.441, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 75.406}, "timestamp": "2026-01-28T13:20:51.294098"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5636.028, "latencies_ms": [5636.028], "images_per_second": 0.177, "prompt_tokens": 1100, "response_tokens_est": 58, "n_tiles": 1, "output_text": " In the image, a woman in a pink and white floral dress and beige shorts is standing in a kitchen, leaning over a black stove with a large black chimney above it. The kitchen is filled with various objects, including a blue kettle, a white bowl, and a wooden spoon.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12586.2, "ram_available_mb": 50254.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12586.1, "ram_available_mb": 50254.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.34}, "power_stats": {"power_gpu_soc_mean_watts": 18.834, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 72.34}, "timestamp": "2026-01-28T13:20:58.983763"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5624.658, "latencies_ms": [5624.658], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. stove: 1\n3. cupboard: 1\n4. shelf: 1\n5. kettle: 1\n6. pan: 1\n7. dish: 1\n8. cup: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.1, "ram_available_mb": 50254.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.792}, "power_stats": {"power_gpu_soc_mean_watts": 18.675, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 71.792}, "timestamp": "2026-01-28T13:21:06.657380"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4755.248, "latencies_ms": [4755.248], "images_per_second": 0.21, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The woman is standing to the left of the stove, which is located in the center of the image. The stove is positioned in the foreground, with the woman's body and the kitchen counter in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.175}, "power_stats": {"power_gpu_soc_mean_watts": 19.737, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 72.175}, "timestamp": "2026-01-28T13:21:13.432825"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3148.776, "latencies_ms": [3148.776], "images_per_second": 0.318, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is standing in a kitchen with a large stove and a black chimney.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.885}, "power_stats": {"power_gpu_soc_mean_watts": 22.338, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 79.885}, "timestamp": "2026-01-28T13:21:18.615476"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6381.861, "latencies_ms": [6381.861], "images_per_second": 0.157, "prompt_tokens": 1110, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image is a black and white photo with a vintage feel, capturing a moment in time in a kitchen with a large black stove and a woman in a floral shirt. The lighting is soft and diffused, creating a warm atmosphere. The materials used in the kitchen are traditional, with wood and metal elements adding to the rustic charm.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.547}, "power_stats": {"power_gpu_soc_mean_watts": 17.965, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.689, "gpu_utilization_percent_mean": 71.547}, "timestamp": "2026-01-28T13:21:27.020298"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3905.532, "latencies_ms": [3905.532], "images_per_second": 0.256, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two giraffes are standing next to each other in a zoo enclosure with a building in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.375}, "power_stats": {"power_gpu_soc_mean_watts": 24.222, "power_cpu_cv_mean_watts": 1.226, "power_sys_5v0_mean_watts": 8.154, "gpu_utilization_percent_mean": 81.375}, "timestamp": "2026-01-28T13:21:32.956952"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6287.758, "latencies_ms": [6287.758], "images_per_second": 0.159, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. giraffe: 2\n2. giraffe: 2\n3. giraffe: 2\n4. giraffe: 2\n5. giraffe: 2\n6. giraffe: 2\n7. giraffe: 2\n8. giraffe: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.113}, "power_stats": {"power_gpu_soc_mean_watts": 20.719, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 7.954, "gpu_utilization_percent_mean": 75.113}, "timestamp": "2026-01-28T13:21:41.270830"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5215.418, "latencies_ms": [5215.418], "images_per_second": 0.192, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The giraffes are positioned in the foreground of the image, with the building serving as the background. The giraffes are standing on a rocky terrain, which is situated in the middle ground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.628}, "power_stats": {"power_gpu_soc_mean_watts": 22.25, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 78.628}, "timestamp": "2026-01-28T13:21:48.502838"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4272.352, "latencies_ms": [4272.352], "images_per_second": 0.234, "prompt_tokens": 1444, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two giraffes are standing on a rocky ground in a zoo enclosure, with a building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12588.4, "ram_available_mb": 50252.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.657}, "power_stats": {"power_gpu_soc_mean_watts": 23.686, "power_cpu_cv_mean_watts": 1.224, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 80.657}, "timestamp": "2026-01-28T13:21:54.812120"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3746.637, "latencies_ms": [3746.637], "images_per_second": 0.267, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The giraffes are brown and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.161}, "power_stats": {"power_gpu_soc_mean_watts": 24.311, "power_cpu_cv_mean_watts": 1.085, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 85.161}, "timestamp": "2026-01-28T13:22:00.593110"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3546.198, "latencies_ms": [3546.198], "images_per_second": 0.282, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young boy wearing a green and yellow baseball uniform is swinging a blue and white baseball bat at a baseball.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 12587.5, "ram_available_mb": 50253.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.069}, "power_stats": {"power_gpu_soc_mean_watts": 22.097, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 79.069}, "timestamp": "2026-01-28T13:22:06.184844"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6201.703, "latencies_ms": [6201.703], "images_per_second": 0.161, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. boy: 1\n2. helmet: 1\n3. bat: 1\n4. ball: 1\n5. chain link fence: 1\n6. chain link fence post: 1\n7. chain link fence mesh: 1\n8. chain link fence fence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.558}, "power_stats": {"power_gpu_soc_mean_watts": 18.217, "power_cpu_cv_mean_watts": 2.141, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 69.558}, "timestamp": "2026-01-28T13:22:14.407083"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5209.907, "latencies_ms": [5209.907], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The baseball player is positioned in the foreground of the image, with the chain link fence and grassy field in the background. The baseball is located near the player, in the air, and the bat is held by the player, positioned in the foreground.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12586.5, "ram_available_mb": 50254.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.814}, "power_stats": {"power_gpu_soc_mean_watts": 19.298, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 71.814}, "timestamp": "2026-01-28T13:22:21.655466"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3186.83, "latencies_ms": [3186.83], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young boy is playing baseball in a field with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.731}, "power_stats": {"power_gpu_soc_mean_watts": 22.828, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 76.731}, "timestamp": "2026-01-28T13:22:26.882748"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6742.102, "latencies_ms": [6742.102], "images_per_second": 0.148, "prompt_tokens": 1109, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image captures a young baseball player in action, wearing a green and yellow uniform, swinging a blue bat at a white baseball. The scene is bathed in bright sunlight, casting a warm glow on the player and the field. The fence in the background is made of chain link, and the grass is a vibrant green, suggesting a well-maintained baseball field.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.125}, "power_stats": {"power_gpu_soc_mean_watts": 17.529, "power_cpu_cv_mean_watts": 2.174, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 70.125}, "timestamp": "2026-01-28T13:22:35.640800"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4948.891, "latencies_ms": [4948.891], "images_per_second": 0.202, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a bustling scene at a historical reenactment event, where vintage cars and motorcycles are parked in a cobblestone plaza, with a crowd of people gathered around, and a red bus parked in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12586.6, "ram_available_mb": 50254.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.537}, "power_stats": {"power_gpu_soc_mean_watts": 19.643, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 71.537}, "timestamp": "2026-01-28T13:22:42.627626"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6346.97, "latencies_ms": [6346.97], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. black car: 2\n2. red bus: 1\n3. black motorcycle: 1\n4. red and white bus: 1\n5. black car: 1\n6. black motorcycle: 1\n7. red and white bus: 1\n8. black car: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.132}, "power_stats": {"power_gpu_soc_mean_watts": 18.031, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.692, "gpu_utilization_percent_mean": 70.132}, "timestamp": "2026-01-28T13:22:51.004739"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4992.799, "latencies_ms": [4992.799], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The red bus is positioned in the background, far from the camera, while the black car is in the foreground, close to the camera. The motorcycles are scattered throughout the scene, with some closer to the foreground and others further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.119}, "power_stats": {"power_gpu_soc_mean_watts": 19.519, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 73.119}, "timestamp": "2026-01-28T13:22:58.053465"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5856.664, "latencies_ms": [5856.664], "images_per_second": 0.171, "prompt_tokens": 1111, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures a bustling scene at a military parade, with vintage cars and motorcycles parked in the foreground, while a crowd of people gathers in the background. The setting appears to be a public square, possibly a park or a town square, with trees and a building visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.46}, "power_stats": {"power_gpu_soc_mean_watts": 18.125, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.655, "gpu_utilization_percent_mean": 68.46}, "timestamp": "2026-01-28T13:23:05.928534"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5105.835, "latencies_ms": [5105.835], "images_per_second": 0.196, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a cobblestone street with a variety of vintage cars and motorcycles parked on the side. The sky is clear and blue, indicating a sunny day. The vehicles are mostly black and silver, with some having red and white accents.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.442}, "power_stats": {"power_gpu_soc_mean_watts": 19.53, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 73.442}, "timestamp": "2026-01-28T13:23:13.071544"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4849.838, "latencies_ms": [4849.838], "images_per_second": 0.206, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a close-up view of two parking meters, one slightly in front of the other, with the sun setting in the background, casting a warm glow and creating a bokeh effect with the city lights.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.854}, "power_stats": {"power_gpu_soc_mean_watts": 19.916, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 72.854}, "timestamp": "2026-01-28T13:23:19.941340"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5915.024, "latencies_ms": [5915.024], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. parking meter: 2\n2. sun: 1\n3. sky: 1\n4. car: 1\n5. window: 1\n6. parking lot: 1\n7. cityscape: 1\n8. parking meter label: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12586.2, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.551}, "power_stats": {"power_gpu_soc_mean_watts": 18.372, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 70.551}, "timestamp": "2026-01-28T13:23:27.889596"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5281.706, "latencies_ms": [5281.706], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The two parking meters are positioned on the left side of the image, with the sun setting in the background, creating a warm and golden glow. The parking meters are in the foreground, with the sun setting in the background, creating a warm and golden glow.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12586.2, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.818}, "power_stats": {"power_gpu_soc_mean_watts": 19.268, "power_cpu_cv_mean_watts": 2.348, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 71.818}, "timestamp": "2026-01-28T13:23:35.215853"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4747.145, "latencies_ms": [4747.145], "images_per_second": 0.211, "prompt_tokens": 1111, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image captures a serene moment at a parking lot during sunset, where two parking meters are prominently displayed in the foreground. The warm glow of the setting sun casts a soft light on the scene, creating a tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.6}, "power_stats": {"power_gpu_soc_mean_watts": 20.143, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 73.6}, "timestamp": "2026-01-28T13:23:41.997923"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5283.821, "latencies_ms": [5283.821], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features two parking meters with a warm sunset in the background, casting a golden glow over the scene. The parking meters are black and have a metallic finish, while the sunset is a vibrant orange and yellow, creating a beautiful contrast with the dark sky.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.956}, "power_stats": {"power_gpu_soc_mean_watts": 19.195, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 73.956}, "timestamp": "2026-01-28T13:23:49.315760"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4253.471, "latencies_ms": [4253.471], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, a couple stands next to a large suitcase with stickers on it, with a building and a sign reading \"Fidelity Investments\" in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.647, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-28T13:23:55.618225"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6438.398, "latencies_ms": [6438.398], "images_per_second": 0.155, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. man: 1\n3. woman: 1\n4. suitcase sticker: 10\n5. suitcase handle: 1\n6. suitcase buckle: 1\n7. suitcase buckle latch: 1\n8. suitcase buckle lock: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.7, "ram_available_mb": 50253.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.259}, "power_stats": {"power_gpu_soc_mean_watts": 18.015, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 71.259}, "timestamp": "2026-01-28T13:24:04.094481"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4341.422, "latencies_ms": [4341.422], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The suitcase is positioned to the left of the couple, who are standing in front of the statue. The suitcase is in the foreground, while the couple is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.725, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 73.222}, "timestamp": "2026-01-28T13:24:10.456312"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5230.7, "latencies_ms": [5230.7], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 52, "n_tiles": 1, "output_text": " In the image, there is a large suitcase with stickers on it, and two people standing next to it. The suitcase is placed on a sidewalk, and there is a building with a sign that says \"Fidelity Investments\" in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.341, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 73.25}, "timestamp": "2026-01-28T13:24:17.741197"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3517.087, "latencies_ms": [3517.087], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The suitcase is brown with white and red stickers, and the couple is standing in front of a statue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.483}, "power_stats": {"power_gpu_soc_mean_watts": 22.081, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 78.483}, "timestamp": "2026-01-28T13:24:23.298981"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4779.544, "latencies_ms": [4779.544], "images_per_second": 0.209, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a close-up view of a plate filled with a variety of cooked food items, including pieces of chicken, mushrooms, and broccoli, all garnished with fresh parsley and sprinkled with black pepper.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12587.2, "ram_available_mb": 50253.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.077}, "power_stats": {"power_gpu_soc_mean_watts": 19.931, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 73.077}, "timestamp": "2026-01-28T13:24:30.109979"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5663.908, "latencies_ms": [5663.908], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. broccoli: 2\n2. mushrooms: 4\n3. garlic: 1\n4. parsley: 1\n5. chicken: 2\n6. sauce: 1\n7. pepper: 1\n8. plate: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.277}, "power_stats": {"power_gpu_soc_mean_watts": 18.634, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 69.277}, "timestamp": "2026-01-28T13:24:37.831421"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4284.933, "latencies_ms": [4284.933], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The mushrooms are located in the foreground, with the broccoli situated in the background. The parsley is sprinkled on top of the mushrooms and broccoli, creating a visually appealing contrast.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.6, "ram_available_mb": 50253.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.744, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 75.886}, "timestamp": "2026-01-28T13:24:44.153287"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4308.672, "latencies_ms": [4308.672], "images_per_second": 0.232, "prompt_tokens": 1111, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, there is a plate of food that includes mushrooms, broccoli, and chicken. The food is arranged in a way that makes it look appetizing and delicious.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12585.3, "ram_available_mb": 50255.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.694}, "power_stats": {"power_gpu_soc_mean_watts": 20.589, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 74.694}, "timestamp": "2026-01-28T13:24:50.494082"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6154.012, "latencies_ms": [6154.012], "images_per_second": 0.162, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a plate of food with a variety of colors, including green broccoli, brown mushrooms, and white chicken. The lighting is bright and natural, highlighting the textures and colors of the food. The plate is made of ceramic and has a glossy finish, reflecting the light and adding to the overall visual appeal of the dish.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12585.3, "ram_available_mb": 50255.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12585.3, "ram_available_mb": 50255.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.731}, "power_stats": {"power_gpu_soc_mean_watts": 18.305, "power_cpu_cv_mean_watts": 1.971, "power_sys_5v0_mean_watts": 7.694, "gpu_utilization_percent_mean": 71.731}, "timestamp": "2026-01-28T13:24:58.675534"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5025.317, "latencies_ms": [5025.317], "images_per_second": 0.199, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce, with a variety of vegetables neatly arranged in baskets and crates, including carrots, leafy greens, and broccoli, all bathed in a soft, natural light that enhances their colors and textures.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12585.3, "ram_available_mb": 50255.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 12585.1, "ram_available_mb": 50255.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.326}, "power_stats": {"power_gpu_soc_mean_watts": 19.539, "power_cpu_cv_mean_watts": 2.58, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 73.326}, "timestamp": "2026-01-28T13:25:05.722988"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5680.419, "latencies_ms": [5680.419], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. carrots: 12\n2. broccoli: 1\n3. kale: 1\n4. lettuce: 1\n5. cauliflower: 1\n6. radishes: 1\n7. onions: 1\n8. celery: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12585.1, "ram_available_mb": 50255.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12585.3, "ram_available_mb": 50255.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.234}, "power_stats": {"power_gpu_soc_mean_watts": 19.01, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 70.234}, "timestamp": "2026-01-28T13:25:13.447619"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4088.049, "latencies_ms": [4088.049], "images_per_second": 0.245, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The carrots are in the foreground, while the broccoli is in the background. The leafy greens are in the middle ground, with the flowers in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12585.3, "ram_available_mb": 50255.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12585.5, "ram_available_mb": 50255.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.026, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 78.382}, "timestamp": "2026-01-28T13:25:19.571370"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4937.483, "latencies_ms": [4937.483], "images_per_second": 0.203, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce at a market stall, with a variety of vegetables and fruits neatly arranged in baskets. The colors and textures of the produce stand out against the dark background, creating a visually appealing scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12585.5, "ram_available_mb": 50255.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12585.5, "ram_available_mb": 50255.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.571}, "power_stats": {"power_gpu_soc_mean_watts": 19.509, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 72.571}, "timestamp": "2026-01-28T13:25:26.553687"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5520.451, "latencies_ms": [5520.451], "images_per_second": 0.181, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a variety of fresh vegetables, including carrots, broccoli, and cauliflower, all displayed in a rustic wooden basket. The lighting is natural and soft, casting a warm glow over the scene, and the vegetables are arranged in a way that highlights their vibrant colors and textures.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12585.5, "ram_available_mb": 50255.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12585.4, "ram_available_mb": 50255.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.239}, "power_stats": {"power_gpu_soc_mean_watts": 18.892, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 73.239}, "timestamp": "2026-01-28T13:25:34.096394"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9104.31, "latencies_ms": [9104.31], "images_per_second": 0.11, "prompt_tokens": 1099, "response_tokens_est": 116, "n_tiles": 1, "output_text": " The image captures a bustling scene inside a donut shop, where a variety of donuts are being meticulously crafted on a conveyor belt. The donuts, in their golden-brown hues, are being expertly handled by a team of workers, who are diligently placing them onto a tray. The shop is well-lit, with a green wall adding a pop of color to the otherwise neutral palette. The workers are dressed in crisp white aprons, adding a professional touch to the scene. The image is taken from a distance, providing a comprehensive view of the shop's operations.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12585.4, "ram_available_mb": 50255.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.218}, "power_stats": {"power_gpu_soc_mean_watts": 16.482, "power_cpu_cv_mean_watts": 2.356, "power_sys_5v0_mean_watts": 7.725, "gpu_utilization_percent_mean": 68.218}, "timestamp": "2026-01-28T13:25:45.245218"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3117.519, "latencies_ms": [3117.519], "images_per_second": 0.321, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " donut: 10\nmachine: 2\nperson: 3", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12586.3, "ram_available_mb": 50254.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.038}, "power_stats": {"power_gpu_soc_mean_watts": 22.964, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 82.038}, "timestamp": "2026-01-28T13:25:50.408521"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3954.228, "latencies_ms": [3954.228], "images_per_second": 0.253, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The donuts are on the left side of the image, the workers are on the right side, and the donut machine is in the middle.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.212}, "power_stats": {"power_gpu_soc_mean_watts": 21.405, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 73.212}, "timestamp": "2026-01-28T13:25:56.376842"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4929.93, "latencies_ms": [4929.93], "images_per_second": 0.203, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a bustling scene inside a donut shop, where a variety of donuts are being prepared on a conveyor belt. The shop is well-lit, with customers visible in the background, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.525}, "power_stats": {"power_gpu_soc_mean_watts": 19.935, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 71.525}, "timestamp": "2026-01-28T13:26:03.326115"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4377.714, "latencies_ms": [4377.714], "images_per_second": 0.228, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken during the day with natural light illuminating the scene. The colors in the image are vibrant, with the doughnuts being a light brown color and the metal equipment being silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.793, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 73.861}, "timestamp": "2026-01-28T13:26:09.726087"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3681.953, "latencies_ms": [3681.953], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man in a green jacket and white sneakers is bending down to pick up an orange frisbee in a forest.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.935, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-28T13:26:15.431862"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5657.855, "latencies_ms": [5657.855], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. tree: 1\n3. frisbee: 2\n4. ground: 1\n5. leaves: 1\n6. sticks: 1\n7. tree trunk: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 12586.7, "ram_available_mb": 50254.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12586.9, "ram_available_mb": 50254.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.083}, "power_stats": {"power_gpu_soc_mean_watts": 18.839, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 71.083}, "timestamp": "2026-01-28T13:26:23.147303"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4166.136, "latencies_ms": [4166.136], "images_per_second": 0.24, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The man is standing in the middle of the image, with the trees forming the background. The orange frisbee is in the foreground, close to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12586.8, "ram_available_mb": 50254.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.894, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 77.657}, "timestamp": "2026-01-28T13:26:29.351374"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3039.917, "latencies_ms": [3039.917], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man in a green jacket is playing frisbee in a forest.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.355, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 78.16}, "timestamp": "2026-01-28T13:26:34.439053"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3844.285, "latencies_ms": [3844.285], "images_per_second": 0.26, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a person in a green jacket and white shoes standing in a forest with a brown tree trunk and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.45, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 74.844}, "timestamp": "2026-01-28T13:26:40.309128"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3723.052, "latencies_ms": [3723.052], "images_per_second": 0.269, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a white toilet, and a shower with a blue and white striped curtain.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.355}, "power_stats": {"power_gpu_soc_mean_watts": 21.38, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 78.355}, "timestamp": "2026-01-28T13:26:46.057184"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5606.492, "latencies_ms": [5606.492], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sink: 1\n2. toilet: 1\n3. shower curtain: 1\n4. mirror: 1\n5. countertop: 1\n6. cabinet: 1\n7. door: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.688}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 2.086, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 70.688}, "timestamp": "2026-01-28T13:26:53.701976"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5498.788, "latencies_ms": [5498.788], "images_per_second": 0.182, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The sink is located to the left of the toilet, which is situated in the middle of the bathroom. The shower curtain is hanging to the right of the toilet, and the mirror is above the sink. The blue and green bottles are placed on the countertop near the sink.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.739}, "power_stats": {"power_gpu_soc_mean_watts": 19.181, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.739}, "timestamp": "2026-01-28T13:27:01.217672"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3672.716, "latencies_ms": [3672.716], "images_per_second": 0.272, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white sink, a white toilet, and a shower with a blue and white striped curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.4}, "power_stats": {"power_gpu_soc_mean_watts": 21.68, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 7.812, "gpu_utilization_percent_mean": 78.4}, "timestamp": "2026-01-28T13:27:06.913246"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4456.378, "latencies_ms": [4456.378], "images_per_second": 0.224, "prompt_tokens": 1110, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The bathroom is well-lit with natural light coming from a window, and the walls are painted in a light beige color. The floor is covered with tiles that are a light brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.0, "ram_available_mb": 50253.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.946}, "power_stats": {"power_gpu_soc_mean_watts": 20.75, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 73.946}, "timestamp": "2026-01-28T13:27:13.405522"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4265.828, "latencies_ms": [4265.828], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a kitchen with a large island made of wood and a black countertop, featuring a sink and a faucet, and a dining area with a table and chairs.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12587.3, "ram_available_mb": 50253.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.59, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 74.417}, "timestamp": "2026-01-28T13:27:19.733935"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4248.555, "latencies_ms": [4248.555], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " sink: 1, countertop: 1, cabinet: 1, window: 1, chair: 1, table: 1, door: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.167}, "power_stats": {"power_gpu_soc_mean_watts": 20.703, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 75.167}, "timestamp": "2026-01-28T13:27:26.022417"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5664.224, "latencies_ms": [5664.224], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The sink is located to the left of the stove, which is situated in the middle of the kitchen. The countertop extends from the sink to the stove, creating a continuous workspace. The dining table is positioned in the background, with chairs placed around it, suggesting a communal dining area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12587.1, "ram_available_mb": 50253.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.191}, "power_stats": {"power_gpu_soc_mean_watts": 18.815, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 71.191}, "timestamp": "2026-01-28T13:27:33.700118"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3011.166, "latencies_ms": [3011.166], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kitchen with a large island and a dining table in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.44}, "power_stats": {"power_gpu_soc_mean_watts": 23.13, "power_cpu_cv_mean_watts": 1.617, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 79.44}, "timestamp": "2026-01-28T13:27:38.736034"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2905.137, "latencies_ms": [2905.137], "images_per_second": 0.344, "prompt_tokens": 1109, "response_tokens_est": 11, "n_tiles": 1, "output_text": " The kitchen has a black countertop and white walls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12587.4, "ram_available_mb": 50253.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.522}, "power_stats": {"power_gpu_soc_mean_watts": 23.506, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 84.522}, "timestamp": "2026-01-28T13:27:43.668184"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4524.923, "latencies_ms": [4524.923], "images_per_second": 0.221, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a dimly lit bedroom with a bed covered in a dark blue comforter adorned with a pattern of white daisies, and a person lying down under the covers.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.8, "ram_available_mb": 50253.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.842}, "power_stats": {"power_gpu_soc_mean_watts": 20.144, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.698, "gpu_utilization_percent_mean": 73.842}, "timestamp": "2026-01-28T13:27:50.239713"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5825.867, "latencies_ms": [5825.867], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. bed: 1\n2. blanket: 1\n3. pillow: 1\n4. sheet: 1\n5. daisy pattern: 1\n6. wall: 1\n7. bedside table: 1\n8. lamp: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12587.9, "ram_available_mb": 50253.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.898}, "power_stats": {"power_gpu_soc_mean_watts": 18.67, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 70.898}, "timestamp": "2026-01-28T13:27:58.105115"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5525.187, "latencies_ms": [5525.187], "images_per_second": 0.181, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The bed is positioned in the center of the image, with the person lying down on the left side. The blanket is draped over the person, covering them partially. The bed is situated in the foreground of the image, with the wall and other objects in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12588.8, "ram_available_mb": 50252.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12598.4, "ram_available_mb": 50242.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.8, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 71.043}, "timestamp": "2026-01-28T13:28:05.674085"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5150.557, "latencies_ms": [5150.557], "images_per_second": 0.194, "prompt_tokens": 1112, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image depicts a dimly lit bedroom with a bed covered in a dark blue comforter adorned with white daisy patterns. The bed is unmade, with the comforter slightly crumpled and the sheets peeking out from underneath.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12598.4, "ram_available_mb": 50242.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.884}, "power_stats": {"power_gpu_soc_mean_watts": 19.168, "power_cpu_cv_mean_watts": 2.216, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 71.884}, "timestamp": "2026-01-28T13:28:12.847522"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4844.416, "latencies_ms": [4844.416], "images_per_second": 0.206, "prompt_tokens": 1110, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a dark blue comforter adorned with white daisy patterns. The room is dimly lit, with a single light source illuminating the bed and creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.757, "power_cpu_cv_mean_watts": 2.433, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 74.4}, "timestamp": "2026-01-28T13:28:19.710339"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3670.062, "latencies_ms": [3670.062], "images_per_second": 0.272, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person is riding a skateboard on a ramp, wearing shorts and sneakers, with a shadow on the ground.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.533}, "power_stats": {"power_gpu_soc_mean_watts": 21.718, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 79.533}, "timestamp": "2026-01-28T13:28:25.406893"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5830.145, "latencies_ms": [5830.145], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. shorts: 1\n4. socks: 1\n5. shoes: 1\n6. skateboard wheels: 2\n7. skateboard deck: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.531}, "power_stats": {"power_gpu_soc_mean_watts": 18.834, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.531}, "timestamp": "2026-01-28T13:28:33.264369"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4781.994, "latencies_ms": [4781.994], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The skateboarder's feet are in the foreground, with the skateboard and the ramp in the middle ground. The skateboarder is positioned to the left of the ramp, and the buildings are in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.3}, "power_stats": {"power_gpu_soc_mean_watts": 19.877, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 71.3}, "timestamp": "2026-01-28T13:28:40.064762"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3532.765, "latencies_ms": [3532.765], "images_per_second": 0.283, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person is riding a skateboard on a concrete surface, with another person sitting on a ledge in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.586}, "power_stats": {"power_gpu_soc_mean_watts": 21.947, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 77.586}, "timestamp": "2026-01-28T13:28:45.644945"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5889.583, "latencies_ms": [5889.583], "images_per_second": 0.17, "prompt_tokens": 1110, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image is in black and white, with the skateboarder's legs and shoes being the main focus. The skateboarder is wearing a white shirt and plaid shorts, and the skateboard has a visible logo on it. The background features a concrete ramp and some buildings, suggesting an urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12599.6, "ram_available_mb": 50241.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.43, "power_cpu_cv_mean_watts": 2.107, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-28T13:28:53.580974"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3507.617, "latencies_ms": [3507.617], "images_per_second": 0.285, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is lying on the floor with a laptop, a tennis racket, and a book on the floor.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12599.6, "ram_available_mb": 50241.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.264, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 78.172}, "timestamp": "2026-01-28T13:28:59.138141"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4344.174, "latencies_ms": [4344.174], "images_per_second": 0.23, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " laptop: 1\ncamera: 1\nphone: 1\nbottle: 1\nbook: 1\nracket: 1\nkey: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.946}, "power_stats": {"power_gpu_soc_mean_watts": 20.59, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 75.946}, "timestamp": "2026-01-28T13:29:05.515088"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5222.66, "latencies_ms": [5222.66], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The laptop is on the left side of the image, the tennis racket is in the middle, and the book is on the right side. The laptop is closest to the camera, followed by the tennis racket, and then the book.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12598.8, "ram_available_mb": 50242.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.651}, "power_stats": {"power_gpu_soc_mean_watts": 19.344, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.67, "gpu_utilization_percent_mean": 71.651}, "timestamp": "2026-01-28T13:29:12.767784"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3429.779, "latencies_ms": [3429.779], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man is laying on the floor with a laptop, a tennis racket, and a book.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.8, "ram_available_mb": 50242.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.271, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 80.5}, "timestamp": "2026-01-28T13:29:18.221814"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3789.406, "latencies_ms": [3789.406], "images_per_second": 0.264, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image is taken in a room with a carpeted floor, the lighting is natural and bright, and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.1, "ram_available_mb": 50241.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.516}, "power_stats": {"power_gpu_soc_mean_watts": 21.808, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 75.516}, "timestamp": "2026-01-28T13:29:24.061124"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4152.236, "latencies_ms": [4152.236], "images_per_second": 0.241, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a kitchen with a black stove top, a black range hood above it, and a backsplash made of tiles in shades of brown and beige.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.966, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 75.229}, "timestamp": "2026-01-28T13:29:30.269145"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5091.525, "latencies_ms": [5091.525], "images_per_second": 0.196, "prompt_tokens": 1113, "response_tokens_est": 49, "n_tiles": 1, "output_text": " 1. black stove top\n2. black range hood\n3. black knife block\n4. black pot\n5. black oven\n6. black stove top burner\n7. black stove top burner\n8. black stove top burner", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.326}, "power_stats": {"power_gpu_soc_mean_watts": 19.59, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 72.326}, "timestamp": "2026-01-28T13:29:37.409635"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4384.596, "latencies_ms": [4384.596], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The stove is located in the foreground, with the backsplash behind it. The knives are on the left side of the stove, while the hanging towels are on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.811}, "power_stats": {"power_gpu_soc_mean_watts": 20.429, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 74.811}, "timestamp": "2026-01-28T13:29:43.833136"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3908.031, "latencies_ms": [3908.031], "images_per_second": 0.256, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image captures a modern kitchen with a black induction cooktop and a backsplash made of large tiles in shades of brown and beige.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.466, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 74.562}, "timestamp": "2026-01-28T13:29:49.772173"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3302.289, "latencies_ms": [3302.289], "images_per_second": 0.303, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The kitchen has a black stove top with a marble backsplash and a black range hood.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12598.1, "ram_available_mb": 50242.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.549, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 79.185}, "timestamp": "2026-01-28T13:29:55.099464"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4294.169, "latencies_ms": [4294.169], "images_per_second": 0.233, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a person is seated at a table in a restaurant, holding a cup of coffee and a donut, with a plate of donuts in front of them.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12598.1, "ram_available_mb": 50242.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.648, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 73.833}, "timestamp": "2026-01-28T13:30:01.448458"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4762.506, "latencies_ms": [4762.506], "images_per_second": 0.21, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " coffee cup: 1, donut: 1, plate: 1, person: 1, table: 1, donut: 1, person: 1, donut: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.513}, "power_stats": {"power_gpu_soc_mean_watts": 20.117, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 73.513}, "timestamp": "2026-01-28T13:30:08.236775"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5336.091, "latencies_ms": [5336.091], "images_per_second": 0.187, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the person in the background. The person is holding a cup of coffee, which is placed on the table. The donuts are placed on the table, with the chocolate donut being the closest to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.289}, "power_stats": {"power_gpu_soc_mean_watts": 19.127, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 70.289}, "timestamp": "2026-01-28T13:30:15.610669"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4208.921, "latencies_ms": [4208.921], "images_per_second": 0.238, "prompt_tokens": 1112, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In a bustling coffee shop, a person is enjoying a delicious chocolate donut with a side of coffee. The shop is filled with other patrons, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12598.4, "ram_available_mb": 50242.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.496, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 74.286}, "timestamp": "2026-01-28T13:30:21.840255"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4011.036, "latencies_ms": [4011.036], "images_per_second": 0.249, "prompt_tokens": 1110, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a dimly lit cafe with warm lighting, and the food is displayed on a tray with a white paper underneath.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12598.4, "ram_available_mb": 50242.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.071, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 75.97}, "timestamp": "2026-01-28T13:30:27.888303"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4515.786, "latencies_ms": [4515.786], "images_per_second": 0.221, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a bathroom with a black and white checkered floor, a white sink with a glass top, and a white toilet with a black and white cow print cover.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.162}, "power_stats": {"power_gpu_soc_mean_watts": 20.081, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.669, "gpu_utilization_percent_mean": 73.162}, "timestamp": "2026-01-28T13:30:34.425464"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5786.408, "latencies_ms": [5786.408], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Sink: 1\n3. Tile: 1\n4. Bathtub: 1\n5. Glass: 1\n6. Plate: 1\n7. Tile: 1\n8. Floor: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12597.8, "ram_available_mb": 50243.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.122}, "power_stats": {"power_gpu_soc_mean_watts": 18.711, "power_cpu_cv_mean_watts": 2.084, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 70.122}, "timestamp": "2026-01-28T13:30:42.267147"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4500.972, "latencies_ms": [4500.972], "images_per_second": 0.222, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the sink and mirror in the background. The sink is situated to the left of the toilet, while the mirror is above the sink.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12597.8, "ram_available_mb": 50243.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.462, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 72.892}, "timestamp": "2026-01-28T13:30:48.788706"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3694.729, "latencies_ms": [3694.729], "images_per_second": 0.271, "prompt_tokens": 1112, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A bathroom with a black and white checkered floor, a white sink, and a black and white checkered toilet seat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12596.8, "ram_available_mb": 50244.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.065}, "power_stats": {"power_gpu_soc_mean_watts": 21.652, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.824, "gpu_utilization_percent_mean": 78.065}, "timestamp": "2026-01-28T13:30:54.520368"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3908.214, "latencies_ms": [3908.214], "images_per_second": 0.256, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The bathroom has a black and white checkered floor, a white sink, and a white toilet with a black and white cow pattern.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12596.8, "ram_available_mb": 50244.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12596.7, "ram_available_mb": 50244.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.242, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 77.344}, "timestamp": "2026-01-28T13:31:00.468659"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6131.214, "latencies_ms": [6131.214], "images_per_second": 0.163, "prompt_tokens": 1100, "response_tokens_est": 67, "n_tiles": 1, "output_text": " In the image, there is a statue of a teddy bear with a sign that reads \"Joseph Pais, 1952-2012, Died 1-1-53, 41-8-88, Died 4-1-98\" placed in a garden.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 12596.7, "ram_available_mb": 50244.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12595.8, "ram_available_mb": 50245.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.962}, "power_stats": {"power_gpu_soc_mean_watts": 18.325, "power_cpu_cv_mean_watts": 2.157, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 71.962}, "timestamp": "2026-01-28T13:31:08.651595"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5625.655, "latencies_ms": [5625.655], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. teddy bear: 1\n2. sign: 1\n3. grass: 1\n4. brick: 1\n5. tree: 1\n6. house: 1\n7. fence: 1\n8. path: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12595.8, "ram_available_mb": 50245.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.723}, "power_stats": {"power_gpu_soc_mean_watts": 18.92, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 69.723}, "timestamp": "2026-01-28T13:31:16.311326"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4325.547, "latencies_ms": [4325.547], "images_per_second": 0.231, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The teddy bear is positioned in the foreground, with the sign behind it. The teddy bear is located to the left of the sign, and the sign is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.771}, "power_stats": {"power_gpu_soc_mean_watts": 20.921, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 70.771}, "timestamp": "2026-01-28T13:31:22.670339"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6962.35, "latencies_ms": [6962.35], "images_per_second": 0.144, "prompt_tokens": 1112, "response_tokens_est": 81, "n_tiles": 1, "output_text": " In a serene garden, a poignant memorial stands, adorned with a teddy bear and a sign that reads \"Joseph Pais, 1952-2012, Died 1-3-13, 41-8-8 Died 4-1-198\". The garden is a tranquil setting, with a house and lush greenery in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.746}, "power_stats": {"power_gpu_soc_mean_watts": 17.584, "power_cpu_cv_mean_watts": 2.036, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 69.746}, "timestamp": "2026-01-28T13:31:31.668596"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6205.394, "latencies_ms": [6205.394], "images_per_second": 0.161, "prompt_tokens": 1110, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image depicts a statue of a teddy bear with a sign that reads \"Joseph Pais\" and \"Misty Malahan\" on it. The statue is made of a beige material and is surrounded by a small garden with green grass and plants. The lighting in the image is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12596.1, "ram_available_mb": 50244.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.558, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 71.25}, "timestamp": "2026-01-28T13:31:39.899639"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4224.665, "latencies_ms": [4224.665], "images_per_second": 0.237, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image captures a bustling restaurant with a large clock face on the wall, where patrons are seated at tables, enjoying their meals and drinks, with a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12596.1, "ram_available_mb": 50244.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12597.0, "ram_available_mb": 50243.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.343}, "power_stats": {"power_gpu_soc_mean_watts": 20.761, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 74.343}, "timestamp": "2026-01-28T13:31:46.158761"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4115.672, "latencies_ms": [4115.672], "images_per_second": 0.243, "prompt_tokens": 1113, "response_tokens_est": 33, "n_tiles": 1, "output_text": " table: 10, chair: 20, clock: 1, person: 20, cup: 10, glass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.0, "ram_available_mb": 50243.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12597.2, "ram_available_mb": 50243.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.059}, "power_stats": {"power_gpu_soc_mean_watts": 21.3, "power_cpu_cv_mean_watts": 1.767, "power_sys_5v0_mean_watts": 7.771, "gpu_utilization_percent_mean": 76.059}, "timestamp": "2026-01-28T13:31:52.289704"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5728.94, "latencies_ms": [5728.94], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The clock is positioned in the background, far from the camera, and occupies a significant portion of the image. The bar is located in the foreground, close to the camera, and is surrounded by patrons. The tables and chairs are situated in the middle ground, with the patrons seated at them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12597.2, "ram_available_mb": 50243.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12598.3, "ram_available_mb": 50242.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.735}, "power_stats": {"power_gpu_soc_mean_watts": 18.547, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 70.735}, "timestamp": "2026-01-28T13:32:00.066313"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4954.311, "latencies_ms": [4954.311], "images_per_second": 0.202, "prompt_tokens": 1111, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a bustling restaurant with a large clock face on the wall, where people are enjoying their meals and drinks. The restaurant is filled with a variety of people, including diners and staff, all engaged in their respective activities.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12598.3, "ram_available_mb": 50242.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12599.5, "ram_available_mb": 50241.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.833}, "power_stats": {"power_gpu_soc_mean_watts": 19.627, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 70.833}, "timestamp": "2026-01-28T13:32:07.079900"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5291.259, "latencies_ms": [5291.259], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image is taken during the day, with natural light streaming in through the large window. The interior is bathed in warm tones, with the wooden beams and metal beams adding a rustic charm. The lighting is soft and diffused, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12599.5, "ram_available_mb": 50241.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12600.0, "ram_available_mb": 50240.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.636}, "power_stats": {"power_gpu_soc_mean_watts": 19.546, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 71.636}, "timestamp": "2026-01-28T13:32:14.397681"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3998.749, "latencies_ms": [3998.749], "images_per_second": 0.25, "prompt_tokens": 1100, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A child in a black jacket and helmet is standing on a snowy slope, while another child in a pink jacket and helmet is skiing down the slope.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12600.0, "ram_available_mb": 50240.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.205, "power_cpu_cv_mean_watts": 1.723, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 75.394}, "timestamp": "2026-01-28T13:32:20.468007"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6079.964, "latencies_ms": [6079.964], "images_per_second": 0.164, "prompt_tokens": 1114, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. skis: 2\n2. snowboard: 1\n3. helmet: 1\n4. goggles: 1\n5. backpack: 1\n6. ski poles: 2\n7. snowboard bindings: 1\n8. skis bindings: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12601.0, "ram_available_mb": 50239.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.348, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T13:32:28.580294"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5169.86, "latencies_ms": [5169.86], "images_per_second": 0.193, "prompt_tokens": 1118, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The skier is positioned in the foreground, with the child in the background. The skier is standing on the left side of the image, while the child is on the right side. The skier is closer to the camera than the child.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12601.0, "ram_available_mb": 50239.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.605}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 73.605}, "timestamp": "2026-01-28T13:32:35.764555"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2982.059, "latencies_ms": [2982.059], "images_per_second": 0.335, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A child is skiing down a snowy hill with trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12601.0, "ram_available_mb": 50239.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.167}, "power_stats": {"power_gpu_soc_mean_watts": 23.164, "power_cpu_cv_mean_watts": 1.285, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 83.167}, "timestamp": "2026-01-28T13:32:40.784336"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4824.556, "latencies_ms": [4824.556], "images_per_second": 0.207, "prompt_tokens": 1110, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a snowy mountain with a child wearing a black jacket and yellow skis standing on the slope. The sky is clear with a few clouds, and the sun is shining brightly, casting shadows on the snow.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12601.0, "ram_available_mb": 50239.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12600.7, "ram_available_mb": 50240.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.866, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 72.775}, "timestamp": "2026-01-28T13:32:47.654519"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3898.628, "latencies_ms": [3898.628], "images_per_second": 0.257, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A pair of feet wearing flip-flops is standing on a wooden floor with a broken mobile phone and its components scattered around them.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12600.7, "ram_available_mb": 50240.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12600.0, "ram_available_mb": 50240.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.114, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 77.375}, "timestamp": "2026-01-28T13:32:53.608402"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5746.354, "latencies_ms": [5746.354], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. flip phone: 2\n2. person: 1\n3. flip phone: 2\n4. person: 1\n5. flip phone: 2\n6. person: 1\n7. flip phone: 2\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.0, "ram_available_mb": 50240.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.083}, "power_stats": {"power_gpu_soc_mean_watts": 18.951, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 71.083}, "timestamp": "2026-01-28T13:33:01.375005"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7501.236, "latencies_ms": [7501.236], "images_per_second": 0.133, "prompt_tokens": 1117, "response_tokens_est": 88, "n_tiles": 1, "output_text": " The main objects are arranged in a diagonal line from the top left to the bottom right of the image. The person's feet are positioned at the bottom of the image, with the cell phones placed above them. The cell phones are positioned in the middle of the image, with the circuit board of the first cell phone placed to the left of the first cell phone, and the second cell phone placed to the right of the first cell phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12600.7, "ram_available_mb": 50240.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.968}, "power_stats": {"power_gpu_soc_mean_watts": 17.344, "power_cpu_cv_mean_watts": 2.193, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 68.968}, "timestamp": "2026-01-28T13:33:10.913787"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3702.27, "latencies_ms": [3702.27], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A pair of feet wearing flip flops are standing on a wooden floor with a broken cell phone and its components scattered around them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12600.7, "ram_available_mb": 50240.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12599.7, "ram_available_mb": 50241.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.452}, "power_stats": {"power_gpu_soc_mean_watts": 21.824, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 76.452}, "timestamp": "2026-01-28T13:33:16.645427"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3539.925, "latencies_ms": [3539.925], "images_per_second": 0.282, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The wooden floor is brown and the person's feet are black. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.7, "ram_available_mb": 50241.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.347, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 78.207}, "timestamp": "2026-01-28T13:33:22.219147"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5697.522, "latencies_ms": [5697.522], "images_per_second": 0.176, "prompt_tokens": 1099, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures the majestic Palace of Westminster, also known as the Houses of Parliament, bathed in the warm glow of the setting sun, with the iconic Big Ben clock tower standing tall in the background, while a boat with a red and white flag floats on the river in the foreground.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12597.0, "ram_available_mb": 50243.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.458}, "power_stats": {"power_gpu_soc_mean_watts": 18.777, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 71.458}, "timestamp": "2026-01-28T13:33:29.965399"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5623.542, "latencies_ms": [5623.542], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Boat: 2\n2. Boat: 1\n3. Boat: 1\n4. Boat: 1\n5. Boat: 1\n6. Boat: 1\n7. Boat: 1\n8. Boat: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12597.0, "ram_available_mb": 50243.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.17}, "power_stats": {"power_gpu_soc_mean_watts": 18.758, "power_cpu_cv_mean_watts": 2.642, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 72.17}, "timestamp": "2026-01-28T13:33:37.619910"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5118.435, "latencies_ms": [5118.435], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The clock tower is located in the background, far away from the camera, while the river is in the foreground, close to the camera. The buildings are in the middle ground, with the clock tower being the tallest and most prominent structure.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.628}, "power_stats": {"power_gpu_soc_mean_watts": 19.367, "power_cpu_cv_mean_watts": 2.664, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 73.628}, "timestamp": "2026-01-28T13:33:44.756889"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7091.147, "latencies_ms": [7091.147], "images_per_second": 0.141, "prompt_tokens": 1111, "response_tokens_est": 82, "n_tiles": 1, "output_text": " The image captures the majestic Palace of Westminster, also known as the Houses of Parliament, in London, England. The scene is set against a backdrop of a cloudy sky, with the river Thames flowing in the foreground. The palace, illuminated by warm lights, stands majestically on the north bank of the river, while boats are seen on the river, adding a touch of life to the otherwise serene setting.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12598.3, "ram_available_mb": 50242.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.883}, "power_stats": {"power_gpu_soc_mean_watts": 17.703, "power_cpu_cv_mean_watts": 2.169, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 71.883}, "timestamp": "2026-01-28T13:33:53.874610"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4509.865, "latencies_ms": [4509.865], "images_per_second": 0.222, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the water is a murky brown. The buildings are bathed in a warm yellow glow, contrasting with the cool tones of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.3, "ram_available_mb": 50242.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.158}, "power_stats": {"power_gpu_soc_mean_watts": 20.185, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 74.158}, "timestamp": "2026-01-28T13:34:00.400743"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4445.449, "latencies_ms": [4445.449], "images_per_second": 0.225, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a spacious living room with a red carpet, a green couch, a black sofa, and a wooden floor, with a ceiling fan, a television, and a bookshelf.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12600.2, "ram_available_mb": 50240.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.189}, "power_stats": {"power_gpu_soc_mean_watts": 20.439, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.189}, "timestamp": "2026-01-28T13:34:06.903987"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4877.238, "latencies_ms": [4877.238], "images_per_second": 0.205, "prompt_tokens": 1113, "response_tokens_est": 45, "n_tiles": 1, "output_text": " chair: 2, sofa: 1, television: 1, potted plant: 2, mirror: 1, television stand: 1, bookshelf: 1, ceiling fan: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12600.2, "ram_available_mb": 50240.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12599.2, "ram_available_mb": 50241.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.659}, "power_stats": {"power_gpu_soc_mean_watts": 19.692, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 74.659}, "timestamp": "2026-01-28T13:34:13.820156"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6180.616, "latencies_ms": [6180.616], "images_per_second": 0.162, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The living room is situated in the center of the image, with the furniture arranged around it. The foreground features a red rug and a coffee table, while the background includes a television and a bookshelf. The ceiling fan is positioned in the upper right corner of the room, and the windows are located on the left and right sides.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12599.2, "ram_available_mb": 50241.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.212}, "power_stats": {"power_gpu_soc_mean_watts": 18.269, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 69.212}, "timestamp": "2026-01-28T13:34:22.054301"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3114.899, "latencies_ms": [3114.899], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A living room with a red carpet, a couch, and a chair.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.72}, "power_stats": {"power_gpu_soc_mean_watts": 22.814, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 79.72}, "timestamp": "2026-01-28T13:34:27.197500"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3371.001, "latencies_ms": [3371.001], "images_per_second": 0.297, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is filled with natural light from the windows, and the wooden floor is polished and shiny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.413, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 78.357}, "timestamp": "2026-01-28T13:34:32.605619"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5300.087, "latencies_ms": [5300.087], "images_per_second": 0.189, "prompt_tokens": 1100, "response_tokens_est": 53, "n_tiles": 1, "output_text": " A red pole with a circular metal ring stands on a sidewalk, with a parking meter attached to it, in front of a building with a large window that has the words \"100 YEARS OF SAVING LIVES\" printed on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.409}, "power_stats": {"power_gpu_soc_mean_watts": 19.454, "power_cpu_cv_mean_watts": 1.975, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 71.409}, "timestamp": "2026-01-28T13:34:39.950122"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5165.576, "latencies_ms": [5165.576], "images_per_second": 0.194, "prompt_tokens": 1114, "response_tokens_est": 51, "n_tiles": 1, "output_text": " 1. red post\n2. red circular holder\n3. red post with holder\n4. parking meter\n5. parking meter with holder\n6. parking meter with holder\n7. parking meter with holder\n8. parking meter with holder", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12598.0, "ram_available_mb": 50242.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.977}, "power_stats": {"power_gpu_soc_mean_watts": 19.496, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 72.977}, "timestamp": "2026-01-28T13:34:47.126377"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5448.857, "latencies_ms": [5448.857], "images_per_second": 0.184, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The red parking meter is located in the foreground on the left side of the image, while the building with the \"100 Years of Saving Lives\" sign is in the background on the right side. The parking meter is positioned closer to the viewer than the building.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12598.0, "ram_available_mb": 50242.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12597.9, "ram_available_mb": 50243.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.13}, "power_stats": {"power_gpu_soc_mean_watts": 18.825, "power_cpu_cv_mean_watts": 2.063, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 72.13}, "timestamp": "2026-01-28T13:34:54.588281"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5770.928, "latencies_ms": [5770.928], "images_per_second": 0.173, "prompt_tokens": 1112, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, where a red parking meter stands proudly on a sidewalk, its circular top gleaming under the sunlight. In the background, a building proudly displays a sign that reads \"100 Years of Saving Lives,\" a testament to the building's long-standing legacy.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12597.9, "ram_available_mb": 50243.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12597.9, "ram_available_mb": 50243.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.042}, "power_stats": {"power_gpu_soc_mean_watts": 18.508, "power_cpu_cv_mean_watts": 2.061, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 72.042}, "timestamp": "2026-01-28T13:35:02.375652"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5919.905, "latencies_ms": [5919.905], "images_per_second": 0.169, "prompt_tokens": 1110, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a red metal pole with a circular metal ring on top, standing on a sidewalk. The pole is located in front of a building with a large window that has the words \"100 Years of Saving Lives\" written on it. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 12597.9, "ram_available_mb": 50243.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12597.9, "ram_available_mb": 50243.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.64}, "power_stats": {"power_gpu_soc_mean_watts": 18.458, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.695, "gpu_utilization_percent_mean": 69.64}, "timestamp": "2026-01-28T13:35:10.340600"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3439.469, "latencies_ms": [3439.469], "images_per_second": 0.291, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man and a woman are sitting on a couch in a living room, watching TV and eating snacks.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12597.9, "ram_available_mb": 50243.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.387, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 79.857}, "timestamp": "2026-01-28T13:35:15.804956"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6002.328, "latencies_ms": [6002.328], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. sofa: 2\n2. television: 1\n3. coffee table: 1\n4. television stand: 1\n5. bookshelf: 1\n6. potted plant: 1\n7. couch: 1\n8. bag of chips: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12598.0, "ram_available_mb": 50242.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.14}, "power_stats": {"power_gpu_soc_mean_watts": 18.522, "power_cpu_cv_mean_watts": 2.042, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 72.14}, "timestamp": "2026-01-28T13:35:23.819425"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4836.856, "latencies_ms": [4836.856], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The television is on the left side of the room, the couch is in the middle, and the coffee table is in the foreground. The person on the right is closer to the camera than the person on the left.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12598.0, "ram_available_mb": 50242.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.825}, "power_stats": {"power_gpu_soc_mean_watts": 19.956, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 73.825}, "timestamp": "2026-01-28T13:35:30.695795"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3135.241, "latencies_ms": [3135.241], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A couple is sitting on a couch in a living room watching TV.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12597.4, "ram_available_mb": 50243.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.4}, "power_stats": {"power_gpu_soc_mean_watts": 22.607, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 79.4}, "timestamp": "2026-01-28T13:35:35.845342"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4317.596, "latencies_ms": [4317.596], "images_per_second": 0.232, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The room is lit by a warm light, and the walls are painted in a light color. The furniture is made of wood, and the floor is covered with a carpet.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12597.4, "ram_available_mb": 50243.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12597.4, "ram_available_mb": 50243.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.67, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 74.639}, "timestamp": "2026-01-28T13:35:42.212653"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3204.752, "latencies_ms": [3204.752], "images_per_second": 0.312, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A person is holding a white power strip with multiple outlets in front of a white appliance.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12597.4, "ram_available_mb": 50243.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.038}, "power_stats": {"power_gpu_soc_mean_watts": 23.047, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 80.038}, "timestamp": "2026-01-28T13:35:47.453498"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5731.944, "latencies_ms": [5731.944], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. hand: 1\n3. box: 1\n4. floor: 1\n5. wall: 1\n6. floor lamp: 1\n7. electrical outlet: 1\n8. electrical switch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.6, "ram_available_mb": 50243.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12597.8, "ram_available_mb": 50243.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.979}, "power_stats": {"power_gpu_soc_mean_watts": 18.876, "power_cpu_cv_mean_watts": 1.852, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 71.979}, "timestamp": "2026-01-28T13:35:55.234103"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4810.658, "latencies_ms": [4810.658], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The hand is holding the power strip in front of the washing machine, which is located to the left of the power strip. The power strip is positioned in the foreground, while the washing machine is situated in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12597.8, "ram_available_mb": 50243.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.561}, "power_stats": {"power_gpu_soc_mean_watts": 19.908, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 74.561}, "timestamp": "2026-01-28T13:36:02.088056"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3509.462, "latencies_ms": [3509.462], "images_per_second": 0.285, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is holding a white power strip with multiple outlets. The power strip is plugged into a wall outlet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.124, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 79.103}, "timestamp": "2026-01-28T13:36:07.612331"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3280.735, "latencies_ms": [3280.735], "images_per_second": 0.305, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the floor is made of wood.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.572, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 78.296}, "timestamp": "2026-01-28T13:36:12.928422"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4611.923, "latencies_ms": [4611.923], "images_per_second": 0.217, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In the image, a snowboarder is captured mid-air performing a trick on a snowy ramp, with a crowd of spectators watching from the side, and a red flag marking the end of the ramp.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12596.6, "ram_available_mb": 50244.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.154}, "power_stats": {"power_gpu_soc_mean_watts": 20.292, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 75.154}, "timestamp": "2026-01-28T13:36:19.582041"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5846.19, "latencies_ms": [5846.19], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. snowboarder: 2\n2. snowboard: 1\n3. crowd: 1\n4. flag: 1\n5. snow: 1\n6. mountain: 1\n7. sky: 1\n8. snowboarder: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.6, "ram_available_mb": 50244.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12596.1, "ram_available_mb": 50244.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.711, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-28T13:36:27.475962"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5718.077, "latencies_ms": [5718.077], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The main objects are the snowboarder and the crowd. The snowboarder is in the foreground, performing a trick in the air, while the crowd is in the background, watching the event. The snowboarder is also near the crowd, as they are both in the same location.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12596.1, "ram_available_mb": 50244.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.404}, "power_stats": {"power_gpu_soc_mean_watts": 18.918, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 71.404}, "timestamp": "2026-01-28T13:36:35.225807"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3694.71, "latencies_ms": [3694.71], "images_per_second": 0.271, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air above a snow ramp. The ramp is surrounded by a crowd of spectators.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.194}, "power_stats": {"power_gpu_soc_mean_watts": 21.797, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 75.194}, "timestamp": "2026-01-28T13:36:40.943311"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4796.712, "latencies_ms": [4796.712], "images_per_second": 0.208, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a snowboarder performing a trick in the air, with a clear blue sky in the background. The snowboarder is wearing a red and white outfit, and the snow is white and pristine.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.9}, "power_stats": {"power_gpu_soc_mean_watts": 19.915, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 73.9}, "timestamp": "2026-01-28T13:36:47.800065"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4554.992, "latencies_ms": [4554.992], "images_per_second": 0.22, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a well-organized home office with a wooden desk, a black office chair, and a computer setup, including a monitor, keyboard, and mouse, all placed on the desk.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.108}, "power_stats": {"power_gpu_soc_mean_watts": 20.591, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 75.108}, "timestamp": "2026-01-28T13:36:54.403180"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4487.414, "latencies_ms": [4487.414], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 38, "n_tiles": 1, "output_text": " 1. white sofa\n2. black chair\n3. desk\n4. computer monitor\n5. keyboard\n6. mouse\n7. lamp\n8. potted plant", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12596.1, "ram_available_mb": 50244.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.135}, "power_stats": {"power_gpu_soc_mean_watts": 20.471, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 76.135}, "timestamp": "2026-01-28T13:37:00.911358"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4725.27, "latencies_ms": [4725.27], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The desk is positioned to the left of the white couch, with the chair in front of it. The potted plant is located near the desk, while the bookshelf is situated further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.1, "ram_available_mb": 50244.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12595.7, "ram_available_mb": 50245.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.897}, "power_stats": {"power_gpu_soc_mean_watts": 20.16, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 74.897}, "timestamp": "2026-01-28T13:37:07.654495"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2954.527, "latencies_ms": [2954.527], "images_per_second": 0.338, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A room with a desk, chair, and computer on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12595.7, "ram_available_mb": 50245.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.427, "power_cpu_cv_mean_watts": 1.318, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 79.417}, "timestamp": "2026-01-28T13:37:12.642138"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3348.821, "latencies_ms": [3348.821], "images_per_second": 0.299, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from a window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12595.7, "ram_available_mb": 50245.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.714, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 80.714}, "timestamp": "2026-01-28T13:37:18.030992"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3191.543, "latencies_ms": [3191.543], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is sitting on a motorcycle on a dirt road with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12595.7, "ram_available_mb": 50245.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.784, "power_cpu_cv_mean_watts": 1.34, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 81.5}, "timestamp": "2026-01-28T13:37:23.261054"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6052.292, "latencies_ms": [6052.292], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Motorcycle: 1\n2. Motorcycle: 1\n3. Motorcycle: 1\n4. Motorcycle: 1\n5. Motorcycle: 1\n6. Motorcycle: 1\n7. Motorcycle: 1\n8. Motorcycle: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.46}, "power_stats": {"power_gpu_soc_mean_watts": 18.474, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 69.46}, "timestamp": "2026-01-28T13:37:31.353051"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5967.532, "latencies_ms": [5967.532], "images_per_second": 0.168, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider sitting on it. The motorcycle is in the foreground of the image, while the rider is in the background. The rider is positioned slightly to the right of the motorcycle, and the motorcycle is positioned slightly to the left of the rider.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12595.2, "ram_available_mb": 50245.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.4}, "power_stats": {"power_gpu_soc_mean_watts": 18.313, "power_cpu_cv_mean_watts": 2.082, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 70.4}, "timestamp": "2026-01-28T13:37:39.367069"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3675.479, "latencies_ms": [3675.479], "images_per_second": 0.272, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person is standing on a dirt road with a motorcycle parked beside them. The road is surrounded by mountains and trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12595.2, "ram_available_mb": 50245.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12594.8, "ram_available_mb": 50246.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.433}, "power_stats": {"power_gpu_soc_mean_watts": 21.866, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 76.433}, "timestamp": "2026-01-28T13:37:45.072456"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3145.799, "latencies_ms": [3145.799], "images_per_second": 0.318, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The sky is blue with white clouds, and the road is gray with rocks.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12594.8, "ram_available_mb": 50246.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12595.5, "ram_available_mb": 50245.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.077}, "power_stats": {"power_gpu_soc_mean_watts": 22.769, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 80.077}, "timestamp": "2026-01-28T13:37:50.265372"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3905.982, "latencies_ms": [3905.982], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image shows a kitchen with wooden cabinets, a white stove, and a white refrigerator, with a dining table in the center of the room.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12595.5, "ram_available_mb": 50245.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.216, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 77.242}, "timestamp": "2026-01-28T13:37:56.226772"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6315.956, "latencies_ms": [6315.956], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. white refrigerator: 1\n2. white stove: 1\n3. white oven: 1\n4. white sink: 1\n5. white door: 2\n6. white countertop: 1\n7. wooden cabinets: 10\n8. wooden table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12595.2, "ram_available_mb": 50245.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.396}, "power_stats": {"power_gpu_soc_mean_watts": 17.315, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 7.642, "gpu_utilization_percent_mean": 72.396}, "timestamp": "2026-01-28T13:38:04.557328"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4654.35, "latencies_ms": [4654.35], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The kitchen is located in the background of the image, with the dining table and chairs in the foreground. The stove is on the left side of the kitchen, while the refrigerator is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.2, "ram_available_mb": 50245.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12595.2, "ram_available_mb": 50245.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.079}, "power_stats": {"power_gpu_soc_mean_watts": 20.101, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 74.079}, "timestamp": "2026-01-28T13:38:11.223043"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3982.217, "latencies_ms": [3982.217], "images_per_second": 0.251, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a white stove, and a white refrigerator. There is a dining table with a bowl of oranges on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.2, "ram_available_mb": 50245.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.333}, "power_stats": {"power_gpu_soc_mean_watts": 21.267, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-28T13:38:17.228548"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4300.763, "latencies_ms": [4300.763], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The kitchen has white walls and a white ceiling, with wooden cabinets and a white stove. The floor is tiled, and there is a bowl of oranges on the table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12596.8, "ram_available_mb": 50244.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.64, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 73.222}, "timestamp": "2026-01-28T13:38:23.567734"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3150.636, "latencies_ms": [3150.636], "images_per_second": 0.317, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A female tennis player is preparing to serve the ball on a blue tennis court.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12596.8, "ram_available_mb": 50244.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.154}, "power_stats": {"power_gpu_soc_mean_watts": 22.754, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 77.154}, "timestamp": "2026-01-28T13:38:28.787476"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6435.463, "latencies_ms": [6435.463], "images_per_second": 0.155, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. woman: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. woman's shoes: 2\n5. woman's shorts: 1\n6. woman's shirt: 1\n7. woman's headband: 1\n8. woman's wristband: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.852}, "power_stats": {"power_gpu_soc_mean_watts": 18.219, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 70.852}, "timestamp": "2026-01-28T13:38:37.249731"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5312.583, "latencies_ms": [5312.583], "images_per_second": 0.188, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the tennis ball in the middle ground and the blue wall in the background. The player is facing the tennis ball, which is near the center of the image, and the wall is behind her.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.227}, "power_stats": {"power_gpu_soc_mean_watts": 19.254, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 73.227}, "timestamp": "2026-01-28T13:38:44.577900"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3076.263, "latencies_ms": [3076.263], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A female tennis player is preparing to serve the ball on a blue court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.103, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 82.28}, "timestamp": "2026-01-28T13:38:49.683639"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3206.777, "latencies_ms": [3206.777], "images_per_second": 0.312, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The tennis player is wearing a white shirt and black shorts, and the court is blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12597.7, "ram_available_mb": 50243.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12597.1, "ram_available_mb": 50243.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.017, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.82, "gpu_utilization_percent_mean": 78.923}, "timestamp": "2026-01-28T13:38:54.906003"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3424.127, "latencies_ms": [3424.127], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A red fire hydrant is on the sidewalk, with a yellow sign above it showing a pedestrian crossing symbol.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12597.1, "ram_available_mb": 50243.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12596.9, "ram_available_mb": 50244.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.429}, "power_stats": {"power_gpu_soc_mean_watts": 22.717, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 78.429}, "timestamp": "2026-01-28T13:39:00.350614"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4797.198, "latencies_ms": [4797.198], "images_per_second": 0.208, "prompt_tokens": 1114, "response_tokens_est": 44, "n_tiles": 1, "output_text": " 1. red fire hydrant\n2. yellow pedestrian sign\n3. white helmet\n4. person in white shirt\n5. person in blue shirt\n6. tree\n7. building\n8. sidewalk", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12596.9, "ram_available_mb": 50244.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12597.1, "ram_available_mb": 50243.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.45}, "power_stats": {"power_gpu_soc_mean_watts": 19.838, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 73.45}, "timestamp": "2026-01-28T13:39:07.188335"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5225.378, "latencies_ms": [5225.378], "images_per_second": 0.191, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The red fire hydrant is located on the left side of the image, in the foreground, and is near a sidewalk. In the background, there is a person standing on the sidewalk, and a yellow pedestrian crossing sign is visible above the hydrant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12597.1, "ram_available_mb": 50243.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12598.1, "ram_available_mb": 50242.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.909}, "power_stats": {"power_gpu_soc_mean_watts": 19.238, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 72.909}, "timestamp": "2026-01-28T13:39:14.441014"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3113.636, "latencies_ms": [3113.636], "images_per_second": 0.321, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red fire hydrant is on the sidewalk, and a boy is standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.1, "ram_available_mb": 50242.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.577}, "power_stats": {"power_gpu_soc_mean_watts": 22.708, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 7.821, "gpu_utilization_percent_mean": 81.577}, "timestamp": "2026-01-28T13:39:19.595541"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3102.458, "latencies_ms": [3102.458], "images_per_second": 0.322, "prompt_tokens": 1110, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The fire hydrant is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.731}, "power_stats": {"power_gpu_soc_mean_watts": 22.769, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 82.731}, "timestamp": "2026-01-28T13:39:24.731596"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3583.162, "latencies_ms": [3583.162], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white toilet, a green trash can, and a white paper towel dispenser.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.033}, "power_stats": {"power_gpu_soc_mean_watts": 21.964, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 76.033}, "timestamp": "2026-01-28T13:39:30.374017"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5661.661, "latencies_ms": [5661.661], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " toilet: 1\ntoilet tank: 1\ntoilet seat: 1\ntoilet lid: 1\ntoilet tank lid: 1\ntoilet tank handle: 1\ntoilet tank flush handle: 1\ntoilet tank flush button: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.292}, "power_stats": {"power_gpu_soc_mean_watts": 18.877, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 72.292}, "timestamp": "2026-01-28T13:39:38.091339"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5047.843, "latencies_ms": [5047.843], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The toilet is located in the center of the image, with the tank on the right and the seat on the left. The person's feet are visible in the foreground, while the trash can is positioned to the left of the toilet.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.163}, "power_stats": {"power_gpu_soc_mean_watts": 19.471, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 75.163}, "timestamp": "2026-01-28T13:39:45.174730"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3102.268, "latencies_ms": [3102.268], "images_per_second": 0.322, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A small bathroom with a toilet, a trash can, and a water filter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.48}, "power_stats": {"power_gpu_soc_mean_watts": 23.344, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 7.86, "gpu_utilization_percent_mean": 81.48}, "timestamp": "2026-01-28T13:39:50.305771"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3394.963, "latencies_ms": [3394.963], "images_per_second": 0.295, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The bathroom is small and has a white toilet, a green toilet seat, and a brown carpet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12598.8, "ram_available_mb": 50242.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.786}, "power_stats": {"power_gpu_soc_mean_watts": 22.375, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 77.786}, "timestamp": "2026-01-28T13:39:55.713956"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3681.667, "latencies_ms": [3681.667], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person wearing a red jacket and black pants is skiing down a snowy mountain with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12598.8, "ram_available_mb": 50242.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12599.9, "ram_available_mb": 50240.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.724, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 75.367}, "timestamp": "2026-01-28T13:40:01.438750"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5699.918, "latencies_ms": [5699.918], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skis: 2\n3. poles: 2\n4. backpack: 1\n5. helmet: 1\n6. jacket: 1\n7. pants: 1\n8. snow: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.766}, "power_stats": {"power_gpu_soc_mean_watts": 18.581, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 70.766}, "timestamp": "2026-01-28T13:40:09.167918"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5588.96, "latencies_ms": [5588.96], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the mountain peak in the background. The skier is skiing towards the mountain peak, indicating a forward motion. The skier is also positioned to the left of the image, with the mountain peak to the right.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12599.6, "ram_available_mb": 50241.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.727, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 72.596}, "timestamp": "2026-01-28T13:40:16.770627"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3183.333, "latencies_ms": [3183.333], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is skiing down a snowy mountain with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12599.6, "ram_available_mb": 50241.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12600.6, "ram_available_mb": 50240.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.538}, "power_stats": {"power_gpu_soc_mean_watts": 22.954, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 80.538}, "timestamp": "2026-01-28T13:40:21.967973"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4776.54, "latencies_ms": [4776.54], "images_per_second": 0.209, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a person wearing a red jacket and black pants, skiing down a snow-covered mountain under a clear blue sky. The snow is pristine white, and the person's skis are a vibrant green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.6, "ram_available_mb": 50240.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12600.6, "ram_available_mb": 50240.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.998, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 71.275}, "timestamp": "2026-01-28T13:40:28.773749"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3589.49, "latencies_ms": [3589.49], "images_per_second": 0.279, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a red and white jacket and black pants is skiing down a snowy mountain with trees in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12600.6, "ram_available_mb": 50240.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.897}, "power_stats": {"power_gpu_soc_mean_watts": 22.086, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 74.897}, "timestamp": "2026-01-28T13:40:34.407085"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5964.933, "latencies_ms": [5964.933], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. skier: 1\n2. bib: 1\n3. bib number: 30\n4. skis: 2\n5. ski poles: 2\n6. backpack: 1\n7. hat: 1\n8. gloves: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.411, "power_cpu_cv_mean_watts": 2.38, "power_sys_5v0_mean_watts": 7.732, "gpu_utilization_percent_mean": 71.49}, "timestamp": "2026-01-28T13:40:42.406577"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4664.421, "latencies_ms": [4664.421], "images_per_second": 0.214, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The main object, a person skiing, is in the foreground, with the background consisting of trees and a mountain. The person is positioned to the left of the frame, with the mountain to the right.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.179}, "power_stats": {"power_gpu_soc_mean_watts": 19.927, "power_cpu_cv_mean_watts": 2.393, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 74.179}, "timestamp": "2026-01-28T13:40:49.100952"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2915.614, "latencies_ms": [2915.614], "images_per_second": 0.343, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is skiing down a snowy mountain with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.25}, "power_stats": {"power_gpu_soc_mean_watts": 23.368, "power_cpu_cv_mean_watts": 1.268, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 79.25}, "timestamp": "2026-01-28T13:40:54.073677"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4389.597, "latencies_ms": [4389.597], "images_per_second": 0.228, "prompt_tokens": 1110, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a man skiing in a snowy forest with a white background and a gray sky. The man is wearing a red and white jacket, black pants, and a gray hat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.27}, "power_stats": {"power_gpu_soc_mean_watts": 20.407, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 74.27}, "timestamp": "2026-01-28T13:41:00.501104"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3240.74, "latencies_ms": [3240.74], "images_per_second": 0.309, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A black and white photo of a computer desk with a monitor, keyboard, and mouse.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12602.8, "ram_available_mb": 50238.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.653, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 80.815}, "timestamp": "2026-01-28T13:41:05.791790"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3918.103, "latencies_ms": [3918.103], "images_per_second": 0.255, "prompt_tokens": 1114, "response_tokens_est": 29, "n_tiles": 1, "output_text": " monitor: 1, keyboard: 1, mouse: 1, desk: 1, wall: 1, text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.8, "ram_available_mb": 50238.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12602.1, "ram_available_mb": 50238.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.531}, "power_stats": {"power_gpu_soc_mean_watts": 21.417, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 75.531}, "timestamp": "2026-01-28T13:41:11.729844"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4776.286, "latencies_ms": [4776.286], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The computer monitor is on the left side of the desk, the keyboard is in the middle, and the mouse is on the right side. The desk is in the foreground, and the wall is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.1, "ram_available_mb": 50238.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12602.2, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 19.938, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-28T13:41:18.543297"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3321.273, "latencies_ms": [3321.273], "images_per_second": 0.301, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A black and white photo of a computer desk with a monitor, keyboard, and mouse.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.2, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.148}, "power_stats": {"power_gpu_soc_mean_watts": 21.898, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 77.148}, "timestamp": "2026-01-28T13:41:23.880706"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3869.68, "latencies_ms": [3869.68], "images_per_second": 0.258, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is in black and white, with a computer monitor displaying a webpage. The desk is made of wood and has a white surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.219}, "power_stats": {"power_gpu_soc_mean_watts": 21.492, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 77.219}, "timestamp": "2026-01-28T13:41:29.775814"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3360.413, "latencies_ms": [3360.413], "images_per_second": 0.298, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A woman wearing a striped shirt is sitting at a table on a train and eating a bagel.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12602.8, "ram_available_mb": 50238.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.559, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 80.5}, "timestamp": "2026-01-28T13:41:35.190077"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5617.34, "latencies_ms": [5617.34], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. bagel: 1\n3. coffee cup: 1\n4. box: 1\n5. food: 1\n6. person: 1\n7. window: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.8, "ram_available_mb": 50238.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.234}, "power_stats": {"power_gpu_soc_mean_watts": 19.144, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 71.234}, "timestamp": "2026-01-28T13:41:42.839309"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4151.215, "latencies_ms": [4151.215], "images_per_second": 0.241, "prompt_tokens": 1118, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The woman is in the foreground, holding a bagel, while the coffee cup is in the background. The bagel is closer to the camera than the coffee cup.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.086}, "power_stats": {"power_gpu_soc_mean_watts": 21.196, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 74.086}, "timestamp": "2026-01-28T13:41:49.007541"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3159.551, "latencies_ms": [3159.551], "images_per_second": 0.317, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman is sitting at a table on a train, eating a bagel and smiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.832, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 80.5}, "timestamp": "2026-01-28T13:41:54.183007"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4198.913, "latencies_ms": [4198.913], "images_per_second": 0.238, "prompt_tokens": 1110, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image has a warm color tone, with natural light coming from the window. The woman is wearing a striped shirt, and the food is in a white paper bag.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12602.4, "ram_available_mb": 50238.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.978, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 72.286}, "timestamp": "2026-01-28T13:42:00.439985"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3339.335, "latencies_ms": [3339.335], "images_per_second": 0.299, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two zebras with black and white stripes are grazing on green grass in a grassy field.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12602.4, "ram_available_mb": 50238.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.333}, "power_stats": {"power_gpu_soc_mean_watts": 22.505, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-28T13:42:05.832619"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2462.95, "latencies_ms": [2462.95], "images_per_second": 0.406, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12600.9, "ram_available_mb": 50240.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.4}, "power_stats": {"power_gpu_soc_mean_watts": 24.137, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 7.761, "gpu_utilization_percent_mean": 84.4}, "timestamp": "2026-01-28T13:42:10.317847"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5461.874, "latencies_ms": [5461.874], "images_per_second": 0.183, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the zebra on the left slightly closer to the camera than the one on the right. The zebras are grazing on the grass, with the one on the left eating more than the one on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.9, "ram_available_mb": 50240.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12601.2, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.413}, "power_stats": {"power_gpu_soc_mean_watts": 19.106, "power_cpu_cv_mean_watts": 1.907, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 73.413}, "timestamp": "2026-01-28T13:42:17.831260"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3049.149, "latencies_ms": [3049.149], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two zebras are grazing on green grass in a fenced enclosure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.2, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.199, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 81.4}, "timestamp": "2026-01-28T13:42:22.914806"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5382.268, "latencies_ms": [5382.268], "images_per_second": 0.186, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features two zebras with their black and white stripes grazing on a lush green field. The lighting is natural and bright, suggesting it is daytime. The zebras appear to be in a peaceful environment, with no other animals or objects in the immediate vicinity.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.6}, "power_stats": {"power_gpu_soc_mean_watts": 19.21, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 70.6}, "timestamp": "2026-01-28T13:42:30.319674"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3387.563, "latencies_ms": [3387.563], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two young men are riding a green bicycle on a busy street with a storefront in the background.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12601.3, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12601.3, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.289, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 78.893}, "timestamp": "2026-01-28T13:42:35.759302"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5595.366, "latencies_ms": [5595.366], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bicycle: 2\n2. person: 2\n3. motorcycle: 2\n4. scooter: 1\n5. store: 1\n6. sign: 1\n7. plant: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.3, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.213}, "power_stats": {"power_gpu_soc_mean_watts": 19.092, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 72.213}, "timestamp": "2026-01-28T13:42:43.370672"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4383.212, "latencies_ms": [4383.212], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The two boys are positioned in the foreground of the image, with the bicycle in front of them. The motorcycle is parked behind the bicycle, and the storefront is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.189}, "power_stats": {"power_gpu_soc_mean_watts": 20.44, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 75.189}, "timestamp": "2026-01-28T13:42:49.781879"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3035.959, "latencies_ms": [3035.959], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two young men are riding a green bicycle down a busy street in Vietnam.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.312, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.847, "gpu_utilization_percent_mean": 80.12}, "timestamp": "2026-01-28T13:42:54.866318"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4236.442, "latencies_ms": [4236.442], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken during the day with natural light illuminating the scene. The colors are vibrant, with the green of the bicycle and the blue of the sky standing out.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.703, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 73.029}, "timestamp": "2026-01-28T13:43:01.130356"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8040.226, "latencies_ms": [8040.226], "images_per_second": 0.124, "prompt_tokens": 1099, "response_tokens_est": 98, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a tennis match, with a player in white attire poised to strike the ball, while another player in a contrasting blue outfit is seen preparing to return the shot. The court, marked with crisp white lines, is set against a backdrop of a large, attentive audience, all engrossed in the unfolding action. The scene is further accentuated by the presence of a cameraman and a ball boy, who are strategically positioned to capture the essence of the match.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12601.6, "ram_available_mb": 50239.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.706}, "power_stats": {"power_gpu_soc_mean_watts": 16.96, "power_cpu_cv_mean_watts": 2.221, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 68.706}, "timestamp": "2026-01-28T13:43:11.227935"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4334.615, "latencies_ms": [4334.615], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " 1. tennis court\n2. tennis players\n3. chairs\n4. bags\n5. spectators\n6. ball\n7. net\n8. umpire", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12601.3, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.778}, "power_stats": {"power_gpu_soc_mean_watts": 20.752, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 75.778}, "timestamp": "2026-01-28T13:43:17.588646"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4666.301, "latencies_ms": [4666.301], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the ball in the middle ground, and the audience in the background. The player is closer to the camera than the ball, and the audience is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.359}, "power_stats": {"power_gpu_soc_mean_watts": 20.245, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 72.359}, "timestamp": "2026-01-28T13:43:24.277426"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5110.072, "latencies_ms": [5110.072], "images_per_second": 0.196, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a moment from a professional tennis match, with two players in white attire actively engaged in the game on a grass court. The court is surrounded by a crowd of spectators, all seated in the stands, watching the match intently.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.81}, "power_stats": {"power_gpu_soc_mean_watts": 19.687, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 72.81}, "timestamp": "2026-01-28T13:43:31.447179"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4381.231, "latencies_ms": [4381.231], "images_per_second": 0.228, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is taken during a daytime tennis match, with the players dressed in white and the court's grass green. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.385, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 77.486}, "timestamp": "2026-01-28T13:43:37.856198"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4643.023, "latencies_ms": [4643.023], "images_per_second": 0.215, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a brown sofa, a television on a wooden stand, a coffee table with a few items on it, and a variety of potted plants placed around the room.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12600.9, "ram_available_mb": 50240.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.615}, "power_stats": {"power_gpu_soc_mean_watts": 20.08, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 71.615}, "timestamp": "2026-01-28T13:43:44.560601"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4999.339, "latencies_ms": [4999.339], "images_per_second": 0.2, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " television: 1, sofa: 1, television stand: 1, television stand: 1, sofa cushion: 1, television stand: 1, television stand: 1, television stand: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12600.9, "ram_available_mb": 50240.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.762}, "power_stats": {"power_gpu_soc_mean_watts": 19.561, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 72.762}, "timestamp": "2026-01-28T13:43:51.572570"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5666.312, "latencies_ms": [5666.312], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The sofa is located in the foreground of the image, with the television set and other decorative items placed on the left side of the sofa. The plants are positioned in the background, with the largest one on the wall above the sofa and the smaller ones on the windowsill.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12598.6, "ram_available_mb": 50242.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.659, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 72.021}, "timestamp": "2026-01-28T13:43:59.287373"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3108.797, "latencies_ms": [3108.797], "images_per_second": 0.322, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A living room with a brown couch, a TV, and a coffee table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.6, "ram_available_mb": 50242.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12599.7, "ram_available_mb": 50241.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.346}, "power_stats": {"power_gpu_soc_mean_watts": 23.017, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 7.824, "gpu_utilization_percent_mean": 80.346}, "timestamp": "2026-01-28T13:44:04.423492"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4355.866, "latencies_ms": [4355.866], "images_per_second": 0.23, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the windows, and the walls are painted white. The furniture is made of wood and the floor is covered with a carpet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.7, "ram_available_mb": 50241.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12599.5, "ram_available_mb": 50241.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.753, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 74.861}, "timestamp": "2026-01-28T13:44:10.822720"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3671.924, "latencies_ms": [3671.924], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A woman in a red dress and white visor is holding a tennis racket and smiling on a clay tennis court.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12599.5, "ram_available_mb": 50241.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.7}, "power_stats": {"power_gpu_soc_mean_watts": 21.873, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 75.7}, "timestamp": "2026-01-28T13:44:16.543411"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6117.605, "latencies_ms": [6117.605], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. woman: 1\n2. tennis racket: 1\n3. visor: 1\n4. tennis ball: 0\n5. tennis court: 1\n6. green fence: 1\n7. white line: 1\n8. white cloth: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.922}, "power_stats": {"power_gpu_soc_mean_watts": 18.38, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 7.692, "gpu_utilization_percent_mean": 72.922}, "timestamp": "2026-01-28T13:44:24.705162"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4622.743, "latencies_ms": [4622.743], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, holding a tennis racket and smiling. The tennis court is in the background, with the green fence and white lines marking the boundaries.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.526}, "power_stats": {"power_gpu_soc_mean_watts": 20.124, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 74.526}, "timestamp": "2026-01-28T13:44:31.364060"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3326.717, "latencies_ms": [3326.717], "images_per_second": 0.301, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A female tennis player is on a clay court, holding a tennis racket and smiling.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12599.8, "ram_available_mb": 50241.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.449, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 80.63}, "timestamp": "2026-01-28T13:44:36.717081"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3786.439, "latencies_ms": [3786.439], "images_per_second": 0.264, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The tennis player is wearing a red dress and a white visor. The court is made of red clay and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.8, "ram_available_mb": 50241.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.774}, "power_stats": {"power_gpu_soc_mean_watts": 21.735, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 75.774}, "timestamp": "2026-01-28T13:44:42.523296"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4249.798, "latencies_ms": [4249.798], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image captures a bustling city street lined with a variety of shops and restaurants, including a prominent \"Omni-Restaurant\" sign, under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.623, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 76.057}, "timestamp": "2026-01-28T13:44:48.808215"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5692.924, "latencies_ms": [5692.924], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. car: 4\n2. street: 1\n3. building: 10\n4. sign: 10\n5. person: 2\n6. table: 1\n7. streetlight: 1\n8. airplane: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.646}, "power_stats": {"power_gpu_soc_mean_watts": 18.753, "power_cpu_cv_mean_watts": 2.036, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 71.646}, "timestamp": "2026-01-28T13:44:56.533573"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5652.884, "latencies_ms": [5652.884], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The main objects in the image are the cars on the street, the buildings, and the people sitting at the outdoor tables. The cars are located in the foreground, while the buildings are in the background. The people are sitting at the outdoor tables, which are located near the buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.255}, "power_stats": {"power_gpu_soc_mean_watts": 18.741, "power_cpu_cv_mean_watts": 2.02, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 71.255}, "timestamp": "2026-01-28T13:45:04.206610"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4184.822, "latencies_ms": [4184.822], "images_per_second": 0.239, "prompt_tokens": 1111, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image captures a bustling city street lined with a variety of shops and restaurants. The street is filled with cars and people going about their day, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12598.7, "ram_available_mb": 50242.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.629}, "power_stats": {"power_gpu_soc_mean_watts": 21.07, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 75.629}, "timestamp": "2026-01-28T13:45:10.412120"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6492.534, "latencies_ms": [6492.534], "images_per_second": 0.154, "prompt_tokens": 1109, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image depicts a bustling city street with a variety of colors, including the red brick buildings, the green awnings of the restaurants, and the white cars parked along the street. The lighting is natural, with the sun casting shadows on the buildings and the street. The weather appears to be overcast, with a gray sky and no visible sunshine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.236}, "power_stats": {"power_gpu_soc_mean_watts": 18.062, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 7.685, "gpu_utilization_percent_mean": 71.236}, "timestamp": "2026-01-28T13:45:18.943346"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3684.167, "latencies_ms": [3684.167], "images_per_second": 0.271, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A female tennis player in a red outfit is playing a tennis match on a blue court, with a tennis ball in the air.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12598.2, "ram_available_mb": 50242.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.935}, "power_stats": {"power_gpu_soc_mean_watts": 21.852, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 77.935}, "timestamp": "2026-01-28T13:45:24.699006"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6079.575, "latencies_ms": [6079.575], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. tennis racket: 1\n2. tennis ball: 1\n3. tennis player: 1\n4. tennis court: 1\n5. white line: 1\n6. blue surface: 1\n7. green surface: 1\n8. white shoes: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12597.5, "ram_available_mb": 50243.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.922}, "power_stats": {"power_gpu_soc_mean_watts": 18.363, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 7.704, "gpu_utilization_percent_mean": 70.922}, "timestamp": "2026-01-28T13:45:32.821659"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4415.19, "latencies_ms": [4415.19], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball located in the center. The player is in the foreground, while the tennis court extends into the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12598.5, "ram_available_mb": 50242.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.919}, "power_stats": {"power_gpu_soc_mean_watts": 20.569, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 73.919}, "timestamp": "2026-01-28T13:45:39.260782"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3712.041, "latencies_ms": [3712.041], "images_per_second": 0.269, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A female tennis player is playing on a green court with a blue boundary line. She is wearing a red outfit and white shoes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.5, "ram_available_mb": 50242.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12597.8, "ram_available_mb": 50243.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.731, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 76.161}, "timestamp": "2026-01-28T13:45:45.022118"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3484.996, "latencies_ms": [3484.996], "images_per_second": 0.287, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The tennis player is wearing a red outfit and white shoes, and the court is blue with a green surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.8, "ram_available_mb": 50243.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.31}, "power_stats": {"power_gpu_soc_mean_watts": 22.223, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 78.31}, "timestamp": "2026-01-28T13:45:50.531474"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3751.981, "latencies_ms": [3751.981], "images_per_second": 0.267, "prompt_tokens": 1432, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A blue and orange train is traveling on a track through a wooded area.", "error": null, "sys_before": {"cpu_percent": 8.1, "ram_used_mb": 12597.0, "ram_available_mb": 50243.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12596.6, "ram_available_mb": 50244.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.419}, "power_stats": {"power_gpu_soc_mean_watts": 24.279, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 84.419}, "timestamp": "2026-01-28T13:45:56.365707"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6329.568, "latencies_ms": [6329.568], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. train: 1\n2. tracks: 1\n3. bushes: 1\n4. trees: 1\n5. grass: 1\n6. train car: 1\n7. windows: 1\n8. doors: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12596.6, "ram_available_mb": 50244.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12595.7, "ram_available_mb": 50245.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.396}, "power_stats": {"power_gpu_soc_mean_watts": 20.685, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 72.396}, "timestamp": "2026-01-28T13:46:04.754331"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5189.874, "latencies_ms": [5189.874], "images_per_second": 0.193, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, moving towards the right. The train is in the foreground, with the tracks curving to the left in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.7, "ram_available_mb": 50245.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12595.8, "ram_available_mb": 50245.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.477}, "power_stats": {"power_gpu_soc_mean_watts": 21.501, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.948, "gpu_utilization_percent_mean": 76.477}, "timestamp": "2026-01-28T13:46:11.973174"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3812.277, "latencies_ms": [3812.277], "images_per_second": 0.262, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A blue and orange train is traveling down a track through a wooded area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.8, "ram_available_mb": 50245.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.531}, "power_stats": {"power_gpu_soc_mean_watts": 24.517, "power_cpu_cv_mean_watts": 1.389, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 86.531}, "timestamp": "2026-01-28T13:46:17.812811"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3618.268, "latencies_ms": [3618.268], "images_per_second": 0.276, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The train is blue and orange, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.933}, "power_stats": {"power_gpu_soc_mean_watts": 25.046, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.166, "gpu_utilization_percent_mean": 85.933}, "timestamp": "2026-01-28T13:46:23.464649"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3442.412, "latencies_ms": [3442.412], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two tabby cats are sleeping on a pink blanket, with a remote control on the left cat's back.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12595.6, "ram_available_mb": 50245.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12594.9, "ram_available_mb": 50245.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.57, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 7.831, "gpu_utilization_percent_mean": 79.286}, "timestamp": "2026-01-28T13:46:28.937357"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5589.767, "latencies_ms": [5589.767], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cat: 2\n2. remote control: 2\n3. blanket: 1\n4. couch: 1\n5. tail: 2\n6. paw: 2\n7. head: 1\n8. body: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12594.9, "ram_available_mb": 50245.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.053, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T13:46:36.549450"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6027.277, "latencies_ms": [6027.277], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The two cats are lying on a pink blanket, with the larger cat on the left and the smaller cat on the right. The larger cat is positioned closer to the camera than the smaller cat. The remote controls are placed on the blanket, with one on the left side and the other on the right side of the cats.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.314}, "power_stats": {"power_gpu_soc_mean_watts": 18.424, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 70.314}, "timestamp": "2026-01-28T13:46:44.592621"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2993.75, "latencies_ms": [2993.75], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two tabby cats are sleeping on a pink blanket on a couch.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12594.7, "ram_available_mb": 50246.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.213, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 82.08}, "timestamp": "2026-01-28T13:46:49.631087"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4178.895, "latencies_ms": [4178.895], "images_per_second": 0.239, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features two tabby cats sleeping on a pink blanket, with one cat having a green collar. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12594.7, "ram_available_mb": 50246.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12594.8, "ram_available_mb": 50246.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.886}, "power_stats": {"power_gpu_soc_mean_watts": 21.069, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.794, "gpu_utilization_percent_mean": 74.886}, "timestamp": "2026-01-28T13:46:55.848452"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4574.585, "latencies_ms": [4574.585], "images_per_second": 0.219, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a person clad in a black wetsuit is skillfully riding a wave in a river, while another individual stands on the riverbank, holding a blue surfboard, observing the scene.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12594.8, "ram_available_mb": 50246.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.206, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 72.658}, "timestamp": "2026-01-28T13:47:02.472862"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5507.377, "latencies_ms": [5507.377], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. river: 1\n4. tree: 1\n5. bridge: 1\n6. bench: 1\n7. sign: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12595.1, "ram_available_mb": 50245.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.37}, "power_stats": {"power_gpu_soc_mean_watts": 19.2, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 72.37}, "timestamp": "2026-01-28T13:47:09.997725"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5765.985, "latencies_ms": [5765.985], "images_per_second": 0.173, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding the waves towards the right side of the image. The river is located in the middle ground, with the surfer's location being closer to the viewer. The background features a bridge and trees, providing a sense of depth and scale to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.1, "ram_available_mb": 50245.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.429}, "power_stats": {"power_gpu_soc_mean_watts": 18.776, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 71.429}, "timestamp": "2026-01-28T13:47:17.810251"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3900.025, "latencies_ms": [3900.025], "images_per_second": 0.256, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a wetsuit is surfing on a river with a blue surfboard. The river is surrounded by trees and a bridge.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12595.1, "ram_available_mb": 50245.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.377, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 79.344}, "timestamp": "2026-01-28T13:47:23.741306"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4928.635, "latencies_ms": [4928.635], "images_per_second": 0.203, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features a surfer in a black wetsuit riding a wave in a river, with the water appearing white and foamy. The lighting is natural, suggesting daytime, and the sky is not visible in the frame.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12595.1, "ram_available_mb": 50245.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.683}, "power_stats": {"power_gpu_soc_mean_watts": 19.872, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 73.683}, "timestamp": "2026-01-28T13:47:30.700272"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3883.023, "latencies_ms": [3883.023], "images_per_second": 0.258, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman and a child are flying a colorful kite in a park on a sunny day.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12595.3, "ram_available_mb": 50245.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.125}, "power_stats": {"power_gpu_soc_mean_watts": 24.018, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 8.157, "gpu_utilization_percent_mean": 84.125}, "timestamp": "2026-01-28T13:47:36.628273"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6362.569, "latencies_ms": [6362.569], "images_per_second": 0.157, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. child: 1\n3. kite: 1\n4. grass: 1\n5. trees: 1\n6. sky: 1\n7. person's hand: 1\n8. backpack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12594.6, "ram_available_mb": 50246.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.811}, "power_stats": {"power_gpu_soc_mean_watts": 20.773, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 75.811}, "timestamp": "2026-01-28T13:47:45.024576"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5775.786, "latencies_ms": [5775.786], "images_per_second": 0.173, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the person is in the background, standing on the grass. The person is holding the kite string, which is in the foreground, and the kite is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12595.4, "ram_available_mb": 50245.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.898}, "power_stats": {"power_gpu_soc_mean_watts": 21.449, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 75.898}, "timestamp": "2026-01-28T13:47:52.821362"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3711.973, "latencies_ms": [3711.973], "images_per_second": 0.269, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A woman and a child are flying a kite in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12595.8, "ram_available_mb": 50245.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.323}, "power_stats": {"power_gpu_soc_mean_watts": 24.665, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 86.323}, "timestamp": "2026-01-28T13:47:58.560838"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5874.802, "latencies_ms": [5874.802], "images_per_second": 0.17, "prompt_tokens": 1442, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a vibrant scene of a woman and a child flying a kite in a park on a sunny day. The kite is a striking combination of pink, purple, and orange colors, and the woman is wearing a black jacket and blue jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12595.8, "ram_available_mb": 50245.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12596.9, "ram_available_mb": 50244.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.429}, "power_stats": {"power_gpu_soc_mean_watts": 21.295, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 75.429}, "timestamp": "2026-01-28T13:48:06.467423"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4391.223, "latencies_ms": [4391.223], "images_per_second": 0.228, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A young boy is playing tennis on a court, wearing a red cap and a white shirt, and is about to hit a yellow tennis ball with a yellow and black tennis racket.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12596.9, "ram_available_mb": 50244.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12596.9, "ram_available_mb": 50244.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.459}, "power_stats": {"power_gpu_soc_mean_watts": 20.385, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 74.459}, "timestamp": "2026-01-28T13:48:12.925380"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5847.901, "latencies_ms": [5847.901], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. ball: 1\n4. tennis court: 1\n5. net: 1\n6. green tarp: 1\n7. sign: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.9, "ram_available_mb": 50244.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12596.2, "ram_available_mb": 50244.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.082}, "power_stats": {"power_gpu_soc_mean_watts": 18.631, "power_cpu_cv_mean_watts": 1.97, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 71.082}, "timestamp": "2026-01-28T13:48:20.788266"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6454.365, "latencies_ms": [6454.365], "images_per_second": 0.155, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The main objects are the tennis player, the tennis ball, and the tennis racket. The tennis player is in the foreground, the tennis ball is in the middle ground, and the tennis racket is in the background. The tennis player is to the left of the tennis ball, and the tennis racket is to the right of the tennis ball.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12596.2, "ram_available_mb": 50244.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.145}, "power_stats": {"power_gpu_soc_mean_watts": 18.128, "power_cpu_cv_mean_watts": 2.017, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 72.145}, "timestamp": "2026-01-28T13:48:29.258343"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3396.716, "latencies_ms": [3396.716], "images_per_second": 0.294, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young boy is playing tennis on a court. He is wearing a red hat and a white shirt.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.491, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 78.214}, "timestamp": "2026-01-28T13:48:34.688826"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4682.496, "latencies_ms": [4682.496], "images_per_second": 0.214, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a young boy playing tennis on a green court with a blue net. The boy is wearing a red cap and a white shirt. The lighting is bright and sunny, and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.0, "ram_available_mb": 50244.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12596.7, "ram_available_mb": 50244.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.161, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 72.333}, "timestamp": "2026-01-28T13:48:41.396619"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4282.338, "latencies_ms": [4282.338], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a room with a bed, a chair, and a desk, all of which are covered in various items such as clothes, boxes, and a trash can.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12596.7, "ram_available_mb": 50244.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12596.2, "ram_available_mb": 50244.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.944}, "power_stats": {"power_gpu_soc_mean_watts": 20.463, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 73.944}, "timestamp": "2026-01-28T13:48:47.747089"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5527.903, "latencies_ms": [5527.903], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. chair: 1\n3. desk: 1\n4. box: 1\n5. blanket: 1\n6. pillow: 1\n7. door: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12596.2, "ram_available_mb": 50244.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12596.5, "ram_available_mb": 50244.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.17}, "power_stats": {"power_gpu_soc_mean_watts": 18.853, "power_cpu_cv_mean_watts": 2.037, "power_sys_5v0_mean_watts": 7.784, "gpu_utilization_percent_mean": 72.17}, "timestamp": "2026-01-28T13:48:55.306923"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5554.264, "latencies_ms": [5554.264], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the chair and desk situated on the right side. The desk is positioned closer to the camera than the chair, which is near the door. The bed is in the foreground, while the door is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12596.5, "ram_available_mb": 50244.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.426}, "power_stats": {"power_gpu_soc_mean_watts": 18.784, "power_cpu_cv_mean_watts": 2.037, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 70.426}, "timestamp": "2026-01-28T13:49:02.877710"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3168.29, "latencies_ms": [3168.29], "images_per_second": 0.316, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The room is a bedroom with a bed, a chair, and a desk.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12595.9, "ram_available_mb": 50245.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.038}, "power_stats": {"power_gpu_soc_mean_watts": 22.785, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 76.038}, "timestamp": "2026-01-28T13:49:08.098349"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3384.45, "latencies_ms": [3384.45], "images_per_second": 0.295, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is lit by natural light coming from a window, and the walls are made of brick.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.43, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 76.357}, "timestamp": "2026-01-28T13:49:13.546581"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3450.848, "latencies_ms": [3450.848], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman in a red and green outfit is riding a brown horse over a jump obstacle in a field.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12596.3, "ram_available_mb": 50244.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.571}, "power_stats": {"power_gpu_soc_mean_watts": 22.388, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 77.571}, "timestamp": "2026-01-28T13:49:19.033573"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4708.69, "latencies_ms": [4708.69], "images_per_second": 0.212, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " horse: 1, rider: 1, saddle: 1, bridle: 1, leg: 2, leg protection: 2, helmet: 1, number: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12597.3, "ram_available_mb": 50243.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12598.0, "ram_available_mb": 50242.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.564}, "power_stats": {"power_gpu_soc_mean_watts": 19.915, "power_cpu_cv_mean_watts": 2.26, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 72.564}, "timestamp": "2026-01-28T13:49:25.775782"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5058.806, "latencies_ms": [5058.806], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The horse is in the foreground, jumping over the obstacle, while the rider is in the background, wearing a helmet and a red and green jacket. The horse's legs are near the obstacle, while the rider's legs are further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.0, "ram_available_mb": 50242.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12598.1, "ram_available_mb": 50242.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.442}, "power_stats": {"power_gpu_soc_mean_watts": 19.471, "power_cpu_cv_mean_watts": 1.975, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 71.442}, "timestamp": "2026-01-28T13:49:32.873606"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3407.358, "latencies_ms": [3407.358], "images_per_second": 0.293, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman in a red and green outfit is riding a brown horse over a jump obstacle in a field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12598.1, "ram_available_mb": 50242.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.488, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 7.78, "gpu_utilization_percent_mean": 80.464}, "timestamp": "2026-01-28T13:49:38.316537"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5443.889, "latencies_ms": [5443.889], "images_per_second": 0.184, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a vibrant scene with a brown horse and rider jumping over a wooden fence, set against a backdrop of lush green trees and a clear blue sky. The horse's coat gleams under the sunlight, while the rider's attire stands out with its bright colors.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.267}, "power_stats": {"power_gpu_soc_mean_watts": 19.031, "power_cpu_cv_mean_watts": 1.967, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 73.267}, "timestamp": "2026-01-28T13:49:45.787745"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3779.407, "latencies_ms": [3779.407], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two men are sitting under a large umbrella on a sidewalk, with a car parked behind them and a bicycle leaning against a wall.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12599.4, "ram_available_mb": 50241.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12600.1, "ram_available_mb": 50240.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.387}, "power_stats": {"power_gpu_soc_mean_watts": 21.603, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 76.387}, "timestamp": "2026-01-28T13:49:51.628761"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5535.416, "latencies_ms": [5535.416], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. umbrella: 1\n2. man: 2\n3. chair: 1\n4. table: 1\n5. car: 1\n6. bicycle: 1\n7. sign: 1\n8. street: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.1, "ram_available_mb": 50240.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12600.3, "ram_available_mb": 50240.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.962, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 71.021}, "timestamp": "2026-01-28T13:49:59.206609"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4538.881, "latencies_ms": [4538.881], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The man sitting on the chair is to the left of the man standing, and the man standing is in the foreground. The man sitting on the chair is closer to the camera than the man standing.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12600.3, "ram_available_mb": 50240.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12599.9, "ram_available_mb": 50241.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.737}, "power_stats": {"power_gpu_soc_mean_watts": 20.324, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 70.737}, "timestamp": "2026-01-28T13:50:05.790350"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3300.901, "latencies_ms": [3300.901], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two men are sitting under a large umbrella on a sidewalk, with a car parked behind them.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12599.9, "ram_available_mb": 50241.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12600.5, "ram_available_mb": 50240.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.773, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 80.296}, "timestamp": "2026-01-28T13:50:11.111028"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4020.97, "latencies_ms": [4020.97], "images_per_second": 0.249, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is in black and white, with the exception of the man's white shirt. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12600.5, "ram_available_mb": 50240.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.121}, "power_stats": {"power_gpu_soc_mean_watts": 21.387, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 76.121}, "timestamp": "2026-01-28T13:50:17.150662"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4082.774, "latencies_ms": [4082.774], "images_per_second": 0.245, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a kitchen with white cabinets, a white stove, and a white refrigerator, all of which are situated in a room with a tiled floor.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12601.3, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.147}, "power_stats": {"power_gpu_soc_mean_watts": 20.935, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 75.147}, "timestamp": "2026-01-28T13:50:23.262558"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4624.597, "latencies_ms": [4624.597], "images_per_second": 0.216, "prompt_tokens": 1114, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. white cabinets\n2. white refrigerator\n3. white stove\n4. white dishwasher\n5. white oven\n6. white sink\n7. white microwave\n8. white toaster", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.3, "ram_available_mb": 50239.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.231}, "power_stats": {"power_gpu_soc_mean_watts": 20.273, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 74.231}, "timestamp": "2026-01-28T13:50:29.907321"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4945.914, "latencies_ms": [4945.914], "images_per_second": 0.202, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The stove is located to the left of the sink, and the refrigerator is positioned to the right of the sink. The sink is situated in the middle of the kitchen, with the stove and refrigerator flanking it on either side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12601.2, "ram_available_mb": 50239.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.738}, "power_stats": {"power_gpu_soc_mean_watts": 19.809, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 73.738}, "timestamp": "2026-01-28T13:50:36.871876"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4364.984, "latencies_ms": [4364.984], "images_per_second": 0.229, "prompt_tokens": 1112, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a kitchen with white cabinets, a white stove, and a white refrigerator. There is a ceiling fan hanging from the ceiling, and a clock is hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12601.2, "ram_available_mb": 50239.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.389}, "power_stats": {"power_gpu_soc_mean_watts": 20.506, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 73.389}, "timestamp": "2026-01-28T13:50:43.298445"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3428.433, "latencies_ms": [3428.433], "images_per_second": 0.292, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light coming through the windows, and the cabinets are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12600.7, "ram_available_mb": 50240.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.502, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 78.679}, "timestamp": "2026-01-28T13:50:48.747188"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4582.382, "latencies_ms": [4582.382], "images_per_second": 0.218, "prompt_tokens": 1100, "response_tokens_est": 41, "n_tiles": 1, "output_text": " A young child is sleeping in a bed with a blue and white checkered blanket, wearing a white tank top and blue pajama pants with a pattern of white daisies and other shapes.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12600.7, "ram_available_mb": 50240.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.483, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 72.237}, "timestamp": "2026-01-28T13:50:55.364840"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4109.414, "latencies_ms": [4109.414], "images_per_second": 0.243, "prompt_tokens": 1114, "response_tokens_est": 32, "n_tiles": 1, "output_text": " 1. child\n2. bed\n3. pillow\n4. blanket\n5. wall\n6. television\n7. cable\n8. light", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.8, "ram_available_mb": 50240.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12600.2, "ram_available_mb": 50240.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.529}, "power_stats": {"power_gpu_soc_mean_watts": 21.242, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 75.529}, "timestamp": "2026-01-28T13:51:01.493429"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4784.57, "latencies_ms": [4784.57], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The child is lying on the bed, which is positioned in the foreground of the image. The bed is situated in the middle of the room, with the wall and a television mounted on it in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12600.2, "ram_available_mb": 50240.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12600.3, "ram_available_mb": 50240.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.475}, "power_stats": {"power_gpu_soc_mean_watts": 19.787, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 75.475}, "timestamp": "2026-01-28T13:51:08.314011"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3311.684, "latencies_ms": [3311.684], "images_per_second": 0.302, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A young child is sleeping in a small room with a blue and white checkered blanket.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12600.1, "ram_available_mb": 50240.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12600.5, "ram_available_mb": 50240.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.281, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 80.222}, "timestamp": "2026-01-28T13:51:13.671286"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5106.828, "latencies_ms": [5106.828], "images_per_second": 0.196, "prompt_tokens": 1110, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a child sleeping on a bed. The child is wearing a white tank top and blue patterned pajama pants. The bed has a blue and white checkered comforter.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12600.5, "ram_available_mb": 50240.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12600.1, "ram_available_mb": 50240.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.233}, "power_stats": {"power_gpu_soc_mean_watts": 19.189, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 73.233}, "timestamp": "2026-01-28T13:51:20.808287"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3604.978, "latencies_ms": [3604.978], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A green highway sign with the words \"No Trucks\" and \"Eat\" on it is hanging from a metal structure.", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 12600.1, "ram_available_mb": 50240.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12599.9, "ram_available_mb": 50241.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.967}, "power_stats": {"power_gpu_soc_mean_watts": 22.138, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 77.967}, "timestamp": "2026-01-28T13:51:26.476832"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5680.726, "latencies_ms": [5680.726], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 1\n2. graffiti: 1\n3. bridge: 1\n4. road: 1\n5. highway: 1\n6. highway sign: 1\n7. metal: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.9, "ram_available_mb": 50241.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.468}, "power_stats": {"power_gpu_soc_mean_watts": 18.904, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 70.468}, "timestamp": "2026-01-28T13:51:34.192758"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4592.867, "latencies_ms": [4592.867], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The green highway sign is positioned in the foreground, with the metal bridge structure in the background. The sign is to the left of the bridge, and the bridge is to the right of the sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.3, "ram_available_mb": 50241.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.421}, "power_stats": {"power_gpu_soc_mean_watts": 20.122, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 75.421}, "timestamp": "2026-01-28T13:51:40.807506"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3632.256, "latencies_ms": [3632.256], "images_per_second": 0.275, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A green highway sign with the words \"No Trucks\" and \"Eat\" on it is hanging from a metal structure.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12598.9, "ram_available_mb": 50242.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12599.2, "ram_available_mb": 50241.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.267}, "power_stats": {"power_gpu_soc_mean_watts": 21.99, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 76.267}, "timestamp": "2026-01-28T13:51:46.452847"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3792.947, "latencies_ms": [3792.947], "images_per_second": 0.264, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The sign is green with white lettering and has a black border. The sky is overcast and the sign is lit by natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12599.2, "ram_available_mb": 50241.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12599.2, "ram_available_mb": 50241.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.812}, "power_stats": {"power_gpu_soc_mean_watts": 21.842, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 76.812}, "timestamp": "2026-01-28T13:51:52.302452"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3762.192, "latencies_ms": [3762.192], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A red Chevrolet pickup truck is parked in a parking lot, with a tall light pole and a green canopy in the background.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12599.0, "ram_available_mb": 50241.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.798, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 73.71}, "timestamp": "2026-01-28T13:51:58.095593"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4683.495, "latencies_ms": [4683.495], "images_per_second": 0.214, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. red truck\n2. white wheels\n3. white license plate\n4. green canopy\n5. blue flag\n6. white light\n7. black tires\n8. silver exhaust", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12603.8, "ram_available_mb": 50237.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.395}, "power_stats": {"power_gpu_soc_mean_watts": 20.269, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 74.395}, "timestamp": "2026-01-28T13:52:04.789359"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4881.173, "latencies_ms": [4881.173], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The red pickup truck is positioned in the foreground of the image, with the blue pickup truck in the background. The truck is parked on the left side of the image, while the street lamp is located on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.8, "ram_available_mb": 50237.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12603.6, "ram_available_mb": 50237.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.04, "power_cpu_cv_mean_watts": 1.742, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T13:52:11.684032"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3610.258, "latencies_ms": [3610.258], "images_per_second": 0.277, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A red Chevrolet pickup truck is parked in a parking lot, with a blue flag flying in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12603.6, "ram_available_mb": 50237.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.125, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-28T13:52:17.320990"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3426.395, "latencies_ms": [3426.395], "images_per_second": 0.292, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The truck is red with chrome wheels and a shiny finish. The sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.929}, "power_stats": {"power_gpu_soc_mean_watts": 22.388, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 77.929}, "timestamp": "2026-01-28T13:52:22.766820"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3647.132, "latencies_ms": [3647.132], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In this black and white photo, a group of cows are standing behind a barbed wire fence, looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 14.8, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.99, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 77.5}, "timestamp": "2026-01-28T13:52:28.443834"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5662.867, "latencies_ms": [5662.867], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. barbed wire: 1\n2. cows: 5\n3. grass: 1\n4. fence: 1\n5. trees: 2\n6. clouds: 1\n7. sky: 1\n8. fence post: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.521}, "power_stats": {"power_gpu_soc_mean_watts": 18.651, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 71.521}, "timestamp": "2026-01-28T13:52:36.152492"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3849.568, "latencies_ms": [3849.568], "images_per_second": 0.26, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The cows are positioned in the foreground of the image, with the barbed wire fence in the middle ground, and the distant landscape in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.281}, "power_stats": {"power_gpu_soc_mean_watts": 21.68, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 76.281}, "timestamp": "2026-01-28T13:52:42.041378"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3379.375, "latencies_ms": [3379.375], "images_per_second": 0.296, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of cows are standing in a field behind a barbed wire fence, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.7, "ram_available_mb": 50239.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.036}, "power_stats": {"power_gpu_soc_mean_watts": 22.288, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 80.036}, "timestamp": "2026-01-28T13:52:47.447443"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3555.264, "latencies_ms": [3555.264], "images_per_second": 0.281, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is in black and white, with a barbed wire fence in the foreground and a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.417, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 77.552}, "timestamp": "2026-01-28T13:52:53.034948"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4095.064, "latencies_ms": [4095.064], "images_per_second": 0.244, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed, a comfortable chair, and a fireplace, all set against a warm and inviting backdrop of wooden walls and ceiling.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12601.9, "ram_available_mb": 50239.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12602.0, "ram_available_mb": 50238.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.219, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 73.324}, "timestamp": "2026-01-28T13:52:59.177975"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5791.203, "latencies_ms": [5791.203], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. bed: 1\n2. clock: 1\n3. television: 1\n4. chair: 2\n5. ottoman: 1\n6. fireplace: 1\n7. window blinds: 1\n8. lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.0, "ram_available_mb": 50238.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.551}, "power_stats": {"power_gpu_soc_mean_watts": 18.582, "power_cpu_cv_mean_watts": 2.043, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 70.551}, "timestamp": "2026-01-28T13:53:07.029118"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5213.651, "latencies_ms": [5213.651], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the clock above it. The fireplace is on the right side of the room, with the television above it. The chair is in the middle of the room, with the window behind it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.682}, "power_stats": {"power_gpu_soc_mean_watts": 19.31, "power_cpu_cv_mean_watts": 1.975, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 72.682}, "timestamp": "2026-01-28T13:53:14.299345"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5048.295, "latencies_ms": [5048.295], "images_per_second": 0.198, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed, a fireplace, and a television. The room is well-lit with warm lighting, and there are several pieces of furniture, including a chair, a bench, and a dresser.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.786}, "power_stats": {"power_gpu_soc_mean_watts": 19.504, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 71.786}, "timestamp": "2026-01-28T13:53:21.378321"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3611.297, "latencies_ms": [3611.297], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a wooden ceiling and walls, and a fireplace with a stone surround.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.2}, "power_stats": {"power_gpu_soc_mean_watts": 21.817, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 78.2}, "timestamp": "2026-01-28T13:53:27.015399"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4843.27, "latencies_ms": [4843.27], "images_per_second": 0.206, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " In the image, there are three birds with black feathers and white spots, standing on a dry, grassy field, with one bird having a blue head and red neck, and another bird having a red head and blue neck.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.05}, "power_stats": {"power_gpu_soc_mean_watts": 19.837, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 74.05}, "timestamp": "2026-01-28T13:53:33.907160"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5508.856, "latencies_ms": [5508.856], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 4\n2. grass: 1\n3. bush: 1\n4. tree: 1\n5. sky: 1\n6. ground: 1\n7. dirt: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.978}, "power_stats": {"power_gpu_soc_mean_watts": 19.096, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 69.978}, "timestamp": "2026-01-28T13:53:41.438365"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5157.091, "latencies_ms": [5157.091], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the two larger birds in the center and the smaller bird to the right. The larger birds are positioned closer to the camera than the smaller bird, which is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.279}, "power_stats": {"power_gpu_soc_mean_watts": 19.274, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 71.279}, "timestamp": "2026-01-28T13:53:48.609612"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3351.277, "latencies_ms": [3351.277], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of birds, possibly guineafowl, are walking on a dry, grassy field.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.533, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 79.071}, "timestamp": "2026-01-28T13:53:53.986136"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3830.216, "latencies_ms": [3830.216], "images_per_second": 0.261, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a group of birds with black feathers and white speckles, standing on a dry, grassy field under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.43, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 76.562}, "timestamp": "2026-01-28T13:53:59.876928"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3418.543, "latencies_ms": [3418.543], "images_per_second": 0.293, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Three people are standing in the snow, wearing winter clothing and holding ski poles, with a forested background.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12603.2, "ram_available_mb": 50237.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.432, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 7.805, "gpu_utilization_percent_mean": 78.5}, "timestamp": "2026-01-28T13:54:05.336796"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5807.2, "latencies_ms": [5807.2], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skis: 3\n2. snow: 1\n3. trees: 1\n4. people: 3\n5. poles: 3\n6. jacket: 1\n7. hat: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.2, "ram_available_mb": 50237.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.714}, "power_stats": {"power_gpu_soc_mean_watts": 17.912, "power_cpu_cv_mean_watts": 2.101, "power_sys_5v0_mean_watts": 7.637, "gpu_utilization_percent_mean": 70.714}, "timestamp": "2026-01-28T13:54:13.171668"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9356.947, "latencies_ms": [9356.947], "images_per_second": 0.107, "prompt_tokens": 1117, "response_tokens_est": 118, "n_tiles": 1, "output_text": " The skier on the left is positioned closer to the camera than the skier in the middle, who is standing slightly behind and to the right of the skier on the left. The skier on the right is positioned furthest from the camera, standing in the background. The skier in the middle is standing on a snow-covered slope, while the skier on the left is standing on a snow-covered hill. The skier on the right is standing on a snow-covered slope, while the skier on the left is standing on a snow-covered hill.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.662}, "power_stats": {"power_gpu_soc_mean_watts": 16.37, "power_cpu_cv_mean_watts": 2.163, "power_sys_5v0_mean_watts": 7.672, "gpu_utilization_percent_mean": 68.662}, "timestamp": "2026-01-28T13:54:24.573731"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3098.65, "latencies_ms": [3098.65], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three people are standing in the snow wearing winter clothing and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12602.2, "ram_available_mb": 50238.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.28, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 76.24}, "timestamp": "2026-01-28T13:54:29.722108"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4672.606, "latencies_ms": [4672.606], "images_per_second": 0.214, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features three people standing in a snowy landscape, wearing winter clothing and holding ski poles. The sky is overcast, and the snow is pristine white, with a few trees visible in the background.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12602.2, "ram_available_mb": 50238.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12602.2, "ram_available_mb": 50238.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.143, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 71.342}, "timestamp": "2026-01-28T13:54:36.418000"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4387.169, "latencies_ms": [4387.169], "images_per_second": 0.228, "prompt_tokens": 1432, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A white city bus with a blue stripe and the number 61 on it is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12602.2, "ram_available_mb": 50238.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.083}, "power_stats": {"power_gpu_soc_mean_watts": 22.842, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 80.083}, "timestamp": "2026-01-28T13:54:42.848834"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6782.777, "latencies_ms": [6782.777], "images_per_second": 0.147, "prompt_tokens": 1446, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Bus: 1\n2. License plate: 1\n3. Bike rack: 1\n4. Side mirror: 1\n5. Headlights: 2\n6. Windshield: 1\n7. Roof rack: 1\n8. Side mirror: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12602.4, "ram_available_mb": 50238.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.14}, "power_stats": {"power_gpu_soc_mean_watts": 20.247, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 74.14}, "timestamp": "2026-01-28T13:54:51.646549"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5395.508, "latencies_ms": [5395.508], "images_per_second": 0.185, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the street and sidewalk on the right. The license plate is located on the front of the bus, near the bottom of the windshield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.4, "ram_available_mb": 50238.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.978}, "power_stats": {"power_gpu_soc_mean_watts": 21.818, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 76.978}, "timestamp": "2026-01-28T13:54:59.074823"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4096.803, "latencies_ms": [4096.803], "images_per_second": 0.244, "prompt_tokens": 1444, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A white city bus with a bike rack on the front is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.118}, "power_stats": {"power_gpu_soc_mean_watts": 24.056, "power_cpu_cv_mean_watts": 1.225, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 82.118}, "timestamp": "2026-01-28T13:55:05.220518"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4049.97, "latencies_ms": [4049.97], "images_per_second": 0.247, "prompt_tokens": 1442, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bus is white with blue and green graphics, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.152}, "power_stats": {"power_gpu_soc_mean_watts": 24.349, "power_cpu_cv_mean_watts": 1.359, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 84.152}, "timestamp": "2026-01-28T13:55:11.285233"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4161.126, "latencies_ms": [4161.126], "images_per_second": 0.24, "prompt_tokens": 768, "response_tokens_est": 46, "n_tiles": 1, "output_text": " A man is standing in front of a wall with a red stripe on the bottom, wearing a blue blazer, a white shirt, a red and blue striped tie, a gray skirt, black tights, and black shoes.", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12603.6, "ram_available_mb": 50237.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.648, "power_cpu_cv_mean_watts": 2.518, "power_sys_5v0_mean_watts": 7.668, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-28T13:55:17.499844"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4781.612, "latencies_ms": [4781.612], "images_per_second": 0.209, "prompt_tokens": 782, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. suit: 1\n2. tie: 1\n3. shirt: 1\n4. tie: 1\n5. skirt: 1\n6. bag: 1\n7. shoes: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.6, "ram_available_mb": 50237.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.725}, "power_stats": {"power_gpu_soc_mean_watts": 17.516, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 7.68, "gpu_utilization_percent_mean": 69.725}, "timestamp": "2026-01-28T13:55:24.319463"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3918.193, "latencies_ms": [3918.193], "images_per_second": 0.255, "prompt_tokens": 786, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is standing in the foreground of the image, with the red carpet and white wall in the background. The black bag is held in his left hand, while his right hand is resting on his hip.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.515}, "power_stats": {"power_gpu_soc_mean_watts": 18.548, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 70.515}, "timestamp": "2026-01-28T13:55:30.272218"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3356.738, "latencies_ms": [3356.738], "images_per_second": 0.298, "prompt_tokens": 780, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man is standing in front of a wall with a red stripe on it. He is wearing a blue blazer, a white shirt, and a tie.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12602.5, "ram_available_mb": 50238.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12602.0, "ram_available_mb": 50238.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.074}, "power_stats": {"power_gpu_soc_mean_watts": 19.775, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 71.074}, "timestamp": "2026-01-28T13:55:35.652288"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3552.119, "latencies_ms": [3552.119], "images_per_second": 0.282, "prompt_tokens": 778, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with a red carpet on the floor. The man is wearing a blue blazer, a white shirt, and a tie.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12602.0, "ram_available_mb": 50238.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12600.9, "ram_available_mb": 50240.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.31}, "power_stats": {"power_gpu_soc_mean_watts": 19.242, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 70.31}, "timestamp": "2026-01-28T13:55:41.245470"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5513.661, "latencies_ms": [5513.661], "images_per_second": 0.181, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a serene scene of a railway track shrouded in a hazy mist, with numerous train cars lined up in a row, their metallic bodies gleaming under the soft light, and the sky above them painted in a muted palette of grays and browns.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12600.9, "ram_available_mb": 50240.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12600.6, "ram_available_mb": 50240.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.826}, "power_stats": {"power_gpu_soc_mean_watts": 19.106, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 71.826}, "timestamp": "2026-01-28T13:55:48.793081"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5807.729, "latencies_ms": [5807.729], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. train: 3\n2. train tracks: 2\n3. poles: 10\n4. wires: 10\n5. metal pipes: 2\n6. fence: 1\n7. trees: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12600.6, "ram_available_mb": 50240.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.771}, "power_stats": {"power_gpu_soc_mean_watts": 18.727, "power_cpu_cv_mean_watts": 2.036, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 69.771}, "timestamp": "2026-01-28T13:55:56.631167"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4431.276, "latencies_ms": [4431.276], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The trains are positioned on the tracks, with the tracks running parallel to each other. The trains are located in the foreground of the image, while the poles and wires are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12603.2, "ram_available_mb": 50237.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.053}, "power_stats": {"power_gpu_soc_mean_watts": 20.448, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 75.053}, "timestamp": "2026-01-28T13:56:03.106384"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5113.606, "latencies_ms": [5113.606], "images_per_second": 0.196, "prompt_tokens": 1111, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a serene scene of a railway track shrouded in a hazy mist, with numerous train tracks stretching out into the distance. The tracks are lined with a series of metal poles and wires, creating a sense of order amidst the fog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.2, "ram_available_mb": 50237.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.048}, "power_stats": {"power_gpu_soc_mean_watts": 19.801, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 74.048}, "timestamp": "2026-01-28T13:56:10.231397"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4872.492, "latencies_ms": [4872.492], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a sepia-toned photograph with a hazy atmosphere, showcasing a series of train tracks and overhead power lines. The trains are stationary, and the sky is overcast, creating a somber mood.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.585}, "power_stats": {"power_gpu_soc_mean_watts": 19.949, "power_cpu_cv_mean_watts": 1.709, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 72.585}, "timestamp": "2026-01-28T13:56:17.138787"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4078.842, "latencies_ms": [4078.842], "images_per_second": 0.245, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white toilet, a blue stool with a green plant on it, and a pile of clothes and shoes scattered on the floor.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12603.1, "ram_available_mb": 50237.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12603.9, "ram_available_mb": 50237.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.183, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 74.324}, "timestamp": "2026-01-28T13:56:23.264747"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5480.801, "latencies_ms": [5480.801], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 55, "n_tiles": 1, "output_text": " toilet: 1\ntoilet paper: 0\ntoilet brush: 0\ntoilet seat: 1\ntoilet lid: 1\ntoilet tank: 1\ntoilet paper holder: 0\ntoilet paper roll: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.9, "ram_available_mb": 50237.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12603.7, "ram_available_mb": 50237.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.522}, "power_stats": {"power_gpu_soc_mean_watts": 18.864, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 70.522}, "timestamp": "2026-01-28T13:56:30.760993"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4742.427, "latencies_ms": [4742.427], "images_per_second": 0.211, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the bookshelf is on the right side. The clothes are scattered throughout the room, with some near the toilet and others near the bookshelf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.7, "ram_available_mb": 50237.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12603.7, "ram_available_mb": 50237.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.897}, "power_stats": {"power_gpu_soc_mean_watts": 20.028, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 71.897}, "timestamp": "2026-01-28T13:56:37.529879"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3289.382, "latencies_ms": [3289.382], "images_per_second": 0.304, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A messy bathroom with a toilet, a plant, and a bunch of clothes on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.7, "ram_available_mb": 50237.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.311, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 79.63}, "timestamp": "2026-01-28T13:56:42.856296"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3354.665, "latencies_ms": [3354.665], "images_per_second": 0.298, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is lit by natural light coming from a window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.63}, "power_stats": {"power_gpu_soc_mean_watts": 22.756, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 7.8, "gpu_utilization_percent_mean": 80.63}, "timestamp": "2026-01-28T13:56:48.232845"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4255.185, "latencies_ms": [4255.185], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a polar bear is seen playfully interacting with two green and yellow balls in a pool of water, with a rocky background and a sandy shore visible.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.759, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 77.057}, "timestamp": "2026-01-28T13:56:54.519215"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3955.359, "latencies_ms": [3955.359], "images_per_second": 0.253, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " polar bear: 1, ball: 3, water: 1, rock: 1, sand: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12602.7, "ram_available_mb": 50238.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12603.6, "ram_available_mb": 50237.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.455}, "power_stats": {"power_gpu_soc_mean_watts": 21.521, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 76.455}, "timestamp": "2026-01-28T13:57:00.502597"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4571.249, "latencies_ms": [4571.249], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The green and yellow balls are in the foreground, with the polar bear in the background. The polar bear is in the water, which is in the foreground, and the rocks are in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12603.6, "ram_available_mb": 50237.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.438, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 74.342}, "timestamp": "2026-01-28T13:57:07.093267"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3607.923, "latencies_ms": [3607.923], "images_per_second": 0.277, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " In a zoo enclosure, a polar bear is playfully interacting with two green and yellow balls in a pool of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12603.0, "ram_available_mb": 50237.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.767}, "power_stats": {"power_gpu_soc_mean_watts": 21.923, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 76.767}, "timestamp": "2026-01-28T13:57:12.751411"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4340.585, "latencies_ms": [4340.585], "images_per_second": 0.23, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The polar bear is in a pool of water, with a green and yellow ball in its mouth. The lighting is natural, and the bear's fur is wet and matted.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12602.9, "ram_available_mb": 50238.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.722}, "power_stats": {"power_gpu_soc_mean_watts": 20.749, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 74.722}, "timestamp": "2026-01-28T13:57:19.105003"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5116.473, "latencies_ms": [5116.473], "images_per_second": 0.195, "prompt_tokens": 1432, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is a split-screen photo showing a person sitting on a chair with their legs crossed, wearing blue socks and black pants, and holding a silver cell phone with a black screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12602.3, "ram_available_mb": 50238.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12602.1, "ram_available_mb": 50238.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.767}, "power_stats": {"power_gpu_soc_mean_watts": 22.013, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 79.767}, "timestamp": "2026-01-28T13:57:26.266134"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4966.43, "latencies_ms": [4966.43], "images_per_second": 0.201, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " chair: 1, person: 1, cell phone: 1, window: 1, floor: 1, legs: 1, socks: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12602.1, "ram_available_mb": 50238.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.583, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-28T13:57:33.247862"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6348.172, "latencies_ms": [6348.172], "images_per_second": 0.158, "prompt_tokens": 1450, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The left side of the image shows a person sitting on a chair with their legs crossed, with the chair positioned on the left side of the image. The right side of the image shows a person holding a cell phone, with the cell phone positioned on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.698}, "power_stats": {"power_gpu_soc_mean_watts": 20.669, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 75.698}, "timestamp": "2026-01-28T13:57:41.626410"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4082.212, "latencies_ms": [4082.212], "images_per_second": 0.245, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is sitting on a chair with their feet up on the floor, while holding a cell phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12601.8, "ram_available_mb": 50239.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.294}, "power_stats": {"power_gpu_soc_mean_watts": 24.359, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 83.294}, "timestamp": "2026-01-28T13:57:47.727195"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4700.134, "latencies_ms": [4700.134], "images_per_second": 0.213, "prompt_tokens": 1442, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image features a wooden floor with a chair and a person wearing blue jeans. The sky outside the window is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.9}, "power_stats": {"power_gpu_soc_mean_watts": 23.063, "power_cpu_cv_mean_watts": 1.472, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 79.9}, "timestamp": "2026-01-28T13:57:54.475276"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3729.457, "latencies_ms": [3729.457], "images_per_second": 0.268, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A yellow train is traveling down a snowy track, surrounded by trees and bushes.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12601.5, "ram_available_mb": 50239.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.742}, "power_stats": {"power_gpu_soc_mean_watts": 24.481, "power_cpu_cv_mean_watts": 1.305, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 82.742}, "timestamp": "2026-01-28T13:58:00.267733"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6450.871, "latencies_ms": [6450.871], "images_per_second": 0.155, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. train: 1\n2. trees: 4\n3. snow: 1\n4. sky: 1\n5. wires: 1\n6. poles: 1\n7. tracks: 1\n8. snow on train: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12601.4, "ram_available_mb": 50239.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.815}, "power_stats": {"power_gpu_soc_mean_watts": 20.665, "power_cpu_cv_mean_watts": 1.899, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 74.815}, "timestamp": "2026-01-28T13:58:08.740372"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5039.137, "latencies_ms": [5039.137], "images_per_second": 0.198, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The train is moving from the left to the right of the image, while the trees are located in the background. The train is closer to the viewer than the trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12622.1, "ram_available_mb": 50218.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.262}, "power_stats": {"power_gpu_soc_mean_watts": 22.049, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 77.262}, "timestamp": "2026-01-28T13:58:15.817433"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3946.819, "latencies_ms": [3946.819], "images_per_second": 0.253, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A yellow train is traveling down a snowy track, surrounded by trees and bushes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12622.1, "ram_available_mb": 50218.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12622.6, "ram_available_mb": 50218.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.969}, "power_stats": {"power_gpu_soc_mean_watts": 24.244, "power_cpu_cv_mean_watts": 1.364, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 83.969}, "timestamp": "2026-01-28T13:58:21.785623"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4364.955, "latencies_ms": [4364.955], "images_per_second": 0.229, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a yellow train traveling through a snowy landscape, with the sky appearing overcast and the trees covered in snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.6, "ram_available_mb": 50218.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12622.8, "ram_available_mb": 50218.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.917}, "power_stats": {"power_gpu_soc_mean_watts": 23.711, "power_cpu_cv_mean_watts": 1.591, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 77.917}, "timestamp": "2026-01-28T13:58:28.167351"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4175.904, "latencies_ms": [4175.904], "images_per_second": 0.239, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a pile of snow has been piled up on a street, with a black pipe protruding from the snow, and people walking in the background.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12622.8, "ram_available_mb": 50218.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.371}, "power_stats": {"power_gpu_soc_mean_watts": 20.541, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 74.371}, "timestamp": "2026-01-28T13:58:34.387141"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6121.215, "latencies_ms": [6121.215], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. snow: 1000\n2. people: 6\n3. pipe: 1\n4. snowbank: 1\n5. building: 1\n6. road: 1\n7. snowplow: 1\n8. snowdrift: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12619.9, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.235}, "power_stats": {"power_gpu_soc_mean_watts": 18.433, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.705, "gpu_utilization_percent_mean": 69.235}, "timestamp": "2026-01-28T13:58:42.566048"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5944.883, "latencies_ms": [5944.883], "images_per_second": 0.168, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the snow-covered pipe being the closest object to the viewer. The people are in the background, walking away from the camera. The snow-covered area is to the left of the pipe, and the brick building is to the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12619.9, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.306}, "power_stats": {"power_gpu_soc_mean_watts": 18.45, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 7.702, "gpu_utilization_percent_mean": 69.306}, "timestamp": "2026-01-28T13:58:50.525722"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3707.922, "latencies_ms": [3707.922], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In a snowy urban setting, a group of people are walking on a street, with a pile of snow in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.233}, "power_stats": {"power_gpu_soc_mean_watts": 21.858, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 74.233}, "timestamp": "2026-01-28T13:58:56.251375"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4787.931, "latencies_ms": [4787.931], "images_per_second": 0.209, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image depicts a snowy scene with a pile of snow in the foreground, and a group of people walking in the background. The snow is white and fluffy, and the lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12619.3, "ram_available_mb": 50221.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 19.999, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-28T13:59:03.058941"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4984.558, "latencies_ms": [4984.558], "images_per_second": 0.201, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features a street sign with a red and white \"TOW ZONE\" sign, indicating a restricted area for towing, and a yellow sign with a black and white cartoon face, possibly a warning or caution sign.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12619.3, "ram_available_mb": 50221.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12618.4, "ram_available_mb": 50222.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.293}, "power_stats": {"power_gpu_soc_mean_watts": 19.949, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 71.293}, "timestamp": "2026-01-28T13:59:10.112657"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5758.611, "latencies_ms": [5758.611], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sign: 2\n2. pole: 2\n3. tree: 2\n4. building: 1\n5. street light: 1\n6. fence: 1\n7. trash can: 1\n8. car: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12618.4, "ram_available_mb": 50222.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.604}, "power_stats": {"power_gpu_soc_mean_watts": 18.667, "power_cpu_cv_mean_watts": 1.911, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 72.604}, "timestamp": "2026-01-28T13:59:17.908741"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4174.641, "latencies_ms": [4174.641], "images_per_second": 0.24, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The sign is located in the foreground, to the right of the tree, and is near a street. The tree is in the background, behind the sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.793, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 75.029}, "timestamp": "2026-01-28T13:59:24.110945"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3545.589, "latencies_ms": [3545.589], "images_per_second": 0.282, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image captures a street scene with a sign indicating a tow zone, surrounded by lush green trees and buildings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.655}, "power_stats": {"power_gpu_soc_mean_watts": 22.071, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 76.655}, "timestamp": "2026-01-28T13:59:29.694436"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4570.845, "latencies_ms": [4570.845], "images_per_second": 0.219, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a street scene with a sign indicating a tow zone, surrounded by lush green trees and a brick building. The sunlight filters through the leaves, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.048, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 73.026}, "timestamp": "2026-01-28T13:59:36.289625"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3576.589, "latencies_ms": [3576.589], "images_per_second": 0.28, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A teddy bear wearing glasses and headphones sits on a desk with a keyboard, a microphone, and a tape recorder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.112, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-28T13:59:41.920119"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4777.926, "latencies_ms": [4777.926], "images_per_second": 0.209, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " teddy bear: 1\nkeyboard: 1\nmic: 1\ncamera: 1\nipod: 1\nglasses: 1\nremote: 1\nmouse: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.847, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 73.25}, "timestamp": "2026-01-28T13:59:48.758694"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5994.338, "latencies_ms": [5994.338], "images_per_second": 0.167, "prompt_tokens": 1118, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The teddy bear is positioned in the center of the image, with the keyboard to its left and the microphone to its right. The objects are arranged in a way that the teddy bear is the focal point, with the keyboard and microphone placed in front of it, and the iPod and tape recorder positioned to its right.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.38}, "power_stats": {"power_gpu_soc_mean_watts": 18.537, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 72.38}, "timestamp": "2026-01-28T13:59:56.789890"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3474.62, "latencies_ms": [3474.62], "images_per_second": 0.288, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A teddy bear wearing glasses and headphones is sitting on a desk with a keyboard, a microphone, and a tape recorder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12616.6, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.138}, "power_stats": {"power_gpu_soc_mean_watts": 22.321, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 7.876, "gpu_utilization_percent_mean": 77.138}, "timestamp": "2026-01-28T14:00:02.318003"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3101.193, "latencies_ms": [3101.193], "images_per_second": 0.322, "prompt_tokens": 1110, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The teddy bear is brown, the keyboard is black, and the background is blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12616.6, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12614.4, "ram_available_mb": 50226.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.371, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.902, "gpu_utilization_percent_mean": 80.808}, "timestamp": "2026-01-28T14:00:07.452205"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7882.728, "latencies_ms": [7882.728], "images_per_second": 0.127, "prompt_tokens": 1432, "response_tokens_est": 84, "n_tiles": 1, "output_text": " The image captures a dynamic moment of a skier in mid-air, with their skis and poles prominently displayed against the backdrop of a snowy mountain landscape. The skier is dressed in a white and orange suit, and the image is marked with various logos and text, including \"TATA,\" \"Tour de Sas,\" and \"Trentino,\" suggesting a possible association with a skiing event or brand.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12614.4, "ram_available_mb": 50226.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12614.6, "ram_available_mb": 50226.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.409}, "power_stats": {"power_gpu_soc_mean_watts": 19.338, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 73.409}, "timestamp": "2026-01-28T14:00:17.364731"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6410.261, "latencies_ms": [6410.261], "images_per_second": 0.156, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skis: 2\n2. person: 1\n3. snow: 1\n4. mountain: 1\n5. trees: 1\n6. sky: 1\n7. logo: 4\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.6, "ram_available_mb": 50226.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12614.8, "ram_available_mb": 50226.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.594, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 7.942, "gpu_utilization_percent_mean": 73.057}, "timestamp": "2026-01-28T14:00:25.800031"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5267.131, "latencies_ms": [5267.131], "images_per_second": 0.19, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The skier is in the foreground, with the mountain and trees in the background. The skier is to the left of the mountain, and the skier is in front of the mountain.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12614.8, "ram_available_mb": 50226.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12614.6, "ram_available_mb": 50226.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.958, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 76.75}, "timestamp": "2026-01-28T14:00:33.090828"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3871.589, "latencies_ms": [3871.589], "images_per_second": 0.258, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A skier is performing a jump in the snow, wearing a helmet and goggles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12614.6, "ram_available_mb": 50226.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12614.5, "ram_available_mb": 50226.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.531}, "power_stats": {"power_gpu_soc_mean_watts": 24.685, "power_cpu_cv_mean_watts": 1.164, "power_sys_5v0_mean_watts": 8.127, "gpu_utilization_percent_mean": 83.531}, "timestamp": "2026-01-28T14:00:39.010642"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6549.635, "latencies_ms": [6549.635], "images_per_second": 0.153, "prompt_tokens": 1442, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a skier in a white and orange suit, with the skis in the air, against a backdrop of snow-covered mountains and a clear blue sky. The lighting is bright and natural, suggesting daytime, and the snow appears to be freshly fallen, giving it a pristine white appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.5, "ram_available_mb": 50226.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12614.8, "ram_available_mb": 50226.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.2}, "power_stats": {"power_gpu_soc_mean_watts": 20.714, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 75.2}, "timestamp": "2026-01-28T14:00:47.591906"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5222.736, "latencies_ms": [5222.736], "images_per_second": 0.191, "prompt_tokens": 1432, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In the image, there are two surfers riding the waves in the ocean, with one surfer on a green surfboard and the other on a black surfboard, both skillfully navigating the waves.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12614.8, "ram_available_mb": 50226.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12614.2, "ram_available_mb": 50226.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.432}, "power_stats": {"power_gpu_soc_mean_watts": 21.594, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 77.432}, "timestamp": "2026-01-28T14:00:54.867926"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6421.717, "latencies_ms": [6421.717], "images_per_second": 0.156, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. surfboard: 2\n2. surfer: 2\n3. wave: 2\n4. ocean: 2\n5. sky: 1\n6. sun: 1\n7. water: 2\n8. sand: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12614.2, "ram_available_mb": 50226.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12614.0, "ram_available_mb": 50226.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.648}, "power_stats": {"power_gpu_soc_mean_watts": 20.724, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.963, "gpu_utilization_percent_mean": 74.648}, "timestamp": "2026-01-28T14:01:03.332063"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6640.466, "latencies_ms": [6640.466], "images_per_second": 0.151, "prompt_tokens": 1450, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The surfer on the left is closer to the camera than the surfer on the right. The surfer on the left is in the foreground, while the surfer on the right is in the background. The surfer on the left is closer to the camera than the surfer on the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12614.0, "ram_available_mb": 50226.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12614.0, "ram_available_mb": 50226.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.143}, "power_stats": {"power_gpu_soc_mean_watts": 20.064, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 73.143}, "timestamp": "2026-01-28T14:01:12.030156"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4117.201, "latencies_ms": [4117.201], "images_per_second": 0.243, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two surfers are riding the waves in the ocean, with the sun setting in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12614.0, "ram_available_mb": 50226.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12614.5, "ram_available_mb": 50226.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.882}, "power_stats": {"power_gpu_soc_mean_watts": 23.797, "power_cpu_cv_mean_watts": 1.331, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 80.882}, "timestamp": "2026-01-28T14:01:18.198646"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6314.401, "latencies_ms": [6314.401], "images_per_second": 0.158, "prompt_tokens": 1442, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image captures the dynamic interaction between the surfer and the ocean, with the surfer riding a wave and the ocean's surface reflecting the sunlight. The colors are predominantly blue and white, with the surfer's dark attire contrasting against the lighter hues of the water and sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12614.5, "ram_available_mb": 50226.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12614.0, "ram_available_mb": 50226.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.396}, "power_stats": {"power_gpu_soc_mean_watts": 20.566, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 75.396}, "timestamp": "2026-01-28T14:01:26.547333"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3967.974, "latencies_ms": [3967.974], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A pizza with a variety of toppings is placed on a metal tray, with a glass jar of pepperoni sauce and a napkin nearby.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12614.0, "ram_available_mb": 50226.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.303}, "power_stats": {"power_gpu_soc_mean_watts": 21.17, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.717, "gpu_utilization_percent_mean": 74.303}, "timestamp": "2026-01-28T14:01:32.570318"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4348.433, "latencies_ms": [4348.433], "images_per_second": 0.23, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " pizza: 1, plate: 1, pepperoni: 1, cheese: 1, sauce: 1, crust: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.472}, "power_stats": {"power_gpu_soc_mean_watts": 20.414, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 75.472}, "timestamp": "2026-01-28T14:01:38.933378"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4582.689, "latencies_ms": [4582.689], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The pizza is located in the foreground, with the pepperoni pizza in the background. The pepperoni pizza is placed on the table, while the salt shaker is positioned closer to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.895}, "power_stats": {"power_gpu_soc_mean_watts": 20.132, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 74.895}, "timestamp": "2026-01-28T14:01:45.564333"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4792.189, "latencies_ms": [4792.189], "images_per_second": 0.209, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In a dimly lit room, a pizza sits on a table, its golden crust and colorful toppings inviting. A glass jar of pepperoni sits nearby, ready to add a spicy kick to the meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12615.9, "ram_available_mb": 50225.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.538}, "power_stats": {"power_gpu_soc_mean_watts": 20.066, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 70.538}, "timestamp": "2026-01-28T14:01:52.385040"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3227.822, "latencies_ms": [3227.822], "images_per_second": 0.31, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The pizza is on a metal tray with a red tablecloth in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.9, "ram_available_mb": 50225.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12615.9, "ram_available_mb": 50225.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.654}, "power_stats": {"power_gpu_soc_mean_watts": 22.63, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 81.654}, "timestamp": "2026-01-28T14:01:57.654754"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6104.193, "latencies_ms": [6104.193], "images_per_second": 0.164, "prompt_tokens": 1100, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a quaint town square bathed in the soft glow of dusk, with a prominent clock tower standing tall on the left, its face adorned with Roman numerals, and a row of buildings lining the street, their facades painted in a palette of red and brown, their windows reflecting the fading light of the day.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12615.9, "ram_available_mb": 50225.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12613.5, "ram_available_mb": 50227.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.353}, "power_stats": {"power_gpu_soc_mean_watts": 18.379, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 71.353}, "timestamp": "2026-01-28T14:02:05.798002"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5717.39, "latencies_ms": [5717.39], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. clock: 1\n2. pole: 1\n3. snow: 1\n4. building: 2\n5. street: 1\n6. car: 1\n7. tree: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12613.5, "ram_available_mb": 50227.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12613.5, "ram_available_mb": 50227.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.245}, "power_stats": {"power_gpu_soc_mean_watts": 18.051, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.63, "gpu_utilization_percent_mean": 70.245}, "timestamp": "2026-01-28T14:02:13.545081"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4398.326, "latencies_ms": [4398.326], "images_per_second": 0.227, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The clock is positioned on the left side of the image, with the street extending into the background. The clock is in the foreground, with the buildings and street extending into the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12613.5, "ram_available_mb": 50227.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12613.7, "ram_available_mb": 50227.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.696, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 73.861}, "timestamp": "2026-01-28T14:02:19.964891"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5814.068, "latencies_ms": [5814.068], "images_per_second": 0.172, "prompt_tokens": 1112, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a quaint town square bathed in the soft glow of dusk. A clock, standing tall on a black pole, marks the passage of time amidst the serene beauty of the snow-covered streets. The buildings, adorned with festive lights, stand as silent spectators to the quiet beauty of the evening.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12613.7, "ram_available_mb": 50227.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12613.4, "ram_available_mb": 50227.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.394, "power_cpu_cv_mean_watts": 2.093, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 71.49}, "timestamp": "2026-01-28T14:02:27.791093"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3205.847, "latencies_ms": [3205.847], "images_per_second": 0.312, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The clock is black with white numbers and hands, and the street is covered in snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12613.4, "ram_available_mb": 50227.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12613.7, "ram_available_mb": 50227.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.889}, "power_stats": {"power_gpu_soc_mean_watts": 22.773, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 7.819, "gpu_utilization_percent_mean": 78.889}, "timestamp": "2026-01-28T14:02:33.039796"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3863.652, "latencies_ms": [3863.652], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A baseball player in a white uniform with blue stripes and a blue helmet is swinging a wooden bat at a baseball that is in mid-air.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12613.7, "ram_available_mb": 50227.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12612.9, "ram_available_mb": 50228.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.643, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-28T14:02:38.950793"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6682.399, "latencies_ms": [6682.399], "images_per_second": 0.15, "prompt_tokens": 1113, "response_tokens_est": 75, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball: 1\n3. catcher's mitt: 1\n4. baseball player: 1\n5. baseball player's uniform: 1\n6. baseball player's helmet: 1\n7. baseball player's cleats: 1\n8. baseball player's glove: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12612.9, "ram_available_mb": 50228.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12613.0, "ram_available_mb": 50227.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.561}, "power_stats": {"power_gpu_soc_mean_watts": 17.772, "power_cpu_cv_mean_watts": 2.164, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 69.561}, "timestamp": "2026-01-28T14:02:47.663488"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4083.482, "latencies_ms": [4083.482], "images_per_second": 0.245, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher in the background. The ball is in the middle ground, between the batter and the catcher.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12613.0, "ram_available_mb": 50227.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12613.3, "ram_available_mb": 50227.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.441}, "power_stats": {"power_gpu_soc_mean_watts": 21.181, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 78.441}, "timestamp": "2026-01-28T14:02:53.767183"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4050.914, "latencies_ms": [4050.914], "images_per_second": 0.247, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A baseball player in a white uniform is swinging a bat at a baseball. The catcher is wearing a red uniform and is ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12613.3, "ram_available_mb": 50227.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12613.2, "ram_available_mb": 50227.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.794}, "power_stats": {"power_gpu_soc_mean_watts": 21.171, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.784, "gpu_utilization_percent_mean": 75.794}, "timestamp": "2026-01-28T14:02:59.840696"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7694.425, "latencies_ms": [7694.425], "images_per_second": 0.13, "prompt_tokens": 1109, "response_tokens_est": 91, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter in full swing, the ball suspended in mid-air, and the catcher poised to catch it. The colors are vibrant, with the blue of the batter's uniform standing out against the green of the field and the red of the catcher's uniform. The lighting is natural, suggesting it's a sunny day, and the shadows cast by the players add depth to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12613.2, "ram_available_mb": 50227.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12613.2, "ram_available_mb": 50227.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.462}, "power_stats": {"power_gpu_soc_mean_watts": 17.145, "power_cpu_cv_mean_watts": 2.12, "power_sys_5v0_mean_watts": 7.72, "gpu_utilization_percent_mean": 70.462}, "timestamp": "2026-01-28T14:03:09.546949"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3302.047, "latencies_ms": [3302.047], "images_per_second": 0.303, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A brown teddy bear with a red bow tie is sitting on a chair with a red cushion.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12613.2, "ram_available_mb": 50227.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12612.9, "ram_available_mb": 50228.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.407}, "power_stats": {"power_gpu_soc_mean_watts": 22.608, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 80.407}, "timestamp": "2026-01-28T14:03:14.898665"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5941.208, "latencies_ms": [5941.208], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. chair: 1\n2. teddy bear: 1\n3. cushion: 1\n4. wall: 1\n5. curtain: 1\n6. chair backrest: 1\n7. chair seat: 1\n8. wall sconce: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12612.9, "ram_available_mb": 50228.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12613.8, "ram_available_mb": 50227.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 18.506, "power_cpu_cv_mean_watts": 2.083, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-28T14:03:22.854815"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4950.426, "latencies_ms": [4950.426], "images_per_second": 0.202, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The teddy bear is positioned on the left side of the chair, which is located in the foreground of the image. The teddy bear is sitting on the right side of the chair, which is positioned in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12613.8, "ram_available_mb": 50227.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12613.8, "ram_available_mb": 50227.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.439}, "power_stats": {"power_gpu_soc_mean_watts": 19.764, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 73.439}, "timestamp": "2026-01-28T14:03:29.826901"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2936.494, "latencies_ms": [2936.494], "images_per_second": 0.341, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A teddy bear is sitting on a chair with a red cushion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12613.8, "ram_available_mb": 50227.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.583}, "power_stats": {"power_gpu_soc_mean_watts": 23.148, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 82.583}, "timestamp": "2026-01-28T14:03:34.800026"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3227.472, "latencies_ms": [3227.472], "images_per_second": 0.31, "prompt_tokens": 1110, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The teddy bear is brown, the chair is red, and the background is yellow.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12614.3, "ram_available_mb": 50226.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.462}, "power_stats": {"power_gpu_soc_mean_watts": 22.786, "power_cpu_cv_mean_watts": 1.34, "power_sys_5v0_mean_watts": 7.793, "gpu_utilization_percent_mean": 76.462}, "timestamp": "2026-01-28T14:03:40.041293"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3256.526, "latencies_ms": [3256.526], "images_per_second": 0.307, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain, one of them is holding a snowboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.3, "ram_available_mb": 50226.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.074}, "power_stats": {"power_gpu_soc_mean_watts": 22.608, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 78.074}, "timestamp": "2026-01-28T14:03:45.363525"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5628.256, "latencies_ms": [5628.256], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. helmet: 1\n3. goggles: 1\n4. jacket: 2\n5. pants: 2\n6. boots: 2\n7. sun: 1\n8. rock: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.979}, "power_stats": {"power_gpu_soc_mean_watts": 18.912, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 70.979}, "timestamp": "2026-01-28T14:03:53.023226"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6280.261, "latencies_ms": [6280.261], "images_per_second": 0.159, "prompt_tokens": 1118, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The person on the left is standing closer to the camera than the person on the right. The person on the right is standing in the foreground of the image, while the person on the left is standing in the background. The person on the right is holding a snowboard, while the person on the left is wearing a helmet and goggles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.1, "ram_available_mb": 50226.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12614.4, "ram_available_mb": 50226.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.491}, "power_stats": {"power_gpu_soc_mean_watts": 18.085, "power_cpu_cv_mean_watts": 1.964, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 69.491}, "timestamp": "2026-01-28T14:04:01.328427"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3456.134, "latencies_ms": [3456.134], "images_per_second": 0.289, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two snowboarders stand on a snowy mountain, one holding a snowboard and the other wearing a helmet.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12614.4, "ram_available_mb": 50226.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12614.4, "ram_available_mb": 50226.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.128, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 77.143}, "timestamp": "2026-01-28T14:04:06.815247"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5481.399, "latencies_ms": [5481.399], "images_per_second": 0.182, "prompt_tokens": 1110, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features two snowboarders standing on a snowy mountain with a bright sun shining in the background. The snowboarders are wearing red jackets and black pants, and they are holding snowboards. The sun is shining brightly, creating a lens flare effect in the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12614.4, "ram_available_mb": 50226.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.304}, "power_stats": {"power_gpu_soc_mean_watts": 19.035, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 72.304}, "timestamp": "2026-01-28T14:04:14.311115"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4510.548, "latencies_ms": [4510.548], "images_per_second": 0.222, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a tree with a large, prominent knot in its trunk, surrounded by a variety of apples hanging from its branches, set against a backdrop of a warm, autumnal forest.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.211}, "power_stats": {"power_gpu_soc_mean_watts": 20.395, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 75.211}, "timestamp": "2026-01-28T14:04:20.870342"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4256.193, "latencies_ms": [4256.193], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " apple: 5, tree: 1, hole: 1, branch: 1, leaf: 1, tree trunk: 1, background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.75}, "power_stats": {"power_gpu_soc_mean_watts": 20.707, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 75.75}, "timestamp": "2026-01-28T14:04:27.163770"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4842.104, "latencies_ms": [4842.104], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The tree trunk is located in the foreground on the right side of the image, while the apples are hanging from the branches in the background on the left side. The apples are positioned closer to the camera than the tree trunk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.366}, "power_stats": {"power_gpu_soc_mean_watts": 19.95, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 72.366}, "timestamp": "2026-01-28T14:04:34.062156"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5357.721, "latencies_ms": [5357.721], "images_per_second": 0.187, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a serene autumn scene where a tree laden with ripe red apples stands tall, surrounded by a field of golden leaves. The warm hues of the setting sun cast a soft glow on the scene, enhancing the natural beauty of the apple tree and its surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12615.4, "ram_available_mb": 50225.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.911}, "power_stats": {"power_gpu_soc_mean_watts": 19.262, "power_cpu_cv_mean_watts": 1.833, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 72.911}, "timestamp": "2026-01-28T14:04:41.455158"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5471.282, "latencies_ms": [5471.282], "images_per_second": 0.183, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a tree with a hole in its trunk, surrounded by red apples and autumn leaves. The lighting is warm and soft, creating a serene atmosphere. The colors are vibrant, with the red apples contrasting against the brown tree bark and the orange hues of the leaves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.4, "ram_available_mb": 50225.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12616.1, "ram_available_mb": 50224.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.957}, "power_stats": {"power_gpu_soc_mean_watts": 19.175, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 71.957}, "timestamp": "2026-01-28T14:04:48.937347"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 8977.484, "latencies_ms": [8977.484], "images_per_second": 0.111, "prompt_tokens": 1099, "response_tokens_est": 114, "n_tiles": 1, "output_text": " In the image, a bustling kitchen scene unfolds with two chefs diligently working. The chef in the foreground, donned in a crisp white shirt and a blue baseball cap, is engrossed in the task of preparing food, his hands skillfully maneuvering a metal container. His counterpart in the background, also clad in a white shirt and a baseball cap, is engrossed in the task of grilling, his hands moving with practiced ease over the grill. The kitchen itself is a symphony of stainless steel appliances and white countertops, a testament to the efficiency and cleanliness of the culinary space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12616.1, "ram_available_mb": 50224.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.468}, "power_stats": {"power_gpu_soc_mean_watts": 16.663, "power_cpu_cv_mean_watts": 2.08, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 68.468}, "timestamp": "2026-01-28T14:04:59.940839"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6093.948, "latencies_ms": [6093.948], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. person: 2\n2. white t-shirt: 2\n3. blue cap: 1\n4. metal tray: 1\n5. food container: 1\n6. metal container: 1\n7. metal tray: 1\n8. food container: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.635}, "power_stats": {"power_gpu_soc_mean_watts": 18.211, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 70.635}, "timestamp": "2026-01-28T14:05:08.084574"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4650.096, "latencies_ms": [4650.096], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man in the foreground is working on a fryer, while the man in the background is working on a grill. The man in the foreground is closer to the camera than the man in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.872}, "power_stats": {"power_gpu_soc_mean_watts": 20.232, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 74.872}, "timestamp": "2026-01-28T14:05:14.751221"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3290.27, "latencies_ms": [3290.27], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two men are working in a kitchen, one is preparing food and the other is cooking.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.148}, "power_stats": {"power_gpu_soc_mean_watts": 22.562, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 82.148}, "timestamp": "2026-01-28T14:05:20.084695"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3555.009, "latencies_ms": [3555.009], "images_per_second": 0.281, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The kitchen is well-lit with fluorescent lights, and the stainless steel appliances gleam under the bright lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.139, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 80.517}, "timestamp": "2026-01-28T14:05:25.650963"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3092.397, "latencies_ms": [3092.397], "images_per_second": 0.323, "prompt_tokens": 766, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A group of motorcyclists are gathered on a roadside, with several parked motorcycles and a few standing, and a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12615.8, "ram_available_mb": 50225.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12614.9, "ram_available_mb": 50226.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5033.1, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.786, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.642, "gpu_utilization_percent_mean": 69.4}, "timestamp": "2026-01-28T14:05:30.793057"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3740.491, "latencies_ms": [3740.491], "images_per_second": 0.267, "prompt_tokens": 780, "response_tokens_est": 38, "n_tiles": 1, "output_text": " motorcycle: 10, person: 10, road: 1, sky: 1, clouds: 1, car: 1, motorbike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12614.9, "ram_available_mb": 50226.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.633}, "power_stats": {"power_gpu_soc_mean_watts": 18.998, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 70.633}, "timestamp": "2026-01-28T14:05:36.549571"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3736.689, "latencies_ms": [3736.689], "images_per_second": 0.268, "prompt_tokens": 784, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The motorcycles are positioned on the left side of the road, with the group of people standing on the right side. The motorcycles are in the foreground, while the people are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.452}, "power_stats": {"power_gpu_soc_mean_watts": 18.567, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 7.678, "gpu_utilization_percent_mean": 68.452}, "timestamp": "2026-01-28T14:05:42.345530"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2862.797, "latencies_ms": [2862.797], "images_per_second": 0.349, "prompt_tokens": 778, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of motorcyclists are gathered on a roadside near a body of water, with a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.739}, "power_stats": {"power_gpu_soc_mean_watts": 20.427, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 73.739}, "timestamp": "2026-01-28T14:05:47.230635"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4006.301, "latencies_ms": [4006.301], "images_per_second": 0.25, "prompt_tokens": 776, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a group of motorcyclists gathered on a roadside, with their motorcycles parked in a line. The sky is filled with clouds, and the lighting suggests it is either early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12616.9, "ram_available_mb": 50224.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.181, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.635, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-28T14:05:53.278732"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3883.554, "latencies_ms": [3883.554], "images_per_second": 0.257, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A small airplane with the letters G-RMWZ on the tail flies through the sky, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12616.9, "ram_available_mb": 50224.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.219}, "power_stats": {"power_gpu_soc_mean_watts": 21.154, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 75.219}, "timestamp": "2026-01-28T14:05:59.229196"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5626.231, "latencies_ms": [5626.231], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. smoke: 1\n3. clouds: 2\n4. sky: 1\n5. tail number: 1\n6. propeller: 1\n7. wing: 1\n8. fuselage: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.872}, "power_stats": {"power_gpu_soc_mean_watts": 18.776, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 71.872}, "timestamp": "2026-01-28T14:06:06.881016"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4044.502, "latencies_ms": [4044.502], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The airplane is in the foreground, flying from left to right, while the clouds are in the background. The airplane is flying higher than the clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.921, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 76.971}, "timestamp": "2026-01-28T14:06:12.944168"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3230.117, "latencies_ms": [3230.117], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small airplane is flying in the sky, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12617.1, "ram_available_mb": 50223.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.615}, "power_stats": {"power_gpu_soc_mean_watts": 22.751, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.789, "gpu_utilization_percent_mean": 76.615}, "timestamp": "2026-01-28T14:06:18.187248"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3550.039, "latencies_ms": [3550.039], "images_per_second": 0.282, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is in black and white, with a sepia tone, and the sky is filled with clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.1, "ram_available_mb": 50223.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12616.6, "ram_available_mb": 50224.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.759}, "power_stats": {"power_gpu_soc_mean_watts": 21.987, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 80.759}, "timestamp": "2026-01-28T14:06:23.756275"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3766.475, "latencies_ms": [3766.475], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a group of sheep are grazing on a grassy hillside, with a serene lake and majestic mountains in the background.", "error": null, "sys_before": {"cpu_percent": 14.8, "ram_used_mb": 12616.6, "ram_available_mb": 50224.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.581}, "power_stats": {"power_gpu_soc_mean_watts": 21.535, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 75.581}, "timestamp": "2026-01-28T14:06:29.566278"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5582.696, "latencies_ms": [5582.696], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 4\n2. mountains: 3\n3. lake: 1\n4. grass: 1\n5. rocks: 1\n6. sky: 1\n7. clouds: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.674}, "power_stats": {"power_gpu_soc_mean_watts": 18.946, "power_cpu_cv_mean_watts": 1.95, "power_sys_5v0_mean_watts": 7.703, "gpu_utilization_percent_mean": 72.674}, "timestamp": "2026-01-28T14:06:37.177180"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4466.048, "latencies_ms": [4466.048], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the mountains in the background. The sheep are standing on a grassy hill, with the lake visible to the right of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.541}, "power_stats": {"power_gpu_soc_mean_watts": 20.557, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 74.541}, "timestamp": "2026-01-28T14:06:43.677643"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3740.377, "latencies_ms": [3740.377], "images_per_second": 0.267, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In this picturesque landscape, a group of sheep graze on a grassy hillside, with a serene lake and majestic mountains in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.774}, "power_stats": {"power_gpu_soc_mean_watts": 21.95, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 75.774}, "timestamp": "2026-01-28T14:06:49.449751"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5776.176, "latencies_ms": [5776.176], "images_per_second": 0.173, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a group of sheep standing on a grassy hill, with the mountains in the background. The sky is clear and blue, and the sun is shining brightly, casting a warm glow on the scene. The sheep are white, with some having black faces, and they are grazing on the grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.875}, "power_stats": {"power_gpu_soc_mean_watts": 18.992, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 72.875}, "timestamp": "2026-01-28T14:06:57.246825"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3103.223, "latencies_ms": [3103.223], "images_per_second": 0.322, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman in a wheelchair is holding a tennis racket and looking at something.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.195, "power_cpu_cv_mean_watts": 1.441, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 77.76}, "timestamp": "2026-01-28T14:07:02.385125"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5703.051, "latencies_ms": [5703.051], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. woman: 1\n2. wheelchair: 1\n3. racket: 1\n4. person: 2\n5. wall: 1\n6. floor: 1\n7. ball: 1\n8. racket strings: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.438}, "power_stats": {"power_gpu_soc_mean_watts": 18.765, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 71.438}, "timestamp": "2026-01-28T14:07:10.106879"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3987.72, "latencies_ms": [3987.72], "images_per_second": 0.251, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The woman in the wheelchair is in the foreground, holding a tennis racket. The other person is in the background, standing near the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.515}, "power_stats": {"power_gpu_soc_mean_watts": 21.092, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 75.515}, "timestamp": "2026-01-28T14:07:16.153791"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3605.784, "latencies_ms": [3605.784], "images_per_second": 0.277, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A woman in a wheelchair is holding a tennis racket and looking at something. There are other people in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.633}, "power_stats": {"power_gpu_soc_mean_watts": 22.122, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 7.799, "gpu_utilization_percent_mean": 77.633}, "timestamp": "2026-01-28T14:07:21.807863"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5878.009, "latencies_ms": [5878.009], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image is a photograph taken in an indoor sports facility with a white wall in the background. The lighting is natural, coming from the windows on the left side of the room. The woman is wearing a gray t-shirt and blue shorts, and she is holding a tennis racket in her right hand.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12615.8, "ram_available_mb": 50225.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.3}, "power_stats": {"power_gpu_soc_mean_watts": 18.504, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 7.744, "gpu_utilization_percent_mean": 71.3}, "timestamp": "2026-01-28T14:07:29.732210"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3811.337, "latencies_ms": [3811.337], "images_per_second": 0.262, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young girl is sitting on a brown saddle with a black helmet on her head.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 12615.8, "ram_available_mb": 50225.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12615.3, "ram_available_mb": 50225.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.129}, "power_stats": {"power_gpu_soc_mean_watts": 24.274, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 81.129}, "timestamp": "2026-01-28T14:07:35.588650"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6589.614, "latencies_ms": [6589.614], "images_per_second": 0.152, "prompt_tokens": 1446, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. girl: 1\n2. helmet: 1\n3. pink shirt: 1\n4. blue jeans: 1\n5. brown saddle: 1\n6. purple blanket: 1\n7. white fence: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.3, "ram_available_mb": 50225.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.927}, "power_stats": {"power_gpu_soc_mean_watts": 20.395, "power_cpu_cv_mean_watts": 2.323, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 72.927}, "timestamp": "2026-01-28T14:07:44.229680"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7010.93, "latencies_ms": [7010.93], "images_per_second": 0.143, "prompt_tokens": 1450, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The child is sitting on the saddle of the horse, which is positioned in the foreground of the image. The child is wearing a pink and white plaid shirt, blue jeans, and a black helmet, which are all in the foreground. The background of the image features a green field with trees, which is far away from the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12615.4, "ram_available_mb": 50225.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.881}, "power_stats": {"power_gpu_soc_mean_watts": 20.293, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 72.881}, "timestamp": "2026-01-28T14:07:53.257333"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3591.011, "latencies_ms": [3591.011], "images_per_second": 0.278, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A little girl is sitting on a brown saddle in a field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.4, "ram_available_mb": 50225.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12618.3, "ram_available_mb": 50222.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.167}, "power_stats": {"power_gpu_soc_mean_watts": 25.379, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 87.167}, "timestamp": "2026-01-28T14:07:58.870350"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4636.102, "latencies_ms": [4636.102], "images_per_second": 0.216, "prompt_tokens": 1442, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The child is wearing a pink and white plaid shirt, blue jeans, and a black helmet. The child is sitting on a brown leather saddle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.3, "ram_available_mb": 50222.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.342}, "power_stats": {"power_gpu_soc_mean_watts": 23.44, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 78.342}, "timestamp": "2026-01-28T14:08:05.518579"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4557.987, "latencies_ms": [4557.987], "images_per_second": 0.219, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a dynamic scene of three surfers riding the waves in the ocean, with the text \"Ranglin - New Zealand\" at the bottom, indicating the location of the surfing activity.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12619.2, "ram_available_mb": 50221.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.421}, "power_stats": {"power_gpu_soc_mean_watts": 20.438, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 72.421}, "timestamp": "2026-01-28T14:08:12.124286"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5838.963, "latencies_ms": [5838.963], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Surfboard: 1\n2. Surfer: 2\n3. Ocean: 1\n4. Wave: 1\n5. Photographer: 1\n6. Photograph: 1\n7. Frame: 1\n8. Text: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12619.2, "ram_available_mb": 50221.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.633}, "power_stats": {"power_gpu_soc_mean_watts": 18.726, "power_cpu_cv_mean_watts": 1.978, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.633}, "timestamp": "2026-01-28T14:08:19.997490"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4103.832, "latencies_ms": [4103.832], "images_per_second": 0.244, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The surfer is positioned on the left side of the image, with the wave on the right side. The surfer is closer to the camera than the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12619.4, "ram_available_mb": 50221.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.588}, "power_stats": {"power_gpu_soc_mean_watts": 21.075, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 74.588}, "timestamp": "2026-01-28T14:08:26.120230"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3707.906, "latencies_ms": [3707.906], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two surfers are riding the waves in the ocean, one is closer to the camera and the other is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12619.4, "ram_available_mb": 50221.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.548}, "power_stats": {"power_gpu_soc_mean_watts": 21.407, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.739, "gpu_utilization_percent_mean": 74.548}, "timestamp": "2026-01-28T14:08:31.887619"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5280.674, "latencies_ms": [5280.674], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a dynamic scene of two surfers riding the waves in the ocean, with the water appearing deep blue and the sky clear. The surfers are dressed in wetsuits, and the sunlight reflects off the water, creating a shimmering effect.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.306, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T14:08:39.185571"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4014.462, "latencies_ms": [4014.462], "images_per_second": 0.249, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a cozy kitchen with a large window that has frosted glass, a wooden cabinet, and a stove with pots and pans on it.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.303}, "power_stats": {"power_gpu_soc_mean_watts": 21.106, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 75.303}, "timestamp": "2026-01-28T14:08:45.252025"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5554.286, "latencies_ms": [5554.286], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. window: 1\n2. shelf: 2\n3. cabinet: 1\n4. stove: 1\n5. pot: 1\n6. plant: 1\n7. cupboard: 1\n8. shelf: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.022}, "power_stats": {"power_gpu_soc_mean_watts": 18.982, "power_cpu_cv_mean_watts": 2.081, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 71.022}, "timestamp": "2026-01-28T14:08:52.824405"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4997.765, "latencies_ms": [4997.765], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The window is located in the center of the image, with the wooden cabinet to the right and the stove to the left. The plants are placed on the windowsill, which is in the foreground, while the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.833}, "power_stats": {"power_gpu_soc_mean_watts": 19.808, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 73.833}, "timestamp": "2026-01-28T14:08:59.860364"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5918.149, "latencies_ms": [5918.149], "images_per_second": 0.169, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a cozy kitchen scene with a large window that allows natural light to filter in. The window is adorned with a colorful paper decoration, adding a touch of whimsy to the room. The kitchen is equipped with various appliances and utensils, suggesting it's a well-used space for cooking and meal preparation.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.44}, "power_stats": {"power_gpu_soc_mean_watts": 18.744, "power_cpu_cv_mean_watts": 2.074, "power_sys_5v0_mean_watts": 7.761, "gpu_utilization_percent_mean": 71.44}, "timestamp": "2026-01-28T14:09:07.792289"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4456.27, "latencies_ms": [4456.27], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a window that lets in a soft glow. The walls are painted a warm yellow, and the wooden cabinet is a rich, dark brown.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.667, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 73.324}, "timestamp": "2026-01-28T14:09:14.302575"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7491.154, "latencies_ms": [7491.154], "images_per_second": 0.133, "prompt_tokens": 1099, "response_tokens_est": 89, "n_tiles": 1, "output_text": " In the image, a vibrant red background serves as a backdrop for a traditional Chinese altar, adorned with a pineapple, a vase filled with red incense sticks, and a plate of oranges. The altar is meticulously arranged with a red plate holding the oranges, a white pedestal supporting the vase of incense sticks, and a red cup placed in front of the plate. The arrangement exudes a sense of reverence and tranquility, characteristic of Chinese cultural practices.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12617.1, "ram_available_mb": 50223.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.781}, "power_stats": {"power_gpu_soc_mean_watts": 17.416, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 69.781}, "timestamp": "2026-01-28T14:09:23.836689"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4112.77, "latencies_ms": [4112.77], "images_per_second": 0.243, "prompt_tokens": 1113, "response_tokens_est": 32, "n_tiles": 1, "output_text": " pineapple: 1, red cups: 6, oranges: 4, candle: 1, incense sticks: 1, red plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.1, "ram_available_mb": 50223.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.676}, "power_stats": {"power_gpu_soc_mean_watts": 21.122, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 74.676}, "timestamp": "2026-01-28T14:09:29.982026"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5495.914, "latencies_ms": [5495.914], "images_per_second": 0.182, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The pineapple is positioned to the left of the incense holder, which is situated in the center of the image. The oranges are placed on a white pedestal to the right of the incense holder, while the red cups are arranged in a row in the foreground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.543}, "power_stats": {"power_gpu_soc_mean_watts": 18.606, "power_cpu_cv_mean_watts": 2.08, "power_sys_5v0_mean_watts": 7.661, "gpu_utilization_percent_mean": 69.543}, "timestamp": "2026-01-28T14:09:37.490149"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4520.43, "latencies_ms": [4520.43], "images_per_second": 0.221, "prompt_tokens": 1111, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In this image, we can see a pineapple, a pot with some objects, a plate with some oranges, and some cups. We can also see a wall with some text written on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12617.3, "ram_available_mb": 50223.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.298, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 75.789}, "timestamp": "2026-01-28T14:09:44.027303"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5251.21, "latencies_ms": [5251.21], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a vibrant red background with a pineapple and a plate of oranges. The lighting is bright and even, highlighting the colors and textures of the objects. The materials appear to be wood and ceramic, and the weather seems to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12617.3, "ram_available_mb": 50223.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.545}, "power_stats": {"power_gpu_soc_mean_watts": 19.218, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.545}, "timestamp": "2026-01-28T14:09:51.328221"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3871.895, "latencies_ms": [3871.895], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man wearing glasses and a beard is smiling while eating a large slice of pizza with a side of fries and a small cup of sauce.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12618.2, "ram_available_mb": 50222.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.466, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 75.156}, "timestamp": "2026-01-28T14:09:57.241719"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5592.044, "latencies_ms": [5592.044], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. fries: 1\n3. sandwich: 1\n4. sauce: 1\n5. man: 1\n6. clock: 1\n7. wall: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.2, "ram_available_mb": 50222.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.609}, "power_stats": {"power_gpu_soc_mean_watts": 18.912, "power_cpu_cv_mean_watts": 2.29, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 70.609}, "timestamp": "2026-01-28T14:10:04.859376"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3974.387, "latencies_ms": [3974.387], "images_per_second": 0.252, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The man is in the foreground, holding a plate of food. The fries are in the middle ground, and the background shows a restaurant with other people.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.472, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 7.814, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-28T14:10:10.892450"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3763.896, "latencies_ms": [3763.896], "images_per_second": 0.266, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man is eating a large slice of pizza with fries and dipping sauce. He is in a restaurant with other people in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.548}, "power_stats": {"power_gpu_soc_mean_watts": 21.746, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.797, "gpu_utilization_percent_mean": 77.548}, "timestamp": "2026-01-28T14:10:16.702376"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3402.751, "latencies_ms": [3402.751], "images_per_second": 0.294, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The image is taken in a restaurant with warm lighting and the food is served on a white plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.429}, "power_stats": {"power_gpu_soc_mean_watts": 22.458, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 77.429}, "timestamp": "2026-01-28T14:10:22.147623"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4312.821, "latencies_ms": [4312.821], "images_per_second": 0.232, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a rainy day scene from inside a building, where the view outside is of a courtyard with a tall metal structure, bicycles parked, and people walking with umbrellas.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.79, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 74.861}, "timestamp": "2026-01-28T14:10:28.487413"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6040.191, "latencies_ms": [6040.191], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Bike: 4\n2. Bike: 2\n3. Bike: 1\n4. Bike: 1\n5. Bike: 1\n6. Bike: 1\n7. Bike: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.373}, "power_stats": {"power_gpu_soc_mean_watts": 18.643, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 71.373}, "timestamp": "2026-01-28T14:10:36.568498"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3561.467, "latencies_ms": [3561.467], "images_per_second": 0.281, "prompt_tokens": 1118, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bicycle is in the foreground, the building is in the background, and the person is in the middle ground.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.069, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 78.448}, "timestamp": "2026-01-28T14:10:42.148943"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4340.161, "latencies_ms": [4340.161], "images_per_second": 0.23, "prompt_tokens": 1112, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a rainy day at a university campus, with a large courtyard in the center. The courtyard is surrounded by modern buildings, and there are several bicycles parked in the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.25}, "power_stats": {"power_gpu_soc_mean_watts": 20.515, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 74.25}, "timestamp": "2026-01-28T14:10:48.520474"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6278.742, "latencies_ms": [6278.742], "images_per_second": 0.159, "prompt_tokens": 1110, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image is taken from inside a building, looking out through a window. The weather outside is rainy, as evidenced by the wet ground and the people holding umbrellas. The colors in the image are muted due to the overcast sky, with the gray of the buildings and the wet ground providing a neutral backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.558}, "power_stats": {"power_gpu_soc_mean_watts": 18.702, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 7.729, "gpu_utilization_percent_mean": 72.558}, "timestamp": "2026-01-28T14:10:56.819472"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5328.435, "latencies_ms": [5328.435], "images_per_second": 0.188, "prompt_tokens": 1099, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image shows a close-up view of a plate with a creamy, yellow-colored pasta dish, possibly macaroni and cheese, topped with a generous amount of melted cheese that has a slightly glossy appearance, suggesting it has been recently cooked and is still warm.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.844}, "power_stats": {"power_gpu_soc_mean_watts": 19.241, "power_cpu_cv_mean_watts": 2.109, "power_sys_5v0_mean_watts": 7.791, "gpu_utilization_percent_mean": 71.844}, "timestamp": "2026-01-28T14:11:04.205198"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3543.452, "latencies_ms": [3543.452], "images_per_second": 0.282, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " fork: 1, knife: 1, plate: 1, noodles: 1, cheese: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.176, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.866, "gpu_utilization_percent_mean": 78.033}, "timestamp": "2026-01-28T14:11:09.773074"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4332.534, "latencies_ms": [4332.534], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The fork is located to the right of the plate, which is in the foreground of the image. The plate is placed on a table, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.793, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-28T14:11:16.157179"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6075.895, "latencies_ms": [6075.895], "images_per_second": 0.165, "prompt_tokens": 1111, "response_tokens_est": 65, "n_tiles": 1, "output_text": " In the image, a close-up view of a plate of food is presented, featuring a layer of yellow cheese that has been melted and spread evenly over a bed of noodles. The noodles are arranged in a somewhat random pattern, and the cheese has a glossy sheen, suggesting it has been cooked to a perfect consistency.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.765}, "power_stats": {"power_gpu_soc_mean_watts": 18.438, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 69.765}, "timestamp": "2026-01-28T14:11:24.287605"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5270.166, "latencies_ms": [5270.166], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a close-up of a plate of macaroni and cheese, with a fork and knife placed on the plate. The macaroni and cheese is topped with a creamy yellow sauce, and the plate is placed on a dark surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.045}, "power_stats": {"power_gpu_soc_mean_watts": 19.217, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 72.045}, "timestamp": "2026-01-28T14:11:31.569788"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3513.884, "latencies_ms": [3513.884], "images_per_second": 0.285, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A silver laptop sits open on a desk with a green leaf wallpaper, a black mouse, and a black keyboard.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.759}, "power_stats": {"power_gpu_soc_mean_watts": 22.264, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.835, "gpu_utilization_percent_mean": 78.759}, "timestamp": "2026-01-28T14:11:37.117989"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5638.462, "latencies_ms": [5638.462], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. laptop: 1\n2. mouse: 1\n3. keyboard: 1\n4. monitor: 2\n5. speaker: 1\n6. mouse pad: 1\n7. computer: 1\n8. screen: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.986, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 7.71, "gpu_utilization_percent_mean": 70.957}, "timestamp": "2026-01-28T14:11:44.812888"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5008.153, "latencies_ms": [5008.153], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The laptop is in the foreground, with the mouse to its right. The keyboard is in front of the laptop, and the mousepad is in front of the keyboard. The computer monitor is to the left of the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12615.8, "ram_available_mb": 50225.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.929}, "power_stats": {"power_gpu_soc_mean_watts": 19.289, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 74.929}, "timestamp": "2026-01-28T14:11:51.859144"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3072.346, "latencies_ms": [3072.346], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A silver laptop computer is open on a desk with a green leaf wallpaper.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12615.8, "ram_available_mb": 50225.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.162, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-28T14:11:56.946646"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3693.624, "latencies_ms": [3693.624], "images_per_second": 0.271, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The laptop is silver and the mouse is black. The desk is white and the laptop is on the left side of the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.935}, "power_stats": {"power_gpu_soc_mean_watts": 21.793, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 76.935}, "timestamp": "2026-01-28T14:12:02.667679"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3448.968, "latencies_ms": [3448.968], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young girl is sitting on a bed in a bedroom with orange walls, playing with toys on the floor.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12614.7, "ram_available_mb": 50226.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.64, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 7.841, "gpu_utilization_percent_mean": 77.679}, "timestamp": "2026-01-28T14:12:08.161277"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5605.203, "latencies_ms": [5605.203], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bed: 1\n2. girl: 1\n3. lamp: 1\n4. nightstand: 1\n5. blanket: 1\n6. box: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12614.7, "ram_available_mb": 50226.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-28T14:12:15.823303"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5757.844, "latencies_ms": [5757.844], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The bed is positioned to the left of the girl, who is sitting on it. The bed is in the foreground of the image, while the lamp and the clothes on the chair are in the background. The girl is sitting near the bed, while the clothes on the chair are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.75}, "power_stats": {"power_gpu_soc_mean_watts": 18.68, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 71.75}, "timestamp": "2026-01-28T14:12:23.629726"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3711.896, "latencies_ms": [3711.896], "images_per_second": 0.269, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young girl is sitting on a bed in a bedroom with orange walls. She is playing with a toy on the floor.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12615.7, "ram_available_mb": 50225.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.097}, "power_stats": {"power_gpu_soc_mean_watts": 21.613, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 76.097}, "timestamp": "2026-01-28T14:12:29.389666"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4293.612, "latencies_ms": [4293.612], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The room is painted in a warm orange color, and the floor is made of stone tiles. The lighting is natural, coming from a window on the left side of the room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.778}, "power_stats": {"power_gpu_soc_mean_watts": 20.824, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 74.778}, "timestamp": "2026-01-28T14:12:35.728809"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4665.074, "latencies_ms": [4665.074], "images_per_second": 0.214, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In the image, a baseball game is in progress with a batter in a red uniform and a catcher in a gray uniform, both in the midst of a swing, while the umpire stands nearby.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12616.3, "ram_available_mb": 50224.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.256}, "power_stats": {"power_gpu_soc_mean_watts": 20.273, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 73.256}, "timestamp": "2026-01-28T14:12:42.441181"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5982.54, "latencies_ms": [5982.54], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball player: 1\n3. catcher: 1\n4. umpire: 1\n5. pitcher: 1\n6. baseball field: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.42}, "power_stats": {"power_gpu_soc_mean_watts": 18.447, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 70.42}, "timestamp": "2026-01-28T14:12:50.444295"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4374.801, "latencies_ms": [4374.801], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.7, "ram_available_mb": 50224.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.194}, "power_stats": {"power_gpu_soc_mean_watts": 20.805, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 73.194}, "timestamp": "2026-01-28T14:12:56.852936"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3706.354, "latencies_ms": [3706.354], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A baseball game is taking place on a sunny day in a stadium with a batter, catcher, and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.967}, "power_stats": {"power_gpu_soc_mean_watts": 21.976, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 75.967}, "timestamp": "2026-01-28T14:13:02.575263"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7608.831, "latencies_ms": [7608.831], "images_per_second": 0.131, "prompt_tokens": 1109, "response_tokens_est": 88, "n_tiles": 1, "output_text": " The image captures a moment of intense action in a baseball game, with the batter in the midst of a powerful swing, the catcher poised to react, and the umpire closely observing the play. The colors are vibrant, with the green of the field contrasting against the red of the batter's uniform and the black of the catcher's gear. The lighting is natural, casting sharp shadows and highlighting the dynamic movement of the players.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.812}, "power_stats": {"power_gpu_soc_mean_watts": 17.198, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 7.675, "gpu_utilization_percent_mean": 68.812}, "timestamp": "2026-01-28T14:13:12.243407"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2884.794, "latencies_ms": [2884.794], "images_per_second": 0.347, "prompt_tokens": 1099, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A cat is eating a bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12616.9, "ram_available_mb": 50224.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.435}, "power_stats": {"power_gpu_soc_mean_watts": 23.453, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 79.435}, "timestamp": "2026-01-28T14:13:17.174459"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5507.164, "latencies_ms": [5507.164], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. bird: 1\n3. feathers: 1\n4. fur: 1\n5. concrete: 1\n6. leaves: 1\n7. grass: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.9, "ram_available_mb": 50224.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12616.1, "ram_available_mb": 50224.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.152}, "power_stats": {"power_gpu_soc_mean_watts": 18.962, "power_cpu_cv_mean_watts": 2.124, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 71.152}, "timestamp": "2026-01-28T14:13:24.720472"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4588.031, "latencies_ms": [4588.031], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The bird is in the foreground, with the cat's head in the middle ground. The cat's body is partially obscured by the bird, and the bird is positioned to the left of the cat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12616.1, "ram_available_mb": 50224.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.531, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 70.676}, "timestamp": "2026-01-28T14:13:31.326147"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2810.833, "latencies_ms": [2810.833], "images_per_second": 0.356, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A cat is eating a bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.739}, "power_stats": {"power_gpu_soc_mean_watts": 23.769, "power_cpu_cv_mean_watts": 1.305, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 83.739}, "timestamp": "2026-01-28T14:13:36.187920"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5180.796, "latencies_ms": [5180.796], "images_per_second": 0.193, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a cat with a white and gray coat, a black nose, and a pink tongue, standing on a concrete surface. The lighting is natural, and the cat is in the foreground, with a shadow cast on the ground behind it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12616.8, "ram_available_mb": 50224.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.279}, "power_stats": {"power_gpu_soc_mean_watts": 19.456, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 73.279}, "timestamp": "2026-01-28T14:13:43.381321"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3843.069, "latencies_ms": [3843.069], "images_per_second": 0.26, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a sandwich with lettuce, tomato, and cheese in their hand.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12616.6, "ram_available_mb": 50224.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.245, "power_cpu_cv_mean_watts": 1.239, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 84.0}, "timestamp": "2026-01-28T14:13:49.243561"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6179.367, "latencies_ms": [6179.367], "images_per_second": 0.162, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. hand: 1\n2. sandwich: 1\n3. bread: 1\n4. tomato: 1\n5. lettuce: 1\n6. cheese: 1\n7. stove: 1\n8. bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.538}, "power_stats": {"power_gpu_soc_mean_watts": 20.999, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 75.538}, "timestamp": "2026-01-28T14:13:57.453622"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4779.538, "latencies_ms": [4779.538], "images_per_second": 0.209, "prompt_tokens": 1450, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The sandwich is held in the left hand, with the right hand holding the plate. The sandwich is in the foreground, while the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12618.3, "ram_available_mb": 50222.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.35}, "power_stats": {"power_gpu_soc_mean_watts": 23.181, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 80.35}, "timestamp": "2026-01-28T14:14:04.247696"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4010.161, "latencies_ms": [4010.161], "images_per_second": 0.249, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A person is holding a sandwich with lettuce, tomato, and cheese on a white cutting board.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.3, "ram_available_mb": 50222.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12619.5, "ram_available_mb": 50221.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.485}, "power_stats": {"power_gpu_soc_mean_watts": 24.456, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 85.485}, "timestamp": "2026-01-28T14:14:10.285425"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4452.025, "latencies_ms": [4452.025], "images_per_second": 0.225, "prompt_tokens": 1442, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The sandwich is white, the bread is white, the tomato is red, the lettuce is green, and the cheese is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12619.5, "ram_available_mb": 50221.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12619.7, "ram_available_mb": 50221.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.784}, "power_stats": {"power_gpu_soc_mean_watts": 23.562, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 80.784}, "timestamp": "2026-01-28T14:14:16.752943"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3154.207, "latencies_ms": [3154.207], "images_per_second": 0.317, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three girls are sitting on the back of a boat, looking out at the ocean.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12619.7, "ram_available_mb": 50221.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12619.6, "ram_available_mb": 50221.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.104, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.837, "gpu_utilization_percent_mean": 81.538}, "timestamp": "2026-01-28T14:14:21.948604"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5637.125, "latencies_ms": [5637.125], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. hat: 2\n2. lifebuoy: 1\n3. rope: 2\n4. sail: 1\n5. boat: 1\n6. person: 3\n7. ocean: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12619.6, "ram_available_mb": 50221.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12619.5, "ram_available_mb": 50221.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.792}, "power_stats": {"power_gpu_soc_mean_watts": 18.924, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.792}, "timestamp": "2026-01-28T14:14:29.623133"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5284.352, "latencies_ms": [5284.352], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The girl on the left is closer to the camera than the girl on the right. The girl on the right is farther away from the camera than the girl on the left. The girl on the right is closer to the water than the girl on the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12619.5, "ram_available_mb": 50221.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.409}, "power_stats": {"power_gpu_soc_mean_watts": 19.261, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.409}, "timestamp": "2026-01-28T14:14:36.940394"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3133.11, "latencies_ms": [3133.11], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " Three people are on a boat in the ocean, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12619.3, "ram_available_mb": 50221.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.308}, "power_stats": {"power_gpu_soc_mean_watts": 22.874, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 79.308}, "timestamp": "2026-01-28T14:14:42.128740"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6504.577, "latencies_ms": [6504.577], "images_per_second": 0.154, "prompt_tokens": 1109, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The image captures a serene moment on a boat with three individuals, two of whom are seated on a lifebuoy, while the third stands on the deck. The sky is clear, and the water is a deep blue, reflecting the sunlight. The individuals are dressed in casual summer attire, and the lifebuoy is a stark contrast to the surrounding water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12619.3, "ram_available_mb": 50221.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12618.3, "ram_available_mb": 50222.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.818}, "power_stats": {"power_gpu_soc_mean_watts": 18.001, "power_cpu_cv_mean_watts": 2.046, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 68.818}, "timestamp": "2026-01-28T14:14:50.695911"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4274.976, "latencies_ms": [4274.976], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the image, a white sheep with fluffy fur stands on a grassy field, its gaze directed towards the camera, with a stone wall adorned with yellow moss in the background.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12618.3, "ram_available_mb": 50222.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.783, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-28T14:14:57.025875"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5576.166, "latencies_ms": [5576.166], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. grass: 1\n3. wall: 1\n4. stone: 1\n5. ear: 1\n6. eye: 1\n7. nose: 1\n8. hoof: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.283}, "power_stats": {"power_gpu_soc_mean_watts": 18.922, "power_cpu_cv_mean_watts": 2.046, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 73.283}, "timestamp": "2026-01-28T14:15:04.613481"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4374.904, "latencies_ms": [4374.904], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sheep is located in the foreground of the image, standing on a grassy field. The stone wall is in the background, and the green bushes are situated to the left of the sheep.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12617.6, "ram_available_mb": 50223.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.711, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 7.798, "gpu_utilization_percent_mean": 73.838}, "timestamp": "2026-01-28T14:15:11.001351"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3091.469, "latencies_ms": [3091.469], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A sheep is standing in a grassy field with a stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.166, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 80.923}, "timestamp": "2026-01-28T14:15:16.139303"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3115.317, "latencies_ms": [3115.317], "images_per_second": 0.321, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The sheep is white, the grass is green, and the wall is gray.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.028, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 80.269}, "timestamp": "2026-01-28T14:15:21.272569"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3597.573, "latencies_ms": [3597.573], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man in a white shirt and plaid shorts is standing next to a truck with a large black pipe on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.467}, "power_stats": {"power_gpu_soc_mean_watts": 21.949, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 76.467}, "timestamp": "2026-01-28T14:15:26.935040"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4613.776, "latencies_ms": [4613.776], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " truck: 1, man: 2, man on truck: 1, man on ground: 1, container: 1, cable: 1, manhole cover: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.447}, "power_stats": {"power_gpu_soc_mean_watts": 20.206, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 71.447}, "timestamp": "2026-01-28T14:15:33.593346"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4650.188, "latencies_ms": [4650.188], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man in the foreground is standing near the truck, while the man in the background is standing further away. The man on top of the truck is positioned to the left of the man in the foreground.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12617.2, "ram_available_mb": 50223.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.872}, "power_stats": {"power_gpu_soc_mean_watts": 20.201, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 73.872}, "timestamp": "2026-01-28T14:15:40.270794"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3659.074, "latencies_ms": [3659.074], "images_per_second": 0.273, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man in a white shirt and plaid shorts is standing next to a truck with a large black pipe on it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.967}, "power_stats": {"power_gpu_soc_mean_watts": 21.855, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 76.967}, "timestamp": "2026-01-28T14:15:45.968247"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4425.789, "latencies_ms": [4425.789], "images_per_second": 0.226, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a man standing on the side of a truck, with a large black pipe on the back of the truck. The sky is overcast, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12616.6, "ram_available_mb": 50224.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.298, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-28T14:15:52.413359"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3941.873, "latencies_ms": [3941.873], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, there are four giraffes walking in a line on a dirt path, with a pond nearby, and a deer sitting on the ground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12616.6, "ram_available_mb": 50224.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.278, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 75.576}, "timestamp": "2026-01-28T14:15:58.419016"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5608.398, "latencies_ms": [5608.398], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. giraffe: 4\n2. giraffe: 1\n3. giraffe: 1\n4. giraffe: 1\n5. giraffe: 1\n6. giraffe: 1\n7. giraffe: 1\n8. giraffe: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12615.5, "ram_available_mb": 50225.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.767, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 72.957}, "timestamp": "2026-01-28T14:16:06.070875"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4454.183, "latencies_ms": [4454.183], "images_per_second": 0.225, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The giraffes are positioned in the foreground of the image, with the deer in the background. The pond is located to the left of the giraffes, and the trees are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12615.9, "ram_available_mb": 50224.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.297}, "power_stats": {"power_gpu_soc_mean_watts": 20.19, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 73.297}, "timestamp": "2026-01-28T14:16:12.580648"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4756.511, "latencies_ms": [4756.511], "images_per_second": 0.21, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In a serene setting, four giraffes are seen traversing a dirt path, their long necks reaching towards the sky. The backdrop is a lush expanse of trees and bushes, providing a natural habitat for these majestic creatures.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12615.9, "ram_available_mb": 50224.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.282}, "power_stats": {"power_gpu_soc_mean_watts": 20.08, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 73.282}, "timestamp": "2026-01-28T14:16:19.355315"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3315.648, "latencies_ms": [3315.648], "images_per_second": 0.302, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The giraffes are brown and white, the trees are green, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.481}, "power_stats": {"power_gpu_soc_mean_watts": 22.785, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 76.481}, "timestamp": "2026-01-28T14:16:24.692667"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3631.393, "latencies_ms": [3631.393], "images_per_second": 0.275, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A pizza with various toppings is on a white plate, with a glass of beer and a wine glass in the background.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12616.2, "ram_available_mb": 50224.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12616.4, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.057, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-28T14:16:30.377953"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5679.619, "latencies_ms": [5679.619], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. plate: 1\n2. pizza: 1\n3. wine glass: 2\n4. beer glass: 1\n5. fork: 1\n6. knife: 1\n7. tablecloth: 1\n8. chair: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12616.4, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.021}, "power_stats": {"power_gpu_soc_mean_watts": 19.15, "power_cpu_cv_mean_watts": 1.96, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 72.021}, "timestamp": "2026-01-28T14:16:38.079278"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4694.179, "latencies_ms": [4694.179], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the glasses of beer and the wine bottle in the background. The glasses of beer are on the right side of the pizza, while the wine bottle is on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.4, "ram_available_mb": 50223.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.675}, "power_stats": {"power_gpu_soc_mean_watts": 20.106, "power_cpu_cv_mean_watts": 2.744, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 73.675}, "timestamp": "2026-01-28T14:16:44.807656"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3818.281, "latencies_ms": [3818.281], "images_per_second": 0.262, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In a restaurant with tables and chairs, a pizza is served on a white plate with a glass of beer and a glass of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.517, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 77.844}, "timestamp": "2026-01-28T14:16:50.671359"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5773.403, "latencies_ms": [5773.403], "images_per_second": 0.173, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a pizza with a variety of toppings, including ham, pineapple, and mushrooms, placed on a white plate. The pizza is served on a tablecloth with a blue and white pattern. The lighting in the room is warm, and the colors are vibrant, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12618.4, "ram_available_mb": 50222.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.776}, "power_stats": {"power_gpu_soc_mean_watts": 18.696, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 71.776}, "timestamp": "2026-01-28T14:16:58.472678"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3010.226, "latencies_ms": [3010.226], "images_per_second": 0.332, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black cat is drinking water from a faucet in a bathroom sink.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12618.4, "ram_available_mb": 50222.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.057, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-28T14:17:03.507815"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4250.424, "latencies_ms": [4250.424], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. black cat\n2. sink\n3. faucet\n4. water\n5. soap bottle\n6. soap dish\n7. wall\n8. window", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.028}, "power_stats": {"power_gpu_soc_mean_watts": 20.783, "power_cpu_cv_mean_watts": 2.225, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 76.028}, "timestamp": "2026-01-28T14:17:09.801266"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4890.975, "latencies_ms": [4890.975], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is positioned to the right of the faucet, with the sink basin directly in front of it. The soap bottle is located to the left of the faucet, and the dish is situated to the right of the faucet.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.813, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.776, "gpu_utilization_percent_mean": 71.463}, "timestamp": "2026-01-28T14:17:16.723890"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3024.85, "latencies_ms": [3024.85], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black cat is drinking water from a faucet in a bathroom sink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.958}, "power_stats": {"power_gpu_soc_mean_watts": 23.565, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 7.847, "gpu_utilization_percent_mean": 77.958}, "timestamp": "2026-01-28T14:17:21.768634"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6005.533, "latencies_ms": [6005.533], "images_per_second": 0.167, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image depicts a black cat drinking water from a faucet in a bathroom. The cat is positioned in front of a white sink, with a bottle of soap and a soap dish nearby. The lighting in the bathroom is bright, and the overall color scheme consists of white, black, and beige tones.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12618.7, "ram_available_mb": 50222.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.76}, "power_stats": {"power_gpu_soc_mean_watts": 18.059, "power_cpu_cv_mean_watts": 1.946, "power_sys_5v0_mean_watts": 7.643, "gpu_utilization_percent_mean": 71.76}, "timestamp": "2026-01-28T14:17:29.822722"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5092.639, "latencies_ms": [5092.639], "images_per_second": 0.196, "prompt_tokens": 1432, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, a man wearing a cowboy hat and a woman wearing a hat are riding in a horse-drawn carriage, with the horse pulling the carriage through a muddy field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12618.4, "ram_available_mb": 50222.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.738}, "power_stats": {"power_gpu_soc_mean_watts": 22.078, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 79.738}, "timestamp": "2026-01-28T14:17:36.949654"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6727.87, "latencies_ms": [6727.87], "images_per_second": 0.149, "prompt_tokens": 1446, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. horse: 1\n2. carriage: 1\n3. man: 2\n4. woman: 1\n5. horse's tail: 1\n6. horse's mane: 1\n7. horse's hoof: 1\n8. horse's leg: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.4, "ram_available_mb": 50222.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12619.1, "ram_available_mb": 50221.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.035}, "power_stats": {"power_gpu_soc_mean_watts": 20.458, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 75.035}, "timestamp": "2026-01-28T14:17:45.734239"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6336.602, "latencies_ms": [6336.602], "images_per_second": 0.158, "prompt_tokens": 1450, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The horse is in the foreground, pulling the carriage, while the two people are in the background. The carriage is in the middle of the image, with the horse in front of it. The reflection of the carriage and horse can be seen in the puddle of water below them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12619.1, "ram_available_mb": 50221.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.83}, "power_stats": {"power_gpu_soc_mean_watts": 20.604, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 75.83}, "timestamp": "2026-01-28T14:17:54.093909"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5498.529, "latencies_ms": [5498.529], "images_per_second": 0.182, "prompt_tokens": 1444, "response_tokens_est": 44, "n_tiles": 1, "output_text": " A man and woman are riding in a horse-drawn carriage, with a horse pulling it. The carriage is in a muddy field, and there is a puddle of water reflecting the carriage and the people in it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.5, "ram_available_mb": 50222.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12619.1, "ram_available_mb": 50221.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.543}, "power_stats": {"power_gpu_soc_mean_watts": 21.656, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 76.543}, "timestamp": "2026-01-28T14:18:01.642020"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6434.446, "latencies_ms": [6434.446], "images_per_second": 0.155, "prompt_tokens": 1442, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a muddy field with a horse-drawn carriage, reflecting the sky and surrounding trees. The sky is clear and blue, indicating a sunny day. The carriage is made of wood and has large spoked wheels, while the horse is brown with a black mane and tail.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12619.1, "ram_available_mb": 50221.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12619.1, "ram_available_mb": 50221.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.796}, "power_stats": {"power_gpu_soc_mean_watts": 20.483, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 75.796}, "timestamp": "2026-01-28T14:18:10.108232"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3562.631, "latencies_ms": [3562.631], "images_per_second": 0.281, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man and woman are standing under a white and black umbrella, with a stone building and other people in the background.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12619.1, "ram_available_mb": 50221.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.167}, "power_stats": {"power_gpu_soc_mean_watts": 22.031, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.807, "gpu_utilization_percent_mean": 77.167}, "timestamp": "2026-01-28T14:18:15.721224"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4205.821, "latencies_ms": [4205.821], "images_per_second": 0.238, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " umbrella: 1, man: 1, woman: 1, flower: 1, grass: 1, stone: 1, house: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.874, "power_cpu_cv_mean_watts": 1.773, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-28T14:18:21.960857"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5169.987, "latencies_ms": [5169.987], "images_per_second": 0.193, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The bride is standing to the left of the groom, with the umbrella held above them. The bride is positioned closer to the camera than the groom. The umbrella is held by the groom, and the bride is holding a bouquet of flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12618.6, "ram_available_mb": 50222.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.721}, "power_stats": {"power_gpu_soc_mean_watts": 19.432, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 7.718, "gpu_utilization_percent_mean": 71.721}, "timestamp": "2026-01-28T14:18:29.141825"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3150.257, "latencies_ms": [3150.257], "images_per_second": 0.317, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A newlywed couple is standing under a black and white umbrella in a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.654}, "power_stats": {"power_gpu_soc_mean_watts": 22.597, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 78.654}, "timestamp": "2026-01-28T14:18:34.311407"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6042.513, "latencies_ms": [6042.513], "images_per_second": 0.165, "prompt_tokens": 1110, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a couple dressed in formal attire, with the bride wearing a white wedding dress and the groom in a black suit. The weather appears to be rainy, as evidenced by the presence of an umbrella held by the groom. The couple is standing on a grassy lawn, with a stone building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12617.1, "ram_available_mb": 50223.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.32}, "power_stats": {"power_gpu_soc_mean_watts": 18.355, "power_cpu_cv_mean_watts": 2.035, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 69.32}, "timestamp": "2026-01-28T14:18:42.388312"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3052.396, "latencies_ms": [3052.396], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man is lying on the beach with a kite flying in the sky.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12617.1, "ram_available_mb": 50223.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.84}, "power_stats": {"power_gpu_soc_mean_watts": 22.991, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 80.84}, "timestamp": "2026-01-28T14:18:47.492209"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5573.767, "latencies_ms": [5573.767], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. legs: 2\n3. shorts: 2\n4. feet: 2\n5. sand: 1\n6. kite: 1\n7. kite string: 1\n8. ocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.417}, "power_stats": {"power_gpu_soc_mean_watts": 18.752, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 71.417}, "timestamp": "2026-01-28T14:18:55.106202"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4858.082, "latencies_ms": [4858.082], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the person is in the background, lying on the beach. The person is near the kite, as they are both in the same location on the beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12617.7, "ram_available_mb": 50223.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12618.1, "ram_available_mb": 50222.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.732}, "power_stats": {"power_gpu_soc_mean_watts": 19.911, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 72.732}, "timestamp": "2026-01-28T14:19:01.986924"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3548.16, "latencies_ms": [3548.16], "images_per_second": 0.282, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is laying on the beach with his legs up in the air, while another man is flying a kite.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12618.1, "ram_available_mb": 50222.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12618.1, "ram_available_mb": 50222.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.264, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 80.379}, "timestamp": "2026-01-28T14:19:07.544721"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5876.856, "latencies_ms": [5876.856], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a man lying on the sand, wearing a white shirt and brown shorts, while another person is sitting on the sand, holding a colorful kite. The sky is clear with a few clouds, and the sun is shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.52}, "power_stats": {"power_gpu_soc_mean_watts": 18.569, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 71.52}, "timestamp": "2026-01-28T14:19:15.446824"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4358.285, "latencies_ms": [4358.285], "images_per_second": 0.229, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a brown sofa, a red armchair, a small table, and a television set, all arranged around a window with wooden shutters.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12617.9, "ram_available_mb": 50223.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.028}, "power_stats": {"power_gpu_soc_mean_watts": 20.596, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 74.028}, "timestamp": "2026-01-28T14:19:21.844637"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4281.212, "latencies_ms": [4281.212], "images_per_second": 0.234, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " sofa: 1, chair: 1, television: 1, lamp: 1, table: 1, window: 2, floor lamp: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12617.5, "ram_available_mb": 50223.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.808, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 75.222}, "timestamp": "2026-01-28T14:19:28.150749"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6326.157, "latencies_ms": [6326.157], "images_per_second": 0.158, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The sofa is located to the left of the coffee table, which is in front of the television. The coffee table is situated in the middle of the room, with the sofa to its left and the television to its right. The lamp is positioned to the left of the television, and the chair is to the right of the television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.698}, "power_stats": {"power_gpu_soc_mean_watts": 18.117, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 7.722, "gpu_utilization_percent_mean": 70.698}, "timestamp": "2026-01-28T14:19:36.486362"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3241.816, "latencies_ms": [3241.816], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A living room with a brown couch, red chair, and a TV is shown.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12618.0, "ram_available_mb": 50222.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.534, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 79.259}, "timestamp": "2026-01-28T14:19:41.773170"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3410.076, "latencies_ms": [3410.076], "images_per_second": 0.293, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is well lit with natural light coming through the windows, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12617.8, "ram_available_mb": 50223.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.348, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 78.071}, "timestamp": "2026-01-28T14:19:47.218320"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4180.022, "latencies_ms": [4180.022], "images_per_second": 0.239, "prompt_tokens": 1432, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A bald man wearing glasses and a blue shirt is eating a slice of cake with a fork in a park.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.9, "ram_available_mb": 50222.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12618.1, "ram_available_mb": 50222.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.057}, "power_stats": {"power_gpu_soc_mean_watts": 23.371, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.108, "gpu_utilization_percent_mean": 81.057}, "timestamp": "2026-01-28T14:19:53.439819"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6332.997, "latencies_ms": [6332.997], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. plate: 1\n3. fork: 1\n4. spoon: 1\n5. cake: 1\n6. grass: 1\n7. tree: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12618.1, "ram_available_mb": 50222.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.132}, "power_stats": {"power_gpu_soc_mean_watts": 20.467, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 75.132}, "timestamp": "2026-01-28T14:20:01.824325"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5385.368, "latencies_ms": [5385.368], "images_per_second": 0.186, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man is in the foreground of the image, holding a plate of cake in his hands. The cake is in the middle of the image, with the man's face and the trees in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12618.8, "ram_available_mb": 50222.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.289}, "power_stats": {"power_gpu_soc_mean_watts": 21.925, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 78.289}, "timestamp": "2026-01-28T14:20:09.233898"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3876.725, "latencies_ms": [3876.725], "images_per_second": 0.258, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing glasses and a blue shirt is eating a slice of cake in a park.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12620.0, "ram_available_mb": 50220.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12620.3, "ram_available_mb": 50220.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.469}, "power_stats": {"power_gpu_soc_mean_watts": 24.846, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 84.469}, "timestamp": "2026-01-28T14:20:15.142765"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4424.615, "latencies_ms": [4424.615], "images_per_second": 0.226, "prompt_tokens": 1442, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and is eating a slice of cake in a park with green grass and trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12620.3, "ram_available_mb": 50220.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.324}, "power_stats": {"power_gpu_soc_mean_watts": 23.491, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 82.324}, "timestamp": "2026-01-28T14:20:21.595304"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3801.428, "latencies_ms": [3801.428], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man wearing a purple vest and gray pants is walking alongside a brown horse that is carrying a large load of luggage on its back.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12622.2, "ram_available_mb": 50218.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.871}, "power_stats": {"power_gpu_soc_mean_watts": 21.552, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 72.871}, "timestamp": "2026-01-28T14:20:27.440117"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5571.271, "latencies_ms": [5571.271], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. horse: 1\n3. luggage: 1\n4. backpack: 1\n5. blanket: 1\n6. rope: 1\n7. tree: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12622.2, "ram_available_mb": 50218.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.587}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 70.587}, "timestamp": "2026-01-28T14:20:35.050715"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5118.841, "latencies_ms": [5118.841], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The man is standing to the left of the donkey, which is positioned in the foreground of the image. The donkey is facing the camera, while the man is facing away from it. The man is standing closer to the camera than the donkey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.465}, "power_stats": {"power_gpu_soc_mean_watts": 19.626, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 72.465}, "timestamp": "2026-01-28T14:20:42.185536"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3832.746, "latencies_ms": [3832.746], "images_per_second": 0.261, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man is walking with a donkey that is carrying a large load of luggage. The man is wearing a purple vest and gray pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.312}, "power_stats": {"power_gpu_soc_mean_watts": 21.541, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 76.312}, "timestamp": "2026-01-28T14:20:48.067334"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4830.285, "latencies_ms": [4830.285], "images_per_second": 0.207, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a man and a horse with a colorful blanket on the horse. The man is wearing a purple and white jacket, and the horse is brown. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.225}, "power_stats": {"power_gpu_soc_mean_watts": 19.859, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 72.225}, "timestamp": "2026-01-28T14:20:54.911498"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4983.096, "latencies_ms": [4983.096], "images_per_second": 0.201, "prompt_tokens": 766, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge adorned with blue lights, standing majestically over a river, with a boat gently floating on the water, and a crowd of people gathered on the riverbank, all bathed in the soft glow of the illuminated bridge and the surrounding lights.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5033.1, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 67.929}, "power_stats": {"power_gpu_soc_mean_watts": 16.652, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.602, "gpu_utilization_percent_mean": 67.929}, "timestamp": "2026-01-28T14:21:01.935522"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5083.865, "latencies_ms": [5083.865], "images_per_second": 0.197, "prompt_tokens": 780, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bridge: 3\n2. lights: 100\n3. people: 10\n4. boat: 1\n5. water: 1\n6. street: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 66.929}, "power_stats": {"power_gpu_soc_mean_watts": 16.711, "power_cpu_cv_mean_watts": 2.022, "power_sys_5v0_mean_watts": 7.585, "gpu_utilization_percent_mean": 66.929}, "timestamp": "2026-01-28T14:21:09.042804"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4239.159, "latencies_ms": [4239.159], "images_per_second": 0.236, "prompt_tokens": 784, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main objects in the image are the bridge and the river. The bridge is located in the background, while the river is in the foreground. The bridge is near the river, and the river is far from the bridge.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12623.3, "ram_available_mb": 50217.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.514}, "power_stats": {"power_gpu_soc_mean_watts": 17.67, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.619, "gpu_utilization_percent_mean": 69.514}, "timestamp": "2026-01-28T14:21:15.296478"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5528.507, "latencies_ms": [5528.507], "images_per_second": 0.181, "prompt_tokens": 778, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge adorned with blue lights, spanning across a river. The bridge, a marvel of engineering, is a spectacle in the dark sky, its lights reflecting off the water's surface. People can be seen strolling along the riverbank, adding a touch of life to the serene setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12623.3, "ram_available_mb": 50217.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.261}, "power_stats": {"power_gpu_soc_mean_watts": 16.335, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 7.57, "gpu_utilization_percent_mean": 68.261}, "timestamp": "2026-01-28T14:21:22.865948"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4695.381, "latencies_ms": [4695.381], "images_per_second": 0.213, "prompt_tokens": 776, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge adorned with blue lights, reflecting beautifully on the calm river below. The sky is a dark canvas, punctuated by a few clouds, while the city lights in the distance add a warm glow to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 66.256}, "power_stats": {"power_gpu_soc_mean_watts": 16.956, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.558, "gpu_utilization_percent_mean": 66.256}, "timestamp": "2026-01-28T14:21:29.584612"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3297.452, "latencies_ms": [3297.452], "images_per_second": 0.303, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A person's foot is resting on a wooden surface with a pink shoe and blue jeans.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.001, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 76.423}, "timestamp": "2026-01-28T14:21:34.915852"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4566.405, "latencies_ms": [4566.405], "images_per_second": 0.219, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. pink shoe\n2. blue jeans\n3. wooden surface\n4. pink bow\n5. blue paint\n6. green paint\n7. yellow paint\n8. black paint", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.295, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.786, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-28T14:21:41.513534"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4624.616, "latencies_ms": [4624.616], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The pink shoe is positioned on the left side of the image, while the blue jeans are located on the right side. The pink shoe is in the foreground, while the blue jeans are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.0, "ram_available_mb": 50217.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.249, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.754, "gpu_utilization_percent_mean": 74.474}, "timestamp": "2026-01-28T14:21:48.156466"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2810.817, "latencies_ms": [2810.817], "images_per_second": 0.356, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A person is wearing a pink shoe and blue jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.609}, "power_stats": {"power_gpu_soc_mean_watts": 23.719, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 7.824, "gpu_utilization_percent_mean": 84.609}, "timestamp": "2026-01-28T14:21:52.994215"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5290.138, "latencies_ms": [5290.138], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a person wearing a pink high-heeled shoe with a bow on the toe, standing on a wooden floor with a blue and green paint job. The lighting is bright and the colors are vivid, giving the image a vibrant and lively appearance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12622.3, "ram_available_mb": 50218.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.841}, "power_stats": {"power_gpu_soc_mean_watts": 19.49, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.764, "gpu_utilization_percent_mean": 73.841}, "timestamp": "2026-01-28T14:22:00.304683"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3611.842, "latencies_ms": [3611.842], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A woman and a boy are standing in a room with a red wall, with a table in front of them.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12621.6, "ram_available_mb": 50219.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12621.4, "ram_available_mb": 50219.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.155, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 76.207}, "timestamp": "2026-01-28T14:22:05.943031"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4365.216, "latencies_ms": [4365.216], "images_per_second": 0.229, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " woman: 1, boy: 1, mug: 1, plate: 1, cake: 1, chair: 1, door: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12621.4, "ram_available_mb": 50219.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12621.5, "ram_available_mb": 50219.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.652, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 75.222}, "timestamp": "2026-01-28T14:22:12.351811"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4184.581, "latencies_ms": [4184.581], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The woman is standing to the left of the boy, and the table is in front of them. The boy is standing closer to the table than the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12621.5, "ram_available_mb": 50219.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12621.5, "ram_available_mb": 50219.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.735}, "power_stats": {"power_gpu_soc_mean_watts": 21.122, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 74.735}, "timestamp": "2026-01-28T14:22:18.560365"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4420.336, "latencies_ms": [4420.336], "images_per_second": 0.226, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A woman and a boy are standing in a room with a red wall. The woman is holding a knife and the boy is standing next to a table with a cake on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12621.5, "ram_available_mb": 50219.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12621.5, "ram_available_mb": 50219.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.167}, "power_stats": {"power_gpu_soc_mean_watts": 20.305, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.714, "gpu_utilization_percent_mean": 73.167}, "timestamp": "2026-01-28T14:22:25.017070"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3935.509, "latencies_ms": [3935.509], "images_per_second": 0.254, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a room with a red wall and a white door. The lighting is natural, coming from a window out of frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12621.5, "ram_available_mb": 50219.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.417, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 72.562}, "timestamp": "2026-01-28T14:22:30.973311"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9336.02, "latencies_ms": [9336.02], "images_per_second": 0.107, "prompt_tokens": 1099, "response_tokens_est": 119, "n_tiles": 1, "output_text": " In the center of an indoor arena, three elephants are engaged in a performance, their trunks extended towards a red and yellow circular platform. The platform, adorned with a vibrant border, serves as the stage for this spectacle. The elephants, each distinct in color - one a rich brown, another a lighter shade of brown, and the third a gray - are harnessed with blue ropes, indicating their role in the performance. In the background, a photographer's tripod stands ready to capture the moment, while a disco ball hangs from the ceiling, adding a touch of whimsy to the scene.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.141}, "power_stats": {"power_gpu_soc_mean_watts": 16.495, "power_cpu_cv_mean_watts": 2.069, "power_sys_5v0_mean_watts": 7.706, "gpu_utilization_percent_mean": 68.141}, "timestamp": "2026-01-28T14:22:42.333476"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4198.46, "latencies_ms": [4198.46], "images_per_second": 0.238, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 3, elephant: 3, elephant: 3, elephant: 3, elephant: 3, elephant: 3, elephant: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12621.7, "ram_available_mb": 50219.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.429}, "power_stats": {"power_gpu_soc_mean_watts": 20.92, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.82, "gpu_utilization_percent_mean": 73.429}, "timestamp": "2026-01-28T14:22:48.592606"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4735.605, "latencies_ms": [4735.605], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The elephants are positioned in the foreground of the image, with the camera and the audience in the background. The elephants are standing on a red and yellow striped circus ring, which is surrounded by a white fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12621.7, "ram_available_mb": 50219.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12621.7, "ram_available_mb": 50219.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.205}, "power_stats": {"power_gpu_soc_mean_watts": 20.098, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 74.205}, "timestamp": "2026-01-28T14:22:55.370041"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6791.565, "latencies_ms": [6791.565], "images_per_second": 0.147, "prompt_tokens": 1111, "response_tokens_est": 75, "n_tiles": 1, "output_text": " In a spacious indoor arena, three elephants are engaged in a performance. The largest elephant, adorned with a blue harness, is positioned in the center, while the other two, one brown and one gray, are on either side. The arena is equipped with a red and yellow striped ring on the floor, and a camera is mounted on a tripod to capture the performance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12621.7, "ram_available_mb": 50219.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 68.86}, "power_stats": {"power_gpu_soc_mean_watts": 17.766, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 7.677, "gpu_utilization_percent_mean": 68.86}, "timestamp": "2026-01-28T14:23:04.187759"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4227.537, "latencies_ms": [4227.537], "images_per_second": 0.237, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The elephants are brown and gray, and the circus ring is red and yellow. The lighting is bright and artificial, and the elephants are standing on a dirt floor.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.714}, "power_stats": {"power_gpu_soc_mean_watts": 20.772, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 76.714}, "timestamp": "2026-01-28T14:23:10.474131"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5063.716, "latencies_ms": [5063.716], "images_per_second": 0.197, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In the sepia-toned photograph, a group of jockeys and their horses are captured mid-gallop on a beach, their bodies blurred due to the motion, with the sky and water serving as a backdrop.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.881}, "power_stats": {"power_gpu_soc_mean_watts": 19.275, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 71.881}, "timestamp": "2026-01-28T14:23:17.607480"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4885.569, "latencies_ms": [4885.569], "images_per_second": 0.205, "prompt_tokens": 1113, "response_tokens_est": 43, "n_tiles": 1, "output_text": " horse: 1\nrider: 1\nhorse: 1\nrider: 1\nhorse: 1\nrider: 1\nhorse: 1\nrider: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12623.3, "ram_available_mb": 50217.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.675}, "power_stats": {"power_gpu_soc_mean_watts": 19.719, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 74.675}, "timestamp": "2026-01-28T14:23:24.513012"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4964.571, "latencies_ms": [4964.571], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The horses are positioned in the foreground, with the riders slightly behind them. The riders are positioned in the middle ground, with the horses in the foreground. The background is the sky, which is visible above the horizon line.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.3, "ram_available_mb": 50217.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.854}, "power_stats": {"power_gpu_soc_mean_watts": 19.609, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 69.854}, "timestamp": "2026-01-28T14:23:31.521763"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3222.267, "latencies_ms": [3222.267], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are riding horses on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.704}, "power_stats": {"power_gpu_soc_mean_watts": 22.805, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.837, "gpu_utilization_percent_mean": 79.704}, "timestamp": "2026-01-28T14:23:36.768335"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3606.701, "latencies_ms": [3606.701], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is in black and white, with a sepia tone, and the horses are running on a wet beach.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12623.2, "ram_available_mb": 50217.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.7}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 74.7}, "timestamp": "2026-01-28T14:23:42.397123"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3526.928, "latencies_ms": [3526.928], "images_per_second": 0.284, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person wearing a black jacket and a black helmet with blue goggles is talking on a cell phone in a snowy park.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.338, "power_cpu_cv_mean_watts": 1.63, "power_sys_5v0_mean_watts": 7.842, "gpu_utilization_percent_mean": 78.379}, "timestamp": "2026-01-28T14:23:47.964350"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5608.449, "latencies_ms": [5608.449], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. goggles: 1\n3. jacket: 1\n4. tree: 1\n5. snow: 1\n6. sun: 1\n7. tree trunk: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12621.1, "ram_available_mb": 50219.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.936}, "power_stats": {"power_gpu_soc_mean_watts": 18.81, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 70.936}, "timestamp": "2026-01-28T14:23:55.586944"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4489.942, "latencies_ms": [4489.942], "images_per_second": 0.223, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, wearing a black jacket and a black helmet with goggles. The trees are in the background, and the snow is covering the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12621.1, "ram_available_mb": 50219.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12621.1, "ram_available_mb": 50219.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.135}, "power_stats": {"power_gpu_soc_mean_watts": 20.277, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 74.135}, "timestamp": "2026-01-28T14:24:02.101839"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3349.579, "latencies_ms": [3349.579], "images_per_second": 0.299, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing a black jacket and a black helmet is talking on a cell phone in the snow.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12621.1, "ram_available_mb": 50219.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12621.1, "ram_available_mb": 50219.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.549, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 73.296}, "timestamp": "2026-01-28T14:24:07.470553"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3964.856, "latencies_ms": [3964.856], "images_per_second": 0.252, "prompt_tokens": 1110, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The person is wearing a black jacket and a black helmet with blue goggles. The sun is shining brightly, and there is snow on the ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12621.1, "ram_available_mb": 50219.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12621.8, "ram_available_mb": 50219.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.909}, "power_stats": {"power_gpu_soc_mean_watts": 21.192, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 7.768, "gpu_utilization_percent_mean": 74.909}, "timestamp": "2026-01-28T14:24:13.475287"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3297.161, "latencies_ms": [3297.161], "images_per_second": 0.303, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A motorcycle is parked in a field with a green tent and a blue flag in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12621.8, "ram_available_mb": 50219.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12621.3, "ram_available_mb": 50219.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.741}, "power_stats": {"power_gpu_soc_mean_watts": 22.607, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 79.741}, "timestamp": "2026-01-28T14:24:18.806755"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6078.722, "latencies_ms": [6078.722], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. green tent: 1\n2. motorcycle: 1\n3. backpack: 1\n4. motorcycle bag: 1\n5. motorcycle seat: 1\n6. motorcycle handlebars: 1\n7. motorcycle front wheel: 1\n8. motorcycle rear wheel: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12621.3, "ram_available_mb": 50219.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12623.1, "ram_available_mb": 50217.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.706}, "power_stats": {"power_gpu_soc_mean_watts": 18.472, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 71.706}, "timestamp": "2026-01-28T14:24:26.895359"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5378.502, "latencies_ms": [5378.502], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The motorcycle is positioned to the right of the tent, with the motorcycle being closer to the foreground and the tent being further back in the scene. The motorcycle is also positioned in front of the tent, with the motorcycle being closer to the viewer than the tent.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12623.1, "ram_available_mb": 50217.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12622.2, "ram_available_mb": 50218.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.022}, "power_stats": {"power_gpu_soc_mean_watts": 19.316, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 72.022}, "timestamp": "2026-01-28T14:24:34.290758"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2894.084, "latencies_ms": [2894.084], "images_per_second": 0.346, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A motorcycle and a tent are parked in a field at sunset.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.2, "ram_available_mb": 50218.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.766, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 7.88, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-28T14:24:39.204579"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3756.772, "latencies_ms": [3756.772], "images_per_second": 0.266, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The motorcycle is white and black, and the tent is green. The sun is setting, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12622.4, "ram_available_mb": 50218.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12621.8, "ram_available_mb": 50219.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.839}, "power_stats": {"power_gpu_soc_mean_watts": 21.565, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 73.839}, "timestamp": "2026-01-28T14:24:45.004575"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3816.606, "latencies_ms": [3816.606], "images_per_second": 0.262, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A black and white photo shows a steam locomotive with the number 67371 on it, and people standing near it.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12621.8, "ram_available_mb": 50219.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.329, "power_cpu_cv_mean_watts": 1.727, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 74.562}, "timestamp": "2026-01-28T14:24:50.875238"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5640.267, "latencies_ms": [5640.267], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. steam locomotive: 1\n2. people: 4\n3. train cars: 3\n4. platform: 1\n5. buildings: 2\n6. smoke: 1\n7. tracks: 1\n8. sign: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12621.6, "ram_available_mb": 50219.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.894}, "power_stats": {"power_gpu_soc_mean_watts": 18.775, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 70.894}, "timestamp": "2026-01-28T14:24:58.544389"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4730.793, "latencies_ms": [4730.793], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The train is on the left side of the image, with the platform on the right. The passengers are standing on the platform, near the train. The buildings are in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12621.6, "ram_available_mb": 50219.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12621.6, "ram_available_mb": 50219.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.228, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-28T14:25:05.315040"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3051.201, "latencies_ms": [3051.201], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A black and white photo of a train with people standing next to it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12621.6, "ram_available_mb": 50219.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12622.6, "ram_available_mb": 50218.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.96}, "power_stats": {"power_gpu_soc_mean_watts": 23.249, "power_cpu_cv_mean_watts": 1.698, "power_sys_5v0_mean_watts": 7.839, "gpu_utilization_percent_mean": 80.96}, "timestamp": "2026-01-28T14:25:10.422947"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3101.265, "latencies_ms": [3101.265], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The train is black and white, and the smoke is white.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12622.6, "ram_available_mb": 50218.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.56}, "power_stats": {"power_gpu_soc_mean_watts": 22.739, "power_cpu_cv_mean_watts": 2.131, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 76.56}, "timestamp": "2026-01-28T14:25:15.565762"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4323.972, "latencies_ms": [4323.972], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a densely populated urban area, where numerous signs and banners in Chinese characters are suspended from the buildings, creating a vibrant and chaotic atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.955, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 7.828, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-28T14:25:21.921461"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5800.694, "latencies_ms": [5800.694], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. sign: 10\n2. building: 1\n3. window: 1\n4. air conditioner: 1\n5. power line: 1\n6. street sign: 1\n7. pole: 1\n8. wire: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.5, "ram_available_mb": 50217.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.812}, "power_stats": {"power_gpu_soc_mean_watts": 18.901, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 70.812}, "timestamp": "2026-01-28T14:25:29.752337"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4324.523, "latencies_ms": [4324.523], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The main objects are the signs and the buildings. The signs are in the foreground and the buildings are in the background. The signs are closer to the viewer than the buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.75}, "power_stats": {"power_gpu_soc_mean_watts": 20.696, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 73.75}, "timestamp": "2026-01-28T14:25:36.118777"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4013.348, "latencies_ms": [4013.348], "images_per_second": 0.249, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image captures a bustling street in a densely populated urban area, where numerous signs and banners are suspended from the buildings, creating a vibrant and chaotic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.425, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.79, "gpu_utilization_percent_mean": 75.667}, "timestamp": "2026-01-28T14:25:42.153200"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3848.341, "latencies_ms": [3848.341], "images_per_second": 0.26, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is in black and white, with a high contrast of light and dark. The buildings are made of concrete and have many windows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.781}, "power_stats": {"power_gpu_soc_mean_watts": 21.581, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 77.781}, "timestamp": "2026-01-28T14:25:48.026259"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4056.562, "latencies_ms": [4056.562], "images_per_second": 0.247, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man is lying on the grass by the water, while a sign with the word \"CLOSED\" is lying on the ground in front of him.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12622.9, "ram_available_mb": 50218.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.853}, "power_stats": {"power_gpu_soc_mean_watts": 21.1, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 74.853}, "timestamp": "2026-01-28T14:25:54.119474"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5624.783, "latencies_ms": [5624.783], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. grass: 1\n3. lake: 1\n4. wooden board: 1\n5. sign: 1\n6. trash: 1\n7. water: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.9, "ram_available_mb": 50218.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.277}, "power_stats": {"power_gpu_soc_mean_watts": 19.194, "power_cpu_cv_mean_watts": 1.96, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 72.277}, "timestamp": "2026-01-28T14:26:01.782535"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5310.672, "latencies_ms": [5310.672], "images_per_second": 0.188, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The sign is in the foreground, close to the camera, and the man is in the background, far away from the camera. The wooden planks are in the foreground, close to the camera, and the lake is in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12622.0, "ram_available_mb": 50218.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.023}, "power_stats": {"power_gpu_soc_mean_watts": 19.318, "power_cpu_cv_mean_watts": 2.012, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 72.023}, "timestamp": "2026-01-28T14:26:09.116939"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4382.09, "latencies_ms": [4382.09], "images_per_second": 0.228, "prompt_tokens": 1112, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man is sunbathing on a concrete ledge overlooking a lake. In the foreground, there is a sign that reads \"SENSORI\" and \"CROSSING\".", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12621.7, "ram_available_mb": 50219.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.081}, "power_stats": {"power_gpu_soc_mean_watts": 20.245, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 74.081}, "timestamp": "2026-01-28T14:26:15.547804"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5903.985, "latencies_ms": [5903.985], "images_per_second": 0.169, "prompt_tokens": 1110, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a man lounging on a concrete ledge by a body of water, with a sign in the foreground that reads \"SENSORI\" and a wooden plank with a red and white sign that reads \"CROSS\". The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12621.7, "ram_available_mb": 50219.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12622.2, "ram_available_mb": 50218.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 18.601, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-28T14:26:23.494440"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4391.133, "latencies_ms": [4391.133], "images_per_second": 0.228, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, a brown horse and a golden retriever are standing in a field of tall grass, with the horse looking down at the dog, who is panting happily.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12622.2, "ram_available_mb": 50218.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.417, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.743, "gpu_utilization_percent_mean": 73.324}, "timestamp": "2026-01-28T14:26:29.926056"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4869.245, "latencies_ms": [4869.245], "images_per_second": 0.205, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " horse: 1, dog: 1, grass: 1, horse's mane: 1, horse's tail: 1, horse's ear: 1, horse's eye: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12622.5, "ram_available_mb": 50218.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.125}, "power_stats": {"power_gpu_soc_mean_watts": 19.859, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 72.125}, "timestamp": "2026-01-28T14:26:36.832321"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6248.422, "latencies_ms": [6248.422], "images_per_second": 0.16, "prompt_tokens": 1118, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The brown horse is positioned to the left of the golden retriever, with the horse's head slightly above the dog's. The golden retriever is in the foreground, with the horse's body extending into the background. The horse is closer to the camera than the dog, and the dog is closer to the viewer than the horse.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12623.1, "ram_available_mb": 50217.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.245}, "power_stats": {"power_gpu_soc_mean_watts": 18.314, "power_cpu_cv_mean_watts": 2.071, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 71.245}, "timestamp": "2026-01-28T14:26:45.106864"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4948.135, "latencies_ms": [4948.135], "images_per_second": 0.202, "prompt_tokens": 1112, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In a serene field, a brown horse and a golden retriever are enjoying a sunny day. The horse, with its mane and tail flowing in the wind, stands next to the dog, who is panting happily.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12623.1, "ram_available_mb": 50217.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.634}, "power_stats": {"power_gpu_soc_mean_watts": 19.443, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 71.634}, "timestamp": "2026-01-28T14:26:52.088759"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5194.886, "latencies_ms": [5194.886], "images_per_second": 0.192, "prompt_tokens": 1110, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a brown horse and a golden retriever in a grassy field, with the horse's mane and tail being a darker shade of brown. The lighting in the image is natural and bright, suggesting it was taken during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12621.9, "ram_available_mb": 50219.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 19.511, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 7.746, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-28T14:26:59.340840"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6410.056, "latencies_ms": [6410.056], "images_per_second": 0.156, "prompt_tokens": 1099, "response_tokens_est": 71, "n_tiles": 1, "output_text": " In the image, a group of people are gathered in a gymnasium, playing volleyball. The gymnasium has a blue floor with white lines marking the boundaries of the court. The players are dressed in athletic clothing, with one person in the foreground wearing a blue shirt and shorts, and another person in the background wearing a green shirt and shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.7, "ram_available_mb": 50218.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12622.6, "ram_available_mb": 50218.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.722}, "power_stats": {"power_gpu_soc_mean_watts": 18.092, "power_cpu_cv_mean_watts": 2.21, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 70.722}, "timestamp": "2026-01-28T14:27:07.791176"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4697.451, "latencies_ms": [4697.451], "images_per_second": 0.213, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " volleyball: 1\nvolleyball net: 1\nperson: 1\nperson: 1\nperson: 1\nperson: 1\nperson: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.6, "ram_available_mb": 50218.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12623.3, "ram_available_mb": 50217.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.949}, "power_stats": {"power_gpu_soc_mean_watts": 19.987, "power_cpu_cv_mean_watts": 2.187, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 73.949}, "timestamp": "2026-01-28T14:27:14.516104"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4631.555, "latencies_ms": [4631.555], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The volleyball court is located in the foreground of the image, with the players positioned in the middle ground. The walls of the gymnasium are in the background, and the ceiling is above the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12623.3, "ram_available_mb": 50217.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12623.8, "ram_available_mb": 50217.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.051}, "power_stats": {"power_gpu_soc_mean_watts": 20.11, "power_cpu_cv_mean_watts": 2.085, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 72.051}, "timestamp": "2026-01-28T14:27:21.165359"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2907.855, "latencies_ms": [2907.855], "images_per_second": 0.344, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are playing volleyball in a gymnasium.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12623.8, "ram_available_mb": 50217.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12624.0, "ram_available_mb": 50216.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.699, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 80.333}, "timestamp": "2026-01-28T14:27:26.113149"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4542.752, "latencies_ms": [4542.752], "images_per_second": 0.22, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The indoor volleyball court is blue with white lines, and the ceiling is white with brown acoustic panels. The lighting is bright and natural, coming from the windows on the right side of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12624.0, "ram_available_mb": 50216.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12624.0, "ram_available_mb": 50216.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.763}, "power_stats": {"power_gpu_soc_mean_watts": 20.102, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.741, "gpu_utilization_percent_mean": 73.763}, "timestamp": "2026-01-28T14:27:32.711132"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5192.902, "latencies_ms": [5192.902], "images_per_second": 0.193, "prompt_tokens": 1099, "response_tokens_est": 51, "n_tiles": 1, "output_text": " In the image, a herd of zebras and wildebeests graze on the lush green grass in a vast field, while a flock of pink flamingos wades in the water in the background, creating a picturesque scene of wildlife cohabitation.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12624.0, "ram_available_mb": 50216.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12624.1, "ram_available_mb": 50216.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.744}, "power_stats": {"power_gpu_soc_mean_watts": 19.526, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 71.744}, "timestamp": "2026-01-28T14:27:39.948449"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4285.318, "latencies_ms": [4285.318], "images_per_second": 0.233, "prompt_tokens": 1113, "response_tokens_est": 33, "n_tiles": 1, "output_text": " zebra: 4\nflamingo: 100\ngrass: 100\nwater: 100\nmountain: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12624.1, "ram_available_mb": 50216.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12625.2, "ram_available_mb": 50215.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.627, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 77.657}, "timestamp": "2026-01-28T14:27:46.264295"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4874.966, "latencies_ms": [4874.966], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the flamingos in the background. The zebras are closer to the camera than the flamingos, which are situated in the middle ground of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12625.2, "ram_available_mb": 50215.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12625.4, "ram_available_mb": 50215.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.873, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 75.244}, "timestamp": "2026-01-28T14:27:53.176541"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5419.711, "latencies_ms": [5419.711], "images_per_second": 0.185, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " In the image, a group of zebras and wildebeests are grazing in a grassy field, while a flock of pink flamingos wades in the water behind them. The scene is set in a savanna-like environment with a mountain range in the background.", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 12625.4, "ram_available_mb": 50215.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12631.1, "ram_available_mb": 50209.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.379, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 72.244}, "timestamp": "2026-01-28T14:28:00.613807"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4792.493, "latencies_ms": [4792.493], "images_per_second": 0.209, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a vibrant scene with a mix of green grass, black and white zebras, and pink flamingos. The lighting is natural and bright, suggesting a sunny day, and the colors are vivid and clear.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12631.6, "ram_available_mb": 50209.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12632.0, "ram_available_mb": 50208.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.225}, "power_stats": {"power_gpu_soc_mean_watts": 20.177, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.818, "gpu_utilization_percent_mean": 73.225}, "timestamp": "2026-01-28T14:28:07.440898"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3410.804, "latencies_ms": [3410.804], "images_per_second": 0.293, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A ginger and white cat is sitting on a wooden deck and looking at its reflection in a window.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12632.0, "ram_available_mb": 50208.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12632.5, "ram_available_mb": 50208.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.101, "power_cpu_cv_mean_watts": 1.473, "power_sys_5v0_mean_watts": 7.742, "gpu_utilization_percent_mean": 79.464}, "timestamp": "2026-01-28T14:28:12.902890"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6192.182, "latencies_ms": [6192.182], "images_per_second": 0.161, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. cat: 1\n2. glass: 1\n3. wooden surface: 1\n4. cat's reflection: 1\n5. cat's fur: 1\n6. cat's eyes: 1\n7. cat's nose: 1\n8. cat's mouth: 1", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12632.5, "ram_available_mb": 50208.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12632.7, "ram_available_mb": 50208.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.137}, "power_stats": {"power_gpu_soc_mean_watts": 18.623, "power_cpu_cv_mean_watts": 1.979, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 69.137}, "timestamp": "2026-01-28T14:28:21.119066"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4192.466, "latencies_ms": [4192.466], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at its reflection in the window. The window is in the middle ground, and the cat is positioned on a wooden deck.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12632.7, "ram_available_mb": 50208.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12632.6, "ram_available_mb": 50208.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.954, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 75.886}, "timestamp": "2026-01-28T14:28:27.324725"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3449.141, "latencies_ms": [3449.141], "images_per_second": 0.29, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A ginger and white cat is sitting on a wooden deck, looking at its reflection in a window.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12632.6, "ram_available_mb": 50208.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12633.4, "ram_available_mb": 50207.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.16, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 81.643}, "timestamp": "2026-01-28T14:28:32.798976"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3175.257, "latencies_ms": [3175.257], "images_per_second": 0.315, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The cat is orange and white, and the photo is taken in a cold environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12633.4, "ram_available_mb": 50207.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12634.3, "ram_available_mb": 50206.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.731}, "power_stats": {"power_gpu_soc_mean_watts": 22.939, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 80.731}, "timestamp": "2026-01-28T14:28:38.001376"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4106.53, "latencies_ms": [4106.53], "images_per_second": 0.244, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image captures a serene lakeside scene with boats docked at a pier, a bustling marina, and a picturesque backdrop of mountains under a hazy sky.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12634.3, "ram_available_mb": 50206.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12633.8, "ram_available_mb": 50207.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.029}, "power_stats": {"power_gpu_soc_mean_watts": 21.054, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.777, "gpu_utilization_percent_mean": 75.029}, "timestamp": "2026-01-28T14:28:44.139407"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5505.814, "latencies_ms": [5505.814], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Boat: 3\n2. Boat: 2\n3. Boat: 1\n4. Boat: 1\n5. Boat: 1\n6. Boat: 1\n7. Boat: 1\n8. Boat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12633.8, "ram_available_mb": 50207.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.553}, "power_stats": {"power_gpu_soc_mean_watts": 18.82, "power_cpu_cv_mean_watts": 2.045, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-28T14:28:51.674759"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4021.622, "latencies_ms": [4021.622], "images_per_second": 0.249, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The boats are in the foreground, with the city and mountains in the background. The boats are near the shore, while the city and mountains are far away.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12633.4, "ram_available_mb": 50207.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.606}, "power_stats": {"power_gpu_soc_mean_watts": 21.46, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 77.606}, "timestamp": "2026-01-28T14:28:57.722738"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4869.481, "latencies_ms": [4869.481], "images_per_second": 0.205, "prompt_tokens": 1111, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a serene lakeside scene where boats are docked at a pier, with a backdrop of mountains and a town nestled in the valley. The sky is overcast, casting a soft light over the tranquil waters.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12633.4, "ram_available_mb": 50207.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12633.2, "ram_available_mb": 50207.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.561}, "power_stats": {"power_gpu_soc_mean_watts": 19.637, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.762, "gpu_utilization_percent_mean": 71.561}, "timestamp": "2026-01-28T14:29:04.636612"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3399.702, "latencies_ms": [3399.702], "images_per_second": 0.294, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The sky is overcast, the water is a deep blue, and the boats are white and black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12633.2, "ram_available_mb": 50207.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.515, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.835, "gpu_utilization_percent_mean": 79.714}, "timestamp": "2026-01-28T14:29:10.095699"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4692.719, "latencies_ms": [4692.719], "images_per_second": 0.213, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the black and white photo, a man is standing next to his bicycle, holding the handlebars, while a woman is walking in the background, and a man is riding a bicycle in the street.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.615}, "power_stats": {"power_gpu_soc_mean_watts": 19.946, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 75.615}, "timestamp": "2026-01-28T14:29:16.810803"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5735.877, "latencies_ms": [5735.877], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. man: 1\n2. bicycle: 1\n3. umbrella: 1\n4. building: 1\n5. sign: 2\n6. street light: 1\n7. power lines: 1\n8. air conditioner: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12634.5, "ram_available_mb": 50206.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.896}, "power_stats": {"power_gpu_soc_mean_watts": 18.845, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 7.73, "gpu_utilization_percent_mean": 70.896}, "timestamp": "2026-01-28T14:29:24.563314"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5280.227, "latencies_ms": [5280.227], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The man is standing on the sidewalk, with the bicycle in front of him. The bicycle is parked on the sidewalk, and the man is standing next to it. The man is standing close to the bicycle, and the bicycle is close to the man.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12634.5, "ram_available_mb": 50206.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12634.3, "ram_available_mb": 50206.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.136}, "power_stats": {"power_gpu_soc_mean_watts": 19.037, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.76, "gpu_utilization_percent_mean": 72.136}, "timestamp": "2026-01-28T14:29:31.853142"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3102.243, "latencies_ms": [3102.243], "images_per_second": 0.322, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is standing next to his bicycle in a street with shops and signs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12634.3, "ram_available_mb": 50206.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12634.8, "ram_available_mb": 50206.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.769}, "power_stats": {"power_gpu_soc_mean_watts": 22.971, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 81.769}, "timestamp": "2026-01-28T14:29:37.009075"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4243.795, "latencies_ms": [4243.795], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is in black and white, with the exception of the man's shirt, which is white. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12634.8, "ram_available_mb": 50206.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12635.2, "ram_available_mb": 50205.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.857}, "power_stats": {"power_gpu_soc_mean_watts": 20.933, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.783, "gpu_utilization_percent_mean": 74.857}, "timestamp": "2026-01-28T14:29:43.272498"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 10055.508, "latencies_ms": [10055.508], "images_per_second": 0.099, "prompt_tokens": 1432, "response_tokens_est": 120, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a fruit stand, where bunches of ripe bananas are hanging from the ceiling, their yellow hue contrasting with the blue and white tiled walls. The bananas, varying in size and ripeness, are arranged in neat rows, creating a visually appealing display. In the background, a black curtain adds a touch of contrast to the scene, while a wooden table and a blue door suggest the presence of a store or market setting. The image exudes a sense of freshness and abundance, inviting viewers to imagine the sweet aroma of ripe bananas wafting through the air.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12635.2, "ram_available_mb": 50205.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12633.7, "ram_available_mb": 50207.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.471}, "power_stats": {"power_gpu_soc_mean_watts": 18.064, "power_cpu_cv_mean_watts": 2.262, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 69.471}, "timestamp": "2026-01-28T14:29:55.360316"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5149.175, "latencies_ms": [5149.175], "images_per_second": 0.194, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " banana: 100, bunches: 100, cloth: 1, metal: 1, wall: 1, door: 1, roof: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12633.7, "ram_available_mb": 50207.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12634.3, "ram_available_mb": 50206.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.884}, "power_stats": {"power_gpu_soc_mean_watts": 22.451, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 79.884}, "timestamp": "2026-01-28T14:30:02.536672"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5876.622, "latencies_ms": [5876.622], "images_per_second": 0.17, "prompt_tokens": 1450, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The bananas are hanging from the ceiling, with the ones in the front being closer to the camera than those in the back. The bananas are arranged in rows, with the ones in the front row being closer to the viewer than those in the back row.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12634.3, "ram_available_mb": 50206.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.898}, "power_stats": {"power_gpu_soc_mean_watts": 21.64, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 77.898}, "timestamp": "2026-01-28T14:30:10.428575"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6022.74, "latencies_ms": [6022.74], "images_per_second": 0.166, "prompt_tokens": 1444, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a fruit stand, where bunches of ripe bananas are hanging from the ceiling, ready to be purchased. The stand is situated in a bustling market, with other stalls and people visible in the background, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12633.0, "ram_available_mb": 50207.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.02}, "power_stats": {"power_gpu_soc_mean_watts": 21.183, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 78.02}, "timestamp": "2026-01-28T14:30:18.476016"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4251.497, "latencies_ms": [4251.497], "images_per_second": 0.235, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bananas are yellow and hanging from the ceiling, the lighting is bright and natural, and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12633.0, "ram_available_mb": 50207.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12632.8, "ram_available_mb": 50208.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.943}, "power_stats": {"power_gpu_soc_mean_watts": 23.954, "power_cpu_cv_mean_watts": 1.304, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 82.943}, "timestamp": "2026-01-28T14:30:24.743242"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3546.288, "latencies_ms": [3546.288], "images_per_second": 0.282, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A train with a white and green body is traveling on a track through a green field with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12632.8, "ram_available_mb": 50208.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12633.3, "ram_available_mb": 50207.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.034}, "power_stats": {"power_gpu_soc_mean_watts": 22.237, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 79.034}, "timestamp": "2026-01-28T14:30:30.319176"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5551.522, "latencies_ms": [5551.522], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. train: 1\n2. tracks: 1\n3. grass: 1\n4. mountains: 1\n5. trees: 1\n6. houses: 1\n7. poles: 1\n8. wires: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12633.3, "ram_available_mb": 50207.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12633.4, "ram_available_mb": 50207.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.391}, "power_stats": {"power_gpu_soc_mean_watts": 18.8, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 71.391}, "timestamp": "2026-01-28T14:30:37.896331"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5259.059, "latencies_ms": [5259.059], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, moving from left to right. The grassy field is in the foreground, while the mountains are in the background. The train is relatively close to the camera, while the mountains are farther away.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 12633.4, "ram_available_mb": 50207.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.386}, "power_stats": {"power_gpu_soc_mean_watts": 19.245, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 72.386}, "timestamp": "2026-01-28T14:30:45.185503"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3425.025, "latencies_ms": [3425.025], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A train with a white and green body is traveling through a green field with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.359, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 80.464}, "timestamp": "2026-01-28T14:30:50.649084"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4091.372, "latencies_ms": [4091.372], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The train is white with green accents and red cargo containers. The sky is blue with white clouds, and the landscape is green with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.176}, "power_stats": {"power_gpu_soc_mean_watts": 20.911, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 74.176}, "timestamp": "2026-01-28T14:30:56.774540"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3997.573, "latencies_ms": [3997.573], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is standing on the beach, holding a cell phone and a kite, with the ocean and waves in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12632.9, "ram_available_mb": 50208.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.121, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 75.242}, "timestamp": "2026-01-28T14:31:02.797793"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5480.912, "latencies_ms": [5480.912], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. hat: 1\n3. shorts: 1\n4. sand: 1\n5. chair: 1\n6. kite: 1\n7. ocean: 1\n8. beach: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12632.5, "ram_available_mb": 50208.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.13}, "power_stats": {"power_gpu_soc_mean_watts": 19.166, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 73.13}, "timestamp": "2026-01-28T14:31:10.299855"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4331.811, "latencies_ms": [4331.811], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, with the ocean waves on the right side. The green chair is in the foreground, while the kite is in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12632.5, "ram_available_mb": 50208.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12632.3, "ram_available_mb": 50208.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.841, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.804, "gpu_utilization_percent_mean": 74.861}, "timestamp": "2026-01-28T14:31:16.655845"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3870.986, "latencies_ms": [3870.986], "images_per_second": 0.258, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is standing on a beach, holding a phone and a kite, with the ocean and waves in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12632.3, "ram_available_mb": 50208.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12631.9, "ram_available_mb": 50209.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.532, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 7.809, "gpu_utilization_percent_mean": 76.031}, "timestamp": "2026-01-28T14:31:22.580088"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3690.595, "latencies_ms": [3690.595], "images_per_second": 0.271, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The sky is blue and cloudy, the sand is light brown, and the man is wearing a black shirt and khaki shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12631.9, "ram_available_mb": 50209.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12631.8, "ram_available_mb": 50209.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.29}, "power_stats": {"power_gpu_soc_mean_watts": 21.954, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.835, "gpu_utilization_percent_mean": 74.29}, "timestamp": "2026-01-28T14:31:28.326667"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3261.209, "latencies_ms": [3261.209], "images_per_second": 0.307, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image shows a garden with several potted plants, including broccoli, placed on the ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12631.8, "ram_available_mb": 50209.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12631.9, "ram_available_mb": 50209.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.816, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.837, "gpu_utilization_percent_mean": 78.815}, "timestamp": "2026-01-28T14:31:33.619606"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4630.484, "latencies_ms": [4630.484], "images_per_second": 0.216, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. broccoli plant\n2. broccoli plant\n3. broccoli plant\n4. broccoli plant\n5. broccoli plant\n6. broccoli plant\n7. broccoli plant\n8. broccoli plant", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12631.9, "ram_available_mb": 50209.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.05, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.774, "gpu_utilization_percent_mean": 73.184}, "timestamp": "2026-01-28T14:31:40.280292"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4795.666, "latencies_ms": [4795.666], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The broccoli plants are positioned in the foreground, with the orange plastic pots placed in the middle ground. The dirt ground is visible in the background, and there is a pink object in the top right corner of the image.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.75}, "power_stats": {"power_gpu_soc_mean_watts": 19.845, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 7.769, "gpu_utilization_percent_mean": 72.75}, "timestamp": "2026-01-28T14:31:47.101035"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7435.816, "latencies_ms": [7435.816], "images_per_second": 0.134, "prompt_tokens": 1111, "response_tokens_est": 88, "n_tiles": 1, "output_text": " The image captures a serene garden scene where two large potted plants, each with a vibrant green hue, are nestled in terracotta pots. The plants, exhibiting a mix of broccoli and kale, are the main subjects of this image, their leaves forming a lush canopy over the soil. The background, though blurred, reveals a glimpse of a dirt path, suggesting that this garden is located in a rural or semi-rural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.619}, "power_stats": {"power_gpu_soc_mean_watts": 17.485, "power_cpu_cv_mean_watts": 2.066, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 70.619}, "timestamp": "2026-01-28T14:31:56.553578"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5756.031, "latencies_ms": [5756.031], "images_per_second": 0.174, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image shows a garden with a variety of plants, including broccoli and kale, growing in pots. The plants are green and leafy, and the pots are made of terracotta. The lighting in the garden appears to be natural, coming from the sky, and the weather seems to be clear.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12632.1, "ram_available_mb": 50208.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12632.3, "ram_available_mb": 50208.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.375}, "power_stats": {"power_gpu_soc_mean_watts": 18.768, "power_cpu_cv_mean_watts": 1.944, "power_sys_5v0_mean_watts": 7.763, "gpu_utilization_percent_mean": 69.375}, "timestamp": "2026-01-28T14:32:04.356542"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5720.274, "latencies_ms": [5720.274], "images_per_second": 0.175, "prompt_tokens": 1099, "response_tokens_est": 59, "n_tiles": 1, "output_text": " In the image, an elderly man is seen walking a small brown and white pony on a leash, accompanied by a young boy who is sitting on the pony. They are walking past a red building with white windows and doors, and there is a woman sitting at a table in the background.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12632.3, "ram_available_mb": 50208.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12632.9, "ram_available_mb": 50208.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.83}, "power_stats": {"power_gpu_soc_mean_watts": 18.75, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 70.83}, "timestamp": "2026-01-28T14:32:12.110518"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5517.346, "latencies_ms": [5517.346], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. pony: 1\n3. child: 1\n4. man: 1\n5. building: 1\n6. chair: 1\n7. lantern: 1\n8. rope: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12632.9, "ram_available_mb": 50208.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12633.9, "ram_available_mb": 50207.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.383}, "power_stats": {"power_gpu_soc_mean_watts": 18.964, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 72.383}, "timestamp": "2026-01-28T14:32:19.654079"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5899.294, "latencies_ms": [5899.294], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The man is holding the pony's reins, which are in front of him, and the pony is in front of the man. The pony is in the foreground, while the man and the boy are in the background. The woman is standing to the left of the man, and the building is behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12633.9, "ram_available_mb": 50207.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12636.0, "ram_available_mb": 50204.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 69.82}, "power_stats": {"power_gpu_soc_mean_watts": 18.531, "power_cpu_cv_mean_watts": 2.115, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 69.82}, "timestamp": "2026-01-28T14:32:27.579682"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4149.396, "latencies_ms": [4149.396], "images_per_second": 0.241, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A man is walking a pony with a rope around its neck. The man is wearing a blue shirt and has a pony tail. The pony is brown and white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12636.0, "ram_available_mb": 50204.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12636.0, "ram_available_mb": 50204.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.898, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 75.029}, "timestamp": "2026-01-28T14:32:33.771612"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4100.061, "latencies_ms": [4100.061], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken during the day with natural light illuminating the scene. The colors are vibrant, with the red of the building standing out against the blue sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12636.0, "ram_available_mb": 50204.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12636.5, "ram_available_mb": 50204.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.031, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 72.324}, "timestamp": "2026-01-28T14:32:39.924067"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4987.859, "latencies_ms": [4987.859], "images_per_second": 0.2, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " A young boy with blonde hair, wearing a blue and white striped shirt and blue jeans, is walking down a dirt path in a lush garden filled with blue flowers, carrying a stuffed animal in his left arm.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12636.5, "ram_available_mb": 50204.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12636.3, "ram_available_mb": 50204.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.488}, "power_stats": {"power_gpu_soc_mean_watts": 18.562, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.585, "gpu_utilization_percent_mean": 72.488}, "timestamp": "2026-01-28T14:32:46.957571"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5503.797, "latencies_ms": [5503.797], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. child: 1\n2. blue: 1\n3. striped: 1\n4. blue: 1\n5. blue: 1\n6. blue: 1\n7. blue: 1\n8. blue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12636.3, "ram_available_mb": 50204.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12636.2, "ram_available_mb": 50204.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.196}, "power_stats": {"power_gpu_soc_mean_watts": 19.044, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.738, "gpu_utilization_percent_mean": 70.196}, "timestamp": "2026-01-28T14:32:54.520024"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4297.974, "latencies_ms": [4297.974], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The child is standing on the left side of the image, with the path leading to the right. The child is positioned in the foreground, with the flowers in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12636.2, "ram_available_mb": 50204.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12637.0, "ram_available_mb": 50203.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.472}, "power_stats": {"power_gpu_soc_mean_watts": 20.429, "power_cpu_cv_mean_watts": 1.824, "power_sys_5v0_mean_watts": 7.753, "gpu_utilization_percent_mean": 73.472}, "timestamp": "2026-01-28T14:33:00.857068"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3739.935, "latencies_ms": [3739.935], "images_per_second": 0.267, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young boy with blonde hair is walking down a dirt path in a forest, carrying a stuffed animal in his left hand.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12637.0, "ram_available_mb": 50203.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12636.9, "ram_available_mb": 50204.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.258}, "power_stats": {"power_gpu_soc_mean_watts": 21.671, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 74.258}, "timestamp": "2026-01-28T14:33:06.657237"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6589.833, "latencies_ms": [6589.833], "images_per_second": 0.152, "prompt_tokens": 1109, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a young boy with blonde hair, wearing a blue and white striped shirt and blue jeans, walking on a dirt path surrounded by a field of blue flowers. The lighting is natural and soft, suggesting it is either early morning or late afternoon. The boy is carrying a stuffed animal in his left arm, which appears to be a brown teddy bear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12636.9, "ram_available_mb": 50204.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12636.9, "ram_available_mb": 50204.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.236}, "power_stats": {"power_gpu_soc_mean_watts": 17.911, "power_cpu_cv_mean_watts": 2.105, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 70.236}, "timestamp": "2026-01-28T14:33:15.258065"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4019.416, "latencies_ms": [4019.416], "images_per_second": 0.249, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " An orange is placed on a black asphalt surface with a white line running parallel to it, and in the background, there are parked cars and trees.", "error": null, "sys_before": {"cpu_percent": 5.1, "ram_used_mb": 12636.9, "ram_available_mb": 50204.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12636.8, "ram_available_mb": 50204.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.545}, "power_stats": {"power_gpu_soc_mean_watts": 21.267, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.765, "gpu_utilization_percent_mean": 73.545}, "timestamp": "2026-01-28T14:33:21.352206"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5751.843, "latencies_ms": [5751.843], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Orange: 1\n2. Pavement: 1\n3. White line: 1\n4. Cars: 1\n5. Trees: 1\n6. Sky: 1\n7. Clouds: 1\n8. Orange peel: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12636.8, "ram_available_mb": 50204.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12635.1, "ram_available_mb": 50205.8, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.646}, "power_stats": {"power_gpu_soc_mean_watts": 18.827, "power_cpu_cv_mean_watts": 2.278, "power_sys_5v0_mean_watts": 7.751, "gpu_utilization_percent_mean": 71.646}, "timestamp": "2026-01-28T14:33:29.131665"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4707.072, "latencies_ms": [4707.072], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The orange is positioned to the left of the white line, which is in the foreground of the image. The orange is also in the foreground, while the background features a parking lot with several cars parked.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12635.1, "ram_available_mb": 50205.8, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12635.4, "ram_available_mb": 50205.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.846}, "power_stats": {"power_gpu_soc_mean_watts": 20.069, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 73.846}, "timestamp": "2026-01-28T14:33:35.854979"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3416.741, "latencies_ms": [3416.741], "images_per_second": 0.293, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A single orange is placed on the edge of a parking lot, with cars parked in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12635.4, "ram_available_mb": 50205.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12632.7, "ram_available_mb": 50208.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.317, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 76.893}, "timestamp": "2026-01-28T14:33:41.330383"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4176.099, "latencies_ms": [4176.099], "images_per_second": 0.239, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The orange is a vibrant orange color, and the asphalt is a dark gray color. The sky is cloudy, and there are trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12632.7, "ram_available_mb": 50208.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.412}, "power_stats": {"power_gpu_soc_mean_watts": 21.207, "power_cpu_cv_mean_watts": 2.179, "power_sys_5v0_mean_watts": 7.733, "gpu_utilization_percent_mean": 77.412}, "timestamp": "2026-01-28T14:33:47.538795"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4352.127, "latencies_ms": [4352.127], "images_per_second": 0.23, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit is sitting at a table with a bowl of food and three empty beer bottles.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12633.6, "ram_available_mb": 50207.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.713, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 7.952, "gpu_utilization_percent_mean": 82.222}, "timestamp": "2026-01-28T14:33:53.963405"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4895.528, "latencies_ms": [4895.528], "images_per_second": 0.204, "prompt_tokens": 1446, "response_tokens_est": 29, "n_tiles": 1, "output_text": " man: 1, bowl: 1, bottle: 2, keys: 1, remote: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12633.5, "ram_available_mb": 50207.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12633.7, "ram_available_mb": 50207.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.7}, "power_stats": {"power_gpu_soc_mean_watts": 22.432, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 81.7}, "timestamp": "2026-01-28T14:34:00.892234"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5605.997, "latencies_ms": [5605.997], "images_per_second": 0.178, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is seated at a table with the bottles of beer placed to his right. The bowl is located in front of him on the table. The keys are placed on the table to the left of the bowl.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12633.7, "ram_available_mb": 50207.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12633.9, "ram_available_mb": 50207.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.362}, "power_stats": {"power_gpu_soc_mean_watts": 21.298, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 77.362}, "timestamp": "2026-01-28T14:34:08.555146"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4371.257, "latencies_ms": [4371.257], "images_per_second": 0.229, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting at a table with a bowl of food and three bottles of beer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12633.9, "ram_available_mb": 50207.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12635.0, "ram_available_mb": 50205.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.972}, "power_stats": {"power_gpu_soc_mean_watts": 23.03, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 7.883, "gpu_utilization_percent_mean": 81.972}, "timestamp": "2026-01-28T14:34:14.971425"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4046.927, "latencies_ms": [4046.927], "images_per_second": 0.247, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The man is wearing a grey suit and white shirt, and the bottles are clear glass.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12635.0, "ram_available_mb": 50205.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12635.7, "ram_available_mb": 50205.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.118}, "power_stats": {"power_gpu_soc_mean_watts": 24.033, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 83.118}, "timestamp": "2026-01-28T14:34:21.029948"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4199.729, "latencies_ms": [4199.729], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a neatly made hotel room with a large bed, two pillows, and a neatly made bed with a white comforter and white sheets.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12635.7, "ram_available_mb": 50205.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 13.8, "ram_used_mb": 12693.6, "ram_available_mb": 50147.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.4}, "power_stats": {"power_gpu_soc_mean_watts": 21.035, "power_cpu_cv_mean_watts": 2.335, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 83.4}, "timestamp": "2026-01-28T14:34:27.270108"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6153.273, "latencies_ms": [6153.273], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 2\n2. pillows: 6\n3. chair: 1\n4. desk: 1\n5. lamp: 1\n6. window: 1\n7. carpet: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12694.1, "ram_available_mb": 50146.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.8, "ram_used_mb": 12696.8, "ram_available_mb": 50144.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.824}, "power_stats": {"power_gpu_soc_mean_watts": 18.929, "power_cpu_cv_mean_watts": 2.246, "power_sys_5v0_mean_watts": 7.529, "gpu_utilization_percent_mean": 79.824}, "timestamp": "2026-01-28T14:34:35.458361"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4773.921, "latencies_ms": [4773.921], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The bed is positioned to the left of the desk, which is situated in the foreground of the image. The window is located in the background, behind the bed, and the wall is directly behind the bed.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 12696.8, "ram_available_mb": 50144.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 12.1, "ram_used_mb": 12696.8, "ram_available_mb": 50144.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.6}, "power_stats": {"power_gpu_soc_mean_watts": 20.569, "power_cpu_cv_mean_watts": 2.543, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 80.6}, "timestamp": "2026-01-28T14:34:42.244782"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5810.328, "latencies_ms": [5810.328], "images_per_second": 0.172, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image depicts a hotel room with a large bed, neatly made with white linens and pillows, and a small desk with a chair. The room has a window with a view of the outside, and there is a luggage bag placed on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12696.8, "ram_available_mb": 50144.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12695.3, "ram_available_mb": 50145.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.163}, "power_stats": {"power_gpu_soc_mean_watts": 18.95, "power_cpu_cv_mean_watts": 2.158, "power_sys_5v0_mean_watts": 7.513, "gpu_utilization_percent_mean": 78.163}, "timestamp": "2026-01-28T14:34:50.098517"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3655.262, "latencies_ms": [3655.262], "images_per_second": 0.274, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through a window. The walls are painted white and the carpet is grey.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12695.3, "ram_available_mb": 50145.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12696.2, "ram_available_mb": 50144.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.285, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.854, "gpu_utilization_percent_mean": 83.6}, "timestamp": "2026-01-28T14:34:55.779753"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4916.875, "latencies_ms": [4916.875], "images_per_second": 0.203, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the image, there are three stuffed animals, a teddy bear, a snowman, and a bear wearing a hat, all sitting on a blue surface with a red and orange background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12696.2, "ram_available_mb": 50144.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12696.3, "ram_available_mb": 50144.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.972, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 7.531, "gpu_utilization_percent_mean": 84.976}, "timestamp": "2026-01-28T14:35:02.738110"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5588.716, "latencies_ms": [5588.716], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 54, "n_tiles": 1, "output_text": " teddy bear: 2, green hat: 1, red scarf: 1, black hat: 1, white bear: 1, orange background: 1, red Coca-Cola logo: 1, green hat with white stripes: 1", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12696.3, "ram_available_mb": 50144.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12696.5, "ram_available_mb": 50144.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.979}, "power_stats": {"power_gpu_soc_mean_watts": 18.647, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 7.683, "gpu_utilization_percent_mean": 75.979}, "timestamp": "2026-01-28T14:35:10.385431"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6451.599, "latencies_ms": [6451.599], "images_per_second": 0.155, "prompt_tokens": 1118, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The teddy bear wearing a green hat is positioned to the left of the teddy bear wearing a red hat, which is in front of the teddy bear wearing a black hat. The teddy bear wearing a red hat is in the foreground, while the teddy bear wearing a green hat is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12696.5, "ram_available_mb": 50144.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12696.5, "ram_available_mb": 50144.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.264}, "power_stats": {"power_gpu_soc_mean_watts": 18.662, "power_cpu_cv_mean_watts": 2.071, "power_sys_5v0_mean_watts": 7.435, "gpu_utilization_percent_mean": 80.264}, "timestamp": "2026-01-28T14:35:18.853667"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7107.192, "latencies_ms": [7107.192], "images_per_second": 0.141, "prompt_tokens": 1112, "response_tokens_est": 80, "n_tiles": 1, "output_text": " Three stuffed animals are sitting on a blue and white striped blanket. The teddy bear on the left is wearing a green hat and a red shirt with the word \"Berlin\" on it. The teddy bear in the middle is wearing a red hat with the word \"Coca-Cola\" on it. The teddy bear on the right is wearing a black hat with a white pom pom on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12696.5, "ram_available_mb": 50144.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12697.0, "ram_available_mb": 50143.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.167}, "power_stats": {"power_gpu_soc_mean_watts": 18.514, "power_cpu_cv_mean_watts": 2.196, "power_sys_5v0_mean_watts": 7.69, "gpu_utilization_percent_mean": 75.167}, "timestamp": "2026-01-28T14:35:27.987519"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4795.115, "latencies_ms": [4795.115], "images_per_second": 0.209, "prompt_tokens": 1110, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The teddy bears are made of plush material and are colored in shades of brown, white, and red. The background is a vibrant orange with a floral pattern.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12697.0, "ram_available_mb": 50143.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12697.5, "ram_available_mb": 50143.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.725}, "power_stats": {"power_gpu_soc_mean_watts": 19.609, "power_cpu_cv_mean_watts": 2.033, "power_sys_5v0_mean_watts": 7.407, "gpu_utilization_percent_mean": 86.725}, "timestamp": "2026-01-28T14:35:34.833392"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3577.39, "latencies_ms": [3577.39], "images_per_second": 0.28, "prompt_tokens": 1432, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A glass bowl filled with oranges sits on a table.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12697.5, "ram_available_mb": 50143.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12697.2, "ram_available_mb": 50143.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.448}, "power_stats": {"power_gpu_soc_mean_watts": 24.463, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 87.448}, "timestamp": "2026-01-28T14:35:40.464300"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4248.33, "latencies_ms": [4248.33], "images_per_second": 0.235, "prompt_tokens": 1446, "response_tokens_est": 11, "n_tiles": 1, "output_text": " bowl: 1\noranges: 12", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12697.2, "ram_available_mb": 50143.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12697.2, "ram_available_mb": 50143.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 91.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.731, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 7.638, "gpu_utilization_percent_mean": 91.286}, "timestamp": "2026-01-28T14:35:46.766377"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5722.641, "latencies_ms": [5722.641], "images_per_second": 0.175, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bowl is located in the foreground, and the oranges are placed inside the bowl. The oranges are arranged in a circular pattern, with some oranges placed closer to the center of the bowl and others towards the edges.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12697.2, "ram_available_mb": 50143.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12697.6, "ram_available_mb": 50143.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.723}, "power_stats": {"power_gpu_soc_mean_watts": 21.341, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 78.723}, "timestamp": "2026-01-28T14:35:54.510138"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4388.147, "latencies_ms": [4388.147], "images_per_second": 0.228, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A bowl of oranges is placed on a table with a silver tablecloth.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12697.6, "ram_available_mb": 50143.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12697.9, "ram_available_mb": 50143.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 91.444}, "power_stats": {"power_gpu_soc_mean_watts": 22.754, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.709, "gpu_utilization_percent_mean": 91.444}, "timestamp": "2026-01-28T14:36:00.919902"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5254.047, "latencies_ms": [5254.047], "images_per_second": 0.19, "prompt_tokens": 1442, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The oranges are a vibrant orange color, and the bowl is made of glass. The lighting is bright and natural, and the oranges are placed on a textured silver tablecloth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12697.9, "ram_available_mb": 50143.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12697.9, "ram_available_mb": 50143.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.295}, "power_stats": {"power_gpu_soc_mean_watts": 22.041, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.913, "gpu_utilization_percent_mean": 81.295}, "timestamp": "2026-01-28T14:36:08.201946"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3723.96, "latencies_ms": [3723.96], "images_per_second": 0.269, "prompt_tokens": 766, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a surfer is skillfully riding a large wave on a surfboard, with the ocean's vast expanse and a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12697.9, "ram_available_mb": 50143.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12697.8, "ram_available_mb": 50143.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5033.1, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.323}, "power_stats": {"power_gpu_soc_mean_watts": 18.735, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.439, "gpu_utilization_percent_mean": 83.323}, "timestamp": "2026-01-28T14:36:13.962586"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5601.383, "latencies_ms": [5601.383], "images_per_second": 0.179, "prompt_tokens": 780, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Ocean: 1\n5. Sky: 1\n6. Clouds: 1\n7. Water: 1\n8. Surfboard leash: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12697.8, "ram_available_mb": 50143.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12697.6, "ram_available_mb": 50143.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.913}, "power_stats": {"power_gpu_soc_mean_watts": 16.737, "power_cpu_cv_mean_watts": 2.081, "power_sys_5v0_mean_watts": 7.474, "gpu_utilization_percent_mean": 70.913}, "timestamp": "2026-01-28T14:36:21.575370"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3957.134, "latencies_ms": [3957.134], "images_per_second": 0.253, "prompt_tokens": 784, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the background, with the sky occupying the upper portion of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12697.6, "ram_available_mb": 50143.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12699.7, "ram_available_mb": 50141.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.594}, "power_stats": {"power_gpu_soc_mean_watts": 19.102, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.578, "gpu_utilization_percent_mean": 76.594}, "timestamp": "2026-01-28T14:36:27.549743"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3765.755, "latencies_ms": [3765.755], "images_per_second": 0.266, "prompt_tokens": 778, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A surfer is riding a large wave in the ocean. The surfer is wearing a black wetsuit and is standing on a surfboard.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12699.7, "ram_available_mb": 50141.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.548}, "power_stats": {"power_gpu_soc_mean_watts": 18.398, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.311, "gpu_utilization_percent_mean": 82.548}, "timestamp": "2026-01-28T14:36:33.355024"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4279.749, "latencies_ms": [4279.749], "images_per_second": 0.234, "prompt_tokens": 776, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a surfer riding a large wave in the ocean, with the wave being a deep blue color and the surfer wearing a black wetsuit. The sky is overcast, with gray clouds covering the entire background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5034.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 70.057}, "power_stats": {"power_gpu_soc_mean_watts": 17.932, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 70.057}, "timestamp": "2026-01-28T14:36:39.652014"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3446.585, "latencies_ms": [3446.585], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is sitting on a laptop computer and looking at the screen.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.857}, "power_stats": {"power_gpu_soc_mean_watts": 21.714, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.471, "gpu_utilization_percent_mean": 86.857}, "timestamp": "2026-01-28T14:36:45.128704"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5977.941, "latencies_ms": [5977.941], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. screen: 1\n5. mouse: 1\n6. mousepad: 1\n7. laptop screen: 1\n8. cat collar: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12700.2, "ram_available_mb": 50140.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.466, "power_cpu_cv_mean_watts": 1.97, "power_sys_5v0_mean_watts": 7.622, "gpu_utilization_percent_mean": 71.66}, "timestamp": "2026-01-28T14:36:53.136083"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5841.779, "latencies_ms": [5841.779], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at the laptop screen. The laptop is on a table, and the cat is sitting on the table. The laptop is in the middle of the table, and the cat is on the left side of the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.2, "ram_available_mb": 50140.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.857}, "power_stats": {"power_gpu_soc_mean_watts": 19.143, "power_cpu_cv_mean_watts": 1.978, "power_sys_5v0_mean_watts": 7.441, "gpu_utilization_percent_mean": 82.857}, "timestamp": "2026-01-28T14:37:00.989767"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3035.912, "latencies_ms": [3035.912], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is sitting on a laptop computer and looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.119, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 7.779, "gpu_utilization_percent_mean": 83.36}, "timestamp": "2026-01-28T14:37:06.066090"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3807.9, "latencies_ms": [3807.9], "images_per_second": 0.263, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The cat is white and brown, and the laptop is black. The cat is sitting on a brown couch.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.355}, "power_stats": {"power_gpu_soc_mean_watts": 21.199, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.557, "gpu_utilization_percent_mean": 85.355}, "timestamp": "2026-01-28T14:37:11.897598"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4786.891, "latencies_ms": [4786.891], "images_per_second": 0.209, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a group of horses, including a brown horse and a foal, are gathered around a hay feeder, with a house and trees in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.718}, "power_stats": {"power_gpu_soc_mean_watts": 19.881, "power_cpu_cv_mean_watts": 2.146, "power_sys_5v0_mean_watts": 7.428, "gpu_utilization_percent_mean": 83.718}, "timestamp": "2026-01-28T14:37:18.707362"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4273.333, "latencies_ms": [4273.333], "images_per_second": 0.234, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " horse: 6, hay: 1, fence: 1, house: 1, trees: 1, power lines: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.24, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.788, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-28T14:37:25.007481"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7157.724, "latencies_ms": [7157.724], "images_per_second": 0.14, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The brown horses are standing in a line, with the brown horse on the left being the closest to the camera, and the brown horse on the right being the furthest away. The brown horse on the left is standing in front of the brown horse on the right, and the brown horse on the right is standing in front of the brown horse on the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.833}, "power_stats": {"power_gpu_soc_mean_watts": 18.566, "power_cpu_cv_mean_watts": 2.664, "power_sys_5v0_mean_watts": 7.533, "gpu_utilization_percent_mean": 78.833}, "timestamp": "2026-01-28T14:37:34.203537"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5349.947, "latencies_ms": [5349.947], "images_per_second": 0.187, "prompt_tokens": 1111, "response_tokens_est": 49, "n_tiles": 1, "output_text": " In a rural setting, a group of horses, including a brown foal, are gathered around a hay feeder, enjoying their meal. The scene is set in a field with a fence and trees in the background, under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12701.1, "ram_available_mb": 50139.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.022}, "power_stats": {"power_gpu_soc_mean_watts": 19.529, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.65, "gpu_utilization_percent_mean": 77.022}, "timestamp": "2026-01-28T14:37:41.587930"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6815.174, "latencies_ms": [6815.174], "images_per_second": 0.147, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a group of horses in a field with a mix of brown and orange colors, with the horses being the main focus of the image. The lighting is bright and natural, suggesting that the photo was taken during the day. The material of the horses is likely leather, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12701.1, "ram_available_mb": 50139.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.474}, "power_stats": {"power_gpu_soc_mean_watts": 18.145, "power_cpu_cv_mean_watts": 2.15, "power_sys_5v0_mean_watts": 7.455, "gpu_utilization_percent_mean": 76.474}, "timestamp": "2026-01-28T14:37:50.432579"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3428.43, "latencies_ms": [3428.43], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a black wetsuit is riding a yellow surfboard on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12700.8, "ram_available_mb": 50140.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.966}, "power_stats": {"power_gpu_soc_mean_watts": 22.473, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 7.808, "gpu_utilization_percent_mean": 83.966}, "timestamp": "2026-01-28T14:37:55.910751"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6404.358, "latencies_ms": [6404.358], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Water: 1\n5. Waves: 1\n6. Clouds: 1\n7. Sky: 1\n8. Land: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.8, "ram_available_mb": 50140.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.491}, "power_stats": {"power_gpu_soc_mean_watts": 18.567, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.463, "gpu_utilization_percent_mean": 79.491}, "timestamp": "2026-01-28T14:38:04.332586"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4051.151, "latencies_ms": [4051.151], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, with the ocean and coastline in the background. The surfer is closer to the camera than the coastline.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.758}, "power_stats": {"power_gpu_soc_mean_watts": 21.447, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.759, "gpu_utilization_percent_mean": 78.758}, "timestamp": "2026-01-28T14:38:10.397397"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3639.333, "latencies_ms": [3639.333], "images_per_second": 0.275, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A surfer is riding a wave on a yellow surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.174, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.423, "gpu_utilization_percent_mean": 88.367}, "timestamp": "2026-01-28T14:38:16.077305"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4260.005, "latencies_ms": [4260.005], "images_per_second": 0.235, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The surfer is wearing a black wetsuit and is riding a yellow surfboard. The water is a greenish-blue color, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.9, "ram_available_mb": 50140.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12700.8, "ram_available_mb": 50140.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.143}, "power_stats": {"power_gpu_soc_mean_watts": 20.728, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 7.757, "gpu_utilization_percent_mean": 74.143}, "timestamp": "2026-01-28T14:38:22.385072"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 10572.169, "latencies_ms": [10572.169], "images_per_second": 0.095, "prompt_tokens": 1099, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The image captures a vibrant display of Halloween decorations, featuring a trio of jack-o'-lanterns, each with its own unique design. The largest jack-o'-lantern, positioned in the center, boasts a face carved into its surface, complete with a wide smile and two prominent teeth. To its left, a smaller jack-o'-lantern showcases a more abstract design, with a skull-like face and a prominent eye. On the right, a third jack-o'-lantern features a classic bat face, complete with pointed ears and a bat-like nose. In the background, a collection of children's drawings", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12700.8, "ram_available_mb": 50140.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.5, "ram_used_mb": 12700.6, "ram_available_mb": 50140.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.697}, "power_stats": {"power_gpu_soc_mean_watts": 17.54, "power_cpu_cv_mean_watts": 2.358, "power_sys_5v0_mean_watts": 7.529, "gpu_utilization_percent_mean": 77.697}, "timestamp": "2026-01-28T14:38:34.991955"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4262.931, "latencies_ms": [4262.931], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " pumpkin: 4, flowers: 1, pumpkin: 1, pumpkin: 1, pumpkin: 1, pumpkin: 1, pumpkin: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12700.6, "ram_available_mb": 50140.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.629}, "power_stats": {"power_gpu_soc_mean_watts": 21.183, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 82.629}, "timestamp": "2026-01-28T14:38:41.284923"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6002.305, "latencies_ms": [6002.305], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The large pumpkin with the face carved into it is positioned in the foreground, with the smaller pumpkin and the vase of flowers placed behind it. The smaller pumpkin is located to the left of the large pumpkin, while the vase of flowers is situated to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.16}, "power_stats": {"power_gpu_soc_mean_watts": 18.803, "power_cpu_cv_mean_watts": 1.986, "power_sys_5v0_mean_watts": 7.409, "gpu_utilization_percent_mean": 80.16}, "timestamp": "2026-01-28T14:38:49.344282"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5896.555, "latencies_ms": [5896.555], "images_per_second": 0.17, "prompt_tokens": 1111, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures a vibrant display of Halloween decorations, featuring a trio of jack-o-lanterns with intricate designs and a bouquet of pink and white flowers in a vase. The setting appears to be a classroom or a community center, as indicated by the presence of a bulletin board in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.28}, "power_stats": {"power_gpu_soc_mean_watts": 19.683, "power_cpu_cv_mean_watts": 2.467, "power_sys_5v0_mean_watts": 7.752, "gpu_utilization_percent_mean": 76.28}, "timestamp": "2026-01-28T14:38:57.275751"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3714.466, "latencies_ms": [3714.466], "images_per_second": 0.269, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The pumpkins are orange, the flowers are pink and white, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.452}, "power_stats": {"power_gpu_soc_mean_watts": 21.256, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.454, "gpu_utilization_percent_mean": 87.452}, "timestamp": "2026-01-28T14:39:03.006951"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3694.475, "latencies_ms": [3694.475], "images_per_second": 0.271, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a mirror, and a door, with a black bag placed on the floor.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.677}, "power_stats": {"power_gpu_soc_mean_watts": 21.772, "power_cpu_cv_mean_watts": 2.778, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 75.677}, "timestamp": "2026-01-28T14:39:08.749139"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4712.211, "latencies_ms": [4712.211], "images_per_second": 0.212, "prompt_tokens": 1114, "response_tokens_est": 33, "n_tiles": 1, "output_text": " 1. mirror\n2. sink\n3. door\n4. toilet\n5. shelf\n6. trash bag\n7. wall\n8. floor", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.436}, "power_stats": {"power_gpu_soc_mean_watts": 19.956, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 7.47, "gpu_utilization_percent_mean": 84.436}, "timestamp": "2026-01-28T14:39:15.490319"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5192.584, "latencies_ms": [5192.584], "images_per_second": 0.193, "prompt_tokens": 1118, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The sink is located to the left of the door, and the black garbage bag is positioned in the foreground, closer to the camera than the door. The mirror is above the sink, and the shelf is to the right of the sink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.523}, "power_stats": {"power_gpu_soc_mean_watts": 19.418, "power_cpu_cv_mean_watts": 1.984, "power_sys_5v0_mean_watts": 7.69, "gpu_utilization_percent_mean": 73.523}, "timestamp": "2026-01-28T14:39:22.720137"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3191.658, "latencies_ms": [3191.658], "images_per_second": 0.313, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A bathroom with a sink, mirror, and door.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 90.846}, "power_stats": {"power_gpu_soc_mean_watts": 21.859, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 7.499, "gpu_utilization_percent_mean": 90.846}, "timestamp": "2026-01-28T14:39:27.923908"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3809.171, "latencies_ms": [3809.171], "images_per_second": 0.263, "prompt_tokens": 1110, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The bathroom is lit by a warm yellow light, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.839}, "power_stats": {"power_gpu_soc_mean_watts": 20.584, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.345, "gpu_utilization_percent_mean": 85.839}, "timestamp": "2026-01-28T14:39:33.758798"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3148.47, "latencies_ms": [3148.47], "images_per_second": 0.318, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A little girl is sitting on a bed with a laptop in front of her.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.077}, "power_stats": {"power_gpu_soc_mean_watts": 22.938, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 79.077}, "timestamp": "2026-01-28T14:39:38.965577"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6183.259, "latencies_ms": [6183.259], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. laptop: 1\n2. child: 1\n3. bed: 1\n4. wall: 1\n5. blanket: 1\n6. laptop screen: 1\n7. keyboard: 1\n8. mouse: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12700.1, "ram_available_mb": 50140.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.404}, "power_stats": {"power_gpu_soc_mean_watts": 18.894, "power_cpu_cv_mean_watts": 2.049, "power_sys_5v0_mean_watts": 7.477, "gpu_utilization_percent_mean": 81.404}, "timestamp": "2026-01-28T14:39:47.191231"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4368.981, "latencies_ms": [4368.981], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The laptop is on the left side of the bed, and the child is sitting on the right side of the bed. The child is sitting closer to the laptop than the bed.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.441, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.756, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-28T14:39:53.583884"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3699.548, "latencies_ms": [3699.548], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A little girl is sitting on a bed with a laptop in front of her.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.633}, "power_stats": {"power_gpu_soc_mean_watts": 20.76, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.323, "gpu_utilization_percent_mean": 87.633}, "timestamp": "2026-01-28T14:39:59.310221"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3496.544, "latencies_ms": [3496.544], "images_per_second": 0.286, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The image is in black and white, with a white background and a white bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.3, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.862}, "power_stats": {"power_gpu_soc_mean_watts": 21.768, "power_cpu_cv_mean_watts": 2.058, "power_sys_5v0_mean_watts": 7.53, "gpu_utilization_percent_mean": 82.862}, "timestamp": "2026-01-28T14:40:04.832308"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3550.18, "latencies_ms": [3550.18], "images_per_second": 0.282, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A skier wearing a brown jacket, blue helmet, and goggles is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.19, "power_cpu_cv_mean_watts": 2.443, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 81.2}, "timestamp": "2026-01-28T14:40:10.428126"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6317.532, "latencies_ms": [6317.532], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snow: 1\n5. trees: 1\n6. jacket: 1\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.9, "ram_used_mb": 12700.5, "ram_available_mb": 50140.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.925, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.488, "gpu_utilization_percent_mean": 82.66}, "timestamp": "2026-01-28T14:40:18.780272"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4509.648, "latencies_ms": [4509.648], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The skier is in the foreground, skiing down a slope with trees in the background. The skier is to the left of the trees, and the trees are behind the skier.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.5, "ram_available_mb": 50140.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12700.8, "ram_available_mb": 50140.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.634, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 77.892}, "timestamp": "2026-01-28T14:40:25.300693"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3851.713, "latencies_ms": [3851.713], "images_per_second": 0.26, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A skier in a brown jacket and blue helmet is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12700.7, "ram_available_mb": 50140.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12701.5, "ram_available_mb": 50139.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.028, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 7.447, "gpu_utilization_percent_mean": 85.5}, "timestamp": "2026-01-28T14:40:31.166251"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3698.396, "latencies_ms": [3698.396], "images_per_second": 0.27, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a brown jacket and blue pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12701.5, "ram_available_mb": 50139.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12702.0, "ram_available_mb": 50138.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.124, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 7.552, "gpu_utilization_percent_mean": 80.161}, "timestamp": "2026-01-28T14:40:36.907314"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4681.466, "latencies_ms": [4681.466], "images_per_second": 0.214, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with a large bed, a blue armchair, a small table, and two lamps, all arranged in a well-organized manner.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12702.0, "ram_available_mb": 50138.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12700.4, "ram_available_mb": 50140.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.103}, "power_stats": {"power_gpu_soc_mean_watts": 19.893, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.464, "gpu_utilization_percent_mean": 84.103}, "timestamp": "2026-01-28T14:40:43.640561"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6115.451, "latencies_ms": [6115.451], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bed: 1\n2. lamps: 2\n3. chair: 1\n4. suitcase: 1\n5. window: 1\n6. curtains: 1\n7. wall: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12700.4, "ram_available_mb": 50140.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12701.1, "ram_available_mb": 50139.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.51}, "power_stats": {"power_gpu_soc_mean_watts": 17.962, "power_cpu_cv_mean_watts": 1.987, "power_sys_5v0_mean_watts": 7.514, "gpu_utilization_percent_mean": 74.51}, "timestamp": "2026-01-28T14:40:51.797193"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7252.685, "latencies_ms": [7252.685], "images_per_second": 0.138, "prompt_tokens": 1117, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the nightstands placed on either side. The window is located to the left of the bed, while the armchair is situated to the right. The suitcase is placed on the floor near the bed, and the lamp is positioned on the nightstand to the right of the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.1, "ram_available_mb": 50139.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12701.4, "ram_available_mb": 50139.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.983}, "power_stats": {"power_gpu_soc_mean_watts": 17.979, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 7.4, "gpu_utilization_percent_mean": 77.983}, "timestamp": "2026-01-28T14:41:01.072177"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3426.201, "latencies_ms": [3426.201], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A hotel room with a large bed, a chair, and a lamp.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12701.4, "ram_available_mb": 50139.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12701.6, "ram_available_mb": 50139.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.357}, "power_stats": {"power_gpu_soc_mean_watts": 21.472, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 7.511, "gpu_utilization_percent_mean": 82.357}, "timestamp": "2026-01-28T14:41:06.531439"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3948.279, "latencies_ms": [3948.279], "images_per_second": 0.253, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted in a neutral color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.6, "ram_available_mb": 50139.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 12701.4, "ram_available_mb": 50139.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.848}, "power_stats": {"power_gpu_soc_mean_watts": 20.972, "power_cpu_cv_mean_watts": 2.342, "power_sys_5v0_mean_watts": 7.585, "gpu_utilization_percent_mean": 86.848}, "timestamp": "2026-01-28T14:41:12.505534"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5374.162, "latencies_ms": [5374.162], "images_per_second": 0.186, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a skier dressed in white and orange is skillfully performing a jump on a red rail on a snowy mountain, with other skiers and snowboarders in the background, under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12701.4, "ram_available_mb": 50139.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12699.1, "ram_available_mb": 50141.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.956}, "power_stats": {"power_gpu_soc_mean_watts": 19.467, "power_cpu_cv_mean_watts": 2.074, "power_sys_5v0_mean_watts": 7.482, "gpu_utilization_percent_mean": 82.956}, "timestamp": "2026-01-28T14:41:19.935021"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6543.113, "latencies_ms": [6543.113], "images_per_second": 0.153, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. skier: 1\n3. ski lift: 1\n4. ski pole: 1\n5. ski: 1\n6. snowboarder: 1\n7. snowboarder's pants: 1\n8. snowboarder's jacket: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12699.1, "ram_available_mb": 50141.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.764}, "power_stats": {"power_gpu_soc_mean_watts": 19.241, "power_cpu_cv_mean_watts": 2.236, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 77.764}, "timestamp": "2026-01-28T14:41:28.492079"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7001.359, "latencies_ms": [7001.359], "images_per_second": 0.143, "prompt_tokens": 1117, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The main object, the snowboarder, is in the foreground, performing a trick on the red rail. The background features other skiers and snowboarders, with the ski lift and ski poles in the distance. The snowboarder is positioned to the left of the red rail, with the ski lift and other skiers to the right.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.862}, "power_stats": {"power_gpu_soc_mean_watts": 18.13, "power_cpu_cv_mean_watts": 2.189, "power_sys_5v0_mean_watts": 7.484, "gpu_utilization_percent_mean": 75.862}, "timestamp": "2026-01-28T14:41:37.530099"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7313.158, "latencies_ms": [7313.158], "images_per_second": 0.137, "prompt_tokens": 1111, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image captures a lively scene at a ski resort on a clear day. A skier, dressed in a white jacket and orange pants, is in the midst of performing a daring jump off a red ramp. The ramp is situated on a snowy slope, with other skiers and snowboarders visible in the background, adding to the dynamic atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12699.5, "ram_available_mb": 50141.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.852}, "power_stats": {"power_gpu_soc_mean_watts": 18.282, "power_cpu_cv_mean_watts": 2.114, "power_sys_5v0_mean_watts": 7.448, "gpu_utilization_percent_mean": 79.852}, "timestamp": "2026-01-28T14:41:46.867799"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5568.816, "latencies_ms": [5568.816], "images_per_second": 0.18, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a vibrant scene of a snow-covered slope with a clear blue sky overhead. The snow is a pristine white, and the sunlight casts a bright glow on the landscape, highlighting the texture of the snow and the vibrant colors of the skiers' attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12699.5, "ram_available_mb": 50141.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12699.5, "ram_available_mb": 50141.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.978}, "power_stats": {"power_gpu_soc_mean_watts": 18.836, "power_cpu_cv_mean_watts": 2.02, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 72.978}, "timestamp": "2026-01-28T14:41:54.481935"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 10563.783, "latencies_ms": [10563.783], "images_per_second": 0.095, "prompt_tokens": 1100, "response_tokens_est": 129, "n_tiles": 1, "output_text": " The image captures a scene of urban artistry, where a parking meter stands as a silent observer amidst a vibrant display of graffiti art. The parking meter, a common sight in many cities, is adorned with a colorful mural that adds a touch of whimsy to the otherwise mundane object. The graffiti, a riot of colors and shapes, sprawls across the wall, each piece telling its own story. The words \"THE ONE N' ONLY\" and \"CHAKA\" are prominently displayed, hinting at the identity of the artist or the theme of the artwork. The wall itself is a canvas of urban creativity, with various tags and markings adding", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12699.5, "ram_available_mb": 50141.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.3}, "power_stats": {"power_gpu_soc_mean_watts": 17.318, "power_cpu_cv_mean_watts": 2.381, "power_sys_5v0_mean_watts": 7.539, "gpu_utilization_percent_mean": 74.3}, "timestamp": "2026-01-28T14:42:07.092437"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5853.383, "latencies_ms": [5853.383], "images_per_second": 0.171, "prompt_tokens": 1114, "response_tokens_est": 51, "n_tiles": 1, "output_text": " 1. Graffiti wall\n2. Graffiti art\n3. Graffiti lettering\n4. Graffiti design\n5. Graffiti paint\n6. Graffiti paintbrush\n7. Graffiti spray\n8. Graffiti spray can", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12699.7, "ram_available_mb": 50141.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.551}, "power_stats": {"power_gpu_soc_mean_watts": 19.045, "power_cpu_cv_mean_watts": 2.223, "power_sys_5v0_mean_watts": 7.482, "gpu_utilization_percent_mean": 81.551}, "timestamp": "2026-01-28T14:42:14.971727"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5715.181, "latencies_ms": [5715.181], "images_per_second": 0.175, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The parking meter is located in the foreground of the image, with the graffiti wall extending into the background. The parking meter is positioned to the right of the graffiti wall, and the wall extends from the left to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12699.7, "ram_available_mb": 50141.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.681}, "power_stats": {"power_gpu_soc_mean_watts": 18.606, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.475, "gpu_utilization_percent_mean": 76.681}, "timestamp": "2026-01-28T14:42:22.707817"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5549.101, "latencies_ms": [5549.101], "images_per_second": 0.18, "prompt_tokens": 1112, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a vibrant scene of urban artistry, where a parking meter stands as a silent observer amidst a wall adorned with graffiti. The wall, a canvas of various colors and styles, tells a story of the city's creative spirit.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.043}, "power_stats": {"power_gpu_soc_mean_watts": 19.095, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 7.49, "gpu_utilization_percent_mean": 84.043}, "timestamp": "2026-01-28T14:42:30.269086"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4989.368, "latencies_ms": [4989.368], "images_per_second": 0.2, "prompt_tokens": 1110, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a parking meter with graffiti on it, and the surrounding area has a mix of colors, including blue, yellow, and black. The lighting appears to be natural, and the weather seems to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12700.3, "ram_available_mb": 50140.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12700.0, "ram_available_mb": 50140.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.548}, "power_stats": {"power_gpu_soc_mean_watts": 19.474, "power_cpu_cv_mean_watts": 1.974, "power_sys_5v0_mean_watts": 7.628, "gpu_utilization_percent_mean": 76.548}, "timestamp": "2026-01-28T14:42:37.293289"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3706.204, "latencies_ms": [3706.204], "images_per_second": 0.27, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 89.433}, "power_stats": {"power_gpu_soc_mean_watts": 20.571, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.298, "gpu_utilization_percent_mean": 89.433}, "timestamp": "2026-01-28T14:42:43.030872"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6147.024, "latencies_ms": [6147.024], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. ocean: 1\n5. sky: 0\n6. water: 1\n7. surfboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12699.9, "ram_available_mb": 50141.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.403, "power_cpu_cv_mean_watts": 2.041, "power_sys_5v0_mean_watts": 7.531, "gpu_utilization_percent_mean": 75.596}, "timestamp": "2026-01-28T14:42:51.232590"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5097.13, "latencies_ms": [5097.13], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, riding a wave that is in the middle ground. The surfer is facing towards the right side of the image, with the wave moving towards the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.214}, "power_stats": {"power_gpu_soc_mean_watts": 19.935, "power_cpu_cv_mean_watts": 1.974, "power_sys_5v0_mean_watts": 7.592, "gpu_utilization_percent_mean": 83.214}, "timestamp": "2026-01-28T14:42:58.347468"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3348.489, "latencies_ms": [3348.489], "images_per_second": 0.299, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.107}, "power_stats": {"power_gpu_soc_mean_watts": 21.202, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 7.396, "gpu_utilization_percent_mean": 88.107}, "timestamp": "2026-01-28T14:43:03.734594"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5644.977, "latencies_ms": [5644.977], "images_per_second": 0.177, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a surfer riding a wave in the ocean, with the surfer wearing a black wetsuit and the wave displaying a deep blue color. The lighting in the image suggests it is either early morning or late afternoon, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.553}, "power_stats": {"power_gpu_soc_mean_watts": 19.518, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 75.553}, "timestamp": "2026-01-28T14:43:11.401081"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3929.326, "latencies_ms": [3929.326], "images_per_second": 0.254, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A double-decker bus is parked at a bus stop with a man standing next to it.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12699.8, "ram_available_mb": 50141.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12701.0, "ram_available_mb": 50139.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.562}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 7.397, "gpu_utilization_percent_mean": 86.562}, "timestamp": "2026-01-28T14:43:17.380258"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5039.655, "latencies_ms": [5039.655], "images_per_second": 0.198, "prompt_tokens": 1114, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. double-decker bus\n2. yellow license plate\n3. black front bumper\n4. white flowers\n5. brick sidewalk\n6. bus stop sign\n7. advertisement board\n8. street lamp", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12701.0, "ram_available_mb": 50139.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12701.7, "ram_available_mb": 50139.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.381}, "power_stats": {"power_gpu_soc_mean_watts": 19.58, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 73.381}, "timestamp": "2026-01-28T14:43:24.464229"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5771.777, "latencies_ms": [5771.777], "images_per_second": 0.173, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The bus is parked on the left side of the street, with the bus stop on the right side. The bus is in the foreground, while the bus stop is in the background. The bus is closer to the viewer than the bus stop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12701.7, "ram_available_mb": 50139.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12701.7, "ram_available_mb": 50139.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.875}, "power_stats": {"power_gpu_soc_mean_watts": 19.145, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.446, "gpu_utilization_percent_mean": 82.875}, "timestamp": "2026-01-28T14:43:32.252093"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3105.087, "latencies_ms": [3105.087], "images_per_second": 0.322, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A double decker bus is parked at a bus stop on a city street.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12701.7, "ram_available_mb": 50139.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.92}, "power_stats": {"power_gpu_soc_mean_watts": 22.851, "power_cpu_cv_mean_watts": 1.57, "power_sys_5v0_mean_watts": 7.787, "gpu_utilization_percent_mean": 78.92}, "timestamp": "2026-01-28T14:43:37.394814"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5568.057, "latencies_ms": [5568.057], "images_per_second": 0.18, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a double-decker bus with a yellow and black color scheme, parked at a bus stop with a blue and white advertisement board. The sky is overcast, and the lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.1, "ram_used_mb": 12703.0, "ram_available_mb": 50137.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.63}, "power_stats": {"power_gpu_soc_mean_watts": 19.421, "power_cpu_cv_mean_watts": 2.02, "power_sys_5v0_mean_watts": 7.513, "gpu_utilization_percent_mean": 82.63}, "timestamp": "2026-01-28T14:43:45.005748"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3792.79, "latencies_ms": [3792.79], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A yellow and red biplane with the letters SP-AWF on the side is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12703.0, "ram_available_mb": 50137.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12702.8, "ram_available_mb": 50138.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.032}, "power_stats": {"power_gpu_soc_mean_watts": 21.091, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 7.578, "gpu_utilization_percent_mean": 80.032}, "timestamp": "2026-01-28T14:43:50.827890"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6370.462, "latencies_ms": [6370.462], "images_per_second": 0.157, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. propeller: 1\n2. wing: 2\n3. tail: 1\n4. propeller blade: 1\n5. propeller hub: 1\n6. propeller shaft: 1\n7. propeller blade tip: 1\n8. propeller blade tip end: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12702.8, "ram_available_mb": 50138.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12703.3, "ram_available_mb": 50137.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.208}, "power_stats": {"power_gpu_soc_mean_watts": 19.017, "power_cpu_cv_mean_watts": 2.116, "power_sys_5v0_mean_watts": 7.579, "gpu_utilization_percent_mean": 81.208}, "timestamp": "2026-01-28T14:43:59.216705"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4152.824, "latencies_ms": [4152.824], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The yellow biplane is positioned in the foreground, flying from left to right, while the cloudy sky is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12703.3, "ram_available_mb": 50137.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12704.3, "ram_available_mb": 50136.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.714}, "power_stats": {"power_gpu_soc_mean_watts": 20.545, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 7.475, "gpu_utilization_percent_mean": 84.714}, "timestamp": "2026-01-28T14:44:05.396049"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2929.671, "latencies_ms": [2929.671], "images_per_second": 0.341, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A yellow and red biplane is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12704.3, "ram_available_mb": 50136.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12704.5, "ram_available_mb": 50136.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.292}, "power_stats": {"power_gpu_soc_mean_watts": 23.351, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.81, "gpu_utilization_percent_mean": 88.292}, "timestamp": "2026-01-28T14:44:10.341989"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4181.437, "latencies_ms": [4181.437], "images_per_second": 0.239, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The aircraft is painted in vibrant yellow with red accents and has a blue propeller. The sky is overcast with gray clouds.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12704.5, "ram_available_mb": 50136.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12703.6, "ram_available_mb": 50137.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.829}, "power_stats": {"power_gpu_soc_mean_watts": 20.487, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.457, "gpu_utilization_percent_mean": 83.829}, "timestamp": "2026-01-28T14:44:16.563008"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4611.412, "latencies_ms": [4611.412], "images_per_second": 0.217, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures an aerial view of a bustling airport, with a white airplane wing visible on the left side, and a large parking lot filled with numerous cars, surrounded by a variety of buildings and greenery.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12703.6, "ram_available_mb": 50137.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12703.4, "ram_available_mb": 50137.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.154}, "power_stats": {"power_gpu_soc_mean_watts": 20.122, "power_cpu_cv_mean_watts": 1.92, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 73.154}, "timestamp": "2026-01-28T14:44:23.213259"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5331.716, "latencies_ms": [5331.716], "images_per_second": 0.188, "prompt_tokens": 1113, "response_tokens_est": 43, "n_tiles": 1, "output_text": " airplane wing: 1, car: 100, building: 1, parking lot: 100, trees: 100, clouds: 10, sky: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12703.4, "ram_available_mb": 50137.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12703.4, "ram_available_mb": 50137.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.386}, "power_stats": {"power_gpu_soc_mean_watts": 19.51, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 7.466, "gpu_utilization_percent_mean": 83.386}, "timestamp": "2026-01-28T14:44:30.579075"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4737.221, "latencies_ms": [4737.221], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The airplane wing is on the left side of the image, while the parking lot is on the right side. The parking lot is in the foreground, with the cityscape and fields in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12703.4, "ram_available_mb": 50137.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12704.4, "ram_available_mb": 50136.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 19.859, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 7.7, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-28T14:44:37.330901"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6561.988, "latencies_ms": [6561.988], "images_per_second": 0.152, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a bustling scene from an airplane window, offering a bird's eye view of a sprawling parking lot nestled amidst a verdant landscape. The parking lot, teeming with cars of various colors, is nestled amidst a mix of residential and commercial buildings, creating a harmonious blend of urban and natural elements.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12704.4, "ram_available_mb": 50136.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12704.4, "ram_available_mb": 50136.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.709}, "power_stats": {"power_gpu_soc_mean_watts": 18.624, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 7.471, "gpu_utilization_percent_mean": 81.709}, "timestamp": "2026-01-28T14:44:45.934558"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4155.718, "latencies_ms": [4155.718], "images_per_second": 0.241, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image displays a clear blue sky with white clouds, and the scene is taken from an airplane window, providing a bird's eye view of the landscape below.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12704.4, "ram_available_mb": 50136.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12704.2, "ram_available_mb": 50136.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.866, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.749, "gpu_utilization_percent_mean": 78.886}, "timestamp": "2026-01-28T14:44:52.128136"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3643.333, "latencies_ms": [3643.333], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a pink flip phone with a picture of a girl on it.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12704.2, "ram_available_mb": 50136.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12703.9, "ram_available_mb": 50137.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.285, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 7.458, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-28T14:44:57.814324"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6336.947, "latencies_ms": [6336.947], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 2\n2. phone: 1\n3. cup: 1\n4. book: 1\n5. bag: 1\n6. chair: 1\n7. blanket: 1\n8. person's hand: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12703.9, "ram_available_mb": 50137.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12701.6, "ram_available_mb": 50139.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.358}, "power_stats": {"power_gpu_soc_mean_watts": 18.579, "power_cpu_cv_mean_watts": 2.071, "power_sys_5v0_mean_watts": 7.459, "gpu_utilization_percent_mean": 80.358}, "timestamp": "2026-01-28T14:45:06.170751"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5442.31, "latencies_ms": [5442.31], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The pink flip phone is held in the foreground by a person's hand, while the person is seated on a couch in the background. The phone is positioned to the left of the person's body, and the couch is located behind the person.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.6, "ram_available_mb": 50139.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12701.5, "ram_available_mb": 50139.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.556}, "power_stats": {"power_gpu_soc_mean_watts": 19.915, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 7.622, "gpu_utilization_percent_mean": 81.556}, "timestamp": "2026-01-28T14:45:13.647884"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4526.389, "latencies_ms": [4526.389], "images_per_second": 0.221, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A person is sitting on the floor with a pink flip phone in their hand. There is a cup of soda and a bag of chips on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.5, "ram_available_mb": 50139.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12701.5, "ram_available_mb": 50139.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.684}, "power_stats": {"power_gpu_soc_mean_watts": 19.777, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.479, "gpu_utilization_percent_mean": 77.684}, "timestamp": "2026-01-28T14:45:20.219785"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5307.843, "latencies_ms": [5307.843], "images_per_second": 0.188, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a pink flip phone in the foreground. The lighting is soft and warm, creating a cozy atmosphere. The phone is made of plastic and has a glossy finish, reflecting the light in the room.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12701.5, "ram_available_mb": 50139.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.227}, "power_stats": {"power_gpu_soc_mean_watts": 20.247, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.731, "gpu_utilization_percent_mean": 82.227}, "timestamp": "2026-01-28T14:45:27.566927"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5216.106, "latencies_ms": [5216.106], "images_per_second": 0.192, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In the image, there are two zebras standing in a field of tall, dry grass, with one zebra looking directly at the camera and the other facing away, both exhibiting their distinctive black and white stripes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12701.2, "ram_available_mb": 50139.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12701.8, "ram_available_mb": 50139.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.773}, "power_stats": {"power_gpu_soc_mean_watts": 19.483, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.476, "gpu_utilization_percent_mean": 79.773}, "timestamp": "2026-01-28T14:45:34.820466"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2363.714, "latencies_ms": [2363.714], "images_per_second": 0.423, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.8, "ram_available_mb": 50139.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12701.8, "ram_available_mb": 50139.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.579}, "power_stats": {"power_gpu_soc_mean_watts": 24.64, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.84, "gpu_utilization_percent_mean": 88.579}, "timestamp": "2026-01-28T14:45:39.215933"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5993.985, "latencies_ms": [5993.985], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the one on the right. The background of the image features a grassy field with trees and hills, providing a natural habitat for the zebras.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12701.8, "ram_available_mb": 50139.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 12701.4, "ram_available_mb": 50139.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.36}, "power_stats": {"power_gpu_soc_mean_watts": 18.924, "power_cpu_cv_mean_watts": 2.123, "power_sys_5v0_mean_watts": 7.449, "gpu_utilization_percent_mean": 84.36}, "timestamp": "2026-01-28T14:45:47.229410"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2946.657, "latencies_ms": [2946.657], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Two zebras are standing in a tall, dry grass field.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12701.4, "ram_available_mb": 50139.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12702.0, "ram_available_mb": 50138.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.75}, "power_stats": {"power_gpu_soc_mean_watts": 23.55, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 82.75}, "timestamp": "2026-01-28T14:45:52.211260"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6111.325, "latencies_ms": [6111.325], "images_per_second": 0.164, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features two zebras standing in a field of tall, dry grass. The zebras are black and white with distinctive stripes, and the grass is a golden brown color. The lighting in the image is bright and natural, suggesting that the photo was taken during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12702.0, "ram_available_mb": 50138.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12702.4, "ram_available_mb": 50138.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.725}, "power_stats": {"power_gpu_soc_mean_watts": 19.041, "power_cpu_cv_mean_watts": 2.191, "power_sys_5v0_mean_watts": 7.511, "gpu_utilization_percent_mean": 81.725}, "timestamp": "2026-01-28T14:46:00.350784"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3044.68, "latencies_ms": [3044.68], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is walking into the ocean carrying a yellow surfboard.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12702.4, "ram_available_mb": 50138.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.057, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 84.28}, "timestamp": "2026-01-28T14:46:05.438980"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5792.564, "latencies_ms": [5792.564], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. surfboard: 1\n3. ocean: 2\n4. waves: 2\n5. sky: 1\n6. water: 1\n7. sand: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.875}, "power_stats": {"power_gpu_soc_mean_watts": 19.612, "power_cpu_cv_mean_watts": 2.094, "power_sys_5v0_mean_watts": 7.677, "gpu_utilization_percent_mean": 81.875}, "timestamp": "2026-01-28T14:46:13.241620"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4890.435, "latencies_ms": [4890.435], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The surfer is positioned on the left side of the image, with the ocean waves on the right side. The surfer is in the foreground, with the ocean waves in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.878}, "power_stats": {"power_gpu_soc_mean_watts": 19.793, "power_cpu_cv_mean_watts": 2.393, "power_sys_5v0_mean_watts": 7.53, "gpu_utilization_percent_mean": 79.878}, "timestamp": "2026-01-28T14:46:20.160367"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3603.719, "latencies_ms": [3603.719], "images_per_second": 0.277, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is walking into the ocean with a yellow surfboard. The ocean is blue and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12702.4, "ram_available_mb": 50138.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.111, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.803, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-28T14:46:25.775618"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4700.028, "latencies_ms": [4700.028], "images_per_second": 0.213, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a man in the ocean, holding a yellow surfboard, with the ocean waves crashing around him. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12702.4, "ram_available_mb": 50138.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 12.0, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.975}, "power_stats": {"power_gpu_soc_mean_watts": 20.119, "power_cpu_cv_mean_watts": 2.524, "power_sys_5v0_mean_watts": 7.549, "gpu_utilization_percent_mean": 83.975}, "timestamp": "2026-01-28T14:46:32.502709"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2946.573, "latencies_ms": [2946.573], "images_per_second": 0.339, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cow is standing in the water near the shore.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12702.2, "ram_available_mb": 50138.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12703.1, "ram_available_mb": 50137.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.533, "power_cpu_cv_mean_watts": 2.086, "power_sys_5v0_mean_watts": 7.901, "gpu_utilization_percent_mean": 84.042}, "timestamp": "2026-01-28T14:46:37.493057"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3906.054, "latencies_ms": [3906.054], "images_per_second": 0.256, "prompt_tokens": 1113, "response_tokens_est": 20, "n_tiles": 1, "output_text": " cow: 1\nwater: 1\nsand: 1\nrocks: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12703.1, "ram_available_mb": 50137.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12703.3, "ram_available_mb": 50137.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.219}, "power_stats": {"power_gpu_soc_mean_watts": 20.666, "power_cpu_cv_mean_watts": 1.539, "power_sys_5v0_mean_watts": 7.4, "gpu_utilization_percent_mean": 88.219}, "timestamp": "2026-01-28T14:46:43.412147"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4340.431, "latencies_ms": [4340.431], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The cow is standing in the foreground, close to the camera. The cow is standing on the beach, with the water in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12703.3, "ram_available_mb": 50137.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.528}, "power_stats": {"power_gpu_soc_mean_watts": 20.34, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 7.466, "gpu_utilization_percent_mean": 79.528}, "timestamp": "2026-01-28T14:46:49.796492"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3068.013, "latencies_ms": [3068.013], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cow is standing in the water near the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12703.9, "ram_available_mb": 50136.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.106, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 7.772, "gpu_utilization_percent_mean": 83.12}, "timestamp": "2026-01-28T14:46:54.904948"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3730.618, "latencies_ms": [3730.618], "images_per_second": 0.268, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The cow is black and white, and the photo is in black and white.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12703.9, "ram_available_mb": 50136.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 89.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.61, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 7.336, "gpu_utilization_percent_mean": 89.0}, "timestamp": "2026-01-28T14:47:00.666202"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3983.678, "latencies_ms": [3983.678], "images_per_second": 0.251, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A woman in a white blouse and black pants is standing on a snowy hill, holding ski poles and wearing skis.", "error": null, "sys_before": {"cpu_percent": 15.8, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.0, "ram_used_mb": 12703.8, "ram_available_mb": 50137.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.03}, "power_stats": {"power_gpu_soc_mean_watts": 21.011, "power_cpu_cv_mean_watts": 2.282, "power_sys_5v0_mean_watts": 7.576, "gpu_utilization_percent_mean": 80.03}, "timestamp": "2026-01-28T14:47:06.693370"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6101.127, "latencies_ms": [6101.127], "images_per_second": 0.164, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. woman: 1\n2. ski poles: 2\n3. skis: 2\n4. backpack: 1\n5. trees: 2\n6. clouds: 1\n7. snow: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12703.8, "ram_available_mb": 50137.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12703.8, "ram_available_mb": 50137.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.373}, "power_stats": {"power_gpu_soc_mean_watts": 19.313, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 7.57, "gpu_utilization_percent_mean": 82.373}, "timestamp": "2026-01-28T14:47:14.808250"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4950.563, "latencies_ms": [4950.563], "images_per_second": 0.202, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the ski poles and skis positioned to her left. The trees are located in the background, providing a natural backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12703.8, "ram_available_mb": 50137.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12704.0, "ram_available_mb": 50136.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.878}, "power_stats": {"power_gpu_soc_mean_watts": 19.756, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 7.522, "gpu_utilization_percent_mean": 78.878}, "timestamp": "2026-01-28T14:47:21.780117"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3399.874, "latencies_ms": [3399.874], "images_per_second": 0.294, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is standing on a snowy mountain with skis and poles.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12704.0, "ram_available_mb": 50136.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12703.4, "ram_available_mb": 50137.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.536}, "power_stats": {"power_gpu_soc_mean_watts": 21.334, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.482, "gpu_utilization_percent_mean": 87.536}, "timestamp": "2026-01-28T14:47:27.214575"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5622.203, "latencies_ms": [5622.203], "images_per_second": 0.178, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the subject and the background. The subject is wearing a white blouse with black patterns and black pants, and the background features snow-covered trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12703.4, "ram_available_mb": 50137.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12702.8, "ram_available_mb": 50138.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.319}, "power_stats": {"power_gpu_soc_mean_watts": 19.023, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.43, "gpu_utilization_percent_mean": 78.319}, "timestamp": "2026-01-28T14:47:34.895011"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3969.673, "latencies_ms": [3969.673], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A dog with a yellow frisbee in its mouth is standing on a sandy beach with the ocean and a small island in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12702.8, "ram_available_mb": 50138.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12702.6, "ram_available_mb": 50138.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.072, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 7.696, "gpu_utilization_percent_mean": 81.182}, "timestamp": "2026-01-28T14:47:40.916021"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6332.906, "latencies_ms": [6332.906], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. dog: 1\n2. frisbee: 1\n3. sand: 1\n4. ocean: 1\n5. island: 1\n6. sky: 1\n7. beach: 1\n8. paw: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12702.6, "ram_available_mb": 50138.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12702.5, "ram_available_mb": 50138.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.692}, "power_stats": {"power_gpu_soc_mean_watts": 18.712, "power_cpu_cv_mean_watts": 2.057, "power_sys_5v0_mean_watts": 7.445, "gpu_utilization_percent_mean": 80.692}, "timestamp": "2026-01-28T14:47:49.262034"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5410.582, "latencies_ms": [5410.582], "images_per_second": 0.185, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The dog is in the foreground, holding a yellow frisbee in its mouth. The beach extends into the background, with the ocean and a small island visible. The dog is positioned to the left of the frame, with the ocean to its right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12702.5, "ram_available_mb": 50138.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12702.8, "ram_available_mb": 50138.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.222}, "power_stats": {"power_gpu_soc_mean_watts": 19.69, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.657, "gpu_utilization_percent_mean": 77.222}, "timestamp": "2026-01-28T14:47:56.685442"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4358.841, "latencies_ms": [4358.841], "images_per_second": 0.229, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A dog with a yellow frisbee in its mouth is standing on a beach with the ocean and a small island in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12702.8, "ram_available_mb": 50138.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.472}, "power_stats": {"power_gpu_soc_mean_watts": 20.361, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.432, "gpu_utilization_percent_mean": 86.472}, "timestamp": "2026-01-28T14:48:03.072546"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3719.905, "latencies_ms": [3719.905], "images_per_second": 0.269, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The dog is black, white, and gray, and the beach is sandy. The sky is cloudy and the ocean is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.926, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.811, "gpu_utilization_percent_mean": 74.161}, "timestamp": "2026-01-28T14:48:08.848640"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4937.411, "latencies_ms": [4937.411], "images_per_second": 0.203, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In a kitchen, a group of people, including a woman in a camouflage uniform, are gathered around a large pot on the stove, with a woman in a striped shirt standing nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12703.7, "ram_available_mb": 50137.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12704.6, "ram_available_mb": 50136.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.512}, "power_stats": {"power_gpu_soc_mean_watts": 19.764, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 7.43, "gpu_utilization_percent_mean": 83.512}, "timestamp": "2026-01-28T14:48:15.808354"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5653.956, "latencies_ms": [5653.956], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. refrigerator: 2\n2. stove: 1\n3. pot: 1\n4. bowl: 1\n5. cup: 1\n6. spoon: 1\n7. knife: 1\n8. spoon: 1", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 12704.6, "ram_available_mb": 50136.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 12704.6, "ram_available_mb": 50136.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.447}, "power_stats": {"power_gpu_soc_mean_watts": 18.766, "power_cpu_cv_mean_watts": 2.122, "power_sys_5v0_mean_watts": 7.702, "gpu_utilization_percent_mean": 72.447}, "timestamp": "2026-01-28T14:48:23.492057"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4446.449, "latencies_ms": [4446.449], "images_per_second": 0.225, "prompt_tokens": 1117, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The large pot is in the foreground, the refrigerator is in the background, and the women are standing in the middle of the kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12704.6, "ram_available_mb": 50136.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12704.6, "ram_available_mb": 50136.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.405}, "power_stats": {"power_gpu_soc_mean_watts": 19.854, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.399, "gpu_utilization_percent_mean": 85.405}, "timestamp": "2026-01-28T14:48:29.988934"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3426.517, "latencies_ms": [3426.517], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are in a kitchen with a woman in a military uniform.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12704.6, "ram_available_mb": 50136.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12707.9, "ram_available_mb": 50133.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.179}, "power_stats": {"power_gpu_soc_mean_watts": 21.904, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.579, "gpu_utilization_percent_mean": 79.179}, "timestamp": "2026-01-28T14:48:35.433011"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3921.609, "latencies_ms": [3921.609], "images_per_second": 0.255, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken in a kitchen with a grey wall and a stainless steel refrigerator. The lighting is natural, coming from the windows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12707.9, "ram_available_mb": 50133.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12708.8, "ram_available_mb": 50132.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.531}, "power_stats": {"power_gpu_soc_mean_watts": 21.53, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 82.531}, "timestamp": "2026-01-28T14:48:41.369918"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3907.601, "latencies_ms": [3907.601], "images_per_second": 0.256, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The image depicts a bathroom with a toilet, a mirror, and a shelf with various toiletries.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12708.8, "ram_available_mb": 50132.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.406}, "power_stats": {"power_gpu_soc_mean_watts": 20.779, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.366, "gpu_utilization_percent_mean": 85.406}, "timestamp": "2026-01-28T14:48:47.305439"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5736.214, "latencies_ms": [5736.214], "images_per_second": 0.174, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. mirror: 1\n2. toilet: 1\n3. towel: 2\n4. toilet paper: 1\n5. shelf: 3\n6. bottles: 4\n7. wall: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.396}, "power_stats": {"power_gpu_soc_mean_watts": 18.677, "power_cpu_cv_mean_watts": 2.111, "power_sys_5v0_mean_watts": 7.693, "gpu_utilization_percent_mean": 73.396}, "timestamp": "2026-01-28T14:48:55.072690"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6722.219, "latencies_ms": [6722.219], "images_per_second": 0.149, "prompt_tokens": 1118, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the sink and mirror above it. The towel rack is positioned to the left of the toilet, while the toilet paper holder is located to the right. The mirror is directly above the sink, and the towel is hanging on the towel rack above the sink.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12709.1, "ram_available_mb": 50131.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.036}, "power_stats": {"power_gpu_soc_mean_watts": 18.42, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 7.403, "gpu_utilization_percent_mean": 82.036}, "timestamp": "2026-01-28T14:49:03.854787"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5472.236, "latencies_ms": [5472.236], "images_per_second": 0.183, "prompt_tokens": 1112, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image depicts a bathroom with a toilet, a sink, and a mirror. The toilet is located in the lower right corner of the image, while the sink is situated in the upper left corner. The mirror is positioned above the sink, reflecting the bathroom's interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12709.1, "ram_available_mb": 50131.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12709.1, "ram_available_mb": 50131.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.065}, "power_stats": {"power_gpu_soc_mean_watts": 19.332, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.681, "gpu_utilization_percent_mean": 76.065}, "timestamp": "2026-01-28T14:49:11.351350"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4102.994, "latencies_ms": [4102.994], "images_per_second": 0.244, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The bathroom is well-lit with a warm yellow light, and the walls are covered in beige tiles.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12709.1, "ram_available_mb": 50131.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.294}, "power_stats": {"power_gpu_soc_mean_watts": 20.146, "power_cpu_cv_mean_watts": 2.474, "power_sys_5v0_mean_watts": 7.342, "gpu_utilization_percent_mean": 82.294}, "timestamp": "2026-01-28T14:49:17.464935"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3890.672, "latencies_ms": [3890.672], "images_per_second": 0.257, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A dog wearing a green hat is sitting in the back seat of a car, and the car has a shamrock decoration on the side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12709.2, "ram_available_mb": 50131.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.875}, "power_stats": {"power_gpu_soc_mean_watts": 21.354, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.728, "gpu_utilization_percent_mean": 77.875}, "timestamp": "2026-01-28T14:49:23.385229"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6249.721, "latencies_ms": [6249.721], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. dog: 1\n2. person: 1\n3. hat: 1\n4. shamrock: 1\n5. window: 1\n6. mirror: 1\n7. light: 1\n8. vehicle: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12709.2, "ram_available_mb": 50131.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12709.0, "ram_available_mb": 50131.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.365}, "power_stats": {"power_gpu_soc_mean_watts": 18.858, "power_cpu_cv_mean_watts": 2.08, "power_sys_5v0_mean_watts": 7.434, "gpu_utilization_percent_mean": 82.365}, "timestamp": "2026-01-28T14:49:31.669934"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5365.189, "latencies_ms": [5365.189], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The dog is in the front seat of the vehicle, with the person sitting behind it. The person is wearing a green hat, and the dog is wearing a green hat. The vehicle is parked in a parking lot, and there are other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12709.0, "ram_available_mb": 50131.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.111}, "power_stats": {"power_gpu_soc_mean_watts": 19.105, "power_cpu_cv_mean_watts": 2.038, "power_sys_5v0_mean_watts": 7.747, "gpu_utilization_percent_mean": 72.111}, "timestamp": "2026-01-28T14:49:39.067257"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4734.827, "latencies_ms": [4734.827], "images_per_second": 0.211, "prompt_tokens": 1111, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A dog wearing a green hat is sitting in the back seat of a car, and a person is driving. The car is decorated with shamrocks and green balloons.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.925}, "power_stats": {"power_gpu_soc_mean_watts": 19.98, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.468, "gpu_utilization_percent_mean": 84.925}, "timestamp": "2026-01-28T14:49:45.823043"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5979.089, "latencies_ms": [5979.089], "images_per_second": 0.167, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image depicts a dog wearing a green hat and a green shamrock on its collar, sitting in the passenger seat of a vehicle. The vehicle is decorated with green shamrocks and has a green shamrock on the side mirror. The lighting in the image is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 71.58}, "power_stats": {"power_gpu_soc_mean_watts": 18.708, "power_cpu_cv_mean_watts": 2.139, "power_sys_5v0_mean_watts": 7.726, "gpu_utilization_percent_mean": 71.58}, "timestamp": "2026-01-28T14:49:53.835367"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4708.893, "latencies_ms": [4708.893], "images_per_second": 0.212, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a large elephant is seen in a zoo enclosure, standing in a pool of water and drinking from it, with a fence and trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12708.7, "ram_available_mb": 50132.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.85}, "power_stats": {"power_gpu_soc_mean_watts": 19.951, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 7.458, "gpu_utilization_percent_mean": 84.85}, "timestamp": "2026-01-28T14:50:00.599042"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4580.991, "latencies_ms": [4580.991], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 1, rock: 3, water: 1, tree: 1, fence: 1, person: 2, ground: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12708.7, "ram_available_mb": 50132.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.359}, "power_stats": {"power_gpu_soc_mean_watts": 19.927, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.548, "gpu_utilization_percent_mean": 78.359}, "timestamp": "2026-01-28T14:50:07.206548"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6014.889, "latencies_ms": [6014.889], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The elephant is positioned in the foreground, with the water and rocks in the middle ground, and the people and fence in the background. The elephant is facing the water, with its trunk extended towards it, and the rocks are positioned to the left of the elephant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12708.7, "ram_available_mb": 50132.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.68}, "power_stats": {"power_gpu_soc_mean_watts": 18.892, "power_cpu_cv_mean_watts": 2.011, "power_sys_5v0_mean_watts": 7.44, "gpu_utilization_percent_mean": 84.68}, "timestamp": "2026-01-28T14:50:15.261275"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4498.71, "latencies_ms": [4498.71], "images_per_second": 0.222, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, a large elephant is seen in a zoo enclosure, standing in a pool of water and drinking. The enclosure is surrounded by a fence and has a dirt ground.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12708.7, "ram_available_mb": 50132.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12708.4, "ram_available_mb": 50132.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.079}, "power_stats": {"power_gpu_soc_mean_watts": 20.24, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.66, "gpu_utilization_percent_mean": 77.079}, "timestamp": "2026-01-28T14:50:21.786610"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3576.094, "latencies_ms": [3576.094], "images_per_second": 0.28, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The elephant is gray, the water is blue, and the ground is brown.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12708.4, "ram_available_mb": 50132.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12709.1, "ram_available_mb": 50131.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 89.067}, "power_stats": {"power_gpu_soc_mean_watts": 21.084, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 7.424, "gpu_utilization_percent_mean": 89.067}, "timestamp": "2026-01-28T14:50:27.391118"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4978.653, "latencies_ms": [4978.653], "images_per_second": 0.201, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the image, there are four people standing on a snowy mountain, each equipped with ski equipment and wearing ski jackets, with a clear blue sky and snow-covered mountains in the background.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12709.1, "ram_available_mb": 50131.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12708.1, "ram_available_mb": 50132.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.905}, "power_stats": {"power_gpu_soc_mean_watts": 19.562, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 7.445, "gpu_utilization_percent_mean": 80.905}, "timestamp": "2026-01-28T14:50:34.391760"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5880.79, "latencies_ms": [5880.79], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. skis: 4\n2. ski poles: 4\n3. skiers: 4\n4. mountain: 1\n5. snow: 1\n6. sky: 1\n7. trees: 1\n8. mountain range: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12708.0, "ram_available_mb": 50132.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12708.4, "ram_available_mb": 50132.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.72}, "power_stats": {"power_gpu_soc_mean_watts": 19.636, "power_cpu_cv_mean_watts": 2.043, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 78.72}, "timestamp": "2026-01-28T14:50:42.329310"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6654.881, "latencies_ms": [6654.881], "images_per_second": 0.15, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The skiers are positioned in the foreground of the image, with the mountains in the background. The skier on the left is closest to the camera, while the skier on the right is farthest away. The skiers are standing on the snow-covered slope, with the ski lift poles visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12708.4, "ram_available_mb": 50132.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12709.6, "ram_available_mb": 50131.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.75}, "power_stats": {"power_gpu_soc_mean_watts": 18.685, "power_cpu_cv_mean_watts": 2.139, "power_sys_5v0_mean_watts": 7.499, "gpu_utilization_percent_mean": 78.75}, "timestamp": "2026-01-28T14:50:51.014312"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3474.442, "latencies_ms": [3474.442], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Four people are standing on a snowy mountain, wearing ski gear and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12709.6, "ram_available_mb": 50131.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12709.6, "ram_available_mb": 50131.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.724}, "power_stats": {"power_gpu_soc_mean_watts": 21.714, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 7.588, "gpu_utilization_percent_mean": 85.724}, "timestamp": "2026-01-28T14:50:56.536698"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5220.29, "latencies_ms": [5220.29], "images_per_second": 0.192, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a group of people wearing colorful ski gear, standing on a snowy mountain with a clear blue sky in the background. The sunlight reflects off the snow, creating a bright and vibrant atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12709.6, "ram_available_mb": 50131.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12709.3, "ram_available_mb": 50131.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.397, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 7.432, "gpu_utilization_percent_mean": 83.07}, "timestamp": "2026-01-28T14:51:03.796515"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3422.462, "latencies_ms": [3422.462], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is holding a black smartphone in their hand, and the screen displays a photo of a tree.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12709.3, "ram_available_mb": 50131.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12708.3, "ram_available_mb": 50132.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.421, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.802, "gpu_utilization_percent_mean": 78.286}, "timestamp": "2026-01-28T14:51:09.271467"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6112.752, "latencies_ms": [6112.752], "images_per_second": 0.164, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. hand: 1\n2. smartphone: 1\n3. keyboard: 1\n4. screen: 1\n5. reflection: 1\n6. light: 1\n7. table: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12708.3, "ram_available_mb": 50132.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.4, "ram_used_mb": 12707.7, "ram_available_mb": 50133.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.216}, "power_stats": {"power_gpu_soc_mean_watts": 19.009, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 7.497, "gpu_utilization_percent_mean": 82.216}, "timestamp": "2026-01-28T14:51:17.432865"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4665.042, "latencies_ms": [4665.042], "images_per_second": 0.214, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The smartphone is held in the left hand, with the right hand's thumb resting on the back of the device. The smartphone is positioned in the foreground, with the keyboard and wooden table in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12707.7, "ram_available_mb": 50133.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12707.1, "ram_available_mb": 50133.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.338, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 7.724, "gpu_utilization_percent_mean": 75.385}, "timestamp": "2026-01-28T14:51:24.110900"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3925.813, "latencies_ms": [3925.813], "images_per_second": 0.255, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is holding a black smartphone in their hand, and the screen is reflecting a picture of a keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12707.1, "ram_available_mb": 50133.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.562}, "power_stats": {"power_gpu_soc_mean_watts": 20.718, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 7.463, "gpu_utilization_percent_mean": 85.562}, "timestamp": "2026-01-28T14:51:30.054392"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3135.615, "latencies_ms": [3135.615], "images_per_second": 0.319, "prompt_tokens": 1110, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The phone is black and the screen is reflecting a keyboard.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.154}, "power_stats": {"power_gpu_soc_mean_watts": 22.323, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.6, "gpu_utilization_percent_mean": 83.154}, "timestamp": "2026-01-28T14:51:35.217042"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5783.613, "latencies_ms": [5783.613], "images_per_second": 0.173, "prompt_tokens": 1432, "response_tokens_est": 44, "n_tiles": 1, "output_text": " A red and blue parking meter with a sign that says \"DENVER'S ROAD HOME\" is on a sidewalk next to a sign that says \"CAMPAIGN TO END HOMELESSNESS.\"", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12708.4, "ram_available_mb": 50132.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.083}, "power_stats": {"power_gpu_soc_mean_watts": 21.232, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 84.083}, "timestamp": "2026-01-28T14:51:43.051253"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6345.095, "latencies_ms": [6345.095], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 46, "n_tiles": 1, "output_text": " 1. red and white parking meter\n2. white sign with red text\n3. green bushes\n4. white fence\n5. concrete sidewalk\n6. metal light fixture\n7. yellow flowers\n8. trees", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12708.4, "ram_available_mb": 50132.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12707.7, "ram_available_mb": 50133.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.151}, "power_stats": {"power_gpu_soc_mean_watts": 20.141, "power_cpu_cv_mean_watts": 1.851, "power_sys_5v0_mean_watts": 7.686, "gpu_utilization_percent_mean": 79.151}, "timestamp": "2026-01-28T14:51:51.439958"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6066.125, "latencies_ms": [6066.125], "images_per_second": 0.165, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The parking meter is located on the right side of the image, with a sign placed on the left side of the meter. The sign is positioned in the foreground, while the parking meter is in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12707.7, "ram_available_mb": 50133.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12707.0, "ram_available_mb": 50133.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.78}, "power_stats": {"power_gpu_soc_mean_watts": 20.838, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.701, "gpu_utilization_percent_mean": 84.78}, "timestamp": "2026-01-28T14:51:59.530657"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4992.321, "latencies_ms": [4992.321], "images_per_second": 0.2, "prompt_tokens": 1444, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A red and white parking meter is on the side of the road, with a sign that says \"DENVER'S ROAD HOME\".", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12707.0, "ram_available_mb": 50133.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12706.0, "ram_available_mb": 50134.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.167}, "power_stats": {"power_gpu_soc_mean_watts": 22.337, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 7.91, "gpu_utilization_percent_mean": 83.167}, "timestamp": "2026-01-28T14:52:06.562297"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7437.637, "latencies_ms": [7437.637], "images_per_second": 0.134, "prompt_tokens": 1442, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image shows a red and white parking meter on a sidewalk, with a sign that reads \"CAMPAIGN TO END HOMELESSNESS\" and a sign that reads \"DENVER'S ROAD HOME\". The parking meter is surrounded by green plants and flowers, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.0, "ram_available_mb": 50134.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.1, "ram_used_mb": 12705.8, "ram_available_mb": 50135.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.903}, "power_stats": {"power_gpu_soc_mean_watts": 20.081, "power_cpu_cv_mean_watts": 2.132, "power_sys_5v0_mean_watts": 7.748, "gpu_utilization_percent_mean": 84.903}, "timestamp": "2026-01-28T14:52:16.014997"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3871.634, "latencies_ms": [3871.634], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " In the image, a herd of zebras is grazing in a grassy field, their distinctive black and white stripes standing out against the natural backdrop.", "error": null, "sys_before": {"cpu_percent": 17.9, "ram_used_mb": 12705.8, "ram_available_mb": 50135.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12706.0, "ram_available_mb": 50134.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.625}, "power_stats": {"power_gpu_soc_mean_watts": 21.606, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 7.792, "gpu_utilization_percent_mean": 76.625}, "timestamp": "2026-01-28T14:52:21.921703"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5967.881, "latencies_ms": [5967.881], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 53, "n_tiles": 1, "output_text": " zebra: 1\ngrass: 1\ntrees: 1\ngrassland: 1\nzebra's tail: 1\nzebra's mane: 1\nzebra's legs: 1\nzebra's head: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12706.0, "ram_available_mb": 50134.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12706.0, "ram_available_mb": 50134.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.48}, "power_stats": {"power_gpu_soc_mean_watts": 18.947, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.482, "gpu_utilization_percent_mean": 83.48}, "timestamp": "2026-01-28T14:52:29.915097"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5517.93, "latencies_ms": [5517.93], "images_per_second": 0.181, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main zebra is in the foreground, grazing on the grass. The other zebras are in the background, with some standing and others grazing. The zebras are spread out across the field, with some closer to the foreground and others further in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12706.0, "ram_available_mb": 50134.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.149}, "power_stats": {"power_gpu_soc_mean_watts": 19.032, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 7.628, "gpu_utilization_percent_mean": 73.149}, "timestamp": "2026-01-28T14:52:37.470490"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4815.575, "latencies_ms": [4815.575], "images_per_second": 0.208, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the vast savannah, a group of zebras graze peacefully on the golden grass. Their distinctive black and white stripes stand out against the natural backdrop, creating a striking contrast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12706.8, "ram_available_mb": 50134.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.925}, "power_stats": {"power_gpu_soc_mean_watts": 19.989, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.478, "gpu_utilization_percent_mean": 85.925}, "timestamp": "2026-01-28T14:52:44.319334"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5194.621, "latencies_ms": [5194.621], "images_per_second": 0.193, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a group of zebras grazing in a grassy field with a clear blue sky in the background. The zebras have black and white stripes, and the grass is a mix of green and brown hues.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12706.8, "ram_available_mb": 50134.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.6, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.209}, "power_stats": {"power_gpu_soc_mean_watts": 18.911, "power_cpu_cv_mean_watts": 2.03, "power_sys_5v0_mean_watts": 7.533, "gpu_utilization_percent_mean": 74.209}, "timestamp": "2026-01-28T14:52:51.550354"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3588.328, "latencies_ms": [3588.328], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man in a black wetsuit is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12706.1, "ram_available_mb": 50134.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.448}, "power_stats": {"power_gpu_soc_mean_watts": 21.451, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 7.508, "gpu_utilization_percent_mean": 87.448}, "timestamp": "2026-01-28T14:52:57.176926"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6320.768, "latencies_ms": [6320.768], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. surfboard: 1\n3. wave: 1\n4. ocean: 1\n5. sky: 0\n6. water: 1\n7. surfboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.1, "ram_available_mb": 50134.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12705.8, "ram_available_mb": 50135.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.113}, "power_stats": {"power_gpu_soc_mean_watts": 18.389, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.44, "gpu_utilization_percent_mean": 77.113}, "timestamp": "2026-01-28T14:53:05.537521"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4681.803, "latencies_ms": [4681.803], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that is in the middle ground. The surfer is facing towards the right side of the image, with the wave moving towards the left.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12705.8, "ram_available_mb": 50135.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12706.4, "ram_available_mb": 50134.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.685, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.713, "gpu_utilization_percent_mean": 82.718}, "timestamp": "2026-01-28T14:53:12.242319"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3939.842, "latencies_ms": [3939.842], "images_per_second": 0.254, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A surfer in a black wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12706.4, "ram_available_mb": 50134.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12707.3, "ram_available_mb": 50133.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.864, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.451, "gpu_utilization_percent_mean": 87.333}, "timestamp": "2026-01-28T14:53:18.221621"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4206.315, "latencies_ms": [4206.315], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The surfer is wearing a black wetsuit and is riding a wave on a white surfboard. The ocean is a deep blue color and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12707.3, "ram_available_mb": 50133.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12707.0, "ram_available_mb": 50133.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.955, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.785, "gpu_utilization_percent_mean": 74.486}, "timestamp": "2026-01-28T14:53:24.482012"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4219.685, "latencies_ms": [4219.685], "images_per_second": 0.237, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " Two people dressed in white snow gear are standing on a snowy mountain, one of them is holding a pair of skis.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12707.0, "ram_available_mb": 50133.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.7, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.914}, "power_stats": {"power_gpu_soc_mean_watts": 20.475, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 7.413, "gpu_utilization_percent_mean": 84.914}, "timestamp": "2026-01-28T14:53:30.757433"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6057.068, "latencies_ms": [6057.068], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 2\n2. skis: 2\n3. backpack: 1\n4. snowboard: 1\n5. pole: 1\n6. sun: 1\n7. mountain: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.529}, "power_stats": {"power_gpu_soc_mean_watts": 18.143, "power_cpu_cv_mean_watts": 1.971, "power_sys_5v0_mean_watts": 7.558, "gpu_utilization_percent_mean": 73.529}, "timestamp": "2026-01-28T14:53:38.841026"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5891.258, "latencies_ms": [5891.258], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The skier on the left is positioned closer to the camera, while the skier on the right is farther away. The skier on the left is also closer to the foreground of the image, while the skier on the right is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12707.0, "ram_available_mb": 50133.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.74}, "power_stats": {"power_gpu_soc_mean_watts": 19.168, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 7.499, "gpu_utilization_percent_mean": 81.74}, "timestamp": "2026-01-28T14:53:46.758445"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3474.648, "latencies_ms": [3474.648], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain at sunset, preparing to ski down the mountain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12707.0, "ram_available_mb": 50133.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12707.2, "ram_available_mb": 50133.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.483}, "power_stats": {"power_gpu_soc_mean_watts": 21.905, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 7.641, "gpu_utilization_percent_mean": 82.483}, "timestamp": "2026-01-28T14:53:52.288500"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5888.549, "latencies_ms": [5888.549], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features two individuals dressed in white snow gear, with one of them holding a pair of skis. The sun is setting in the background, casting a warm glow over the scene. The sky is a clear blue, and the snow is pristine white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12707.2, "ram_available_mb": 50133.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12706.3, "ram_available_mb": 50134.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.265}, "power_stats": {"power_gpu_soc_mean_watts": 19.17, "power_cpu_cv_mean_watts": 1.937, "power_sys_5v0_mean_watts": 7.472, "gpu_utilization_percent_mean": 82.265}, "timestamp": "2026-01-28T14:54:00.199186"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3917.032, "latencies_ms": [3917.032], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A baseball player in a red shirt and white pants is swinging a bat at a ball during a game.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12706.3, "ram_available_mb": 50134.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12706.9, "ram_available_mb": 50134.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.781}, "power_stats": {"power_gpu_soc_mean_watts": 20.653, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 7.409, "gpu_utilization_percent_mean": 81.781}, "timestamp": "2026-01-28T14:54:06.160215"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6311.337, "latencies_ms": [6311.337], "images_per_second": 0.158, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball glove: 1\n3. baseball: 1\n4. baseball player: 1\n5. catcher: 1\n6. umpire: 1\n7. fence: 1\n8. spectators: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.9, "ram_available_mb": 50134.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12706.3, "ram_available_mb": 50134.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.283}, "power_stats": {"power_gpu_soc_mean_watts": 19.001, "power_cpu_cv_mean_watts": 2.101, "power_sys_5v0_mean_watts": 7.564, "gpu_utilization_percent_mean": 81.283}, "timestamp": "2026-01-28T14:54:14.512458"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4985.324, "latencies_ms": [4985.324], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire behind him. The field is enclosed by a chain link fence, which separates the players from the spectators in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12706.3, "ram_available_mb": 50134.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.422, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.539, "gpu_utilization_percent_mean": 76.195}, "timestamp": "2026-01-28T14:54:21.522401"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5163.584, "latencies_ms": [5163.584], "images_per_second": 0.194, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " A baseball game is taking place on a sunny day in a park. The batter is swinging his bat at the ball, while the catcher and umpire are ready to catch the ball if the batter misses.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.535}, "power_stats": {"power_gpu_soc_mean_watts": 19.749, "power_cpu_cv_mean_watts": 2.142, "power_sys_5v0_mean_watts": 7.555, "gpu_utilization_percent_mean": 84.535}, "timestamp": "2026-01-28T14:54:28.744938"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5121.916, "latencies_ms": [5121.916], "images_per_second": 0.195, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white and red uniforms, the sun casting a warm glow on the field, and the lush green trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.047}, "power_stats": {"power_gpu_soc_mean_watts": 19.197, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.483, "gpu_utilization_percent_mean": 77.047}, "timestamp": "2026-01-28T14:54:35.911580"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4749.199, "latencies_ms": [4749.199], "images_per_second": 0.211, "prompt_tokens": 1432, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A large milkshake with whipped cream and a slice of cake with a fork on a napkin are on a table.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12707.1, "ram_available_mb": 50133.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.462}, "power_stats": {"power_gpu_soc_mean_watts": 22.327, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.856, "gpu_utilization_percent_mean": 87.462}, "timestamp": "2026-01-28T14:54:42.735722"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7158.632, "latencies_ms": [7158.632], "images_per_second": 0.14, "prompt_tokens": 1446, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. glass: 1\n2. plate: 1\n3. cake: 1\n4. fork: 2\n5. knife: 1\n6. glass of milkshake: 1\n7. table: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12707.1, "ram_available_mb": 50133.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.567}, "power_stats": {"power_gpu_soc_mean_watts": 19.66, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.745, "gpu_utilization_percent_mean": 77.567}, "timestamp": "2026-01-28T14:54:51.909526"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5308.645, "latencies_ms": [5308.645], "images_per_second": 0.188, "prompt_tokens": 1450, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The milkshake is to the left of the cake, the fork is in front of the cake, and the person is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.205}, "power_stats": {"power_gpu_soc_mean_watts": 21.438, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.686, "gpu_utilization_percent_mean": 88.205}, "timestamp": "2026-01-28T14:54:59.244271"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4158.468, "latencies_ms": [4158.468], "images_per_second": 0.24, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A table with a milkshake and a slice of cake on it.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12706.9, "ram_available_mb": 50134.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.529}, "power_stats": {"power_gpu_soc_mean_watts": 23.511, "power_cpu_cv_mean_watts": 1.295, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 86.529}, "timestamp": "2026-01-28T14:55:05.423281"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4691.385, "latencies_ms": [4691.385], "images_per_second": 0.213, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a blue tablecloth, the lighting is dim and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.9, "ram_available_mb": 50134.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12707.2, "ram_available_mb": 50133.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.949}, "power_stats": {"power_gpu_soc_mean_watts": 22.735, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 87.949}, "timestamp": "2026-01-28T14:55:12.155501"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4146.884, "latencies_ms": [4146.884], "images_per_second": 0.241, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A large, multi-tiered wedding cake with blue and gold accents sits on a table covered with a blue tablecloth.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12707.2, "ram_available_mb": 50133.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12706.8, "ram_available_mb": 50134.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.559}, "power_stats": {"power_gpu_soc_mean_watts": 20.662, "power_cpu_cv_mean_watts": 1.92, "power_sys_5v0_mean_watts": 7.501, "gpu_utilization_percent_mean": 87.559}, "timestamp": "2026-01-28T14:55:18.349365"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5879.82, "latencies_ms": [5879.82], "images_per_second": 0.17, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Cake: 1\n2. Tablecloth: 1\n3. Chairs: 1\n4. People: 1\n5. Flowers: 1\n6. Table: 1\n7. Window: 1\n8. Chandelier: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12706.8, "ram_available_mb": 50134.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.3, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.388}, "power_stats": {"power_gpu_soc_mean_watts": 18.98, "power_cpu_cv_mean_watts": 2.313, "power_sys_5v0_mean_watts": 7.77, "gpu_utilization_percent_mean": 74.388}, "timestamp": "2026-01-28T14:55:26.256583"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5312.672, "latencies_ms": [5312.672], "images_per_second": 0.188, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The cake is positioned in the foreground, with the tablecloth and chairs in the background. The cake is located to the left of the tablecloth, and the tablecloth is to the right of the cake.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12706.7, "ram_available_mb": 50134.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.689}, "power_stats": {"power_gpu_soc_mean_watts": 19.326, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 7.439, "gpu_utilization_percent_mean": 81.689}, "timestamp": "2026-01-28T14:55:33.611730"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3078.588, "latencies_ms": [3078.588], "images_per_second": 0.325, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A large wedding cake sits on a table in a room with tables and chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12706.5, "ram_available_mb": 50134.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.115}, "power_stats": {"power_gpu_soc_mean_watts": 22.786, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.833, "gpu_utilization_percent_mean": 81.115}, "timestamp": "2026-01-28T14:55:38.737172"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3799.125, "latencies_ms": [3799.125], "images_per_second": 0.263, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The cake is white with blue and gold accents, and it is lit by a chandelier.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12706.6, "ram_available_mb": 50134.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.177, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.496, "gpu_utilization_percent_mean": 87.375}, "timestamp": "2026-01-28T14:55:44.596985"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4246.53, "latencies_ms": [4246.53], "images_per_second": 0.235, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A woman wearing a blue sweater with red and white patterns is standing in a kitchen and holding a plate with a pie on it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12708.9, "ram_available_mb": 50132.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12706.8, "ram_available_mb": 50134.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.52, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 7.491, "gpu_utilization_percent_mean": 82.629}, "timestamp": "2026-01-28T14:55:50.876120"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6068.248, "latencies_ms": [6068.248], "images_per_second": 0.165, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. stove: 1\n3. pot: 1\n4. pan: 1\n5. oven: 1\n6. wall: 1\n7. poster: 1\n8. wall-mounted shelf: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12706.8, "ram_available_mb": 50134.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.7, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.36}, "power_stats": {"power_gpu_soc_mean_watts": 19.34, "power_cpu_cv_mean_watts": 2.339, "power_sys_5v0_mean_watts": 7.633, "gpu_utilization_percent_mean": 80.36}, "timestamp": "2026-01-28T14:55:58.979167"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5098.115, "latencies_ms": [5098.115], "images_per_second": 0.196, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, with the stove and pot in the background. The person is holding the plate with the pie in the foreground, while the pot is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.023}, "power_stats": {"power_gpu_soc_mean_watts": 19.113, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 7.498, "gpu_utilization_percent_mean": 76.023}, "timestamp": "2026-01-28T14:56:06.096572"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3419.569, "latencies_ms": [3419.569], "images_per_second": 0.292, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman wearing a sweater is standing in a kitchen and holding a plate of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12708.6, "ram_available_mb": 50132.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12708.8, "ram_available_mb": 50132.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.893}, "power_stats": {"power_gpu_soc_mean_watts": 21.902, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.658, "gpu_utilization_percent_mean": 86.893}, "timestamp": "2026-01-28T14:56:11.542421"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4403.95, "latencies_ms": [4403.95], "images_per_second": 0.227, "prompt_tokens": 1110, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a kitchen with a warm and cozy atmosphere, the lighting is natural and soft, and the colors are vibrant and inviting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12708.8, "ram_available_mb": 50132.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12706.4, "ram_available_mb": 50134.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.784}, "power_stats": {"power_gpu_soc_mean_watts": 20.34, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.498, "gpu_utilization_percent_mean": 87.784}, "timestamp": "2026-01-28T14:56:17.987715"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4257.48, "latencies_ms": [4257.48], "images_per_second": 0.235, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A woman wearing a pink shirt, black pants, and brown boots is walking on a dirt path in a fenced area with a white horse wearing a halter.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12706.4, "ram_available_mb": 50134.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12707.2, "ram_available_mb": 50133.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.656, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 7.719, "gpu_utilization_percent_mean": 73.486}, "timestamp": "2026-01-28T14:56:24.271789"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6416.607, "latencies_ms": [6416.607], "images_per_second": 0.156, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. horse: 1\n2. woman: 1\n3. rope: 1\n4. fence: 1\n5. ground: 1\n6. trees: 1\n7. woman's hair: 1\n8. woman's pants: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12707.2, "ram_available_mb": 50133.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 11.2, "ram_used_mb": 12708.2, "ram_available_mb": 50132.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.057}, "power_stats": {"power_gpu_soc_mean_watts": 18.782, "power_cpu_cv_mean_watts": 2.192, "power_sys_5v0_mean_watts": 7.492, "gpu_utilization_percent_mean": 83.057}, "timestamp": "2026-01-28T14:56:32.717718"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4394.704, "latencies_ms": [4394.704], "images_per_second": 0.228, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the horse in the background. The horse is positioned to the left of the woman, and the fence is visible behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12708.2, "ram_available_mb": 50132.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12709.0, "ram_available_mb": 50131.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.678, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 7.801, "gpu_utilization_percent_mean": 75.054}, "timestamp": "2026-01-28T14:56:39.145630"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3715.61, "latencies_ms": [3715.61], "images_per_second": 0.269, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman wearing a pink shirt and black pants is walking a horse in a dirt field.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12709.4, "ram_available_mb": 50131.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12709.3, "ram_available_mb": 50131.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.065}, "power_stats": {"power_gpu_soc_mean_watts": 20.802, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.407, "gpu_utilization_percent_mean": 87.065}, "timestamp": "2026-01-28T14:56:44.902256"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4469.214, "latencies_ms": [4469.214], "images_per_second": 0.224, "prompt_tokens": 1110, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a sunny day with clear sky. The woman is wearing a pink shirt and black pants. The horse is white and has a black mane.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12709.3, "ram_available_mb": 50131.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12709.6, "ram_available_mb": 50131.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.919}, "power_stats": {"power_gpu_soc_mean_watts": 20.308, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.599, "gpu_utilization_percent_mean": 76.919}, "timestamp": "2026-01-28T14:56:51.383740"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5187.563, "latencies_ms": [5187.563], "images_per_second": 0.193, "prompt_tokens": 1100, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a bustling city street during the day, with a mix of vehicles and pedestrians navigating the urban landscape, and a yellow sign with a camera icon hanging from a pole on the right side of the frame.", "error": null, "sys_before": {"cpu_percent": 5.7, "ram_used_mb": 12709.6, "ram_available_mb": 50131.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12710.2, "ram_available_mb": 50130.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.767}, "power_stats": {"power_gpu_soc_mean_watts": 19.628, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 7.537, "gpu_utilization_percent_mean": 81.767}, "timestamp": "2026-01-28T14:56:58.603645"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6174.318, "latencies_ms": [6174.318], "images_per_second": 0.162, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 2\n2. car: 4\n3. person: 1\n4. tree: 2\n5. building: 5\n6. street: 1\n7. traffic light: 1\n8. bus: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12710.2, "ram_available_mb": 50130.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12711.4, "ram_available_mb": 50129.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.471}, "power_stats": {"power_gpu_soc_mean_watts": 17.923, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 7.471, "gpu_utilization_percent_mean": 74.471}, "timestamp": "2026-01-28T14:57:06.792945"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5610.203, "latencies_ms": [5610.203], "images_per_second": 0.178, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The yellow sign is located in the foreground, to the right of the street. The traffic light is located in the background, to the left of the street. The person is located in the background, to the right of the street.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12711.4, "ram_available_mb": 50129.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12710.9, "ram_available_mb": 50130.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.851}, "power_stats": {"power_gpu_soc_mean_watts": 19.126, "power_cpu_cv_mean_watts": 2.045, "power_sys_5v0_mean_watts": 7.47, "gpu_utilization_percent_mean": 82.851}, "timestamp": "2026-01-28T14:57:14.443508"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4630.397, "latencies_ms": [4630.397], "images_per_second": 0.216, "prompt_tokens": 1112, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a bustling city street during the day, with cars and buses navigating through the traffic. The skyline of tall buildings looms in the background, suggesting a metropolitan area.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12710.9, "ram_available_mb": 50130.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12711.1, "ram_available_mb": 50129.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.103}, "power_stats": {"power_gpu_soc_mean_watts": 19.597, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.558, "gpu_utilization_percent_mean": 75.103}, "timestamp": "2026-01-28T14:57:21.102215"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4924.898, "latencies_ms": [4924.898], "images_per_second": 0.203, "prompt_tokens": 1110, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image depicts a city street with a mix of modern and older buildings, with a clear blue sky and a few clouds. The street is lined with trees and has a few cars parked along the side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12711.1, "ram_available_mb": 50129.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12711.3, "ram_available_mb": 50129.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.537}, "power_stats": {"power_gpu_soc_mean_watts": 20.243, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.634, "gpu_utilization_percent_mean": 83.537}, "timestamp": "2026-01-28T14:57:28.061039"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4070.609, "latencies_ms": [4070.609], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image depicts a bathroom with a stainless steel toilet, a blue toilet brush, and a metal toilet paper holder.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 12711.3, "ram_available_mb": 50129.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12710.8, "ram_available_mb": 50130.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.559}, "power_stats": {"power_gpu_soc_mean_watts": 20.677, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.415, "gpu_utilization_percent_mean": 84.559}, "timestamp": "2026-01-28T14:57:34.183151"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5642.904, "latencies_ms": [5642.904], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 53, "n_tiles": 1, "output_text": " toilet: 1, toilet brush: 1, tiled floor: 1, metal toilet tank: 1, metal toilet seat: 1, metal toilet bowl: 1, metal toilet lid: 1, metal toilet seat cover: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12710.8, "ram_available_mb": 50130.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12710.7, "ram_available_mb": 50130.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.106}, "power_stats": {"power_gpu_soc_mean_watts": 19.33, "power_cpu_cv_mean_watts": 2.335, "power_sys_5v0_mean_watts": 7.597, "gpu_utilization_percent_mean": 75.106}, "timestamp": "2026-01-28T14:57:41.840199"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5173.521, "latencies_ms": [5173.521], "images_per_second": 0.193, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The toilet is located in the center of the image, with the person's feet visible in the foreground. The toilet brush is placed to the left of the toilet, while the wall is located in the background.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12710.7, "ram_available_mb": 50130.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12710.9, "ram_available_mb": 50130.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.302}, "power_stats": {"power_gpu_soc_mean_watts": 19.376, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 7.504, "gpu_utilization_percent_mean": 79.302}, "timestamp": "2026-01-28T14:57:49.048545"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3130.883, "latencies_ms": [3130.883], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is standing in a bathroom with a toilet and a blue brush.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12710.9, "ram_available_mb": 50130.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12711.9, "ram_available_mb": 50129.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.48}, "power_stats": {"power_gpu_soc_mean_watts": 23.137, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.827, "gpu_utilization_percent_mean": 80.48}, "timestamp": "2026-01-28T14:57:54.196096"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4946.084, "latencies_ms": [4946.084], "images_per_second": 0.202, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a bathroom with a stainless steel toilet, a blue toilet brush, and a white tiled floor. The lighting is bright and natural, coming from the ceiling.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12711.9, "ram_available_mb": 50129.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12734.6, "ram_available_mb": 50106.3, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.806, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 7.428, "gpu_utilization_percent_mean": 84.244}, "timestamp": "2026-01-28T14:58:01.189878"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3127.455, "latencies_ms": [3127.455], "images_per_second": 0.32, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A pink bicycle is leaning against a wall in a store with other bicycles.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12734.6, "ram_available_mb": 50106.3, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12727.3, "ram_available_mb": 50113.6, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.056, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 7.775, "gpu_utilization_percent_mean": 81.24}, "timestamp": "2026-01-28T14:58:06.347480"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5944.096, "latencies_ms": [5944.096], "images_per_second": 0.168, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bicycle: 1\n2. wall: 1\n3. floor: 1\n4. bicycle: 1\n5. bicycle: 1\n6. bicycle: 1\n7. bicycle: 1\n8. bicycle: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12727.3, "ram_available_mb": 50113.6, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12727.3, "ram_available_mb": 50113.6, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.08}, "power_stats": {"power_gpu_soc_mean_watts": 19.253, "power_cpu_cv_mean_watts": 2.107, "power_sys_5v0_mean_watts": 7.585, "gpu_utilization_percent_mean": 80.08}, "timestamp": "2026-01-28T14:58:14.339671"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4721.738, "latencies_ms": [4721.738], "images_per_second": 0.212, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The pink bicycle is positioned in the foreground, leaning against the wall, while the other bicycles are arranged in the background, with some hanging from the ceiling and others on the floor.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12727.3, "ram_available_mb": 50113.6, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12727.5, "ram_available_mb": 50113.4, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.66, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.532, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-28T14:58:21.080698"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5742.191, "latencies_ms": [5742.191], "images_per_second": 0.174, "prompt_tokens": 1112, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a quaint bicycle shop with a variety of bicycles on display. The shop has a clean and organized appearance, with the bicycles neatly arranged on the floor and on racks. The walls are adorned with various bicycle accessories and tools, creating a welcoming atmosphere for potential customers.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12727.5, "ram_available_mb": 50113.4, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12727.7, "ram_available_mb": 50113.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.979}, "power_stats": {"power_gpu_soc_mean_watts": 19.286, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 7.621, "gpu_utilization_percent_mean": 79.979}, "timestamp": "2026-01-28T14:58:28.882817"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5491.711, "latencies_ms": [5491.711], "images_per_second": 0.182, "prompt_tokens": 1110, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming in from the window. The floor is made of wood, and the walls are painted white. The bicycles are all different colors, including pink, black, and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12727.7, "ram_available_mb": 50113.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12728.1, "ram_available_mb": 50112.8, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.734, "power_cpu_cv_mean_watts": 1.951, "power_sys_5v0_mean_watts": 7.528, "gpu_utilization_percent_mean": 75.851}, "timestamp": "2026-01-28T14:58:36.419178"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3762.989, "latencies_ms": [3762.989], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A giraffe with a brown and white spotted coat stands in a dry grassy field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12728.1, "ram_available_mb": 50112.8, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12727.5, "ram_available_mb": 50113.4, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.484}, "power_stats": {"power_gpu_soc_mean_watts": 21.294, "power_cpu_cv_mean_watts": 1.537, "power_sys_5v0_mean_watts": 7.544, "gpu_utilization_percent_mean": 86.484}, "timestamp": "2026-01-28T14:58:42.224440"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4746.42, "latencies_ms": [4746.42], "images_per_second": 0.211, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " giraffe: 1, tree: 2, bush: 1, sky: 1, cloud: 1, grass: 1, tree trunk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12727.5, "ram_available_mb": 50113.4, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12727.4, "ram_available_mb": 50113.5, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.475}, "power_stats": {"power_gpu_soc_mean_watts": 20.119, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.48, "gpu_utilization_percent_mean": 82.475}, "timestamp": "2026-01-28T14:58:48.991044"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4872.412, "latencies_ms": [4872.412], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The giraffe is positioned in the foreground of the image, with the background consisting of a cloudy sky and sparse trees. The giraffe is facing towards the right side of the image, with its body angled slightly towards the left.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12727.4, "ram_available_mb": 50113.5, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12727.4, "ram_available_mb": 50113.5, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.951}, "power_stats": {"power_gpu_soc_mean_watts": 20.242, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.773, "gpu_utilization_percent_mean": 76.951}, "timestamp": "2026-01-28T14:58:55.903097"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3659.701, "latencies_ms": [3659.701], "images_per_second": 0.273, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A giraffe stands in a dry savanna, surrounded by sparse vegetation and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12727.4, "ram_available_mb": 50113.5, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.4, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.633}, "power_stats": {"power_gpu_soc_mean_watts": 21.309, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.453, "gpu_utilization_percent_mean": 86.633}, "timestamp": "2026-01-28T14:59:01.576005"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3735.929, "latencies_ms": [3735.929], "images_per_second": 0.268, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The giraffe is brown and white with a long neck and legs. The sky is cloudy and the grass is dry.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12726.5, "ram_available_mb": 50114.4, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.29}, "power_stats": {"power_gpu_soc_mean_watts": 21.618, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.655, "gpu_utilization_percent_mean": 79.29}, "timestamp": "2026-01-28T14:59:07.343189"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3734.987, "latencies_ms": [3734.987], "images_per_second": 0.268, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A family with two children is on a luggage cart in front of a car dealership.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12727.2, "ram_available_mb": 50113.7, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.677}, "power_stats": {"power_gpu_soc_mean_watts": 20.985, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 7.444, "gpu_utilization_percent_mean": 87.677}, "timestamp": "2026-01-28T14:59:13.104727"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6636.497, "latencies_ms": [6636.497], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. suitcase: 2\n2. car: 2\n3. child: 2\n4. suitcase handle: 1\n5. suitcase wheels: 2\n6. car mirror: 1\n7. car door: 1\n8. car license plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12727.2, "ram_available_mb": 50113.7, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12725.0, "ram_available_mb": 50115.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.339}, "power_stats": {"power_gpu_soc_mean_watts": 18.485, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.497, "gpu_utilization_percent_mean": 76.339}, "timestamp": "2026-01-28T14:59:21.785109"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4978.713, "latencies_ms": [4978.713], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The luggage is positioned in the foreground, with the children sitting on it. The luggage is located to the left of the children, and the car is positioned to the right of the luggage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12725.0, "ram_available_mb": 50115.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12725.0, "ram_available_mb": 50115.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.862, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.452, "gpu_utilization_percent_mean": 82.488}, "timestamp": "2026-01-28T14:59:28.783622"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4037.846, "latencies_ms": [4037.846], "images_per_second": 0.248, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A family is traveling to a new destination, with their luggage on a cart, and they are in a parking lot.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12725.0, "ram_available_mb": 50115.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12724.4, "ram_available_mb": 50116.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.647}, "power_stats": {"power_gpu_soc_mean_watts": 20.688, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.48, "gpu_utilization_percent_mean": 81.647}, "timestamp": "2026-01-28T14:59:34.851998"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4864.233, "latencies_ms": [4864.233], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image depicts a rainy day with wet pavement and a cloudy sky. The colors in the image are muted due to the rain, with the blue of the sky and the gray of the pavement being the most prominent.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12724.4, "ram_available_mb": 50116.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12724.4, "ram_available_mb": 50116.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.707}, "power_stats": {"power_gpu_soc_mean_watts": 20.624, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 7.708, "gpu_utilization_percent_mean": 81.707}, "timestamp": "2026-01-28T14:59:41.760523"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4148.032, "latencies_ms": [4148.032], "images_per_second": 0.241, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A yellow and blue bus is driving down a street in a town with houses, trees, and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 17.4, "ram_used_mb": 12724.4, "ram_available_mb": 50116.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12724.5, "ram_available_mb": 50116.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.771}, "power_stats": {"power_gpu_soc_mean_watts": 20.51, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 7.422, "gpu_utilization_percent_mean": 84.771}, "timestamp": "2026-01-28T14:59:47.946993"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5665.743, "latencies_ms": [5665.743], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bus: 1\n2. street: 1\n3. building: 2\n4. car: 1\n5. person: 1\n6. flower: 1\n7. street light: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12724.5, "ram_available_mb": 50116.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12724.2, "ram_available_mb": 50116.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.319}, "power_stats": {"power_gpu_soc_mean_watts": 19.202, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 74.319}, "timestamp": "2026-01-28T14:59:55.624253"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5850.84, "latencies_ms": [5850.84], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The yellow and blue bus is in the foreground, driving on the road. The white building is in the background, and the green hill is in the far background. The bus is to the left of the white building, and the green hill is behind the bus.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12724.2, "ram_available_mb": 50116.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 12724.2, "ram_available_mb": 50116.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.429}, "power_stats": {"power_gpu_soc_mean_watts": 19.333, "power_cpu_cv_mean_watts": 2.019, "power_sys_5v0_mean_watts": 7.532, "gpu_utilization_percent_mean": 82.429}, "timestamp": "2026-01-28T15:00:03.518448"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6687.62, "latencies_ms": [6687.62], "images_per_second": 0.15, "prompt_tokens": 1111, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The image captures a quaint town nestled in the mountains, where a vibrant yellow and blue double-decker bus is making its way down the street, passing by a charming white building with a black roof. The lush green grass and colorful flowers add a touch of vibrancy to the scene, creating a picturesque setting that exudes a sense of tranquility and charm.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12724.2, "ram_available_mb": 50116.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12725.7, "ram_available_mb": 50115.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.571}, "power_stats": {"power_gpu_soc_mean_watts": 18.654, "power_cpu_cv_mean_watts": 2.11, "power_sys_5v0_mean_watts": 7.679, "gpu_utilization_percent_mean": 74.571}, "timestamp": "2026-01-28T15:00:12.230576"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4867.328, "latencies_ms": [4867.328], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sky is overcast, casting a muted light over the scene. The colors are muted, with the green of the grass and the blue of the sky blending together.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12725.7, "ram_available_mb": 50115.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12726.9, "ram_available_mb": 50114.0, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.813, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 7.463, "gpu_utilization_percent_mean": 82.195}, "timestamp": "2026-01-28T15:00:19.120594"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3706.879, "latencies_ms": [3706.879], "images_per_second": 0.27, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A pelican stands on a rocky outcropping overlooking a beach, with a cloudy sky and distant mountains in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12726.9, "ram_available_mb": 50114.0, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.1}, "power_stats": {"power_gpu_soc_mean_watts": 21.95, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 7.796, "gpu_utilization_percent_mean": 77.1}, "timestamp": "2026-01-28T15:00:24.850877"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6147.192, "latencies_ms": [6147.192], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 1\n2. rocks: 1\n3. beach: 1\n4. mountains: 1\n5. clouds: 1\n6. sea: 1\n7. pier: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.692}, "power_stats": {"power_gpu_soc_mean_watts": 18.988, "power_cpu_cv_mean_watts": 2.241, "power_sys_5v0_mean_watts": 7.492, "gpu_utilization_percent_mean": 80.692}, "timestamp": "2026-01-28T15:00:33.030502"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5909.371, "latencies_ms": [5909.371], "images_per_second": 0.169, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The pelican is positioned in the foreground, perched on a rock in the middle of the image. The beach, with its sandy shore and thatched umbrellas, is located in the background. The mountains rise up in the far background, providing a sense of depth and scale to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.5, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.224}, "power_stats": {"power_gpu_soc_mean_watts": 19.09, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.716, "gpu_utilization_percent_mean": 76.224}, "timestamp": "2026-01-28T15:00:40.955530"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5401.341, "latencies_ms": [5401.341], "images_per_second": 0.185, "prompt_tokens": 1111, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a pelican perched on a rock, overlooking the calm ocean. The sky is filled with clouds, and the beach is lined with palm trees and thatched-roof huts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.933}, "power_stats": {"power_gpu_soc_mean_watts": 19.423, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 7.475, "gpu_utilization_percent_mean": 83.933}, "timestamp": "2026-01-28T15:00:48.385607"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5220.54, "latencies_ms": [5220.54], "images_per_second": 0.192, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a beach with a rocky outcropping, a pelican standing on it, and a cloudy sky with a hint of blue. The colors are predominantly blue and brown, with the pelican being the only animal in the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 74.884}, "power_stats": {"power_gpu_soc_mean_watts": 19.617, "power_cpu_cv_mean_watts": 1.956, "power_sys_5v0_mean_watts": 7.701, "gpu_utilization_percent_mean": 74.884}, "timestamp": "2026-01-28T15:00:55.643352"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4173.874, "latencies_ms": [4173.874], "images_per_second": 0.24, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing glasses and a plaid shirt is sitting in a chair, holding a remote control and a piece of paper.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12727.1, "ram_available_mb": 50113.8, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.6}, "power_stats": {"power_gpu_soc_mean_watts": 20.59, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 7.441, "gpu_utilization_percent_mean": 86.6}, "timestamp": "2026-01-28T15:01:01.861428"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5876.357, "latencies_ms": [5876.357], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. remote control: 2\n3. paper bag: 1\n4. television: 1\n5. couch: 1\n6. glasses: 1\n7. remote control: 2\n8. television: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12726.3, "ram_available_mb": 50114.6, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 75.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.549, "power_cpu_cv_mean_watts": 1.994, "power_sys_5v0_mean_watts": 7.655, "gpu_utilization_percent_mean": 75.49}, "timestamp": "2026-01-28T15:01:09.772888"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6131.482, "latencies_ms": [6131.482], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The man is seated on the left side of the image, with the remote control and paper bag placed on the right side of the image. The paper bag is positioned in front of the man, while the remote control is located to the right of the paper bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12725.3, "ram_available_mb": 50115.6, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12725.2, "ram_available_mb": 50115.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.725}, "power_stats": {"power_gpu_soc_mean_watts": 18.812, "power_cpu_cv_mean_watts": 2.018, "power_sys_5v0_mean_watts": 7.418, "gpu_utilization_percent_mean": 80.725}, "timestamp": "2026-01-28T15:01:17.924539"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3925.292, "latencies_ms": [3925.292], "images_per_second": 0.255, "prompt_tokens": 1111, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A man is sitting in a chair, holding a remote control and a bag of chips. He is wearing glasses and has a smile on his face.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12725.2, "ram_available_mb": 50115.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12725.4, "ram_available_mb": 50115.5, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 73.152}, "power_stats": {"power_gpu_soc_mean_watts": 21.52, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 7.817, "gpu_utilization_percent_mean": 73.152}, "timestamp": "2026-01-28T15:01:23.872704"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4232.719, "latencies_ms": [4232.719], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The room is dimly lit with a warm ambiance, and the man is wearing a black and white checkered shirt.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12725.4, "ram_available_mb": 50115.5, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12725.7, "ram_available_mb": 50115.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 88.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.599, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.443, "gpu_utilization_percent_mean": 88.029}, "timestamp": "2026-01-28T15:01:30.149735"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4134.269, "latencies_ms": [4134.269], "images_per_second": 0.242, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man in an orange shirt and black shorts is playing tennis on a court with a blue and white tennis racket.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12725.7, "ram_available_mb": 50115.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12723.1, "ram_available_mb": 50117.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.088}, "power_stats": {"power_gpu_soc_mean_watts": 20.146, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 7.407, "gpu_utilization_percent_mean": 83.088}, "timestamp": "2026-01-28T15:01:36.319777"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6442.121, "latencies_ms": [6442.121], "images_per_second": 0.155, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. tennis court: 1\n5. net: 1\n6. orange shirt: 1\n7. black shorts: 1\n8. white shoes: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12723.1, "ram_available_mb": 50117.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.3, "ram_used_mb": 12723.1, "ram_available_mb": 50117.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.855}, "power_stats": {"power_gpu_soc_mean_watts": 18.82, "power_cpu_cv_mean_watts": 2.141, "power_sys_5v0_mean_watts": 7.539, "gpu_utilization_percent_mean": 80.855}, "timestamp": "2026-01-28T15:01:44.784966"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5603.867, "latencies_ms": [5603.867], "images_per_second": 0.178, "prompt_tokens": 1118, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball in the center and the net in the foreground. The player is closer to the camera than the tennis ball, which is in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12723.1, "ram_available_mb": 50117.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12721.4, "ram_available_mb": 50119.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 76.681}, "power_stats": {"power_gpu_soc_mean_watts": 18.536, "power_cpu_cv_mean_watts": 2.037, "power_sys_5v0_mean_watts": 7.484, "gpu_utilization_percent_mean": 76.681}, "timestamp": "2026-01-28T15:01:52.419955"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3477.213, "latencies_ms": [3477.213], "images_per_second": 0.288, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is playing tennis on a court with a green surface.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12721.4, "ram_available_mb": 50119.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 12722.3, "ram_available_mb": 50118.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 89.036}, "power_stats": {"power_gpu_soc_mean_watts": 20.7, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 7.391, "gpu_utilization_percent_mean": 89.036}, "timestamp": "2026-01-28T15:01:57.936887"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3282.283, "latencies_ms": [3282.283], "images_per_second": 0.305, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The tennis player is wearing an orange shirt and black shorts, and the court is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12722.3, "ram_available_mb": 50118.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.111}, "power_stats": {"power_gpu_soc_mean_watts": 22.415, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.781, "gpu_utilization_percent_mean": 77.111}, "timestamp": "2026-01-28T15:02:03.272951"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4778.526, "latencies_ms": [4778.526], "images_per_second": 0.209, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a compact kitchen area with a variety of appliances and cabinets, including a sink, stove, and refrigerator, all arranged in a functional and efficient manner.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 77.675}, "power_stats": {"power_gpu_soc_mean_watts": 22.613, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 77.675}, "timestamp": "2026-01-28T15:02:10.113788"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7102.779, "latencies_ms": [7102.779], "images_per_second": 0.141, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cupboard: 4\n2. counter: 2\n3. sink: 1\n4. stove: 1\n5. refrigerator: 1\n6. door: 1\n7. chair: 1\n8. rug: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 84.339}, "power_stats": {"power_gpu_soc_mean_watts": 20.186, "power_cpu_cv_mean_watts": 2.729, "power_sys_5v0_mean_watts": 7.671, "gpu_utilization_percent_mean": 84.339}, "timestamp": "2026-01-28T15:02:19.238394"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5372.043, "latencies_ms": [5372.043], "images_per_second": 0.186, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The sink is located near the stove, and the refrigerator is positioned in the background. The door is situated on the left side of the room, and the countertop is located in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.222}, "power_stats": {"power_gpu_soc_mean_watts": 22.155, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 83.222}, "timestamp": "2026-01-28T15:02:26.668748"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7230.036, "latencies_ms": [7230.036], "images_per_second": 0.138, "prompt_tokens": 1444, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image captures the interior of a vintage camper van, showcasing its compact yet functional kitchen area. The kitchen is equipped with a sink, stove, and refrigerator, all arranged neatly on the countertops. A red fire extinguisher is mounted on the wall, adding a touch of safety to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12723.5, "ram_available_mb": 50117.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12723.4, "ram_available_mb": 50117.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.59}, "power_stats": {"power_gpu_soc_mean_watts": 19.838, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.683, "gpu_utilization_percent_mean": 80.59}, "timestamp": "2026-01-28T15:02:35.946235"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5670.597, "latencies_ms": [5670.597], "images_per_second": 0.176, "prompt_tokens": 1442, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The interior of the camper is painted in a bright yellow color, with a black rubber mat on the floor. The lighting is provided by fluorescent lights, and the materials used are wood and metal.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12723.4, "ram_available_mb": 50117.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12723.4, "ram_available_mb": 50117.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.277}, "power_stats": {"power_gpu_soc_mean_watts": 21.589, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 87.277}, "timestamp": "2026-01-28T15:02:43.654970"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4087.162, "latencies_ms": [4087.162], "images_per_second": 0.245, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A sandwich with lettuce, tomato, and ham is on a paper plate with pickles and mustard on the side.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12723.4, "ram_available_mb": 50117.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.1, "ram_used_mb": 12723.2, "ram_available_mb": 50117.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 86.412}, "power_stats": {"power_gpu_soc_mean_watts": 20.394, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.371, "gpu_utilization_percent_mean": 86.412}, "timestamp": "2026-01-28T15:02:49.775489"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5687.658, "latencies_ms": [5687.658], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sandwich: 1\n2. lettuce: 1\n3. tomato: 1\n4. cheese: 1\n5. ham: 1\n6. pickle: 2\n7. mustard: 1\n8. paper plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12723.2, "ram_available_mb": 50117.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12723.0, "ram_available_mb": 50117.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.208}, "power_stats": {"power_gpu_soc_mean_watts": 19.729, "power_cpu_cv_mean_watts": 2.078, "power_sys_5v0_mean_watts": 7.758, "gpu_utilization_percent_mean": 78.208}, "timestamp": "2026-01-28T15:02:57.494311"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5317.133, "latencies_ms": [5317.133], "images_per_second": 0.188, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the image, with the plate of pickles and mustard placed to the right of the sandwich. The computer monitor is positioned in the background, behind the plate of pickles and mustard.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12723.0, "ram_available_mb": 50117.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.0, "ram_used_mb": 12723.2, "ram_available_mb": 50117.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.091}, "power_stats": {"power_gpu_soc_mean_watts": 19.382, "power_cpu_cv_mean_watts": 1.993, "power_sys_5v0_mean_watts": 7.472, "gpu_utilization_percent_mean": 78.091}, "timestamp": "2026-01-28T15:03:04.838029"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3243.02, "latencies_ms": [3243.02], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A sandwich is on a paper plate on a desk with a computer in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12723.2, "ram_available_mb": 50117.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12721.6, "ram_available_mb": 50119.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 83.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.549, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.766, "gpu_utilization_percent_mean": 83.185}, "timestamp": "2026-01-28T15:03:10.123599"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3931.954, "latencies_ms": [3931.954], "images_per_second": 0.254, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The sandwich is on a white paper plate with a green and white computer monitor in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12721.6, "ram_available_mb": 50119.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12721.5, "ram_available_mb": 50119.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.156}, "power_stats": {"power_gpu_soc_mean_watts": 20.517, "power_cpu_cv_mean_watts": 1.539, "power_sys_5v0_mean_watts": 7.353, "gpu_utilization_percent_mean": 85.156}, "timestamp": "2026-01-28T15:03:16.090657"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4579.098, "latencies_ms": [4579.098], "images_per_second": 0.218, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a desk with two computer monitors, a keyboard, a mouse, and a tablet, all arranged in a way that suggests a workspace or a home office setup.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12721.5, "ram_available_mb": 50119.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12721.4, "ram_available_mb": 50119.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 78.158}, "power_stats": {"power_gpu_soc_mean_watts": 20.048, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 7.582, "gpu_utilization_percent_mean": 78.158}, "timestamp": "2026-01-28T15:03:22.732534"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4871.129, "latencies_ms": [4871.129], "images_per_second": 0.205, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " monitor: 2, keyboard: 1, mouse: 1, tablet: 1, phone: 1, camera: 1, computer: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12721.4, "ram_available_mb": 50119.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12722.6, "ram_available_mb": 50118.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 85.45}, "power_stats": {"power_gpu_soc_mean_watts": 19.537, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 7.407, "gpu_utilization_percent_mean": 85.45}, "timestamp": "2026-01-28T15:03:29.628900"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6018.55, "latencies_ms": [6018.55], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The keyboard is located in the foreground, to the left of the mouse. The tablet is positioned in the background, to the right of the keyboard. The computer monitors are placed above the keyboard and mouse, with the left monitor positioned to the left and the right monitor positioned to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12722.6, "ram_available_mb": 50118.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12725.8, "ram_available_mb": 50115.1, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 72.42}, "power_stats": {"power_gpu_soc_mean_watts": 18.218, "power_cpu_cv_mean_watts": 2.067, "power_sys_5v0_mean_watts": 7.56, "gpu_utilization_percent_mean": 72.42}, "timestamp": "2026-01-28T15:03:37.660900"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5594.602, "latencies_ms": [5594.602], "images_per_second": 0.179, "prompt_tokens": 1111, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a computer desk with multiple monitors, a keyboard, and a mouse. The monitors are displaying various screens, including a web browser and a document. The desk is equipped with a keyboard, a mouse, and a tablet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12725.8, "ram_available_mb": 50115.1, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.2, "ram_used_mb": 12725.3, "ram_available_mb": 50115.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.4, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 81.326}, "power_stats": {"power_gpu_soc_mean_watts": 19.297, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 7.479, "gpu_utilization_percent_mean": 81.326}, "timestamp": "2026-01-28T15:03:45.278336"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3867.431, "latencies_ms": [3867.431], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The desk is white and the monitors are black. The lighting is dim and the room is dark.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12725.3, "ram_available_mb": 50115.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12725.5, "ram_available_mb": 50115.4, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5354.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 79.875}, "power_stats": {"power_gpu_soc_mean_watts": 20.54, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.413, "gpu_utilization_percent_mean": 79.875}, "timestamp": "2026-01-28T15:03:51.202764"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5423.13, "latencies_ms": [5423.13], "images_per_second": 0.184, "prompt_tokens": 1432, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image shows a bathroom with a tiled floor that has a collage of people's faces on it, and a white toilet bowl with a blue and red sticker on it.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12725.5, "ram_available_mb": 50115.4, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 9.5, "ram_used_mb": 12726.3, "ram_available_mb": 50114.6, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.591}, "power_stats": {"power_gpu_soc_mean_watts": 21.513, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 7.825, "gpu_utilization_percent_mean": 87.591}, "timestamp": "2026-01-28T15:03:58.659938"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5048.197, "latencies_ms": [5048.197], "images_per_second": 0.198, "prompt_tokens": 1446, "response_tokens_est": 34, "n_tiles": 1, "output_text": " 1. Toilet\n2. Floor\n3. Tile\n4. People\n5. Wall\n6. Door\n7. Light\n8. Mirror", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12726.3, "ram_available_mb": 50114.6, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12726.0, "ram_available_mb": 50114.9, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 80.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.659, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 80.071}, "timestamp": "2026-01-28T15:04:05.748208"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5940.206, "latencies_ms": [5940.206], "images_per_second": 0.168, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The main objects are the toilet and the floor. The toilet is located in the background, while the floor is in the foreground. The floor is also the closest object to the viewer, while the toilet is the farthest.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12726.0, "ram_available_mb": 50114.9, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12724.9, "ram_available_mb": 50116.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.633}, "power_stats": {"power_gpu_soc_mean_watts": 21.39, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.813, "gpu_utilization_percent_mean": 82.633}, "timestamp": "2026-01-28T15:04:13.707001"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4360.582, "latencies_ms": [4360.582], "images_per_second": 0.229, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A group of people are standing on a tiled floor in a bathroom.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12724.9, "ram_available_mb": 50116.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12725.2, "ram_available_mb": 50115.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 92.194}, "power_stats": {"power_gpu_soc_mean_watts": 22.877, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 7.734, "gpu_utilization_percent_mean": 92.194}, "timestamp": "2026-01-28T15:04:20.082805"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3651.497, "latencies_ms": [3651.497], "images_per_second": 0.274, "prompt_tokens": 1442, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The bathroom has white tiles and a white toilet.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12725.2, "ram_available_mb": 50115.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12725.2, "ram_available_mb": 50115.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 89.433}, "power_stats": {"power_gpu_soc_mean_watts": 24.7, "power_cpu_cv_mean_watts": 1.094, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 89.433}, "timestamp": "2026-01-28T15:04:25.783669"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4475.87, "latencies_ms": [4475.87], "images_per_second": 0.223, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird with a grey body and black beak is perched on a branch in a forest.", "error": null, "sys_before": {"cpu_percent": 19.0, "ram_used_mb": 12725.2, "ram_available_mb": 50115.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12725.4, "ram_available_mb": 50115.4, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.2, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.622}, "power_stats": {"power_gpu_soc_mean_watts": 22.192, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 7.697, "gpu_utilization_percent_mean": 87.622}, "timestamp": "2026-01-28T15:04:32.297761"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3151.856, "latencies_ms": [3151.856], "images_per_second": 0.317, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " bird: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12725.4, "ram_available_mb": 50115.4, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12725.9, "ram_available_mb": 50115.0, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 93.346}, "power_stats": {"power_gpu_soc_mean_watts": 26.081, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.195, "gpu_utilization_percent_mean": 93.346}, "timestamp": "2026-01-28T15:04:37.478990"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4877.501, "latencies_ms": [4877.501], "images_per_second": 0.205, "prompt_tokens": 1450, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The bird is positioned in the foreground, perched on a branch, while the background is filled with green foliage.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12725.9, "ram_available_mb": 50115.0, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 11.7, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 91.15}, "power_stats": {"power_gpu_soc_mean_watts": 22.098, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 91.15}, "timestamp": "2026-01-28T15:04:44.372124"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3924.662, "latencies_ms": [3924.662], "images_per_second": 0.255, "prompt_tokens": 1444, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A bird is perched on a branch in a forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12726.7, "ram_available_mb": 50114.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12727.4, "ram_available_mb": 50113.5, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 87.656}, "power_stats": {"power_gpu_soc_mean_watts": 23.77, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 87.656}, "timestamp": "2026-01-28T15:04:50.336213"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4507.656, "latencies_ms": [4507.656], "images_per_second": 0.222, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The bird is gray and black, and the photo was taken in a forest with a lot of green leaves.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12727.4, "ram_available_mb": 50113.5, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 12728.6, "ram_available_mb": 50112.3, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6460.0, "gpu_max_mem_alloc_mb": 5677.3, "gpu_max_mem_reserved_mb": 6460.0, "gpu_utilization_percent": 82.216}, "power_stats": {"power_gpu_soc_mean_watts": 22.919, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 82.216}, "timestamp": "2026-01-28T15:04:56.879327"}
