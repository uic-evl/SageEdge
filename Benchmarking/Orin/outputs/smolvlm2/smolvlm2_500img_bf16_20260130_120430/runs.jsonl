{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4263.94, "latencies_ms": [4263.94], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a spacious, well-lit living room with a dining area, featuring a large flat-screen TV, a fireplace, and a kitchen area with a countertop and cabinets.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14760.2, "ram_available_mb": 48080.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14761.7, "ram_available_mb": 48079.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 69.639}, "power_stats": {"power_gpu_soc_mean_watts": 21.26, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 69.639}, "timestamp": "2026-01-30T12:05:35.288558"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9868.29, "latencies_ms": [9868.29], "images_per_second": 0.101, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " television: 1, dining table: 1, chairs: 4, vase: 1, flowers: 2, television stand: 1, window: 1, wall: 1, floor: 1, rug: 1, fireplace: 1, ceiling: 1, light: 1, wall art: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1, wall: 1,", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14761.7, "ram_available_mb": 48079.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 14763.6, "ram_available_mb": 48077.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 65.188}, "power_stats": {"power_gpu_soc_mean_watts": 15.08, "power_cpu_cv_mean_watts": 1.946, "power_sys_5v0_mean_watts": 7.627, "gpu_utilization_percent_mean": 65.188}, "timestamp": "2026-01-30T12:05:47.188591"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5586.16, "latencies_ms": [5586.16], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The dining table is located in the center of the room, with the woman standing near it. The television is on the left side of the room, while the fireplace is on the right side. The woman is standing near the dining table, which is in the center of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14763.6, "ram_available_mb": 48077.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14765.8, "ram_available_mb": 48075.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 68.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.31, "power_cpu_cv_mean_watts": 1.568, "power_sys_5v0_mean_watts": 7.75, "gpu_utilization_percent_mean": 68.957}, "timestamp": "2026-01-30T12:05:54.794106"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2982.731, "latencies_ms": [2982.731], "images_per_second": 0.335, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in a living room with a dining table and chairs.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14765.8, "ram_available_mb": 48075.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14766.8, "ram_available_mb": 48074.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 78.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.479, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 78.16}, "timestamp": "2026-01-30T12:05:59.822249"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4340.694, "latencies_ms": [4340.694], "images_per_second": 0.23, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with hardwood floors and a large window letting in natural light. The walls are painted a bright yellow, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14766.8, "ram_available_mb": 48074.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14769.2, "ram_available_mb": 48071.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 6054.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 6054.0, "gpu_utilization_percent": 70.889}, "power_stats": {"power_gpu_soc_mean_watts": 20.5, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 7.896, "gpu_utilization_percent_mean": 70.889}, "timestamp": "2026-01-30T12:06:06.215069"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4202.308, "latencies_ms": [4202.308], "images_per_second": 0.238, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a large brown bear with a thick coat of fur, standing on a grassy field and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 14769.2, "ram_available_mb": 48071.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14739.3, "ram_available_mb": 48101.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.794, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.273, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T12:06:12.476277"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6212.169, "latencies_ms": [6212.169], "images_per_second": 0.161, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 1\n2. grass: 1\n3. fur: 1\n4. nose: 1\n5. eyes: 1\n6. mouth: 1\n7. ears: 1\n8. fur texture: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14739.3, "ram_available_mb": 48101.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14754.6, "ram_available_mb": 48086.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.173}, "power_stats": {"power_gpu_soc_mean_watts": 20.178, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 72.173}, "timestamp": "2026-01-30T12:06:20.717470"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4554.122, "latencies_ms": [4554.122], "images_per_second": 0.22, "prompt_tokens": 1450, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bear is in the foreground, with the grass in the background. The bear is facing the camera, with its head turned slightly to the left.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14754.6, "ram_available_mb": 48086.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14786.0, "ram_available_mb": 48054.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.395}, "power_stats": {"power_gpu_soc_mean_watts": 23.227, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.203, "gpu_utilization_percent_mean": 77.395}, "timestamp": "2026-01-30T12:06:27.328375"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3377.228, "latencies_ms": [3377.228], "images_per_second": 0.296, "prompt_tokens": 1444, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A large brown bear is sitting on a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14786.0, "ram_available_mb": 48054.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14784.1, "ram_available_mb": 48056.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.5}, "power_stats": {"power_gpu_soc_mean_watts": 26.072, "power_cpu_cv_mean_watts": 0.744, "power_sys_5v0_mean_watts": 8.396, "gpu_utilization_percent_mean": 82.5}, "timestamp": "2026-01-30T12:06:32.754129"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3442.756, "latencies_ms": [3442.756], "images_per_second": 0.29, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The bear has a brown fur, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14784.1, "ram_available_mb": 48056.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14784.8, "ram_available_mb": 48056.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.172}, "power_stats": {"power_gpu_soc_mean_watts": 26.278, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.442, "gpu_utilization_percent_mean": 83.172}, "timestamp": "2026-01-30T12:06:38.236485"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5314.954, "latencies_ms": [5314.954], "images_per_second": 0.188, "prompt_tokens": 1432, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a blue comforter on the bed, a wooden dresser with a mirror, a bookshelf filled with books, and a window that offers a view of a lush green tree outside.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14784.8, "ram_available_mb": 48056.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14785.6, "ram_available_mb": 48055.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.689}, "power_stats": {"power_gpu_soc_mean_watts": 21.62, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 73.689}, "timestamp": "2026-01-30T12:06:45.585424"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6474.74, "latencies_ms": [6474.74], "images_per_second": 0.154, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. bed: 1\n2. dresser: 1\n3. mirror: 1\n4. bookshelf: 1\n5. books: 100\n6. potted plant: 4\n7. window: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14785.6, "ram_available_mb": 48055.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14786.8, "ram_available_mb": 48054.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.618}, "power_stats": {"power_gpu_soc_mean_watts": 19.946, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-30T12:06:54.090460"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6295.426, "latencies_ms": [6295.426], "images_per_second": 0.159, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the window on the right side. The bookshelf is positioned in the background, while the dresser is situated near the bed. The plants are placed in the foreground, with the window being the closest object to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14786.8, "ram_available_mb": 48054.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14788.0, "ram_available_mb": 48052.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.245}, "power_stats": {"power_gpu_soc_mean_watts": 20.048, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 72.245}, "timestamp": "2026-01-30T12:07:02.423577"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5049.779, "latencies_ms": [5049.779], "images_per_second": 0.198, "prompt_tokens": 1444, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bedroom is furnished with a bed, a dresser, a bookshelf, and a window. The room is decorated with a blue comforter, a mirror, and a plant.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14788.0, "ram_available_mb": 48052.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14790.2, "ram_available_mb": 48050.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.279}, "power_stats": {"power_gpu_soc_mean_watts": 21.979, "power_cpu_cv_mean_watts": 1.285, "power_sys_5v0_mean_watts": 8.173, "gpu_utilization_percent_mean": 74.279}, "timestamp": "2026-01-30T12:07:09.512769"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4294.398, "latencies_ms": [4294.398], "images_per_second": 0.233, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The room is bathed in natural light from a window, the walls are adorned with floral wallpaper, and the floor is carpeted.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14790.2, "ram_available_mb": 48050.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14790.9, "ram_available_mb": 48050.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.111}, "power_stats": {"power_gpu_soc_mean_watts": 24.183, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.331, "gpu_utilization_percent_mean": 75.111}, "timestamp": "2026-01-30T12:07:15.828930"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2897.447, "latencies_ms": [2897.447], "images_per_second": 0.345, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14790.9, "ram_available_mb": 48050.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14792.1, "ram_available_mb": 48048.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.292}, "power_stats": {"power_gpu_soc_mean_watts": 23.789, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 74.292}, "timestamp": "2026-01-30T12:07:20.771562"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2283.298, "latencies_ms": [2283.298], "images_per_second": 0.438, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " stop sign: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14792.1, "ram_available_mb": 48048.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 2.8, "ram_used_mb": 14793.4, "ram_available_mb": 48047.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.444}, "power_stats": {"power_gpu_soc_mean_watts": 25.706, "power_cpu_cv_mean_watts": 0.623, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 87.444}, "timestamp": "2026-01-30T12:07:25.070734"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4952.138, "latencies_ms": [4952.138], "images_per_second": 0.202, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The stop sign is in the foreground, to the left of the street. The street is in the middle of the image, with the stop sign on the right side. The background includes trees and buildings, with the sky visible above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14793.4, "ram_available_mb": 48047.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14793.4, "ram_available_mb": 48047.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.561}, "power_stats": {"power_gpu_soc_mean_watts": 19.29, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 69.561}, "timestamp": "2026-01-30T12:07:32.048786"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2883.521, "latencies_ms": [2883.521], "images_per_second": 0.347, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A stop sign is on a pole in front of a parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14793.4, "ram_available_mb": 48047.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14793.8, "ram_available_mb": 48047.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.348}, "power_stats": {"power_gpu_soc_mean_watts": 24.072, "power_cpu_cv_mean_watts": 0.783, "power_sys_5v0_mean_watts": 8.179, "gpu_utilization_percent_mean": 77.348}, "timestamp": "2026-01-30T12:07:36.949007"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2840.674, "latencies_ms": [2840.674], "images_per_second": 0.352, "prompt_tokens": 1110, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The stop sign is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14793.8, "ram_available_mb": 48047.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14795.1, "ram_available_mb": 48045.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.683, "power_cpu_cv_mean_watts": 0.836, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 76.652}, "timestamp": "2026-01-30T12:07:41.816832"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3027.079, "latencies_ms": [3027.079], "images_per_second": 0.33, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three teddy bears of different sizes and colors are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14795.1, "ram_available_mb": 48045.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14796.3, "ram_available_mb": 48044.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 24.053, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T12:07:46.896221"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2342.772, "latencies_ms": [2342.772], "images_per_second": 0.427, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " teddy bear: 4", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14796.3, "ram_available_mb": 48044.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 14797.3, "ram_available_mb": 48043.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.105}, "power_stats": {"power_gpu_soc_mean_watts": 25.07, "power_cpu_cv_mean_watts": 0.59, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 81.105}, "timestamp": "2026-01-30T12:07:51.301917"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6435.673, "latencies_ms": [6435.673], "images_per_second": 0.155, "prompt_tokens": 1118, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The teddy bears are positioned in a close group, with the largest bear in the center and the smallest bear on the left. The largest bear is in the foreground, while the smallest bear is in the background. The teddy bears are arranged in a way that suggests they are huddled together, with the smallest bear resting its head on the largest bear's back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14797.3, "ram_available_mb": 48043.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14795.6, "ram_available_mb": 48045.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.759}, "power_stats": {"power_gpu_soc_mean_watts": 17.524, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.829, "gpu_utilization_percent_mean": 66.759}, "timestamp": "2026-01-30T12:07:59.798894"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2741.224, "latencies_ms": [2741.224], "images_per_second": 0.365, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Three teddy bears are huddled together on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14795.6, "ram_available_mb": 48045.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14796.4, "ram_available_mb": 48044.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.909}, "power_stats": {"power_gpu_soc_mean_watts": 24.421, "power_cpu_cv_mean_watts": 0.837, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 80.909}, "timestamp": "2026-01-30T12:08:04.573213"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3146.271, "latencies_ms": [3146.271], "images_per_second": 0.318, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The teddy bears are brown and beige, and they are sitting on a blue blanket.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14796.4, "ram_available_mb": 48044.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.438, "power_cpu_cv_mean_watts": 1.017, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 73.808}, "timestamp": "2026-01-30T12:08:09.780846"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3392.862, "latencies_ms": [3392.862], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill with ski poles in her hands.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14795.4, "ram_available_mb": 48045.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.621, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.643}, "timestamp": "2026-01-30T12:08:15.230209"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6362.757, "latencies_ms": [6362.757], "images_per_second": 0.157, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. Ski pole: 2\n2. Ski: 2\n3. Ski pole: 2\n4. Ski pole: 2\n5. Ski pole: 2\n6. Ski pole: 2\n7. Ski pole: 2\n8. Ski pole: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14795.4, "ram_available_mb": 48045.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14795.4, "ram_available_mb": 48045.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.585}, "power_stats": {"power_gpu_soc_mean_watts": 17.598, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 7.855, "gpu_utilization_percent_mean": 68.585}, "timestamp": "2026-01-30T12:08:23.628859"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4670.489, "latencies_ms": [4670.489], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski slope stretching out into the background. The skier is to the left of the image, with the ski poles extending towards the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14795.4, "ram_available_mb": 48045.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.436}, "power_stats": {"power_gpu_soc_mean_watts": 19.765, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 69.436}, "timestamp": "2026-01-30T12:08:30.323362"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3077.805, "latencies_ms": [3077.805], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a red jacket and black pants is skiing down a snowy hill.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14797.1, "ram_available_mb": 48043.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14797.9, "ram_available_mb": 48043.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.317, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 70.88}, "timestamp": "2026-01-30T12:08:35.444847"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3232.077, "latencies_ms": [3232.077], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a red jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14797.9, "ram_available_mb": 48043.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14798.3, "ram_available_mb": 48042.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.236, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.133, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-30T12:08:40.722830"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4157.403, "latencies_ms": [4157.403], "images_per_second": 0.241, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a kitchen with a white refrigerator, a white stove, and a white dishwasher, all set against a backdrop of wooden cabinets and a beige tiled floor.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 14798.3, "ram_available_mb": 48042.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14799.6, "ram_available_mb": 48041.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.033, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 72.382}, "timestamp": "2026-01-30T12:08:46.917170"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6227.025, "latencies_ms": [6227.025], "images_per_second": 0.161, "prompt_tokens": 1114, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. white refrigerator: 1\n2. white stove: 1\n3. white oven: 1\n4. white cabinet: 2\n5. white cabinet door: 1\n6. white cabinet handle: 1\n7. white cabinet drawer: 1\n8. white cabinet knob: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14799.6, "ram_available_mb": 48041.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14799.8, "ram_available_mb": 48041.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.096}, "power_stats": {"power_gpu_soc_mean_watts": 17.612, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.846, "gpu_utilization_percent_mean": 67.096}, "timestamp": "2026-01-30T12:08:55.196304"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5116.353, "latencies_ms": [5116.353], "images_per_second": 0.195, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The white refrigerator is located to the right of the white stove, which is situated to the left of the white oven. The white cabinets are positioned above the stove and oven, while the white countertop is situated in the middle of the kitchen.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14799.8, "ram_available_mb": 48041.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14800.3, "ram_available_mb": 48040.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.476}, "power_stats": {"power_gpu_soc_mean_watts": 18.961, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 7.892, "gpu_utilization_percent_mean": 70.476}, "timestamp": "2026-01-30T12:09:02.346345"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2903.635, "latencies_ms": [2903.635], "images_per_second": 0.344, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A small kitchen with white appliances and wood cabinets is shown in the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14800.3, "ram_available_mb": 48040.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14800.0, "ram_available_mb": 48040.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.208}, "power_stats": {"power_gpu_soc_mean_watts": 24.068, "power_cpu_cv_mean_watts": 0.918, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 78.208}, "timestamp": "2026-01-30T12:09:07.299217"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3179.661, "latencies_ms": [3179.661], "images_per_second": 0.314, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14800.0, "ram_available_mb": 48040.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14800.3, "ram_available_mb": 48040.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.346}, "power_stats": {"power_gpu_soc_mean_watts": 23.19, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 8.101, "gpu_utilization_percent_mean": 77.346}, "timestamp": "2026-01-30T12:09:12.515285"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4175.066, "latencies_ms": [4175.066], "images_per_second": 0.24, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two baseball players are running on the field, one of them is wearing a green shirt and the other is wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 14800.3, "ram_available_mb": 48040.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14800.3, "ram_available_mb": 48040.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.229}, "power_stats": {"power_gpu_soc_mean_watts": 24.207, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.417, "gpu_utilization_percent_mean": 76.229}, "timestamp": "2026-01-30T12:09:18.747489"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6864.706, "latencies_ms": [6864.706], "images_per_second": 0.146, "prompt_tokens": 1446, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. baseball glove: 1\n3. baseball bat: 1\n4. baseball cap: 1\n5. baseball helmet: 1\n6. baseball field: 1\n7. baseball player's pants: 1\n8. baseball player's shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14800.3, "ram_available_mb": 48040.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14800.0, "ram_available_mb": 48040.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.81}, "power_stats": {"power_gpu_soc_mean_watts": 19.513, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 70.81}, "timestamp": "2026-01-30T12:09:27.651029"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5432.546, "latencies_ms": [5432.546], "images_per_second": 0.184, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The baseball player in the foreground is running towards the right side of the image, while the other player is running towards the left side. The baseball player in the foreground is closer to the camera than the other player.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14800.0, "ram_available_mb": 48040.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14801.2, "ram_available_mb": 48039.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.378}, "power_stats": {"power_gpu_soc_mean_watts": 21.402, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 73.378}, "timestamp": "2026-01-30T12:09:35.131006"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4195.909, "latencies_ms": [4195.909], "images_per_second": 0.238, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a boy wearing a green shirt and a baseball glove running towards the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14801.2, "ram_available_mb": 48039.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14801.0, "ram_available_mb": 48039.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.486}, "power_stats": {"power_gpu_soc_mean_watts": 24.38, "power_cpu_cv_mean_watts": 1.133, "power_sys_5v0_mean_watts": 8.397, "gpu_utilization_percent_mean": 75.486}, "timestamp": "2026-01-30T12:09:41.388864"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5226.667, "latencies_ms": [5226.667], "images_per_second": 0.191, "prompt_tokens": 1442, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a baseball game with two players running on the field, one wearing a green shirt and the other wearing a white shirt. The field is covered in green grass, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14801.0, "ram_available_mb": 48039.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14801.7, "ram_available_mb": 48039.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.318}, "power_stats": {"power_gpu_soc_mean_watts": 21.894, "power_cpu_cv_mean_watts": 1.429, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 73.318}, "timestamp": "2026-01-30T12:09:48.634094"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3525.22, "latencies_ms": [3525.22], "images_per_second": 0.284, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A tennis player is preparing to hit a ball on a court with a J.P. Morgan advertisement in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14801.7, "ram_available_mb": 48039.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14802.2, "ram_available_mb": 48038.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.381, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 73.103}, "timestamp": "2026-01-30T12:09:54.212523"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5666.825, "latencies_ms": [5666.825], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. tennis player: 1\n2. ball: 1\n3. racket: 1\n4. person: 1\n5. wall: 1\n6. advertisement: 1\n7. spectator: 1\n8. court: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14802.2, "ram_available_mb": 48038.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14802.9, "ram_available_mb": 48038.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.583}, "power_stats": {"power_gpu_soc_mean_watts": 18.27, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.886, "gpu_utilization_percent_mean": 69.583}, "timestamp": "2026-01-30T12:10:01.906242"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4129.227, "latencies_ms": [4129.227], "images_per_second": 0.242, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the ball and the umpire in the background. The player is closer to the camera than the umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14802.9, "ram_available_mb": 48038.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14804.4, "ram_available_mb": 48036.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.041, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T12:10:08.072891"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3070.93, "latencies_ms": [3070.93], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A tennis player is playing on a court with a blue wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14804.4, "ram_available_mb": 48036.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14805.3, "ram_available_mb": 48035.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.36, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.159, "gpu_utilization_percent_mean": 72.52}, "timestamp": "2026-01-30T12:10:13.203154"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5929.819, "latencies_ms": [5929.819], "images_per_second": 0.169, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a vibrant blue tennis court, where a player in a crisp white outfit is in the midst of a powerful swing, his body leaning forward in anticipation. The court is bathed in bright sunlight, casting a sharp contrast between the blue of the court and the green of the surrounding grass.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14805.3, "ram_available_mb": 48035.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14805.1, "ram_available_mb": 48035.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.32}, "power_stats": {"power_gpu_soc_mean_watts": 18.001, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.907, "gpu_utilization_percent_mean": 68.32}, "timestamp": "2026-01-30T12:10:21.146893"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3594.703, "latencies_ms": [3594.703], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court, with one of the adults holding a trophy.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14805.1, "ram_available_mb": 48035.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14805.1, "ram_available_mb": 48035.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.992, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-30T12:10:26.803803"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5470.922, "latencies_ms": [5470.922], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. boy: 4\n2. girl: 3\n3. boy: 2\n4. boy: 1\n5. boy: 1\n6. boy: 1\n7. boy: 1\n8. boy: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14805.1, "ram_available_mb": 48035.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14812.2, "ram_available_mb": 48028.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.609, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 7.917, "gpu_utilization_percent_mean": 67.804}, "timestamp": "2026-01-30T12:10:34.334628"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6121.313, "latencies_ms": [6121.313], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The group of children and adults are standing on a tennis court, with the tennis rackets held by the children and adults. The tennis rackets are positioned in the foreground, with the group of children and adults standing behind them. The tennis court is located in the background, with the tennis net and trees visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14812.2, "ram_available_mb": 48028.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14812.4, "ram_available_mb": 48028.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.519}, "power_stats": {"power_gpu_soc_mean_watts": 17.727, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 68.519}, "timestamp": "2026-01-30T12:10:42.497681"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3018.336, "latencies_ms": [3018.336], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of children and adults are posing for a picture on a tennis court.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14812.4, "ram_available_mb": 48028.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14812.6, "ram_available_mb": 48028.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.32}, "power_stats": {"power_gpu_soc_mean_watts": 23.606, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 72.32}, "timestamp": "2026-01-30T12:10:47.531187"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3276.796, "latencies_ms": [3276.796], "images_per_second": 0.305, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image is taken in a sunny day with clear blue sky. The tennis court is blue in color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14812.6, "ram_available_mb": 48028.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14812.9, "ram_available_mb": 48028.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.519}, "power_stats": {"power_gpu_soc_mean_watts": 23.412, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.188, "gpu_utilization_percent_mean": 75.519}, "timestamp": "2026-01-30T12:10:52.840154"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4701.298, "latencies_ms": [4701.298], "images_per_second": 0.213, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " In the image, a group of people are gathered on a stone-paved walkway, with a large bridge arching above them, and a white bird is seen walking on the ground near the water's edge.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14812.9, "ram_available_mb": 48028.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14813.6, "ram_available_mb": 48027.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.789, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 70.4}, "timestamp": "2026-01-30T12:10:59.586556"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5518.659, "latencies_ms": [5518.659], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. people: 4\n3. birds: 1\n4. rocks: 2\n5. water: 1\n6. trees: 1\n7. buildings: 1\n8. bridge: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14813.6, "ram_available_mb": 48027.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14814.5, "ram_available_mb": 48026.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.409, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.899, "gpu_utilization_percent_mean": 67.638}, "timestamp": "2026-01-30T12:11:07.120687"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5304.03, "latencies_ms": [5304.03], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The main objects are positioned in a way that the bridge is in the foreground, with the people and the bird in the background. The bridge is located to the left of the people and the bird, and the people are sitting on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14814.5, "ram_available_mb": 48026.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14814.3, "ram_available_mb": 48026.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.067}, "power_stats": {"power_gpu_soc_mean_watts": 18.856, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 7.923, "gpu_utilization_percent_mean": 68.067}, "timestamp": "2026-01-30T12:11:14.464683"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3516.592, "latencies_ms": [3516.592], "images_per_second": 0.284, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting on a stone ledge by a river, watching a white bird swim in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14814.3, "ram_available_mb": 48026.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14815.7, "ram_available_mb": 48025.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.556, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 8.119, "gpu_utilization_percent_mean": 69.793}, "timestamp": "2026-01-30T12:11:20.040623"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6298.108, "latencies_ms": [6298.108], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a bridge with a metal structure, a river with a white bird, and a group of people sitting on the bank. The lighting is natural, with the sun shining down on the scene, and the colors are vibrant, with the blue of the river contrasting with the green of the trees and the red of the people's clothing.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14815.7, "ram_available_mb": 48025.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14815.4, "ram_available_mb": 48025.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.434}, "power_stats": {"power_gpu_soc_mean_watts": 17.555, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 65.434}, "timestamp": "2026-01-30T12:11:28.373811"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2910.94, "latencies_ms": [2910.94], "images_per_second": 0.344, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is looking at her phone with a Hello Kitty case.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 14815.4, "ram_available_mb": 48025.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14815.1, "ram_available_mb": 48025.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.542}, "power_stats": {"power_gpu_soc_mean_watts": 23.798, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 79.542}, "timestamp": "2026-01-30T12:11:33.325082"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5746.5, "latencies_ms": [5746.5], "images_per_second": 0.174, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. woman: 1\n2. hair: 1\n3. earring: 1\n4. wristwatch: 1\n5. bracelet: 2\n6. phone: 1\n7. Hello Kitty: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14815.1, "ram_available_mb": 48025.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14815.2, "ram_available_mb": 48025.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.521}, "power_stats": {"power_gpu_soc_mean_watts": 18.318, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 7.942, "gpu_utilization_percent_mean": 69.521}, "timestamp": "2026-01-30T12:11:41.102312"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4284.798, "latencies_ms": [4284.798], "images_per_second": 0.233, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The woman is in the foreground of the image, holding a Hello Kitty phone case. The background is blurred, indicating that the focus is on the woman and her phone case.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14815.2, "ram_available_mb": 48025.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.759, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 72.057}, "timestamp": "2026-01-30T12:11:47.415762"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3017.67, "latencies_ms": [3017.67], "images_per_second": 0.331, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman is taking a picture of herself with a Hello Kitty phone case.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14816.4, "ram_available_mb": 48024.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.208}, "power_stats": {"power_gpu_soc_mean_watts": 23.599, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.196, "gpu_utilization_percent_mean": 77.208}, "timestamp": "2026-01-30T12:11:52.448566"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3522.895, "latencies_ms": [3522.895], "images_per_second": 0.284, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a bright and sunny day, with the woman wearing a white shirt and a green bracelet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.4, "ram_available_mb": 48024.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.541, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 71.517}, "timestamp": "2026-01-30T12:11:58.031595"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3608.571, "latencies_ms": [3608.571], "images_per_second": 0.277, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of children are riding on a red and yellow train car, with a wooden wall and a black speaker in the background.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.333}, "power_stats": {"power_gpu_soc_mean_watts": 22.258, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 8.108, "gpu_utilization_percent_mean": 71.333}, "timestamp": "2026-01-30T12:12:03.667366"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5930.86, "latencies_ms": [5930.86], "images_per_second": 0.169, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. children: 5\n2. train: 1\n3. track: 1\n4. wall: 1\n5. children's clothing: 5\n6. children's hair: 5\n7. children's eyes: 5\n8. children's hands: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14817.6, "ram_available_mb": 48023.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.531}, "power_stats": {"power_gpu_soc_mean_watts": 18.206, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 7.918, "gpu_utilization_percent_mean": 67.531}, "timestamp": "2026-01-30T12:12:11.620874"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4608.804, "latencies_ms": [4608.804], "images_per_second": 0.217, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The children are in the foreground, riding on a train that is in the middle of the image. The train is moving towards the right side of the image, and the children are looking towards the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.6, "ram_available_mb": 48023.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.061, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 68.237}, "timestamp": "2026-01-30T12:12:18.244043"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3276.981, "latencies_ms": [3276.981], "images_per_second": 0.305, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of children are riding on a train car in a room with a wooden floor and a wall.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.704}, "power_stats": {"power_gpu_soc_mean_watts": 22.979, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 75.704}, "timestamp": "2026-01-30T12:12:23.546133"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5187.732, "latencies_ms": [5187.732], "images_per_second": 0.193, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image features a group of children riding on a red and yellow train car, with the train car being the main focus of the image. The lighting in the image is dim, and the children are wearing jackets, indicating that it might be a cold day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.465}, "power_stats": {"power_gpu_soc_mean_watts": 19.181, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 69.465}, "timestamp": "2026-01-30T12:12:30.752156"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3568.264, "latencies_ms": [3568.264], "images_per_second": 0.28, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate with a piece of food on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.414}, "power_stats": {"power_gpu_soc_mean_watts": 25.76, "power_cpu_cv_mean_watts": 0.925, "power_sys_5v0_mean_watts": 8.568, "gpu_utilization_percent_mean": 80.414}, "timestamp": "2026-01-30T12:12:36.359142"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6306.244, "latencies_ms": [6306.244], "images_per_second": 0.159, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. food: 1\n3. cup: 1\n4. fork: 1\n5. knife: 1\n6. table: 1\n7. background: 1\n8. glass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.906}, "power_stats": {"power_gpu_soc_mean_watts": 19.763, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 72.906}, "timestamp": "2026-01-30T12:12:44.702015"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5516.277, "latencies_ms": [5516.277], "images_per_second": 0.181, "prompt_tokens": 1450, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The main object, a piece of food, is in the foreground, with a small dish of sauce in the background. The food is positioned to the left of the dish, and the entire scene is set on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.413}, "power_stats": {"power_gpu_soc_mean_watts": 21.29, "power_cpu_cv_mean_watts": 1.445, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 73.413}, "timestamp": "2026-01-30T12:12:52.254031"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3647.034, "latencies_ms": [3647.034], "images_per_second": 0.274, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a plate of food with a side of salad.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.4}, "power_stats": {"power_gpu_soc_mean_watts": 25.597, "power_cpu_cv_mean_watts": 0.881, "power_sys_5v0_mean_watts": 8.508, "gpu_utilization_percent_mean": 79.4}, "timestamp": "2026-01-30T12:12:57.943826"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4736.661, "latencies_ms": [4736.661], "images_per_second": 0.211, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, with a focus on a plate of food. The lighting is soft and natural, and the food appears to be well-cooked.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14817.0, "ram_available_mb": 48023.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.513}, "power_stats": {"power_gpu_soc_mean_watts": 23.285, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 8.37, "gpu_utilization_percent_mean": 74.513}, "timestamp": "2026-01-30T12:13:04.695045"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2934.361, "latencies_ms": [2934.361], "images_per_second": 0.341, "prompt_tokens": 766, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a wetsuit is standing on a paddleboard in the ocean, holding a paddle in his hand.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 14817.0, "ram_available_mb": 48023.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14816.8, "ram_available_mb": 48024.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5179.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.708}, "power_stats": {"power_gpu_soc_mean_watts": 19.865, "power_cpu_cv_mean_watts": 1.168, "power_sys_5v0_mean_watts": 7.701, "gpu_utilization_percent_mean": 67.708}, "timestamp": "2026-01-30T12:13:09.686623"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4983.73, "latencies_ms": [4983.73], "images_per_second": 0.201, "prompt_tokens": 780, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. paddle: 1\n3. surfboard: 1\n4. water: 1\n5. land: 1\n6. sky: 1\n7. city: 1\n8. buildings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.8, "ram_available_mb": 48024.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.927}, "power_stats": {"power_gpu_soc_mean_watts": 16.207, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.613, "gpu_utilization_percent_mean": 64.927}, "timestamp": "2026-01-30T12:13:16.689481"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5033.331, "latencies_ms": [5033.331], "images_per_second": 0.199, "prompt_tokens": 784, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The person is in the foreground of the image, paddling a paddleboard on the water. The paddleboard is in the middle of the image, and the person is paddling it towards the right side of the image. The background of the image features a shoreline with buildings and trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.19}, "power_stats": {"power_gpu_soc_mean_watts": 16.088, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 7.621, "gpu_utilization_percent_mean": 65.19}, "timestamp": "2026-01-30T12:13:23.774388"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2435.591, "latencies_ms": [2435.591], "images_per_second": 0.411, "prompt_tokens": 778, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is standing on a paddleboard in the ocean, holding a paddle.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.158}, "power_stats": {"power_gpu_soc_mean_watts": 21.987, "power_cpu_cv_mean_watts": 0.969, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 73.158}, "timestamp": "2026-01-30T12:13:28.243630"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4287.935, "latencies_ms": [4287.935], "images_per_second": 0.233, "prompt_tokens": 776, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image is in black and white, with the water being a dark shade and the sky a lighter one. The person is wearing a wetsuit, which is black, and is holding a paddle, which is also black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.829}, "power_stats": {"power_gpu_soc_mean_watts": 17.245, "power_cpu_cv_mean_watts": 1.59, "power_sys_5v0_mean_watts": 7.636, "gpu_utilization_percent_mean": 64.829}, "timestamp": "2026-01-30T12:13:34.550367"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3583.056, "latencies_ms": [3583.056], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A white computer desk with a laptop, keyboard, mouse, and speakers is placed in front of a window with blinds.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14814.6, "ram_available_mb": 48026.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14814.8, "ram_available_mb": 48026.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.067}, "power_stats": {"power_gpu_soc_mean_watts": 21.91, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.088, "gpu_utilization_percent_mean": 70.067}, "timestamp": "2026-01-30T12:13:40.176630"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4076.661, "latencies_ms": [4076.661], "images_per_second": 0.245, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 1, monitor: 1, keyboard: 1, mouse: 1, speakers: 2, printer: 1, lamp: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14814.8, "ram_available_mb": 48026.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14815.0, "ram_available_mb": 48025.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.559}, "power_stats": {"power_gpu_soc_mean_watts": 21.206, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 70.559}, "timestamp": "2026-01-30T12:13:46.272207"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3891.974, "latencies_ms": [3891.974], "images_per_second": 0.257, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The laptop is to the left of the computer monitor, the keyboard is in front of the monitor, and the speakers are to the right of the monitor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14815.0, "ram_available_mb": 48025.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14815.5, "ram_available_mb": 48025.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.25}, "power_stats": {"power_gpu_soc_mean_watts": 21.68, "power_cpu_cv_mean_watts": 1.314, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 72.25}, "timestamp": "2026-01-30T12:13:52.187852"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2860.169, "latencies_ms": [2860.169], "images_per_second": 0.35, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A white desk with a computer, laptop, and speakers on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14815.5, "ram_available_mb": 48025.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.304}, "power_stats": {"power_gpu_soc_mean_watts": 24.697, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.267, "gpu_utilization_percent_mean": 78.304}, "timestamp": "2026-01-30T12:13:57.059129"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3475.331, "latencies_ms": [3475.331], "images_per_second": 0.288, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the desk is made of white wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14817.2, "ram_available_mb": 48023.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.759}, "power_stats": {"power_gpu_soc_mean_watts": 22.348, "power_cpu_cv_mean_watts": 1.105, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 71.759}, "timestamp": "2026-01-30T12:14:02.566505"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5416.059, "latencies_ms": [5416.059], "images_per_second": 0.185, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a bustling highway scene under a concrete overpass, where a green highway sign prominently displays the directions to \"North Ventura 101\" and \"Hollywood Blvd Sunset Blvd\" in white lettering, guiding drivers through the city.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14817.2, "ram_available_mb": 48023.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14817.0, "ram_available_mb": 48023.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.222}, "power_stats": {"power_gpu_soc_mean_watts": 18.595, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.921, "gpu_utilization_percent_mean": 69.222}, "timestamp": "2026-01-30T12:14:10.020460"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5680.791, "latencies_ms": [5680.791], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. sign: 4\n2. car: 3\n3. streetlamp: 1\n4. tree: 1\n5. road: 1\n6. vehicle: 1\n7. road sign: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.0, "ram_available_mb": 48023.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14817.2, "ram_available_mb": 48023.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.377, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 7.947, "gpu_utilization_percent_mean": 68.511}, "timestamp": "2026-01-30T12:14:17.722646"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4184.569, "latencies_ms": [4184.569], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, while the vehicles are in the background. The sign is also above the vehicles, indicating that it is a traffic sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.2, "ram_available_mb": 48023.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14816.9, "ram_available_mb": 48024.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.086}, "power_stats": {"power_gpu_soc_mean_watts": 20.852, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.086}, "timestamp": "2026-01-30T12:14:23.936508"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3115.154, "latencies_ms": [3115.154], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A busy highway with cars and trucks driving under a bridge with signs pointing to different locations.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14816.9, "ram_available_mb": 48024.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.854, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 76.88}, "timestamp": "2026-01-30T12:14:29.064995"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4823.408, "latencies_ms": [4823.408], "images_per_second": 0.207, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image depicts a busy highway with several vehicles, including a black SUV, under a green highway sign that indicates the direction to North Ventura and Hollywood Blvd. The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 19.727, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T12:14:35.933369"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4280.865, "latencies_ms": [4280.865], "images_per_second": 0.234, "prompt_tokens": 1432, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street with a sign on the front that says \"15 Aldwych\".", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14817.6, "ram_available_mb": 48023.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.722}, "power_stats": {"power_gpu_soc_mean_watts": 23.666, "power_cpu_cv_mean_watts": 1.179, "power_sys_5v0_mean_watts": 8.456, "gpu_utilization_percent_mean": 77.722}, "timestamp": "2026-01-30T12:14:42.259825"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5038.74, "latencies_ms": [5038.74], "images_per_second": 0.198, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. red double decker bus\n2. people\n3. trees\n4. buildings\n5. street\n6. license plate\n7. bus number\n8. bus route", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.6, "ram_available_mb": 48023.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.571}, "power_stats": {"power_gpu_soc_mean_watts": 22.584, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.336, "gpu_utilization_percent_mean": 72.571}, "timestamp": "2026-01-30T12:14:49.324513"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5214.12, "latencies_ms": [5214.12], "images_per_second": 0.192, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The red double-decker bus is in the foreground, moving towards the left side of the image. The building in the background is far away from the camera, and the trees are in the middle ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.955}, "power_stats": {"power_gpu_soc_mean_watts": 22.153, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.311, "gpu_utilization_percent_mean": 72.955}, "timestamp": "2026-01-30T12:14:56.557936"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4411.844, "latencies_ms": [4411.844], "images_per_second": 0.227, "prompt_tokens": 1444, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A red double-decker bus is driving down a street in a city, passing by a park with trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.892}, "power_stats": {"power_gpu_soc_mean_watts": 23.807, "power_cpu_cv_mean_watts": 1.136, "power_sys_5v0_mean_watts": 8.413, "gpu_utilization_percent_mean": 73.892}, "timestamp": "2026-01-30T12:15:03.030104"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3540.771, "latencies_ms": [3540.771], "images_per_second": 0.282, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bus is red with a yellow stripe, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.379}, "power_stats": {"power_gpu_soc_mean_watts": 26.233, "power_cpu_cv_mean_watts": 0.842, "power_sys_5v0_mean_watts": 8.595, "gpu_utilization_percent_mean": 82.379}, "timestamp": "2026-01-30T12:15:08.595096"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2896.593, "latencies_ms": [2896.593], "images_per_second": 0.345, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14818.5, "ram_available_mb": 48022.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.917}, "power_stats": {"power_gpu_soc_mean_watts": 24.084, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 76.917}, "timestamp": "2026-01-30T12:15:13.526688"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6117.249, "latencies_ms": [6117.249], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. black and white cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. white wall: 1\n5. white baseboard: 1\n6. white door frame: 1\n7. white door: 1\n8. white wall panel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14816.8, "ram_available_mb": 48024.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.784}, "power_stats": {"power_gpu_soc_mean_watts": 17.828, "power_cpu_cv_mean_watts": 1.727, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 67.784}, "timestamp": "2026-01-30T12:15:21.665136"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4705.113, "latencies_ms": [4705.113], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The black and white cat is positioned to the left of the laptop, which is situated in the middle of the image. The laptop is located in the foreground of the image, while the cat is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14816.8, "ram_available_mb": 48024.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.282}, "power_stats": {"power_gpu_soc_mean_watts": 19.883, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 71.282}, "timestamp": "2026-01-30T12:15:28.417715"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2851.914, "latencies_ms": [2851.914], "images_per_second": 0.351, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A black and white cat is laying on top of a laptop computer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14817.5, "ram_available_mb": 48023.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.087}, "power_stats": {"power_gpu_soc_mean_watts": 24.762, "power_cpu_cv_mean_watts": 0.888, "power_sys_5v0_mean_watts": 8.316, "gpu_utilization_percent_mean": 78.087}, "timestamp": "2026-01-30T12:15:33.286893"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2788.357, "latencies_ms": [2788.357], "images_per_second": 0.359, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is black and white, and the laptop is silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.5, "ram_available_mb": 48023.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14818.0, "ram_available_mb": 48022.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.391}, "power_stats": {"power_gpu_soc_mean_watts": 24.625, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 79.391}, "timestamp": "2026-01-30T12:15:38.090065"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3246.236, "latencies_ms": [3246.236], "images_per_second": 0.308, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two airplanes fly over a bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14818.0, "ram_available_mb": 48022.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14818.0, "ram_available_mb": 48022.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.114, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.166, "gpu_utilization_percent_mean": 73.815}, "timestamp": "2026-01-30T12:15:43.376642"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5613.289, "latencies_ms": [5613.289], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. airplane: 2\n2. bridge: 1\n3. building: 1\n4. city skyline: 1\n5. water: 1\n6. clouds: 1\n7. sky: 1\n8. flags: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14818.0, "ram_available_mb": 48022.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14818.7, "ram_available_mb": 48022.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.277}, "power_stats": {"power_gpu_soc_mean_watts": 18.29, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 68.277}, "timestamp": "2026-01-30T12:15:51.035848"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4279.25, "latencies_ms": [4279.25], "images_per_second": 0.234, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The two airplanes are flying above the Sydney Harbour Bridge, which is positioned in the foreground of the image. The Sydney Opera House is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14818.7, "ram_available_mb": 48022.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.314}, "power_stats": {"power_gpu_soc_mean_watts": 20.898, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 70.314}, "timestamp": "2026-01-30T12:15:57.332394"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3250.739, "latencies_ms": [3250.739], "images_per_second": 0.308, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two airplanes fly over a large bridge and the Sydney Opera House, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14818.1, "ram_available_mb": 48022.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.963}, "power_stats": {"power_gpu_soc_mean_watts": 23.113, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 75.963}, "timestamp": "2026-01-30T12:16:02.617327"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3268.687, "latencies_ms": [3268.687], "images_per_second": 0.306, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the bridge is a dark brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14818.1, "ram_available_mb": 48022.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14817.5, "ram_available_mb": 48023.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.481}, "power_stats": {"power_gpu_soc_mean_watts": 23.022, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 73.481}, "timestamp": "2026-01-30T12:16:07.908530"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3063.034, "latencies_ms": [3063.034], "images_per_second": 0.326, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white photo of a zebra nursing its young in a grassy field.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14817.5, "ram_available_mb": 48023.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.44}, "power_stats": {"power_gpu_soc_mean_watts": 23.584, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 78.44}, "timestamp": "2026-01-30T12:16:12.997956"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2923.356, "latencies_ms": [2923.356], "images_per_second": 0.342, "prompt_tokens": 1113, "response_tokens_est": 15, "n_tiles": 1, "output_text": " zebra: 1\nbaby zebra: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.4, "ram_available_mb": 48023.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.667}, "power_stats": {"power_gpu_soc_mean_watts": 24.366, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 77.667}, "timestamp": "2026-01-30T12:16:17.984520"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6119.988, "latencies_ms": [6119.988], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The zebra is positioned on the left side of the image, with its body facing towards the right side. The baby zebra is positioned on the right side of the image, with its body facing towards the left side. The baby zebra is positioned very close to the mother zebra, with its head near the mother's udder.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.216}, "power_stats": {"power_gpu_soc_mean_watts": 17.766, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.905, "gpu_utilization_percent_mean": 68.216}, "timestamp": "2026-01-30T12:16:26.150482"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2726.937, "latencies_ms": [2726.937], "images_per_second": 0.367, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A zebra is nursing its young in a grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14818.8, "ram_available_mb": 48022.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.318}, "power_stats": {"power_gpu_soc_mean_watts": 24.649, "power_cpu_cv_mean_watts": 0.819, "power_sys_5v0_mean_watts": 8.29, "gpu_utilization_percent_mean": 78.318}, "timestamp": "2026-01-30T12:16:30.915145"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4650.503, "latencies_ms": [4650.503], "images_per_second": 0.215, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is in black and white, with the zebra's stripes standing out against the white background. The lighting is natural, coming from the side, casting shadows and highlighting the texture of the zebra's fur.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14818.8, "ram_available_mb": 48022.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14817.9, "ram_available_mb": 48023.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.154}, "power_stats": {"power_gpu_soc_mean_watts": 19.801, "power_cpu_cv_mean_watts": 1.499, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 67.154}, "timestamp": "2026-01-30T12:16:37.587263"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4070.386, "latencies_ms": [4070.386], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a room with a bed, a small round table, and a chair, all placed in front of a window with a view of a building outside.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14817.9, "ram_available_mb": 48023.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.647}, "power_stats": {"power_gpu_soc_mean_watts": 21.016, "power_cpu_cv_mean_watts": 1.331, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 70.647}, "timestamp": "2026-01-30T12:16:43.692645"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5465.447, "latencies_ms": [5465.447], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. chair: 2\n3. table: 1\n4. lamp: 1\n5. window: 2\n6. door: 1\n7. wall: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.761}, "power_stats": {"power_gpu_soc_mean_watts": 18.495, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.941, "gpu_utilization_percent_mean": 68.761}, "timestamp": "2026-01-30T12:16:51.195556"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4727.948, "latencies_ms": [4727.948], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the window and door to the left and right, respectively. The table and chairs are located in the foreground, while the lamp is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.8, "ram_available_mb": 48023.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14817.3, "ram_available_mb": 48023.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.975}, "power_stats": {"power_gpu_soc_mean_watts": 19.586, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 68.975}, "timestamp": "2026-01-30T12:16:57.943353"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2872.026, "latencies_ms": [2872.026], "images_per_second": 0.348, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A small room with a bed, a table, and a chair.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14817.3, "ram_available_mb": 48023.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14816.7, "ram_available_mb": 48024.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.292}, "power_stats": {"power_gpu_soc_mean_watts": 24.25, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 77.292}, "timestamp": "2026-01-30T12:17:02.855353"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3662.241, "latencies_ms": [3662.241], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The room is painted purple and has a bed with a colorful blanket. The room is lit by natural light coming through the windows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.7, "ram_available_mb": 48024.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.7}, "power_stats": {"power_gpu_soc_mean_watts": 22.136, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 70.7}, "timestamp": "2026-01-30T12:17:08.540955"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3018.831, "latencies_ms": [3018.831], "images_per_second": 0.331, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down the street.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14816.4, "ram_available_mb": 48024.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.4}, "power_stats": {"power_gpu_soc_mean_watts": 24.083, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.271, "gpu_utilization_percent_mean": 76.4}, "timestamp": "2026-01-30T12:17:13.588261"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5427.497, "latencies_ms": [5427.497], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. person: 1\n3. pole: 1\n4. sign: 1\n5. tree: 1\n6. building: 1\n7. street: 1\n8. sidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.4, "ram_available_mb": 48024.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14816.1, "ram_available_mb": 48024.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.836, "power_cpu_cv_mean_watts": 1.611, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T12:17:21.034095"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4333.125, "latencies_ms": [4333.125], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The bus is in the foreground, with the background showing a street and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.1, "ram_available_mb": 48024.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14816.6, "ram_available_mb": 48024.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.529, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 68.306}, "timestamp": "2026-01-30T12:17:27.425529"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3041.626, "latencies_ms": [3041.626], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A purple bus with the number 96 on it is driving down a street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.6, "ram_available_mb": 48024.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14816.6, "ram_available_mb": 48024.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.24}, "power_stats": {"power_gpu_soc_mean_watts": 24.111, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.248, "gpu_utilization_percent_mean": 74.24}, "timestamp": "2026-01-30T12:17:32.518141"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3313.185, "latencies_ms": [3313.185], "images_per_second": 0.302, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The bus is purple with a white roof and has a white license plate. The sky is clear and blue.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14816.6, "ram_available_mb": 48024.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.889}, "power_stats": {"power_gpu_soc_mean_watts": 23.53, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.246, "gpu_utilization_percent_mean": 75.889}, "timestamp": "2026-01-30T12:17:37.863534"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3567.827, "latencies_ms": [3567.827], "images_per_second": 0.28, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a white bowl filled with a bunch of green apples, with the apples being the main focus of the image.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.3}, "power_stats": {"power_gpu_soc_mean_watts": 22.123, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 72.3}, "timestamp": "2026-01-30T12:17:43.477777"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2297.035, "latencies_ms": [2297.035], "images_per_second": 0.435, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " apple: 10", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.105}, "power_stats": {"power_gpu_soc_mean_watts": 25.653, "power_cpu_cv_mean_watts": 0.632, "power_sys_5v0_mean_watts": 8.378, "gpu_utilization_percent_mean": 83.105}, "timestamp": "2026-01-30T12:17:47.799639"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4132.689, "latencies_ms": [4132.689], "images_per_second": 0.242, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The apples are in the foreground, with the bowl placed in the middle of the image. The bowl is located in the foreground, and the apples are placed inside it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14816.8, "ram_available_mb": 48024.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.771, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.4}, "timestamp": "2026-01-30T12:17:53.972222"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3797.306, "latencies_ms": [3797.306], "images_per_second": 0.263, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a dimly lit room, a white bowl cradles a collection of vibrant green apples, their glossy skins reflecting the soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.8, "ram_available_mb": 48024.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14817.5, "ram_available_mb": 48023.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.968}, "power_stats": {"power_gpu_soc_mean_watts": 21.771, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 68.968}, "timestamp": "2026-01-30T12:17:59.795649"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2798.153, "latencies_ms": [2798.153], "images_per_second": 0.357, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The apples are green and shiny, and the bowl is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.5, "ram_available_mb": 48023.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14815.8, "ram_available_mb": 48025.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.957}, "power_stats": {"power_gpu_soc_mean_watts": 24.622, "power_cpu_cv_mean_watts": 0.888, "power_sys_5v0_mean_watts": 8.308, "gpu_utilization_percent_mean": 78.957}, "timestamp": "2026-01-30T12:18:04.639064"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4025.37, "latencies_ms": [4025.37], "images_per_second": 0.248, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter, catcher, and umpire all in position, ready to react to the pitch.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14815.8, "ram_available_mb": 48025.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14815.6, "ram_available_mb": 48025.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.818}, "power_stats": {"power_gpu_soc_mean_watts": 21.412, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.133, "gpu_utilization_percent_mean": 70.818}, "timestamp": "2026-01-30T12:18:10.688618"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5680.239, "latencies_ms": [5680.239], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. grass: 1\n7. dirt: 1\n8. net: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14815.6, "ram_available_mb": 48025.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.75}, "power_stats": {"power_gpu_soc_mean_watts": 18.367, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 69.75}, "timestamp": "2026-01-30T12:18:18.397892"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4410.23, "latencies_ms": [4410.23], "images_per_second": 0.227, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The pitcher is standing on the mound, which is located in the middle of the field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14816.2, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.556}, "power_stats": {"power_gpu_soc_mean_watts": 20.36, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 66.556}, "timestamp": "2026-01-30T12:18:24.826303"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6900.175, "latencies_ms": [6900.175], "images_per_second": 0.145, "prompt_tokens": 1111, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment in a baseball game, with the batter, wearing a red helmet and white uniform, in the midst of swinging his bat at a pitch. The umpire, dressed in a blue shirt and black pants, stands behind the catcher, who is crouched in anticipation. The field is a vibrant green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14816.2, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 14816.6, "ram_available_mb": 48024.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.655}, "power_stats": {"power_gpu_soc_mean_watts": 16.816, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 7.858, "gpu_utilization_percent_mean": 66.655}, "timestamp": "2026-01-30T12:18:33.749333"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6353.001, "latencies_ms": [6353.001], "images_per_second": 0.157, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the lush green of the field contrasting against the brown dirt of the infield. The players are dressed in crisp white uniforms, their red helmets adding a pop of color to the scene. The lighting is natural, casting a warm glow over the field as the sun shines down on the game.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14816.6, "ram_available_mb": 48024.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.444}, "power_stats": {"power_gpu_soc_mean_watts": 17.428, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 7.91, "gpu_utilization_percent_mean": 66.444}, "timestamp": "2026-01-30T12:18:42.132777"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3962.058, "latencies_ms": [3962.058], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white cake with red and blue berries is on a table with a red tablecloth, surrounded by wine glasses, plates of cheese, and bread.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14817.1, "ram_available_mb": 48023.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14817.0, "ram_available_mb": 48023.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.455}, "power_stats": {"power_gpu_soc_mean_watts": 21.082, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-30T12:18:48.168025"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4275.191, "latencies_ms": [4275.191], "images_per_second": 0.234, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cake: 1, glasses: 10, plates: 10, knives: 2, cups: 1, bowls: 1, grapes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14817.0, "ram_available_mb": 48023.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14816.5, "ram_available_mb": 48024.4, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.425, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 71.639}, "timestamp": "2026-01-30T12:18:54.469811"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5551.336, "latencies_ms": [5551.336], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The cake is located in the foreground, to the left of the plates of cheese and grapes. The plates of cheese and grapes are in the middle of the table, with the cake to the left of them. The glasses are located in the background, behind the plates of cheese and grapes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.106}, "power_stats": {"power_gpu_soc_mean_watts": 18.508, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 69.106}, "timestamp": "2026-01-30T12:19:02.038287"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3035.494, "latencies_ms": [3035.494], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A table is set with a cake, plates of food, and glasses of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14816.3, "ram_available_mb": 48024.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.36}, "power_stats": {"power_gpu_soc_mean_watts": 24.058, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 75.36}, "timestamp": "2026-01-30T12:19:07.121153"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4061.666, "latencies_ms": [4061.666], "images_per_second": 0.246, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image features a red tablecloth, with a white cake and a plate of food on it. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.235}, "power_stats": {"power_gpu_soc_mean_watts": 21.061, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 73.235}, "timestamp": "2026-01-30T12:19:13.218307"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3020.74, "latencies_ms": [3020.74], "images_per_second": 0.331, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is riding a wave on a blue surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.405, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-30T12:19:18.295845"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5639.124, "latencies_ms": [5639.124], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. clouds: 0\n7. land: 0\n8. surfboard: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14816.0, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14815.9, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.298, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.938, "gpu_utilization_percent_mean": 66.638}, "timestamp": "2026-01-30T12:19:25.954018"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4520.145, "latencies_ms": [4520.145], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave in the background. The surfer is on the left side of the wave, and the wave is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14815.9, "ram_available_mb": 48024.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.105}, "power_stats": {"power_gpu_soc_mean_watts": 20.005, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 72.105}, "timestamp": "2026-01-30T12:19:32.496738"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2924.68, "latencies_ms": [2924.68], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.861, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T12:19:37.461414"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5826.994, "latencies_ms": [5826.994], "images_per_second": 0.172, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a surfer in a black wetsuit riding a wave in the ocean, with the water appearing a deep green color and the sky not visible in the frame. The lighting is natural, suggesting it is daytime, and the surfer is in the foreground, with the wave in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14815.9, "ram_available_mb": 48025.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14814.9, "ram_available_mb": 48026.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.837}, "power_stats": {"power_gpu_soc_mean_watts": 18.153, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 67.837}, "timestamp": "2026-01-30T12:19:45.321459"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3216.814, "latencies_ms": [3216.814], "images_per_second": 0.311, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14814.9, "ram_available_mb": 48026.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14815.1, "ram_available_mb": 48025.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.275, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 75.654}, "timestamp": "2026-01-30T12:19:50.560614"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4924.456, "latencies_ms": [4924.456], "images_per_second": 0.203, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. group of children\n2. brick wall\n3. children's clothing\n4. children's shoes\n5. children's hair\n6. children's faces\n7. children's eyes\n8. children's noses", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 14815.1, "ram_available_mb": 48025.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14815.1, "ram_available_mb": 48025.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.585}, "power_stats": {"power_gpu_soc_mean_watts": 19.457, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 68.585}, "timestamp": "2026-01-30T12:19:57.501153"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5135.24, "latencies_ms": [5135.24], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The group of children is positioned in front of a brick building, with the children sitting on the ground and standing behind them. The children are arranged in rows, with some sitting and others standing, creating a sense of depth and perspective in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14814.5, "ram_available_mb": 48026.4, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14814.4, "ram_available_mb": 48026.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.767}, "power_stats": {"power_gpu_soc_mean_watts": 19.055, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 68.767}, "timestamp": "2026-01-30T12:20:04.683215"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3225.921, "latencies_ms": [3225.921], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of children are posing for a black and white photo in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14814.4, "ram_available_mb": 48026.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14814.8, "ram_available_mb": 48026.1, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.115}, "power_stats": {"power_gpu_soc_mean_watts": 23.443, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 72.115}, "timestamp": "2026-01-30T12:20:09.930032"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5681.809, "latencies_ms": [5681.809], "images_per_second": 0.176, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is a black and white photograph with a grainy texture, capturing a moment of unity among the children. The lighting is soft and diffused, creating a sense of nostalgia and warmth. The children are dressed in their school uniforms, which are predominantly white and black, suggesting a formal setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14814.8, "ram_available_mb": 48026.1, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 14807.9, "ram_available_mb": 48033.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.604}, "power_stats": {"power_gpu_soc_mean_watts": 18.34, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 68.604}, "timestamp": "2026-01-30T12:20:17.645784"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3101.658, "latencies_ms": [3101.658], "images_per_second": 0.322, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate of bread and a knife on a table with a wine glass in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14807.9, "ram_available_mb": 48033.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14808.2, "ram_available_mb": 48032.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.154}, "power_stats": {"power_gpu_soc_mean_watts": 23.69, "power_cpu_cv_mean_watts": 1.093, "power_sys_5v0_mean_watts": 8.241, "gpu_utilization_percent_mean": 76.154}, "timestamp": "2026-01-30T12:20:22.773344"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4231.585, "latencies_ms": [4231.585], "images_per_second": 0.236, "prompt_tokens": 1114, "response_tokens_est": 36, "n_tiles": 1, "output_text": " knife: 1, plate: 1, bread: 1, cup: 1, wine glass: 1, napkin: 1, butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14808.2, "ram_available_mb": 48032.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14808.2, "ram_available_mb": 48032.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.371}, "power_stats": {"power_gpu_soc_mean_watts": 20.949, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 71.371}, "timestamp": "2026-01-30T12:20:29.032283"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6163.324, "latencies_ms": [6163.324], "images_per_second": 0.162, "prompt_tokens": 1118, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the bread and butter knife in the center, and the wine glass in the background. The bread is placed on the left side of the plate, while the butter knife is on the right side. The wine glass is located behind the plate, and the person is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14808.2, "ram_available_mb": 48032.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14809.1, "ram_available_mb": 48031.8, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.706}, "power_stats": {"power_gpu_soc_mean_watts": 17.793, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 68.706}, "timestamp": "2026-01-30T12:20:37.208749"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3527.969, "latencies_ms": [3527.969], "images_per_second": 0.283, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " In a cozy restaurant, a plate of bread and cheese is served on a table, accompanied by a glass of red wine.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14809.1, "ram_available_mb": 48031.8, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14809.9, "ram_available_mb": 48031.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.759}, "power_stats": {"power_gpu_soc_mean_watts": 22.372, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 71.759}, "timestamp": "2026-01-30T12:20:42.782383"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4018.735, "latencies_ms": [4018.735], "images_per_second": 0.249, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a knife, and a wine glass. The lighting is natural, and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14809.9, "ram_available_mb": 48031.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14810.6, "ram_available_mb": 48030.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.121}, "power_stats": {"power_gpu_soc_mean_watts": 21.263, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.121}, "timestamp": "2026-01-30T12:20:48.813482"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3968.825, "latencies_ms": [3968.825], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A skier in a colorful outfit is jumping in the air with skis attached, while another skier in a white outfit stands nearby.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14810.6, "ram_available_mb": 48030.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14810.6, "ram_available_mb": 48030.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.273}, "power_stats": {"power_gpu_soc_mean_watts": 20.935, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 69.273}, "timestamp": "2026-01-30T12:20:54.831275"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5660.138, "latencies_ms": [5660.138], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snow: 1\n5. trees: 4\n6. person: 1\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14810.6, "ram_available_mb": 48030.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14810.0, "ram_available_mb": 48030.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.149}, "power_stats": {"power_gpu_soc_mean_watts": 18.397, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.941, "gpu_utilization_percent_mean": 69.149}, "timestamp": "2026-01-30T12:21:02.521185"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4142.745, "latencies_ms": [4142.745], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The skier is in the foreground, jumping over a snow ramp, while the trees are in the background. The skier is closer to the camera than the trees.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14810.0, "ram_available_mb": 48030.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14809.3, "ram_available_mb": 48031.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.853}, "power_stats": {"power_gpu_soc_mean_watts": 20.916, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 71.853}, "timestamp": "2026-01-30T12:21:08.701209"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3651.45, "latencies_ms": [3651.45], "images_per_second": 0.274, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A skier is jumping in the air with skis while wearing a colorful outfit. There are other skiers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14809.3, "ram_available_mb": 48031.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14809.3, "ram_available_mb": 48031.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.833}, "power_stats": {"power_gpu_soc_mean_watts": 22.135, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 71.833}, "timestamp": "2026-01-30T12:21:14.409659"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4623.343, "latencies_ms": [4623.343], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skier in mid-air against a clear blue sky, with snow-covered trees in the background. The skier is wearing a colorful jacket and pants, and is holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14809.3, "ram_available_mb": 48031.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14809.4, "ram_available_mb": 48031.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.105}, "power_stats": {"power_gpu_soc_mean_watts": 19.951, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 71.105}, "timestamp": "2026-01-30T12:21:21.045256"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3111.336, "latencies_ms": [3111.336], "images_per_second": 0.321, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain with ski poles and wearing a green jacket.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14809.4, "ram_available_mb": 48031.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14809.2, "ram_available_mb": 48031.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.467, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 76.36}, "timestamp": "2026-01-30T12:21:26.187140"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5526.848, "latencies_ms": [5526.848], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. ski poles: 2\n3. backpack: 1\n4. snow: 1\n5. rocks: 2\n6. trees: 2\n7. clouds: 2\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14809.2, "ram_available_mb": 48031.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14809.7, "ram_available_mb": 48031.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.404}, "power_stats": {"power_gpu_soc_mean_watts": 18.381, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 68.404}, "timestamp": "2026-01-30T12:21:33.755257"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4491.399, "latencies_ms": [4491.399], "images_per_second": 0.223, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is in the foreground of the image, with the snow-covered landscape and mountains in the background. The person is facing away from the camera, with the mountains and sky visible behind them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14809.7, "ram_available_mb": 48031.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14809.9, "ram_available_mb": 48031.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.405}, "power_stats": {"power_gpu_soc_mean_watts": 20.229, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 71.405}, "timestamp": "2026-01-30T12:21:40.262148"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3271.106, "latencies_ms": [3271.106], "images_per_second": 0.306, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is walking on a snowy mountain trail with ski poles, wearing a green shirt and black pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14809.9, "ram_available_mb": 48031.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14809.9, "ram_available_mb": 48031.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.108, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 75.667}, "timestamp": "2026-01-30T12:21:45.583630"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4874.4, "latencies_ms": [4874.4], "images_per_second": 0.205, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person wearing a green jacket and black pants, standing on a snowy mountain with a clear blue sky and white clouds in the background. The snow is pristine and untouched, with the person's footprints visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14809.9, "ram_available_mb": 48031.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14810.3, "ram_available_mb": 48030.6, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.504, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.463}, "timestamp": "2026-01-30T12:21:52.475446"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2900.144, "latencies_ms": [2900.144], "images_per_second": 0.345, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A banana and a chocolate donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14810.3, "ram_available_mb": 48030.6, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14811.6, "ram_available_mb": 48029.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 23.959, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.259, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T12:21:57.440529"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2986.053, "latencies_ms": [2986.053], "images_per_second": 0.335, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " banana: 1, donut: 1, plastic bag: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14811.6, "ram_available_mb": 48029.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14811.7, "ram_available_mb": 48029.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.292}, "power_stats": {"power_gpu_soc_mean_watts": 24.277, "power_cpu_cv_mean_watts": 0.918, "power_sys_5v0_mean_watts": 8.297, "gpu_utilization_percent_mean": 78.292}, "timestamp": "2026-01-30T12:22:02.469040"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4346.668, "latencies_ms": [4346.668], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is positioned to the left of the donut, which is placed in the center of the image. The banana is in the foreground, while the donut is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14811.7, "ram_available_mb": 48029.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14811.4, "ram_available_mb": 48029.5, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.612, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 69.972}, "timestamp": "2026-01-30T12:22:08.874518"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2899.896, "latencies_ms": [2899.896], "images_per_second": 0.345, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana and a donut are placed in a plastic bag.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14811.4, "ram_available_mb": 48029.5, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14811.9, "ram_available_mb": 48029.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.043}, "power_stats": {"power_gpu_soc_mean_watts": 24.011, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 80.043}, "timestamp": "2026-01-30T12:22:13.788348"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4592.167, "latencies_ms": [4592.167], "images_per_second": 0.218, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a banana and a donut in a plastic bag, with the banana being yellow and the donut being brown. The lighting is dim, and the bag appears to be made of clear plastic.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14811.9, "ram_available_mb": 48029.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14811.0, "ram_available_mb": 48029.9, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.158, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.658}, "timestamp": "2026-01-30T12:22:20.411673"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4341.626, "latencies_ms": [4341.626], "images_per_second": 0.23, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design and the words \"PIRATE'S TREASURES\" is placed on a glass surface next to a large knife.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14811.0, "ram_available_mb": 48029.9, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14810.7, "ram_available_mb": 48030.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.194}, "power_stats": {"power_gpu_soc_mean_watts": 20.556, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 70.194}, "timestamp": "2026-01-30T12:22:26.802607"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3280.605, "latencies_ms": [3280.605], "images_per_second": 0.305, "prompt_tokens": 1113, "response_tokens_est": 20, "n_tiles": 1, "output_text": " mug: 1, knife: 1, glass: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14810.7, "ram_available_mb": 48030.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14810.9, "ram_available_mb": 48030.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.778}, "power_stats": {"power_gpu_soc_mean_watts": 23.093, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 71.778}, "timestamp": "2026-01-30T12:22:32.132967"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4209.421, "latencies_ms": [4209.421], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The mug is located to the left of the knife, which is placed in the foreground of the image. The mug is positioned closer to the camera than the knife.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14810.9, "ram_available_mb": 48030.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14811.9, "ram_available_mb": 48029.0, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.343}, "power_stats": {"power_gpu_soc_mean_watts": 20.674, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.343}, "timestamp": "2026-01-30T12:22:38.359942"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4118.953, "latencies_ms": [4118.953], "images_per_second": 0.243, "prompt_tokens": 1111, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A white mug with a pirate skull and crossbones design is sitting on a glass table. Next to the mug is a large knife with a black handle.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14811.9, "ram_available_mb": 48029.0, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14811.2, "ram_available_mb": 48029.7, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.799, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.5}, "timestamp": "2026-01-30T12:22:44.508257"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3301.881, "latencies_ms": [3301.881], "images_per_second": 0.303, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The mug is white and the knife is black. The mug is on a glass table.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 14811.2, "ram_available_mb": 48029.7, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14806.6, "ram_available_mb": 48034.3, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.519}, "power_stats": {"power_gpu_soc_mean_watts": 22.974, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 75.519}, "timestamp": "2026-01-30T12:22:49.835961"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4619.602, "latencies_ms": [4619.602], "images_per_second": 0.216, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A group of people are gathered around a wooden counter in a wine tasting room, with a man in a white shirt and a woman in a black shirt standing out.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 14806.6, "ram_available_mb": 48034.3, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14805.7, "ram_available_mb": 48035.2, "ram_percent": 23.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.053}, "power_stats": {"power_gpu_soc_mean_watts": 23.205, "power_cpu_cv_mean_watts": 1.254, "power_sys_5v0_mean_watts": 8.399, "gpu_utilization_percent_mean": 74.053}, "timestamp": "2026-01-30T12:22:56.501539"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6128.738, "latencies_ms": [6128.738], "images_per_second": 0.163, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14805.7, "ram_available_mb": 48035.2, "ram_percent": 23.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14798.5, "ram_available_mb": 48042.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.157}, "power_stats": {"power_gpu_soc_mean_watts": 20.672, "power_cpu_cv_mean_watts": 1.578, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 71.157}, "timestamp": "2026-01-30T12:23:04.643205"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7598.908, "latencies_ms": [7598.908], "images_per_second": 0.132, "prompt_tokens": 1450, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The man in the white cap is standing to the left of the man in the blue shirt, who is standing in front of the counter. The woman in the black shirt is standing to the right of the man in the blue shirt, and the man in the white shirt is standing behind the counter. The man in the white cap is standing closer to the camera than the man in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14798.5, "ram_available_mb": 48042.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14795.8, "ram_available_mb": 48045.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.688}, "power_stats": {"power_gpu_soc_mean_watts": 18.771, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 70.688}, "timestamp": "2026-01-30T12:23:14.256392"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4154.133, "latencies_ms": [4154.133], "images_per_second": 0.241, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are gathered in a wine tasting room, standing around a wooden counter with wine bottles on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14795.8, "ram_available_mb": 48045.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14791.3, "ram_available_mb": 48049.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.824}, "power_stats": {"power_gpu_soc_mean_watts": 24.051, "power_cpu_cv_mean_watts": 1.119, "power_sys_5v0_mean_watts": 8.397, "gpu_utilization_percent_mean": 76.824}, "timestamp": "2026-01-30T12:23:20.422490"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4213.204, "latencies_ms": [4213.204], "images_per_second": 0.237, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14791.3, "ram_available_mb": 48049.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14791.0, "ram_available_mb": 48049.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.143}, "power_stats": {"power_gpu_soc_mean_watts": 24.219, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.416, "gpu_utilization_percent_mean": 77.143}, "timestamp": "2026-01-30T12:23:26.650498"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4277.7, "latencies_ms": [4277.7], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, there are two white birds standing in a field of tall grass, with a large body of water and a group of boats docked nearby, under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14791.0, "ram_available_mb": 48049.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14790.1, "ram_available_mb": 48050.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.777, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.057}, "timestamp": "2026-01-30T12:23:32.966990"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5512.239, "latencies_ms": [5512.239], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. birds: 2\n2. grass: 1\n3. water: 1\n4. sky: 1\n5. clouds: 1\n6. boats: 1\n7. dock: 1\n8. crane: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14790.1, "ram_available_mb": 48050.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14790.0, "ram_available_mb": 48050.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.396, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 69.043}, "timestamp": "2026-01-30T12:23:40.502159"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3706.012, "latencies_ms": [3706.012], "images_per_second": 0.27, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The two white birds are in the foreground, while the boats are in the background. The birds are closer to the camera than the boats.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14790.0, "ram_available_mb": 48050.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14789.3, "ram_available_mb": 48051.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.968}, "power_stats": {"power_gpu_soc_mean_watts": 22.1, "power_cpu_cv_mean_watts": 1.266, "power_sys_5v0_mean_watts": 8.144, "gpu_utilization_percent_mean": 71.968}, "timestamp": "2026-01-30T12:23:46.268984"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4369.561, "latencies_ms": [4369.561], "images_per_second": 0.229, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " In the foreground, two white birds are standing in a field of tall grass. In the background, there is a body of water with several boats docked, and a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14789.3, "ram_available_mb": 48051.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14788.7, "ram_available_mb": 48052.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.479, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.306}, "timestamp": "2026-01-30T12:23:52.650792"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3533.91, "latencies_ms": [3533.91], "images_per_second": 0.283, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a vibrant green field with two white birds, a cloudy sky, and a body of water in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14788.7, "ram_available_mb": 48052.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14788.1, "ram_available_mb": 48052.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.66, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.18, "gpu_utilization_percent_mean": 72.379}, "timestamp": "2026-01-30T12:23:58.230254"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3350.5, "latencies_ms": [3350.5], "images_per_second": 0.298, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom with a checkered tile wall and a window.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14788.1, "ram_available_mb": 48052.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14788.0, "ram_available_mb": 48052.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.655, "power_cpu_cv_mean_watts": 1.13, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 75.536}, "timestamp": "2026-01-30T12:24:03.631448"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6275.422, "latencies_ms": [6275.422], "images_per_second": 0.159, "prompt_tokens": 1114, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. man: 1\n2. toilet: 1\n3. man's pants: 1\n4. man's shirt: 1\n5. man's shoes: 1\n6. man's socks: 1\n7. man's belt: 1\n8. man's belt buckle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14788.0, "ram_available_mb": 48052.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14788.5, "ram_available_mb": 48052.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.226}, "power_stats": {"power_gpu_soc_mean_watts": 17.575, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 7.935, "gpu_utilization_percent_mean": 68.226}, "timestamp": "2026-01-30T12:24:11.942214"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4396.631, "latencies_ms": [4396.631], "images_per_second": 0.227, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the toilet, which is located in the foreground of the image. The sink is positioned to the left of the toilet, and the window is located above the sink.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14788.5, "ram_available_mb": 48052.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14788.6, "ram_available_mb": 48052.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.431, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T12:24:18.363359"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3059.15, "latencies_ms": [3059.15], "images_per_second": 0.327, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is sitting on a toilet in a bathroom, wearing a shirt and pants.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14788.6, "ram_available_mb": 48052.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.44}, "power_stats": {"power_gpu_soc_mean_watts": 23.689, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 76.44}, "timestamp": "2026-01-30T12:24:23.434629"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3210.786, "latencies_ms": [3210.786], "images_per_second": 0.311, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is in black and white, and the man is wearing a black shirt and jeans.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.407}, "power_stats": {"power_gpu_soc_mean_watts": 23.138, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.172, "gpu_utilization_percent_mean": 76.407}, "timestamp": "2026-01-30T12:24:28.696185"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3598.943, "latencies_ms": [3598.943], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a group of people are standing on a snow-covered mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14788.8, "ram_available_mb": 48052.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14791.0, "ram_available_mb": 48049.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.067}, "power_stats": {"power_gpu_soc_mean_watts": 22.317, "power_cpu_cv_mean_watts": 1.254, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 72.067}, "timestamp": "2026-01-30T12:24:34.358765"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5782.936, "latencies_ms": [5782.936], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. mountain: 1\n2. people: 4\n3. ski tracks: 3\n4. snow: 1\n5. rocks: 1\n6. sky: 1\n7. mountain peak: 1\n8. snow-covered slope: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14791.0, "ram_available_mb": 48049.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14791.0, "ram_available_mb": 48049.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.06, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T12:24:42.153787"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4767.461, "latencies_ms": [4767.461], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The group of people is positioned in the foreground of the image, with the mountain range in the background. The mountain range is located to the right of the group, and the sky is visible above the mountain range.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14791.0, "ram_available_mb": 48049.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14790.6, "ram_available_mb": 48050.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.425}, "power_stats": {"power_gpu_soc_mean_watts": 19.461, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 70.425}, "timestamp": "2026-01-30T12:24:48.939256"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3293.706, "latencies_ms": [3293.706], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are standing on a snowy mountain, with a large rock formation in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14790.6, "ram_available_mb": 48050.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14790.5, "ram_available_mb": 48050.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.778}, "power_stats": {"power_gpu_soc_mean_watts": 23.169, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 70.778}, "timestamp": "2026-01-30T12:24:54.263857"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5173.248, "latencies_ms": [5173.248], "images_per_second": 0.193, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a group of people standing on a snow-covered mountain, with the sky above them being a clear blue. The snow is pristine white, and the mountain's surface is rugged and rocky, with some areas appearing to be covered in snow.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14790.5, "ram_available_mb": 48050.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14790.3, "ram_available_mb": 48050.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.791}, "power_stats": {"power_gpu_soc_mean_watts": 18.979, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 67.791}, "timestamp": "2026-01-30T12:25:01.450726"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3926.832, "latencies_ms": [3926.832], "images_per_second": 0.255, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A white bowl filled with rice, broccoli, and a red bean dish is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 26.7, "ram_used_mb": 14790.3, "ram_available_mb": 48050.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14790.2, "ram_available_mb": 48050.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.719}, "power_stats": {"power_gpu_soc_mean_watts": 24.554, "power_cpu_cv_mean_watts": 1.026, "power_sys_5v0_mean_watts": 8.531, "gpu_utilization_percent_mean": 78.719}, "timestamp": "2026-01-30T12:25:07.410056"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3838.104, "latencies_ms": [3838.104], "images_per_second": 0.261, "prompt_tokens": 1446, "response_tokens_est": 19, "n_tiles": 1, "output_text": " broccoli: 2, rice: 1, bean: 1, vegetable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14790.2, "ram_available_mb": 48050.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14790.5, "ram_available_mb": 48050.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.188}, "power_stats": {"power_gpu_soc_mean_watts": 25.291, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.485, "gpu_utilization_percent_mean": 79.188}, "timestamp": "2026-01-30T12:25:13.279144"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5291.858, "latencies_ms": [5291.858], "images_per_second": 0.189, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The broccoli is located to the left of the rice, which is in the center of the bowl. The red bean dish is on top of the rice, and the white rice is on the bottom of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14790.5, "ram_available_mb": 48050.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14791.4, "ram_available_mb": 48049.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.591}, "power_stats": {"power_gpu_soc_mean_watts": 21.981, "power_cpu_cv_mean_watts": 1.429, "power_sys_5v0_mean_watts": 8.324, "gpu_utilization_percent_mean": 73.591}, "timestamp": "2026-01-30T12:25:20.614618"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3212.248, "latencies_ms": [3212.248], "images_per_second": 0.311, "prompt_tokens": 1444, "response_tokens_est": 9, "n_tiles": 1, "output_text": " A bowl of food is on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14791.4, "ram_available_mb": 48049.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14789.9, "ram_available_mb": 48051.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.962}, "power_stats": {"power_gpu_soc_mean_watts": 26.985, "power_cpu_cv_mean_watts": 0.723, "power_sys_5v0_mean_watts": 8.637, "gpu_utilization_percent_mean": 82.962}, "timestamp": "2026-01-30T12:25:25.858947"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3260.623, "latencies_ms": [3260.623], "images_per_second": 0.307, "prompt_tokens": 1442, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The bowl is white and the food is colorful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14789.9, "ram_available_mb": 48051.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14790.4, "ram_available_mb": 48050.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.037}, "power_stats": {"power_gpu_soc_mean_watts": 26.758, "power_cpu_cv_mean_watts": 0.786, "power_sys_5v0_mean_watts": 8.628, "gpu_utilization_percent_mean": 80.037}, "timestamp": "2026-01-30T12:25:31.139835"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3793.768, "latencies_ms": [3793.768], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp, wearing black and white sneakers with a checkered pattern on the bottom.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14790.4, "ram_available_mb": 48050.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14786.8, "ram_available_mb": 48054.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.548}, "power_stats": {"power_gpu_soc_mean_watts": 21.625, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.106, "gpu_utilization_percent_mean": 73.548}, "timestamp": "2026-01-30T12:25:36.977384"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6259.26, "latencies_ms": [6259.26], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. wooden plank: 1\n4. grass: 1\n5. wooden board: 1\n6. white letters: 1\n7. black and white checkered pattern: 1\n8. black and white shoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14786.8, "ram_available_mb": 48054.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14784.9, "ram_available_mb": 48056.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.981}, "power_stats": {"power_gpu_soc_mean_watts": 17.598, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 68.981}, "timestamp": "2026-01-30T12:25:45.298969"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4043.212, "latencies_ms": [4043.212], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The skateboard is in the foreground, with the person's feet on it. The person is wearing jeans, and the skateboard is on a wooden ramp.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14784.9, "ram_available_mb": 48056.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14785.3, "ram_available_mb": 48055.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.118}, "power_stats": {"power_gpu_soc_mean_watts": 20.836, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 72.118}, "timestamp": "2026-01-30T12:25:51.372948"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3038.134, "latencies_ms": [3038.134], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is riding a skateboard on a wooden ramp in a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14785.3, "ram_available_mb": 48055.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14781.6, "ram_available_mb": 48059.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.898, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.252, "gpu_utilization_percent_mean": 77.56}, "timestamp": "2026-01-30T12:25:56.461486"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4511.865, "latencies_ms": [4511.865], "images_per_second": 0.222, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a person wearing black and white sneakers with a checkered pattern on the bottom, standing on a wooden ramp. The lighting is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14781.6, "ram_available_mb": 48059.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14781.3, "ram_available_mb": 48059.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.065, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 70.342}, "timestamp": "2026-01-30T12:26:03.003156"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3027.248, "latencies_ms": [3027.248], "images_per_second": 0.33, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14781.3, "ram_available_mb": 48059.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14781.6, "ram_available_mb": 48059.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.72}, "power_stats": {"power_gpu_soc_mean_watts": 23.614, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 70.72}, "timestamp": "2026-01-30T12:26:08.099399"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2235.205, "latencies_ms": [2235.205], "images_per_second": 0.447, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14781.6, "ram_available_mb": 48059.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 14782.1, "ram_available_mb": 48058.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.167}, "power_stats": {"power_gpu_soc_mean_watts": 25.695, "power_cpu_cv_mean_watts": 0.623, "power_sys_5v0_mean_watts": 8.355, "gpu_utilization_percent_mean": 85.167}, "timestamp": "2026-01-30T12:26:12.372214"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4741.65, "latencies_ms": [4741.65], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The bananas are located in the foreground of the image, with the keyboard and computer monitor in the background. The bananas are positioned to the left of the keyboard, and the computer monitor is to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14782.1, "ram_available_mb": 48058.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14782.1, "ram_available_mb": 48058.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.692}, "power_stats": {"power_gpu_soc_mean_watts": 19.881, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 69.692}, "timestamp": "2026-01-30T12:26:19.148340"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3051.972, "latencies_ms": [3051.972], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bunch of bananas are on a desk with a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14782.1, "ram_available_mb": 48058.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14782.4, "ram_available_mb": 48058.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.582, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 72.56}, "timestamp": "2026-01-30T12:26:24.258046"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2938.36, "latencies_ms": [2938.36], "images_per_second": 0.34, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14782.4, "ram_available_mb": 48058.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14782.4, "ram_available_mb": 48058.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.875}, "power_stats": {"power_gpu_soc_mean_watts": 24.195, "power_cpu_cv_mean_watts": 0.918, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 76.875}, "timestamp": "2026-01-30T12:26:29.244315"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2972.091, "latencies_ms": [2972.091], "images_per_second": 0.336, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A plate of food with rice, vegetables, and chicken is on a table.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14782.4, "ram_available_mb": 48058.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14782.6, "ram_available_mb": 48058.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.125}, "power_stats": {"power_gpu_soc_mean_watts": 24.31, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 8.303, "gpu_utilization_percent_mean": 75.125}, "timestamp": "2026-01-30T12:26:34.240401"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4453.53, "latencies_ms": [4453.53], "images_per_second": 0.225, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " plate: 1, fork: 1, knife: 1, glass: 1, rice: 1, carrots: 1, broccoli: 1, cauliflower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14782.6, "ram_available_mb": 48058.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14782.6, "ram_available_mb": 48058.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.186, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 71.324}, "timestamp": "2026-01-30T12:26:40.732392"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4459.894, "latencies_ms": [4459.894], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the glass of water is in the background. The fork is on the left side of the plate, and the spoon is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14782.6, "ram_available_mb": 48058.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14780.8, "ram_available_mb": 48060.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.568}, "power_stats": {"power_gpu_soc_mean_watts": 20.475, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.568}, "timestamp": "2026-01-30T12:26:47.227774"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2899.548, "latencies_ms": [2899.548], "images_per_second": 0.345, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food is on a table with a glass of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14780.8, "ram_available_mb": 48060.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14781.1, "ram_available_mb": 48059.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.167}, "power_stats": {"power_gpu_soc_mean_watts": 23.959, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 75.167}, "timestamp": "2026-01-30T12:26:52.155218"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3636.151, "latencies_ms": [3636.151], "images_per_second": 0.275, "prompt_tokens": 1109, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The plate is white and red, and the food is colorful. The lighting is natural, and the table is made of wood.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14781.1, "ram_available_mb": 48059.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14779.8, "ram_available_mb": 48061.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.088, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 71.5}, "timestamp": "2026-01-30T12:26:57.838957"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4064.374, "latencies_ms": [4064.374], "images_per_second": 0.246, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A young girl in a colorful dress is playing with a Wii remote in a living room with a couch, a coffee table, and a staircase in the background.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14779.8, "ram_available_mb": 48061.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14779.6, "ram_available_mb": 48061.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.636}, "power_stats": {"power_gpu_soc_mean_watts": 21.224, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 72.636}, "timestamp": "2026-01-30T12:27:03.926752"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5562.908, "latencies_ms": [5562.908], "images_per_second": 0.18, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. couch: 1\n2. rug: 1\n3. chair: 1\n4. table: 1\n5. sofa: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14779.6, "ram_available_mb": 48061.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14774.1, "ram_available_mb": 48066.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.681}, "power_stats": {"power_gpu_soc_mean_watts": 18.389, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.924, "gpu_utilization_percent_mean": 67.681}, "timestamp": "2026-01-30T12:27:11.526417"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4612.42, "latencies_ms": [4612.42], "images_per_second": 0.217, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The couch is located in the background, with the girl standing in the foreground. The person in the white dress is standing near the couch, while the person in the green shirt is standing near the bar.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14774.1, "ram_available_mb": 48066.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14773.7, "ram_available_mb": 48067.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.205}, "power_stats": {"power_gpu_soc_mean_watts": 19.737, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.205}, "timestamp": "2026-01-30T12:27:18.166666"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3538.693, "latencies_ms": [3538.693], "images_per_second": 0.283, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are gathered in a living room, with a young girl playing with a toy in the center of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14773.7, "ram_available_mb": 48067.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.793}, "power_stats": {"power_gpu_soc_mean_watts": 22.726, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 72.793}, "timestamp": "2026-01-30T12:27:23.718796"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3335.797, "latencies_ms": [3335.797], "images_per_second": 0.3, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from the windows, and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.714}, "power_stats": {"power_gpu_soc_mean_watts": 23.27, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 74.714}, "timestamp": "2026-01-30T12:27:29.086570"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3319.195, "latencies_ms": [3319.195], "images_per_second": 0.301, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with tables and chairs, and other people in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.519}, "power_stats": {"power_gpu_soc_mean_watts": 23.091, "power_cpu_cv_mean_watts": 1.142, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 71.519}, "timestamp": "2026-01-30T12:27:34.433864"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5470.018, "latencies_ms": [5470.018], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. man: 1\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.457}, "power_stats": {"power_gpu_soc_mean_watts": 18.498, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.936, "gpu_utilization_percent_mean": 69.457}, "timestamp": "2026-01-30T12:27:41.932429"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6265.445, "latencies_ms": [6265.445], "images_per_second": 0.16, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The man in the dark suit is standing to the right of the man in the patterned shirt, and the man in the dark suit is in the foreground of the image. The man in the patterned shirt is standing to the left of the man in the dark suit, and the man in the patterned shirt is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14773.6, "ram_available_mb": 48067.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14773.2, "ram_available_mb": 48067.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.075}, "power_stats": {"power_gpu_soc_mean_watts": 17.558, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 66.075}, "timestamp": "2026-01-30T12:27:50.217461"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2894.629, "latencies_ms": [2894.629], "images_per_second": 0.345, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are shaking hands in a large room with many other people.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14773.2, "ram_available_mb": 48067.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14772.6, "ram_available_mb": 48068.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.083}, "power_stats": {"power_gpu_soc_mean_watts": 24.144, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 76.083}, "timestamp": "2026-01-30T12:27:55.147019"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3474.58, "latencies_ms": [3474.58], "images_per_second": 0.288, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with warm lighting, and the attendees are dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14772.6, "ram_available_mb": 48068.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14772.6, "ram_available_mb": 48068.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.897}, "power_stats": {"power_gpu_soc_mean_watts": 22.48, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.133, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-30T12:28:00.637922"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3081.476, "latencies_ms": [3081.476], "images_per_second": 0.325, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a white shirt and a striped tie is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14772.6, "ram_available_mb": 48068.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.48}, "power_stats": {"power_gpu_soc_mean_watts": 23.642, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 75.48}, "timestamp": "2026-01-30T12:28:05.761873"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5501.618, "latencies_ms": [5501.618], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tie: 1\n2. shirt: 1\n3. hand: 1\n4. person: 1\n5. tie: 1\n6. shirt: 1\n7. hand: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14772.2, "ram_available_mb": 48068.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.17}, "power_stats": {"power_gpu_soc_mean_watts": 18.386, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.937, "gpu_utilization_percent_mean": 65.17}, "timestamp": "2026-01-30T12:28:13.304363"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4413.566, "latencies_ms": [4413.566], "images_per_second": 0.227, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is standing in the foreground, wearing a white shirt and a striped tie. The background is dark and out of focus, suggesting that the man is in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14771.8, "ram_available_mb": 48069.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14771.8, "ram_available_mb": 48069.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.342, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-30T12:28:19.730134"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2927.311, "latencies_ms": [2927.311], "images_per_second": 0.342, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man wearing a tie and a shirt is standing in a dark room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14771.8, "ram_available_mb": 48069.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14771.2, "ram_available_mb": 48069.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.906, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T12:28:24.679725"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3358.891, "latencies_ms": [3358.891], "images_per_second": 0.298, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The man is wearing a white shirt and a striped tie. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14771.2, "ram_available_mb": 48069.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14770.2, "ram_available_mb": 48070.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.036}, "power_stats": {"power_gpu_soc_mean_watts": 22.951, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 75.036}, "timestamp": "2026-01-30T12:28:30.073245"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3768.922, "latencies_ms": [3768.922], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A room with a red chair, a blue and red plaid couch, a TV on a stand, and a whiteboard with writing on it.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 14770.2, "ram_available_mb": 48070.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14769.9, "ram_available_mb": 48071.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.355}, "power_stats": {"power_gpu_soc_mean_watts": 22.024, "power_cpu_cv_mean_watts": 1.266, "power_sys_5v0_mean_watts": 8.157, "gpu_utilization_percent_mean": 72.355}, "timestamp": "2026-01-30T12:28:35.877549"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3474.683, "latencies_ms": [3474.683], "images_per_second": 0.288, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " chair: 1, couch: 2, television: 1, whiteboard: 1, poster: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14769.9, "ram_available_mb": 48071.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14769.9, "ram_available_mb": 48071.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.7, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 74.724}, "timestamp": "2026-01-30T12:28:41.398375"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5562.31, "latencies_ms": [5562.31], "images_per_second": 0.18, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red armchair is positioned to the left of the television, which is placed on a wooden stand in the center of the room. The blue and red plaid couch is located to the right of the television, and the whiteboard is mounted on the wall to the left of the television.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14769.9, "ram_available_mb": 48071.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14769.8, "ram_available_mb": 48071.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.913}, "power_stats": {"power_gpu_soc_mean_watts": 18.637, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 68.913}, "timestamp": "2026-01-30T12:28:48.981039"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2810.269, "latencies_ms": [2810.269], "images_per_second": 0.356, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A room with a TV, chairs, and a whiteboard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14769.8, "ram_available_mb": 48071.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14770.0, "ram_available_mb": 48070.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.028, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 74.652}, "timestamp": "2026-01-30T12:28:53.818703"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2791.789, "latencies_ms": [2791.789], "images_per_second": 0.358, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The room is painted yellow and has a plaid couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.0, "ram_available_mb": 48070.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14769.9, "ram_available_mb": 48070.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.391}, "power_stats": {"power_gpu_soc_mean_watts": 24.22, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 75.391}, "timestamp": "2026-01-30T12:28:58.666894"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3673.179, "latencies_ms": [3673.179], "images_per_second": 0.272, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14769.9, "ram_available_mb": 48070.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.3}, "power_stats": {"power_gpu_soc_mean_watts": 25.711, "power_cpu_cv_mean_watts": 1.014, "power_sys_5v0_mean_watts": 8.61, "gpu_utilization_percent_mean": 81.3}, "timestamp": "2026-01-30T12:29:04.365153"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7326.095, "latencies_ms": [7326.095], "images_per_second": 0.136, "prompt_tokens": 1446, "response_tokens_est": 76, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wetsuit: 1\n4. Wetsuit sleeve: 1\n5. Wetsuit leg: 1\n6. Wetsuit arm: 1\n7. Wetsuit chest: 1\n8. Wetsuit back: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.328}, "power_stats": {"power_gpu_soc_mean_watts": 19.091, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 70.328}, "timestamp": "2026-01-30T12:29:13.721223"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5359.129, "latencies_ms": [5359.129], "images_per_second": 0.187, "prompt_tokens": 1450, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that is in the middle of the image. The surfer is wearing a yellow shirt and black shorts, and is positioned on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14770.3, "ram_available_mb": 48070.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.205}, "power_stats": {"power_gpu_soc_mean_watts": 21.916, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 8.309, "gpu_utilization_percent_mean": 72.205}, "timestamp": "2026-01-30T12:29:21.111378"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3945.146, "latencies_ms": [3945.146], "images_per_second": 0.253, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14770.3, "ram_available_mb": 48070.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14769.6, "ram_available_mb": 48071.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.121}, "power_stats": {"power_gpu_soc_mean_watts": 25.01, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.499, "gpu_utilization_percent_mean": 78.121}, "timestamp": "2026-01-30T12:29:27.095265"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4206.381, "latencies_ms": [4206.381], "images_per_second": 0.238, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a yellow shirt and black pants, and the water is a greenish-blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14769.6, "ram_available_mb": 48071.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14768.6, "ram_available_mb": 48072.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.514}, "power_stats": {"power_gpu_soc_mean_watts": 23.604, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 8.343, "gpu_utilization_percent_mean": 75.514}, "timestamp": "2026-01-30T12:29:33.362836"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3046.79, "latencies_ms": [3046.79], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14768.6, "ram_available_mb": 48072.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14768.5, "ram_available_mb": 48072.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.931, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 77.28}, "timestamp": "2026-01-30T12:29:38.469117"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4176.87, "latencies_ms": [4176.87], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. black cat\n2. laptop\n3. computer monitor\n4. keyboard\n5. mouse\n6. phone\n7. mousepad\n8. desk", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14768.5, "ram_available_mb": 48072.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14768.5, "ram_available_mb": 48072.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.857, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 71.971}, "timestamp": "2026-01-30T12:29:44.672818"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4762.702, "latencies_ms": [4762.702], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, with its head turned towards the computer screen, which is located in the middle ground. The laptop is situated to the left of the cat, while the phone is placed to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.5, "ram_available_mb": 48072.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.975}, "power_stats": {"power_gpu_soc_mean_watts": 19.753, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 71.975}, "timestamp": "2026-01-30T12:29:51.456132"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3122.944, "latencies_ms": [3122.944], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black cat is sitting in front of a computer monitor, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14768.5, "ram_available_mb": 48072.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.659, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.208, "gpu_utilization_percent_mean": 78.76}, "timestamp": "2026-01-30T12:29:56.592254"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5551.109, "latencies_ms": [5551.109], "images_per_second": 0.18, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a close-up of a black cat sitting in front of a computer screen, with the cat's head turned to the side, and the screen displaying a webpage with text. The lighting in the image is bright, and the cat's fur appears to be soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14768.5, "ram_available_mb": 48072.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14768.7, "ram_available_mb": 48072.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.915}, "power_stats": {"power_gpu_soc_mean_watts": 18.507, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 68.915}, "timestamp": "2026-01-30T12:30:04.181784"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4250.145, "latencies_ms": [4250.145], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of people, including a man in a blue shirt and a child in a pink jacket, are cutting a red ribbon with a pair of scissors in front of a building.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14768.7, "ram_available_mb": 48072.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.343}, "power_stats": {"power_gpu_soc_mean_watts": 20.709, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 70.343}, "timestamp": "2026-01-30T12:30:10.483082"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5929.854, "latencies_ms": [5929.854], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. People: 10\n2. Balloons: 2\n3. Helmet: 2\n4. Helmet: 1\n5. Helmet: 1\n6. Helmet: 1\n7. Helmet: 1\n8. Helmet: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.92}, "power_stats": {"power_gpu_soc_mean_watts": 18.068, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.944, "gpu_utilization_percent_mean": 68.92}, "timestamp": "2026-01-30T12:30:18.440125"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6035.868, "latencies_ms": [6035.868], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the people standing in front of the building. The ribbon is positioned in the center of the image, with the people standing on either side of it. The people are positioned in the background of the image, with the building being the main focus of the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.745}, "power_stats": {"power_gpu_soc_mean_watts": 17.846, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 67.745}, "timestamp": "2026-01-30T12:30:26.510939"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3290.212, "latencies_ms": [3290.212], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered outside a building, cutting a red ribbon with a pair of scissors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14768.9, "ram_available_mb": 48072.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.889}, "power_stats": {"power_gpu_soc_mean_watts": 23.161, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 70.889}, "timestamp": "2026-01-30T12:30:31.819323"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5612.76, "latencies_ms": [5612.76], "images_per_second": 0.178, "prompt_tokens": 1109, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image is a vibrant and lively scene with a mix of warm and cool colors, capturing the essence of a bustling city street. The lighting is natural, with the sun casting a soft glow on the scene, and the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 14768.9, "ram_available_mb": 48072.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14768.9, "ram_available_mb": 48072.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.809}, "power_stats": {"power_gpu_soc_mean_watts": 18.248, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 67.809}, "timestamp": "2026-01-30T12:30:39.474118"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4193.243, "latencies_ms": [4193.243], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A white and pink bus with the number 65745 on the front is driving down a street with a sign that says \"First Group\" on top.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14768.9, "ram_available_mb": 48072.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.382}, "power_stats": {"power_gpu_soc_mean_watts": 20.822, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 71.382}, "timestamp": "2026-01-30T12:30:45.703032"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5503.497, "latencies_ms": [5503.497], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 1\n3. buildings: 1\n4. flowers: 1\n5. road: 1\n6. sky: 1\n7. clouds: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.565}, "power_stats": {"power_gpu_soc_mean_watts": 18.472, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.928, "gpu_utilization_percent_mean": 67.565}, "timestamp": "2026-01-30T12:30:53.220599"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4336.443, "latencies_ms": [4336.443], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the street and buildings in the background. The bus is in the foreground, with the sidewalk and people in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.583}, "power_stats": {"power_gpu_soc_mean_watts": 20.532, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 70.583}, "timestamp": "2026-01-30T12:30:59.607387"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3190.573, "latencies_ms": [3190.573], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A white and pink bus is driving down a street with buildings and people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14768.6, "ram_available_mb": 48072.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.347, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 77.269}, "timestamp": "2026-01-30T12:31:04.809525"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2979.138, "latencies_ms": [2979.138], "images_per_second": 0.336, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The bus is white, blue, and pink, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14767.9, "ram_available_mb": 48073.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.833}, "power_stats": {"power_gpu_soc_mean_watts": 24.337, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 78.833}, "timestamp": "2026-01-30T12:31:09.818394"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3123.399, "latencies_ms": [3123.399], "images_per_second": 0.32, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, holding a cell phone.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14768.1, "ram_available_mb": 48072.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.544, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.218, "gpu_utilization_percent_mean": 76.846}, "timestamp": "2026-01-30T12:31:15.003784"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5442.126, "latencies_ms": [5442.126], "images_per_second": 0.184, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Mirror: 1\n3. Floor: 1\n4. Wall: 1\n5. Window: 1\n6. Door: 1\n7. Table: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.1, "ram_available_mb": 48072.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14767.9, "ram_available_mb": 48073.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.739}, "power_stats": {"power_gpu_soc_mean_watts": 18.654, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 68.739}, "timestamp": "2026-01-30T12:31:22.493850"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5375.404, "latencies_ms": [5375.404], "images_per_second": 0.186, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is sitting in front of the mirror, which is positioned on the left side of the image. The mirror is reflecting the room behind him, which is located in the background. The man is sitting on the floor, which is in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14767.9, "ram_available_mb": 48073.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14768.6, "ram_available_mb": 48072.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.889}, "power_stats": {"power_gpu_soc_mean_watts": 18.732, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 67.889}, "timestamp": "2026-01-30T12:31:29.923280"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3194.25, "latencies_ms": [3194.25], "images_per_second": 0.313, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is sitting on the floor in front of a mirror, taking a picture of himself.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.6, "ram_available_mb": 48072.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14769.1, "ram_available_mb": 48071.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.098, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.23, "gpu_utilization_percent_mean": 73.423}, "timestamp": "2026-01-30T12:31:35.141759"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3201.091, "latencies_ms": [3201.091], "images_per_second": 0.312, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the wooden floor is polished and clean.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14769.1, "ram_available_mb": 48071.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.422, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T12:31:40.364268"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3719.686, "latencies_ms": [3719.686], "images_per_second": 0.269, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people, including a man holding a surfboard, are posing for a photo in a room with a door and a window.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.387}, "power_stats": {"power_gpu_soc_mean_watts": 22.047, "power_cpu_cv_mean_watts": 1.265, "power_sys_5v0_mean_watts": 8.144, "gpu_utilization_percent_mean": 71.387}, "timestamp": "2026-01-30T12:31:46.122202"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5550.242, "latencies_ms": [5550.242], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. surfboard: 4\n2. person: 4\n3. person: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.3, "ram_available_mb": 48072.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.783}, "power_stats": {"power_gpu_soc_mean_watts": 18.505, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 68.783}, "timestamp": "2026-01-30T12:31:53.693129"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4812.481, "latencies_ms": [4812.481], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The surfboards are positioned in the foreground, with the group of people standing behind them. The person taking the photo is positioned to the left of the surfboards, while the person holding the flag is positioned to the right.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.125}, "power_stats": {"power_gpu_soc_mean_watts": 19.619, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 68.125}, "timestamp": "2026-01-30T12:32:00.525866"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3030.531, "latencies_ms": [3030.531], "images_per_second": 0.33, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are posing for a picture in a room with surfboards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.4, "ram_available_mb": 48072.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14768.1, "ram_available_mb": 48072.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.75, "power_cpu_cv_mean_watts": 1.041, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 77.36}, "timestamp": "2026-01-30T12:32:05.591519"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4167.506, "latencies_ms": [4167.506], "images_per_second": 0.24, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a white wall and a black door. The surfboards are in various colors, including yellow, blue, and red.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 14768.1, "ram_available_mb": 48072.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14767.8, "ram_available_mb": 48073.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.686}, "power_stats": {"power_gpu_soc_mean_watts": 20.893, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 71.686}, "timestamp": "2026-01-30T12:32:11.809014"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4722.414, "latencies_ms": [4722.414], "images_per_second": 0.212, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a large, golden-colored airplane with the words \"POLSKIE LOTNIE LOTNICZE\" written on its side, parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14767.8, "ram_available_mb": 48073.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14768.0, "ram_available_mb": 48072.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.718}, "power_stats": {"power_gpu_soc_mean_watts": 19.898, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 69.718}, "timestamp": "2026-01-30T12:32:18.560288"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5547.646, "latencies_ms": [5547.646], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. engine: 2\n5. wheels: 2\n6. logo: 1\n7. clouds: 1\n8. runway: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.0, "ram_available_mb": 48072.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.739}, "power_stats": {"power_gpu_soc_mean_watts": 18.307, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 69.739}, "timestamp": "2026-01-30T12:32:26.127551"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4480.589, "latencies_ms": [4480.589], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The airplane is positioned in the foreground, with the runway and other aircraft in the background. The airplane is facing towards the left side of the image, and the tail of the airplane is visible.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.158}, "power_stats": {"power_gpu_soc_mean_watts": 20.042, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 71.158}, "timestamp": "2026-01-30T12:32:32.625012"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3178.306, "latencies_ms": [3178.306], "images_per_second": 0.315, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A golden-colored airplane is parked on a runway with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14768.2, "ram_available_mb": 48072.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14770.1, "ram_available_mb": 48070.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.346}, "power_stats": {"power_gpu_soc_mean_watts": 23.116, "power_cpu_cv_mean_watts": 1.17, "power_sys_5v0_mean_watts": 8.188, "gpu_utilization_percent_mean": 71.346}, "timestamp": "2026-01-30T12:32:37.846434"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2993.569, "latencies_ms": [2993.569], "images_per_second": 0.334, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The airplane is gold and blue, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14770.1, "ram_available_mb": 48070.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14770.3, "ram_available_mb": 48070.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.977, "power_cpu_cv_mean_watts": 1.009, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 76.08}, "timestamp": "2026-01-30T12:32:42.873618"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2907.31, "latencies_ms": [2907.31], "images_per_second": 0.344, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A toilet with a lid up and water in it is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 18.8, "ram_used_mb": 14770.3, "ram_available_mb": 48070.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.41, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.289, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T12:32:47.837053"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5464.031, "latencies_ms": [5464.031], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " toilet: 1\ntoilet lid: 1\ntoilet seat: 1\ntoilet bowl: 1\ntoilet tank: 1\ntoilet tank lid: 1\ntoilet tank handle: 1\ntoilet tank knob: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14770.2, "ram_available_mb": 48070.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.348}, "power_stats": {"power_gpu_soc_mean_watts": 18.647, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 68.348}, "timestamp": "2026-01-30T12:32:55.328806"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4772.489, "latencies_ms": [4772.489], "images_per_second": 0.21, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the sink and towel rack in the background. The person's legs are visible in the bottom left corner of the image, suggesting they are standing near the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.2, "ram_available_mb": 48070.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.325}, "power_stats": {"power_gpu_soc_mean_watts": 19.499, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 71.325}, "timestamp": "2026-01-30T12:33:02.128963"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2714.187, "latencies_ms": [2714.187], "images_per_second": 0.368, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A toilet with a lid up is in a bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.727}, "power_stats": {"power_gpu_soc_mean_watts": 24.168, "power_cpu_cv_mean_watts": 0.819, "power_sys_5v0_mean_watts": 8.267, "gpu_utilization_percent_mean": 82.727}, "timestamp": "2026-01-30T12:33:06.892662"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2605.849, "latencies_ms": [2605.849], "images_per_second": 0.384, "prompt_tokens": 1110, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The toilet is white and the water is clear.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14770.4, "ram_available_mb": 48070.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.301, "power_cpu_cv_mean_watts": 0.781, "power_sys_5v0_mean_watts": 8.334, "gpu_utilization_percent_mean": 82.0}, "timestamp": "2026-01-30T12:33:11.513424"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3225.66, "latencies_ms": [3225.66], "images_per_second": 0.31, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person wearing a blue jacket and a white helmet is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 2.6, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14770.3, "ram_available_mb": 48070.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.703, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 75.731}, "timestamp": "2026-01-30T12:33:16.781303"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5668.14, "latencies_ms": [5668.14], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. goggles: 1\n4. ski poles: 2\n5. skis: 2\n6. snow: 1\n7. trees: 1\n8. snowboard: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.3, "ram_available_mb": 48070.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.833}, "power_stats": {"power_gpu_soc_mean_watts": 18.243, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 67.833}, "timestamp": "2026-01-30T12:33:24.464757"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4883.495, "latencies_ms": [4883.495], "images_per_second": 0.205, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the snowy forest and trees in the background. The skier is skiing towards the left side of the image, with the trees and forest extending towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14770.6, "ram_available_mb": 48070.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14770.7, "ram_available_mb": 48070.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.39}, "power_stats": {"power_gpu_soc_mean_watts": 19.327, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 68.39}, "timestamp": "2026-01-30T12:33:31.381981"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2658.148, "latencies_ms": [2658.148], "images_per_second": 0.376, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A person is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 60.0, "ram_used_mb": 14770.7, "ram_available_mb": 48070.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.045}, "power_stats": {"power_gpu_soc_mean_watts": 25.075, "power_cpu_cv_mean_watts": 0.928, "power_sys_5v0_mean_watts": 8.438, "gpu_utilization_percent_mean": 81.045}, "timestamp": "2026-01-30T12:33:36.100290"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3278.434, "latencies_ms": [3278.434], "images_per_second": 0.305, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a blue jacket and black pants, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.296}, "power_stats": {"power_gpu_soc_mean_watts": 23.089, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 70.296}, "timestamp": "2026-01-30T12:33:41.417428"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3569.515, "latencies_ms": [3569.515], "images_per_second": 0.28, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14771.6, "ram_available_mb": 48069.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.967}, "power_stats": {"power_gpu_soc_mean_watts": 22.383, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 73.967}, "timestamp": "2026-01-30T12:33:47.019164"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6297.1, "latencies_ms": [6297.1], "images_per_second": 0.159, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. blue court: 1\n5. white lines: 1\n6. white lines on court: 1\n7. white lines on court: 1\n8. white lines on court: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14771.6, "ram_available_mb": 48069.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.094}, "power_stats": {"power_gpu_soc_mean_watts": 17.67, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 7.945, "gpu_utilization_percent_mean": 68.094}, "timestamp": "2026-01-30T12:33:55.351886"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3891.984, "latencies_ms": [3891.984], "images_per_second": 0.257, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the crowd in the background. The player is near the net, while the ball is in the air.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14770.9, "ram_available_mb": 48070.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14771.6, "ram_available_mb": 48069.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.406}, "power_stats": {"power_gpu_soc_mean_watts": 21.446, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 70.406}, "timestamp": "2026-01-30T12:34:01.257514"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3705.644, "latencies_ms": [3705.644], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a yellow shirt and black shorts is playing tennis on a blue court, with a crowd of people watching in the stands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14771.6, "ram_available_mb": 48069.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14772.3, "ram_available_mb": 48068.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.067}, "power_stats": {"power_gpu_soc_mean_watts": 22.157, "power_cpu_cv_mean_watts": 1.254, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 71.067}, "timestamp": "2026-01-30T12:34:06.987750"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4618.703, "latencies_ms": [4618.703], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a tennis court with a blue surface, white lines, and a man in a yellow shirt and black shorts playing tennis. The lighting is bright, and the court is surrounded by a crowd of spectators.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14772.3, "ram_available_mb": 48068.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14771.8, "ram_available_mb": 48069.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.421}, "power_stats": {"power_gpu_soc_mean_watts": 20.201, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 70.421}, "timestamp": "2026-01-30T12:34:13.631598"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3914.937, "latencies_ms": [3914.937], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image shows a plate with two small metal bowls, one containing a reddish-brown curry and the other filled with orange and white dumplings.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14771.8, "ram_available_mb": 48069.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14771.1, "ram_available_mb": 48069.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.844}, "power_stats": {"power_gpu_soc_mean_watts": 21.584, "power_cpu_cv_mean_watts": 1.314, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 72.844}, "timestamp": "2026-01-30T12:34:19.587327"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3603.717, "latencies_ms": [3603.717], "images_per_second": 0.277, "prompt_tokens": 1113, "response_tokens_est": 25, "n_tiles": 1, "output_text": " bowl: 2, plate: 1, napkin: 1, glass: 1, food: 3", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14771.1, "ram_available_mb": 48069.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14770.6, "ram_available_mb": 48070.3, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.867}, "power_stats": {"power_gpu_soc_mean_watts": 22.024, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 72.867}, "timestamp": "2026-01-30T12:34:25.234630"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4896.696, "latencies_ms": [4896.696], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The bowl of curry is located to the left of the bowl of fruit, with the curry bowl being closer to the camera than the fruit bowl. The fruit bowl is positioned in the foreground, while the curry bowl is in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14770.6, "ram_available_mb": 48070.3, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14773.2, "ram_available_mb": 48067.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.488}, "timestamp": "2026-01-30T12:34:32.150594"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3405.461, "latencies_ms": [3405.461], "images_per_second": 0.294, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A plate with two bowls of food on it, one with a red sauce and the other with orange food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14773.2, "ram_available_mb": 48067.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14774.2, "ram_available_mb": 48066.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.738, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 72.214}, "timestamp": "2026-01-30T12:34:37.610819"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5081.501, "latencies_ms": [5081.501], "images_per_second": 0.197, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a plate with two bowls of food, one containing a reddish-brown dish and the other a bowl of orange and white food. The food is placed on a white napkin, and the background is a dark green tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14774.2, "ram_available_mb": 48066.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14770.5, "ram_available_mb": 48070.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.095}, "power_stats": {"power_gpu_soc_mean_watts": 19.038, "power_cpu_cv_mean_watts": 1.554, "power_sys_5v0_mean_watts": 7.954, "gpu_utilization_percent_mean": 69.095}, "timestamp": "2026-01-30T12:34:44.715139"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4002.663, "latencies_ms": [4002.663], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, there are four sheep standing in a grassy area, with one sheep looking directly at the camera, and the others facing away from it.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14770.5, "ram_available_mb": 48070.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14773.0, "ram_available_mb": 48067.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.727}, "power_stats": {"power_gpu_soc_mean_watts": 21.003, "power_cpu_cv_mean_watts": 1.359, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 70.727}, "timestamp": "2026-01-30T12:34:50.783522"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2304.831, "latencies_ms": [2304.831], "images_per_second": 0.434, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 5", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14773.0, "ram_available_mb": 48067.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 14773.8, "ram_available_mb": 48067.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.556}, "power_stats": {"power_gpu_soc_mean_watts": 25.155, "power_cpu_cv_mean_watts": 0.622, "power_sys_5v0_mean_watts": 8.232, "gpu_utilization_percent_mean": 83.556}, "timestamp": "2026-01-30T12:34:55.107762"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4602.212, "latencies_ms": [4602.212], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the brick wall serving as the background. The sheep are standing close to each other, with one sheep in the foreground and the others in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14773.8, "ram_available_mb": 48067.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14774.0, "ram_available_mb": 48066.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.553}, "power_stats": {"power_gpu_soc_mean_watts": 20.19, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-30T12:35:01.748954"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3323.621, "latencies_ms": [3323.621], "images_per_second": 0.301, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " In a sunny day, a group of sheep are standing in a grassy area near a brick wall.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14774.0, "ram_available_mb": 48066.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14773.7, "ram_available_mb": 48067.2, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.074}, "power_stats": {"power_gpu_soc_mean_watts": 22.867, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 75.074}, "timestamp": "2026-01-30T12:35:07.084449"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4651.479, "latencies_ms": [4651.479], "images_per_second": 0.215, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a group of sheep with thick wool coats, standing in a grassy area with a brick wall in the background. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14773.7, "ram_available_mb": 48067.2, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.041, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 68.718}, "timestamp": "2026-01-30T12:35:13.764761"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3945.551, "latencies_ms": [3945.551], "images_per_second": 0.253, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " In the image, a bunch of bananas and an apple are placed on a blue and white patterned background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.909}, "power_stats": {"power_gpu_soc_mean_watts": 24.465, "power_cpu_cv_mean_watts": 1.128, "power_sys_5v0_mean_watts": 8.496, "gpu_utilization_percent_mean": 78.909}, "timestamp": "2026-01-30T12:35:19.754788"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3230.278, "latencies_ms": [3230.278], "images_per_second": 0.31, "prompt_tokens": 1446, "response_tokens_est": 9, "n_tiles": 1, "output_text": " banana: 5, apple: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.154}, "power_stats": {"power_gpu_soc_mean_watts": 27.012, "power_cpu_cv_mean_watts": 0.739, "power_sys_5v0_mean_watts": 8.642, "gpu_utilization_percent_mean": 83.154}, "timestamp": "2026-01-30T12:35:25.004968"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6301.654, "latencies_ms": [6301.654], "images_per_second": 0.159, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The red apple is positioned in the center of the image, with the bananas surrounding it. The bananas are arranged in a circular pattern, with the red apple placed in the middle. The background is a blue and white floral pattern, which provides a contrast to the vibrant colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14773.1, "ram_available_mb": 48067.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14773.2, "ram_available_mb": 48067.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.321}, "power_stats": {"power_gpu_soc_mean_watts": 20.07, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 70.321}, "timestamp": "2026-01-30T12:35:33.359903"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6117.908, "latencies_ms": [6117.908], "images_per_second": 0.163, "prompt_tokens": 1444, "response_tokens_est": 55, "n_tiles": 1, "output_text": " In the center of the image, a vibrant red apple sits atop a bunch of bananas, which are arranged in a circular pattern around it. The bananas are a bright yellow color, and the apple's red hue stands out against the backdrop of a blue and white floral pattern.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14773.2, "ram_available_mb": 48067.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14773.2, "ram_available_mb": 48067.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.353, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-30T12:35:41.515557"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6982.049, "latencies_ms": [6982.049], "images_per_second": 0.143, "prompt_tokens": 1442, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a vibrant display of bananas and an apple, with the bananas arranged in a circular pattern around the apple. The bananas are a bright yellow color, while the apple is a striking combination of red and yellow hues. The background is a cool blue color with a floral pattern, providing a stark contrast to the warm colors of the fruit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14773.2, "ram_available_mb": 48067.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14779.4, "ram_available_mb": 48061.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.898}, "power_stats": {"power_gpu_soc_mean_watts": 19.136, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.158, "gpu_utilization_percent_mean": 70.898}, "timestamp": "2026-01-30T12:35:50.539659"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3405.168, "latencies_ms": [3405.168], "images_per_second": 0.294, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A blue and white train with red seats is parked at a station with trees and power lines in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14779.4, "ram_available_mb": 48061.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14780.2, "ram_available_mb": 48060.7, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.727, "power_cpu_cv_mean_watts": 1.13, "power_sys_5v0_mean_watts": 8.157, "gpu_utilization_percent_mean": 71.821}, "timestamp": "2026-01-30T12:35:55.983921"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5696.804, "latencies_ms": [5696.804], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. windows: 12\n3. doors: 2\n4. seats: 12\n5. trolley: 1\n6. tracks: 2\n7. trees: 1\n8. wires: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14780.2, "ram_available_mb": 48060.7, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14779.9, "ram_available_mb": 48061.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.267, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-30T12:36:03.709275"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4497.491, "latencies_ms": [4497.491], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, with the tracks extending towards the right. The background features a clear blue sky and trees, while the foreground includes a fence and a building.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14779.9, "ram_available_mb": 48061.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14786.5, "ram_available_mb": 48054.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.27}, "power_stats": {"power_gpu_soc_mean_watts": 20.26, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 72.27}, "timestamp": "2026-01-30T12:36:10.228889"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3324.586, "latencies_ms": [3324.586], "images_per_second": 0.301, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue and white train is parked at a station, with trees and other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14786.5, "ram_available_mb": 48054.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14786.8, "ram_available_mb": 48054.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.963}, "power_stats": {"power_gpu_soc_mean_watts": 22.85, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 76.963}, "timestamp": "2026-01-30T12:36:15.581401"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2922.012, "latencies_ms": [2922.012], "images_per_second": 0.342, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The train is blue and white, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14786.8, "ram_available_mb": 48054.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14787.9, "ram_available_mb": 48053.0, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.825, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 80.333}, "timestamp": "2026-01-30T12:36:20.556903"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3633.897, "latencies_ms": [3633.897], "images_per_second": 0.275, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a bathroom with a shower, a bathtub, and a double sink vanity, all with a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14787.9, "ram_available_mb": 48053.0, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14788.4, "ram_available_mb": 48052.5, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.133, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 71.233}, "timestamp": "2026-01-30T12:36:26.254492"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5806.666, "latencies_ms": [5806.666], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Bathtub: 1\n2. Shower: 1\n3. Mirror: 2\n4. Sink: 1\n5. Cabinet: 1\n6. Towel: 1\n7. Rug: 1\n8. Light: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14788.4, "ram_available_mb": 48052.5, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14789.3, "ram_available_mb": 48051.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.812}, "power_stats": {"power_gpu_soc_mean_watts": 18.118, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.941, "gpu_utilization_percent_mean": 69.812}, "timestamp": "2026-01-30T12:36:34.088817"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4322.129, "latencies_ms": [4322.129], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The shower is located to the left of the sink, and the bathtub is situated behind the shower. The sink is positioned in the foreground, while the mirror is located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14789.3, "ram_available_mb": 48051.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14789.3, "ram_available_mb": 48051.6, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.943}, "power_stats": {"power_gpu_soc_mean_watts": 20.913, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 72.943}, "timestamp": "2026-01-30T12:36:40.431979"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2991.605, "latencies_ms": [2991.605], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a shower, bathtub, and sink is shown in the image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14789.3, "ram_available_mb": 48051.6, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14789.5, "ram_available_mb": 48051.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.625}, "power_stats": {"power_gpu_soc_mean_watts": 24.289, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 77.625}, "timestamp": "2026-01-30T12:36:45.438014"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4106.347, "latencies_ms": [4106.347], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The bathroom has a warm color scheme with beige walls and a red rug on the floor. The lighting is bright and natural, coming from a window in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14789.5, "ram_available_mb": 48051.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14789.0, "ram_available_mb": 48051.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.676}, "power_stats": {"power_gpu_soc_mean_watts": 21.091, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 71.676}, "timestamp": "2026-01-30T12:36:51.597297"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3833.456, "latencies_ms": [3833.456], "images_per_second": 0.261, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A black and white photo captures a surfer skillfully riding a wave, with the word \"STAR\" prominently displayed in the top right corner.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14789.0, "ram_available_mb": 48051.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14789.0, "ram_available_mb": 48051.9, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.719}, "power_stats": {"power_gpu_soc_mean_watts": 21.548, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.106, "gpu_utilization_percent_mean": 68.719}, "timestamp": "2026-01-30T12:36:57.486362"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5705.254, "latencies_ms": [5705.254], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Water: 1\n5. Ocean: 1\n6. Sky: 1\n7. Clouds: 1\n8. Text: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14789.0, "ram_available_mb": 48051.9, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14789.1, "ram_available_mb": 48051.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.309, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 70.638}, "timestamp": "2026-01-30T12:37:05.201893"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4936.412, "latencies_ms": [4936.412], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The surfer is in the middle of the wave, with the spray of water from the wave being the closest object to the camera.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 14789.1, "ram_available_mb": 48051.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14789.1, "ram_available_mb": 48051.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.439}, "power_stats": {"power_gpu_soc_mean_watts": 19.503, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 68.439}, "timestamp": "2026-01-30T12:37:12.192306"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2994.392, "latencies_ms": [2994.392], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14789.1, "ram_available_mb": 48051.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14789.1, "ram_available_mb": 48051.8, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.583}, "power_stats": {"power_gpu_soc_mean_watts": 23.788, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 73.583}, "timestamp": "2026-01-30T12:37:17.219253"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5367.812, "latencies_ms": [5367.812], "images_per_second": 0.186, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image is in black and white, with the surfer's silhouette standing out against the white foam of the wave. The lighting is natural, with the sun reflecting off the water, creating a dramatic contrast between the dark silhouette of the surfer and the bright white foam.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14789.1, "ram_available_mb": 48051.8, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14789.8, "ram_available_mb": 48051.1, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.729, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 69.2}, "timestamp": "2026-01-30T12:37:24.603268"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4917.88, "latencies_ms": [4917.88], "images_per_second": 0.203, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " A baseball player in a white uniform with the number 10 on it is standing at home plate with a bat in his hand, while a catcher in a black uniform and a umpire in a blue shirt are behind him.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14789.8, "ram_available_mb": 48051.1, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14787.5, "ram_available_mb": 48053.4, "ram_percent": 23.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.829}, "power_stats": {"power_gpu_soc_mean_watts": 19.572, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 70.829}, "timestamp": "2026-01-30T12:37:31.567500"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5825.867, "latencies_ms": [5825.867], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. home plate: 1\n6. baseball: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14787.5, "ram_available_mb": 48053.4, "ram_percent": 23.5}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14080.8, "ram_available_mb": 48760.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.286}, "power_stats": {"power_gpu_soc_mean_watts": 17.973, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.922, "gpu_utilization_percent_mean": 68.286}, "timestamp": "2026-01-30T12:37:39.436976"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4258.193, "latencies_ms": [4258.193], "images_per_second": 0.235, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14080.8, "ram_available_mb": 48760.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14080.0, "ram_available_mb": 48760.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.139}, "power_stats": {"power_gpu_soc_mean_watts": 20.533, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 72.139}, "timestamp": "2026-01-30T12:37:45.733199"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2953.005, "latencies_ms": [2953.005], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A baseball game is taking place in a stadium with a crowd of people watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14080.0, "ram_available_mb": 48760.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14080.2, "ram_available_mb": 48760.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.292}, "power_stats": {"power_gpu_soc_mean_watts": 24.592, "power_cpu_cv_mean_watts": 0.967, "power_sys_5v0_mean_watts": 8.319, "gpu_utilization_percent_mean": 75.292}, "timestamp": "2026-01-30T12:37:50.703100"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5954.593, "latencies_ms": [5954.593], "images_per_second": 0.168, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white uniforms and the lush green grass of the field contrasting against the blue sky. The lighting is natural, casting a warm glow on the players and the field, while the weather appears to be clear, with no signs of rain or wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14080.2, "ram_available_mb": 48760.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14080.1, "ram_available_mb": 48760.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.42}, "power_stats": {"power_gpu_soc_mean_watts": 18.011, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 69.42}, "timestamp": "2026-01-30T12:37:58.698582"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3694.98, "latencies_ms": [3694.98], "images_per_second": 0.271, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14080.1, "ram_available_mb": 48760.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.4}, "power_stats": {"power_gpu_soc_mean_watts": 25.262, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 8.553, "gpu_utilization_percent_mean": 79.4}, "timestamp": "2026-01-30T12:38:04.414563"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5048.465, "latencies_ms": [5048.465], "images_per_second": 0.198, "prompt_tokens": 1446, "response_tokens_est": 39, "n_tiles": 1, "output_text": " apple: 2, grapes: 10, orange: 1, grapes: 10, grapes: 10, grapes: 10, grapes: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14080.8, "ram_available_mb": 48760.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.905}, "power_stats": {"power_gpu_soc_mean_watts": 22.45, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 8.334, "gpu_utilization_percent_mean": 74.905}, "timestamp": "2026-01-30T12:38:11.508005"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7260.983, "latencies_ms": [7260.983], "images_per_second": 0.138, "prompt_tokens": 1450, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The main objects are arranged in a diagonal line from the top left to the bottom right, with the grapes and oranges placed in the foreground and the peanuts in the background. The objects are positioned in a way that creates a sense of depth and perspective, with the larger objects (grapes and oranges) in the foreground and the smaller objects (peanuts) in the background.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 14080.8, "ram_available_mb": 48760.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14081.2, "ram_available_mb": 48759.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.787}, "power_stats": {"power_gpu_soc_mean_watts": 19.246, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 8.199, "gpu_utilization_percent_mean": 69.787}, "timestamp": "2026-01-30T12:38:20.794052"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3760.998, "latencies_ms": [3760.998], "images_per_second": 0.266, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a bunch of fruits and nuts on a white surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14081.2, "ram_available_mb": 48759.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.161}, "power_stats": {"power_gpu_soc_mean_watts": 25.018, "power_cpu_cv_mean_watts": 0.93, "power_sys_5v0_mean_watts": 8.492, "gpu_utilization_percent_mean": 78.161}, "timestamp": "2026-01-30T12:38:26.608607"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4168.914, "latencies_ms": [4168.914], "images_per_second": 0.24, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a black and white photo with a white background, and the fruits are all in shades of white and gray.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.771}, "power_stats": {"power_gpu_soc_mean_watts": 24.39, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.463, "gpu_utilization_percent_mean": 77.771}, "timestamp": "2026-01-30T12:38:32.831814"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7778.928, "latencies_ms": [7778.928], "images_per_second": 0.129, "prompt_tokens": 1099, "response_tokens_est": 96, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where a variety of vehicles, including cars and a bus, are in motion, while pedestrians can be seen walking along the sidewalks. The buildings lining the street are a mix of modern and older architectural styles, with some featuring balconies and others boasting large windows. The sky overhead is a clear blue, suggesting a bright and sunny day, and the street is lined with trees and greenery, adding a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.538}, "power_stats": {"power_gpu_soc_mean_watts": 16.527, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 66.538}, "timestamp": "2026-01-30T12:38:42.649088"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5592.998, "latencies_ms": [5592.998], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. street: 2 lanes\n2. car: 2\n3. building: 3\n4. sidewalk: 1\n5. streetlight: 2\n6. tree: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.085}, "power_stats": {"power_gpu_soc_mean_watts": 18.395, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 68.085}, "timestamp": "2026-01-30T12:38:50.286587"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6458.776, "latencies_ms": [6458.776], "images_per_second": 0.155, "prompt_tokens": 1117, "response_tokens_est": 72, "n_tiles": 1, "output_text": " The main objects in the image are positioned in a way that the street is in the foreground, with the buildings and trees in the background. The street is on the left side of the image, while the buildings and trees are on the right side. The buildings are located on both sides of the street, with the trees lining the sidewalk on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14077.6, "ram_available_mb": 48763.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.519}, "power_stats": {"power_gpu_soc_mean_watts": 17.357, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 70.519}, "timestamp": "2026-01-30T12:38:58.782303"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6241.629, "latencies_ms": [6241.629], "images_per_second": 0.16, "prompt_tokens": 1111, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The image captures a bustling urban street scene, where modern buildings of varying heights and designs line the street. The buildings are adorned with balconies and windows, reflecting the city's vibrant life. Cars are parked neatly along the side of the road, and a few pedestrians can be seen strolling along the sidewalk, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14077.6, "ram_available_mb": 48763.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14077.6, "ram_available_mb": 48763.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.462}, "power_stats": {"power_gpu_soc_mean_watts": 17.574, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.935, "gpu_utilization_percent_mean": 70.462}, "timestamp": "2026-01-30T12:39:07.056423"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3977.043, "latencies_ms": [3977.043], "images_per_second": 0.251, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image features a street with a clear blue sky and a few clouds. The buildings are made of brick and concrete, and the road is paved with asphalt.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14077.6, "ram_available_mb": 48763.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.545}, "power_stats": {"power_gpu_soc_mean_watts": 21.418, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 8.127, "gpu_utilization_percent_mean": 71.545}, "timestamp": "2026-01-30T12:39:13.055689"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4209.565, "latencies_ms": [4209.565], "images_per_second": 0.238, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, there are two people standing close to each other, with one person wearing a blue shirt and the other wearing a white shirt, both smiling and embracing each other.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14076.8, "ram_available_mb": 48764.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.81, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-30T12:39:19.302448"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5463.393, "latencies_ms": [5463.393], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. tie: 1\n3. television: 1\n4. wall: 1\n5. chair: 1\n6. table: 1\n7. wall clock: 1\n8. picture: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.8, "ram_available_mb": 48764.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14076.9, "ram_available_mb": 48764.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.739}, "power_stats": {"power_gpu_soc_mean_watts": 18.63, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.739}, "timestamp": "2026-01-30T12:39:26.810823"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4255.756, "latencies_ms": [4255.756], "images_per_second": 0.235, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, with her arm around his shoulder. The man is standing in front of a bar counter, with the woman standing behind him.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14076.9, "ram_available_mb": 48764.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14078.5, "ram_available_mb": 48762.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.821, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 72.029}, "timestamp": "2026-01-30T12:39:33.093078"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2605.984, "latencies_ms": [2605.984], "images_per_second": 0.384, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " Two people are posing for a picture in a bar.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14078.5, "ram_available_mb": 48762.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14076.7, "ram_available_mb": 48764.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.619}, "power_stats": {"power_gpu_soc_mean_watts": 25.263, "power_cpu_cv_mean_watts": 0.705, "power_sys_5v0_mean_watts": 8.373, "gpu_utilization_percent_mean": 79.619}, "timestamp": "2026-01-30T12:39:37.725912"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3498.57, "latencies_ms": [3498.57], "images_per_second": 0.286, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm ambiance, and the subjects are wearing formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.7, "ram_available_mb": 48764.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14076.0, "ram_available_mb": 48764.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.586}, "power_stats": {"power_gpu_soc_mean_watts": 22.589, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 70.586}, "timestamp": "2026-01-30T12:39:43.238512"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3097.396, "latencies_ms": [3097.396], "images_per_second": 0.323, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a costume is smiling at the camera while standing in a crowd of people.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14076.0, "ram_available_mb": 48764.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14075.8, "ram_available_mb": 48765.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.995, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 75.24}, "timestamp": "2026-01-30T12:39:48.370626"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5617.178, "latencies_ms": [5617.178], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. headband: 1\n4. earring: 1\n5. necklace: 1\n6. bracelet: 1\n7. shirt: 1\n8. pants: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14075.8, "ram_available_mb": 48765.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14074.9, "ram_available_mb": 48766.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.766}, "power_stats": {"power_gpu_soc_mean_watts": 18.412, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 68.766}, "timestamp": "2026-01-30T12:39:56.048007"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4382.72, "latencies_ms": [4382.72], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a black and gold costume, while the man is in the background, wearing a white hat. The woman is closer to the camera than the man.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14074.9, "ram_available_mb": 48766.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14074.0, "ram_available_mb": 48766.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.568, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 71.639}, "timestamp": "2026-01-30T12:40:02.475751"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3277.472, "latencies_ms": [3277.472], "images_per_second": 0.305, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered in an outdoor setting, dressed in elaborate costumes and engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14074.0, "ram_available_mb": 48766.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.093, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 73.222}, "timestamp": "2026-01-30T12:40:07.792209"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3386.504, "latencies_ms": [3386.504], "images_per_second": 0.295, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the woman is wearing a black and gold costume.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.798, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.163, "gpu_utilization_percent_mean": 74.214}, "timestamp": "2026-01-30T12:40:13.239617"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6302.655, "latencies_ms": [6302.655], "images_per_second": 0.159, "prompt_tokens": 1100, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image depicts a small bathroom with white tiled walls and floor, a white toilet, a white sink, a white shower head, a white pipe, a white toilet tank, a white toilet paper holder, a green bucket, a red bucket, a white soap dish, a white soap dispenser, a white window, and a white drain.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.585}, "power_stats": {"power_gpu_soc_mean_watts": 17.544, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.916, "gpu_utilization_percent_mean": 68.585}, "timestamp": "2026-01-30T12:40:21.568922"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4649.174, "latencies_ms": [4649.174], "images_per_second": 0.215, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " 1. white toilet\n2. white sink\n3. white bathtub\n4. white shower head\n5. white pipe\n6. white toilet tank\n7. white toilet paper\n8. white soap", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.385}, "power_stats": {"power_gpu_soc_mean_watts": 19.951, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 70.385}, "timestamp": "2026-01-30T12:40:28.257316"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5399.71, "latencies_ms": [5399.71], "images_per_second": 0.185, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The green bucket is located in the foreground, near the sink, while the red bucket is positioned in the background, near the toilet. The white pipe is situated in the middle of the image, with the shower head on the left side and the toilet on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.856, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T12:40:35.672971"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3375.468, "latencies_ms": [3375.468], "images_per_second": 0.296, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A small bathroom with white walls and a white floor has a shower, a toilet, and a sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.852}, "power_stats": {"power_gpu_soc_mean_watts": 22.615, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.152, "gpu_utilization_percent_mean": 74.852}, "timestamp": "2026-01-30T12:40:41.079064"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3194.176, "latencies_ms": [3194.176], "images_per_second": 0.313, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is white with a blue and green bucket, and a window with a black frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.472, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 75.731}, "timestamp": "2026-01-30T12:40:46.296284"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3564.893, "latencies_ms": [3564.893], "images_per_second": 0.281, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing glasses and a green shirt is standing next to a large gray elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.479, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 72.1}, "timestamp": "2026-01-30T12:40:51.914237"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4431.203, "latencies_ms": [4431.203], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " elephant: 1, man: 1, glasses: 1, shirt: 1, elephant's trunk: 1, elephant's ear: 1, elephant's eye: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14070.2, "ram_available_mb": 48770.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.56, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.324}, "timestamp": "2026-01-30T12:40:58.374722"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4236.714, "latencies_ms": [4236.714], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The man is standing to the right of the elephant, with the elephant's trunk reaching towards his face. The man is in the foreground, while the elephant is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.2, "ram_available_mb": 48770.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.257}, "power_stats": {"power_gpu_soc_mean_watts": 20.81, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 71.257}, "timestamp": "2026-01-30T12:41:04.655146"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3201.271, "latencies_ms": [3201.271], "images_per_second": 0.312, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing glasses is standing next to an elephant in a natural setting with trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.779, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.265, "gpu_utilization_percent_mean": 76.538}, "timestamp": "2026-01-30T12:41:09.880379"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5160.278, "latencies_ms": [5160.278], "images_per_second": 0.194, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features a man wearing glasses and a green shirt standing next to a large elephant. The elephant is gray and has wrinkled skin, while the man's shirt is a solid color. The background is a lush green forest with trees and hills visible.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.419}, "power_stats": {"power_gpu_soc_mean_watts": 18.996, "power_cpu_cv_mean_watts": 1.536, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 67.419}, "timestamp": "2026-01-30T12:41:17.091315"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3233.106, "latencies_ms": [3233.106], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Five children are sitting on the grass holding frisbees, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.221, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-30T12:41:22.393290"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2447.292, "latencies_ms": [2447.292], "images_per_second": 0.409, "prompt_tokens": 1113, "response_tokens_est": 7, "n_tiles": 1, "output_text": " 1. boy: 5", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.55}, "power_stats": {"power_gpu_soc_mean_watts": 25.219, "power_cpu_cv_mean_watts": 0.7, "power_sys_5v0_mean_watts": 8.347, "gpu_utilization_percent_mean": 82.55}, "timestamp": "2026-01-30T12:41:26.863465"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6047.55, "latencies_ms": [6047.55], "images_per_second": 0.165, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The frisbees are positioned in the foreground, with the child on the left holding a white frisbee and the child on the right holding a red frisbee. The children are sitting on the grass, with the child on the left being closest to the camera and the child on the right being farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14071.2, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.38}, "power_stats": {"power_gpu_soc_mean_watts": 17.955, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 66.38}, "timestamp": "2026-01-30T12:41:34.925662"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2885.028, "latencies_ms": [2885.028], "images_per_second": 0.347, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " Five children are sitting on the grass playing with frisbees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.174}, "power_stats": {"power_gpu_soc_mean_watts": 23.986, "power_cpu_cv_mean_watts": 0.748, "power_sys_5v0_mean_watts": 8.225, "gpu_utilization_percent_mean": 80.174}, "timestamp": "2026-01-30T12:41:39.837271"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3743.544, "latencies_ms": [3743.544], "images_per_second": 0.267, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image is taken in a bright and sunny day with clear sky. The children are sitting on the grass, which is green and lush.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.839}, "power_stats": {"power_gpu_soc_mean_watts": 21.841, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 68.839}, "timestamp": "2026-01-30T12:41:45.641135"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3567.66, "latencies_ms": [3567.66], "images_per_second": 0.28, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young girl wearing a red coat and holding a black umbrella with pink designs stands on a wet sidewalk in front of a bush.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.138}, "power_stats": {"power_gpu_soc_mean_watts": 22.613, "power_cpu_cv_mean_watts": 1.215, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 73.138}, "timestamp": "2026-01-30T12:41:51.259246"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4117.922, "latencies_ms": [4117.922], "images_per_second": 0.243, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " umbrella: 1, child: 1, sidewalk: 1, house: 1, bush: 1, car: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.882}, "power_stats": {"power_gpu_soc_mean_watts": 21.163, "power_cpu_cv_mean_watts": 1.295, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 71.882}, "timestamp": "2026-01-30T12:41:57.405710"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4443.319, "latencies_ms": [4443.319], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The child is standing in the foreground of the image, with the umbrella held above her head. The umbrella is positioned to the left of the child, and the background features a hedge and a house.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.865}, "power_stats": {"power_gpu_soc_mean_watts": 20.462, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 70.865}, "timestamp": "2026-01-30T12:42:03.898093"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2762.161, "latencies_ms": [2762.161], "images_per_second": 0.362, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A little girl is standing on the sidewalk with an umbrella.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.227}, "power_stats": {"power_gpu_soc_mean_watts": 24.149, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 78.227}, "timestamp": "2026-01-30T12:42:08.672485"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4125.976, "latencies_ms": [4125.976], "images_per_second": 0.242, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a young girl wearing a red coat and holding a black umbrella with pink patterns. The scene is set on a rainy day with wet pavement and a gray sky.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.829}, "power_stats": {"power_gpu_soc_mean_watts": 21.071, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 72.829}, "timestamp": "2026-01-30T12:42:14.832563"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4534.127, "latencies_ms": [4534.127], "images_per_second": 0.221, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a group of elephants is seen walking through a muddy area, with one elephant in the foreground prominently displayed and the others slightly blurred in the background, creating a sense of depth and movement.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14073.4, "ram_available_mb": 48767.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.169, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.868}, "timestamp": "2026-01-30T12:42:21.406596"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4088.046, "latencies_ms": [4088.046], "images_per_second": 0.245, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " elephant: 1, trunk: 1, ear: 1, eye: 1, leg: 1, tail: 1, water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.4, "ram_available_mb": 48767.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.794}, "power_stats": {"power_gpu_soc_mean_watts": 21.28, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 71.794}, "timestamp": "2026-01-30T12:42:27.520739"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4155.23, "latencies_ms": [4155.23], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking towards the camera, with the main elephant in the center of the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.143}, "power_stats": {"power_gpu_soc_mean_watts": 21.025, "power_cpu_cv_mean_watts": 1.441, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 71.143}, "timestamp": "2026-01-30T12:42:33.701380"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2950.637, "latencies_ms": [2950.637], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of elephants are walking through a muddy area near a body of water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.404, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.306, "gpu_utilization_percent_mean": 77.5}, "timestamp": "2026-01-30T12:42:38.664151"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3891.52, "latencies_ms": [3891.52], "images_per_second": 0.257, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The elephants are in a muddy environment, with a mix of brown and red tones. The lighting is natural, and the elephants are in a natural setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.938}, "power_stats": {"power_gpu_soc_mean_watts": 21.794, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 72.938}, "timestamp": "2026-01-30T12:42:44.571716"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3814.143, "latencies_ms": [3814.143], "images_per_second": 0.262, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.419}, "power_stats": {"power_gpu_soc_mean_watts": 24.811, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 8.517, "gpu_utilization_percent_mean": 77.419}, "timestamp": "2026-01-30T12:42:50.420302"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6515.238, "latencies_ms": [6515.238], "images_per_second": 0.153, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. wave: 1\n3. surfboard: 1\n4. water: 1\n5. sky: 0\n6. surfboard deck: 1\n7. surfboard leash: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.855}, "power_stats": {"power_gpu_soc_mean_watts": 20.131, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 70.855}, "timestamp": "2026-01-30T12:42:58.977875"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5660.346, "latencies_ms": [5660.346], "images_per_second": 0.177, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave dominating the background. The surfer is leaning into the wave, with the surfboard positioned in the lower right corner of the image, close to the surfer.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.426}, "power_stats": {"power_gpu_soc_mean_watts": 21.196, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 8.259, "gpu_utilization_percent_mean": 71.426}, "timestamp": "2026-01-30T12:43:06.678368"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3377.445, "latencies_ms": [3377.445], "images_per_second": 0.296, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.786}, "power_stats": {"power_gpu_soc_mean_watts": 26.595, "power_cpu_cv_mean_watts": 0.772, "power_sys_5v0_mean_watts": 8.612, "gpu_utilization_percent_mean": 80.786}, "timestamp": "2026-01-30T12:43:12.091722"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4002.549, "latencies_ms": [4002.549], "images_per_second": 0.25, "prompt_tokens": 1442, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The surfer is wearing a red and green wetsuit, and the wave is a deep green color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.788}, "power_stats": {"power_gpu_soc_mean_watts": 25.014, "power_cpu_cv_mean_watts": 1.055, "power_sys_5v0_mean_watts": 8.53, "gpu_utilization_percent_mean": 78.788}, "timestamp": "2026-01-30T12:43:18.146348"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3258.654, "latencies_ms": [3258.654], "images_per_second": 0.307, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean and a few people in the background.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.778}, "power_stats": {"power_gpu_soc_mean_watts": 23.309, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 75.778}, "timestamp": "2026-01-30T12:43:23.445997"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5421.416, "latencies_ms": [5421.416], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. rider: 1\n4. rider: 1\n5. rider: 1\n6. rider: 1\n7. rider: 1\n8. rider: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.73, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 67.2}, "timestamp": "2026-01-30T12:43:30.887600"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5704.747, "latencies_ms": [5704.747], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The two men on horseback are positioned in the foreground, with the ocean and beach extending into the background. The man on the left is closer to the camera, while the man on the right is farther away. The man on the left is also closer to the camera than the man on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.292}, "power_stats": {"power_gpu_soc_mean_watts": 18.324, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 69.292}, "timestamp": "2026-01-30T12:43:38.606607"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3084.857, "latencies_ms": [3084.857], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two men on horseback are riding on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.8}, "power_stats": {"power_gpu_soc_mean_watts": 23.782, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 74.8}, "timestamp": "2026-01-30T12:43:43.714401"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4406.933, "latencies_ms": [4406.933], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a sandy beach with a clear blue sky and ocean in the background. The two men are dressed in white traditional clothing and are riding horses, which are kicking up dust as they move.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.405}, "power_stats": {"power_gpu_soc_mean_watts": 20.527, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 71.405}, "timestamp": "2026-01-30T12:43:50.172739"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3121.75, "latencies_ms": [3121.75], "images_per_second": 0.32, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A small dog is standing in front of a motorcycle that is parked in a driveway.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.48}, "power_stats": {"power_gpu_soc_mean_watts": 24.073, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.306, "gpu_utilization_percent_mean": 77.48}, "timestamp": "2026-01-30T12:43:55.335118"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5677.3, "latencies_ms": [5677.3], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. dog: 1\n3. tire: 1\n4. handlebar: 1\n5. seat: 1\n6. front wheel: 1\n7. rear wheel: 1\n8. garage door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14075.5, "ram_available_mb": 48765.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.318, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 68.667}, "timestamp": "2026-01-30T12:44:03.054282"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4309.207, "latencies_ms": [4309.207], "images_per_second": 0.232, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The motorcycle is positioned to the left of the garage door, with the dog standing in front of it. The motorcycle is in the foreground, while the garage door is in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14075.5, "ram_available_mb": 48765.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.637, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 71.4}, "timestamp": "2026-01-30T12:44:09.404102"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2975.801, "latencies_ms": [2975.801], "images_per_second": 0.336, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A motorcycle is parked outside a garage with a dog standing next to it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14073.4, "ram_available_mb": 48767.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.936, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.244, "gpu_utilization_percent_mean": 74.417}, "timestamp": "2026-01-30T12:44:14.399333"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3496.365, "latencies_ms": [3496.365], "images_per_second": 0.286, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The motorcycle is red and silver, and the garage is beige. The sky is blue and the grass is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.4, "ram_available_mb": 48767.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.49, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 70.69}, "timestamp": "2026-01-30T12:44:19.911185"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3172.738, "latencies_ms": [3172.738], "images_per_second": 0.315, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man is flying a kite on the beach, with a few other people in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.038}, "power_stats": {"power_gpu_soc_mean_watts": 23.358, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 74.038}, "timestamp": "2026-01-30T12:44:25.150359"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5418.813, "latencies_ms": [5418.813], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. kite: 1\n3. sand: 1\n4. water: 1\n5. trees: 1\n6. buildings: 1\n7. clouds: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.778}, "power_stats": {"power_gpu_soc_mean_watts": 18.756, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 69.778}, "timestamp": "2026-01-30T12:44:32.588631"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4618.057, "latencies_ms": [4618.057], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is in the foreground, flying the kite in the middle of the beach. The kite is in the background, flying high in the sky. The beach is in the background, with people and trees.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.949}, "power_stats": {"power_gpu_soc_mean_watts": 19.795, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 70.949}, "timestamp": "2026-01-30T12:44:39.231162"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3002.787, "latencies_ms": [3002.787], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is flying a kite on a beach with a lake in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.833}, "power_stats": {"power_gpu_soc_mean_watts": 24.055, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.273, "gpu_utilization_percent_mean": 75.833}, "timestamp": "2026-01-30T12:44:44.268770"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3318.331, "latencies_ms": [3318.331], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The sky is blue and the kite is blue and black. The beach is sandy and the water is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.481}, "power_stats": {"power_gpu_soc_mean_watts": 23.428, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 73.481}, "timestamp": "2026-01-30T12:44:49.622238"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4630.438, "latencies_ms": [4630.438], "images_per_second": 0.216, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image depicts a kitchen with wooden cabinets, a stainless steel refrigerator, and a black countertop, with various items such as a green bottle, a red bow, and a blue bottle placed on the countertop.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.887, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T12:44:56.311112"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4045.802, "latencies_ms": [4045.802], "images_per_second": 0.247, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " sink: 1, bottle: 2, bowl: 1, cup: 1, dish: 1, bottle: 1, bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.879}, "power_stats": {"power_gpu_soc_mean_watts": 21.559, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 72.879}, "timestamp": "2026-01-30T12:45:02.370876"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4373.097, "latencies_ms": [4373.097], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The green dish soap bottle is located near the sink, while the blue dish soap bottle is placed further back on the counter. The red bow is positioned in the foreground, close to the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.722}, "power_stats": {"power_gpu_soc_mean_watts": 20.663, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 70.722}, "timestamp": "2026-01-30T12:45:08.781626"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3087.251, "latencies_ms": [3087.251], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A kitchen with wooden cabinets, a black countertop, and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.668, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 71.88}, "timestamp": "2026-01-30T12:45:13.882600"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3127.699, "latencies_ms": [3127.699], "images_per_second": 0.32, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.845, "power_cpu_cv_mean_watts": 1.041, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 75.4}, "timestamp": "2026-01-30T12:45:19.026533"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2832.894, "latencies_ms": [2832.894], "images_per_second": 0.353, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.043}, "power_stats": {"power_gpu_soc_mean_watts": 24.733, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.33, "gpu_utilization_percent_mean": 80.043}, "timestamp": "2026-01-30T12:45:23.892237"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2217.365, "latencies_ms": [2217.365], "images_per_second": 0.451, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " kite: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.444}, "power_stats": {"power_gpu_soc_mean_watts": 25.775, "power_cpu_cv_mean_watts": 0.6, "power_sys_5v0_mean_watts": 8.367, "gpu_utilization_percent_mean": 86.444}, "timestamp": "2026-01-30T12:45:28.163353"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5023.184, "latencies_ms": [5023.184], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The kite is in the foreground, flying in the sky, and the background is the clear blue sky. The kite is positioned to the left of the frame, and the strings are attached to the kite, which is the main object in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.167}, "power_stats": {"power_gpu_soc_mean_watts": 19.419, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 71.167}, "timestamp": "2026-01-30T12:45:35.223151"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2889.858, "latencies_ms": [2889.858], "images_per_second": 0.346, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kite with a red and white design is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.938, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-30T12:45:40.156170"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3051.339, "latencies_ms": [3051.339], "images_per_second": 0.328, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The kite is white with red and black patterns, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.83, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 76.16}, "timestamp": "2026-01-30T12:45:45.255893"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4965.246, "latencies_ms": [4965.246], "images_per_second": 0.201, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with two queen-sized beds, each adorned with white linens and a dark-colored bedspread, positioned side by side, with a window in the background allowing natural light to filter into the room.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.951}, "power_stats": {"power_gpu_soc_mean_watts": 19.338, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 67.951}, "timestamp": "2026-01-30T12:45:52.269269"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5565.936, "latencies_ms": [5565.936], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 55, "n_tiles": 1, "output_text": " 1. beds: 2\n2. pillows: 12\n3. lamps: 2\n4. paintings: 2\n5. window: 1\n6. door: 1\n7. floor: wooden\n8. ceiling: white", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.609}, "power_stats": {"power_gpu_soc_mean_watts": 17.93, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 67.609}, "timestamp": "2026-01-30T12:45:59.857128"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6116.637, "latencies_ms": [6116.637], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The beds are positioned on the left side of the room, with the window and door located on the right side. The lamp on the left bedside table is positioned closer to the camera than the lamp on the right bedside table. The artwork is positioned above the beds, with the window and door being further away from the beds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.885}, "power_stats": {"power_gpu_soc_mean_watts": 17.786, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 69.885}, "timestamp": "2026-01-30T12:46:08.007707"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5913.368, "latencies_ms": [5913.368], "images_per_second": 0.169, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a serene hotel room bathed in soft light, where two queen-sized beds rest against a wall adorned with a vibrant abstract painting. The room exudes a sense of tranquility, with each bed neatly made and a lamp perched on the nightstand, ready to bathe the room in a warm glow.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.878}, "power_stats": {"power_gpu_soc_mean_watts": 18.051, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 7.935, "gpu_utilization_percent_mean": 69.878}, "timestamp": "2026-01-30T12:46:15.941050"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4633.851, "latencies_ms": [4633.851], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The room is bathed in warm light, with a mix of natural and artificial light illuminating the space. The walls are painted in a soothing shade of green, and the wooden floor adds a touch of rustic charm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14075.6, "ram_available_mb": 48765.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.342}, "power_stats": {"power_gpu_soc_mean_watts": 20.191, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.342}, "timestamp": "2026-01-30T12:46:22.609233"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4004.115, "latencies_ms": [4004.115], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road with a crowd of people watching from behind a fence.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14075.6, "ram_available_mb": 48765.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14075.3, "ram_available_mb": 48765.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.848}, "power_stats": {"power_gpu_soc_mean_watts": 21.244, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 70.848}, "timestamp": "2026-01-30T12:46:28.644565"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4134.892, "latencies_ms": [4134.892], "images_per_second": 0.242, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. motorcycle: 1\n2. rider: 1\n3. helmet: 1\n4. fence: 2\n5. people: 8", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14075.3, "ram_available_mb": 48765.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14075.9, "ram_available_mb": 48765.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.941}, "power_stats": {"power_gpu_soc_mean_watts": 21.255, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 71.941}, "timestamp": "2026-01-30T12:46:34.791321"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4630.256, "latencies_ms": [4630.256], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider leaning into a turn. The spectators are located in the background, on the right side of the image, and are positioned behind a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14075.2, "ram_available_mb": 48765.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14075.3, "ram_available_mb": 48765.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.156, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.474}, "timestamp": "2026-01-30T12:46:41.434391"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3989.751, "latencies_ms": [3989.751], "images_per_second": 0.251, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a white helmet and a white and green racing suit is riding a white motorcycle on a road. There are people standing behind a fence watching him.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14075.3, "ram_available_mb": 48765.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14076.6, "ram_available_mb": 48764.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.212}, "power_stats": {"power_gpu_soc_mean_watts": 21.426, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 69.212}, "timestamp": "2026-01-30T12:46:47.452748"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2834.981, "latencies_ms": [2834.981], "images_per_second": 0.353, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The motorcycle is white and green, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.6, "ram_available_mb": 48764.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14076.8, "ram_available_mb": 48764.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.839, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.325, "gpu_utilization_percent_mean": 78.652}, "timestamp": "2026-01-30T12:46:52.306518"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3132.423, "latencies_ms": [3132.423], "images_per_second": 0.319, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A table set with a vase of white flowers and wine glasses is illuminated by a soft light.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14076.8, "ram_available_mb": 48764.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14077.3, "ram_available_mb": 48763.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.759, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 76.538}, "timestamp": "2026-01-30T12:46:57.495621"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4189.866, "latencies_ms": [4189.866], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " table: 1\nflowers: 1\nglass: 4\nwine glass: 2\nspoon: 1\nplate: 1\ncloth: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14077.3, "ram_available_mb": 48763.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14077.5, "ram_available_mb": 48763.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.048, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 71.6}, "timestamp": "2026-01-30T12:47:03.714400"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4340.809, "latencies_ms": [4340.809], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The vase with flowers is placed in the center of the table, with the glasses arranged around it. The table is set against a dark background, with the lights reflecting off the glassware.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.5, "ram_available_mb": 48763.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14076.5, "ram_available_mb": 48764.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.944}, "power_stats": {"power_gpu_soc_mean_watts": 20.653, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 67.944}, "timestamp": "2026-01-30T12:47:10.097208"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3102.391, "latencies_ms": [3102.391], "images_per_second": 0.322, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A table set for a dinner party with a centerpiece of white flowers and wine glasses.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14076.5, "ram_available_mb": 48764.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14076.0, "ram_available_mb": 48764.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.654, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 77.885}, "timestamp": "2026-01-30T12:47:15.236738"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3910.207, "latencies_ms": [3910.207], "images_per_second": 0.256, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The table is covered with a white tablecloth, and the glasses are clear. The lighting is dim, and the table is set for a formal dinner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.0, "ram_available_mb": 48764.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.631, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.114, "gpu_utilization_percent_mean": 73.375}, "timestamp": "2026-01-30T12:47:21.172898"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3723.121, "latencies_ms": [3723.121], "images_per_second": 0.269, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14074.2, "ram_available_mb": 48766.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.903}, "power_stats": {"power_gpu_soc_mean_watts": 25.482, "power_cpu_cv_mean_watts": 0.981, "power_sys_5v0_mean_watts": 8.589, "gpu_utilization_percent_mean": 79.903}, "timestamp": "2026-01-30T12:47:26.926074"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4780.685, "latencies_ms": [4780.685], "images_per_second": 0.209, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " 1. clock: 2\n2. pole: 1\n3. sky: 1\n4. clouds: 1\n5. bird: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.2, "ram_available_mb": 48766.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14074.0, "ram_available_mb": 48766.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.55}, "power_stats": {"power_gpu_soc_mean_watts": 23.054, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.375, "gpu_utilization_percent_mean": 72.55}, "timestamp": "2026-01-30T12:47:33.755601"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5052.891, "latencies_ms": [5052.891], "images_per_second": 0.198, "prompt_tokens": 1450, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The clock is positioned in the center of the image, with the pole extending upwards and the sky in the background. The clock is relatively close to the camera, while the sky is farther away.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14074.0, "ram_available_mb": 48766.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14074.2, "ram_available_mb": 48766.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.881}, "power_stats": {"power_gpu_soc_mean_watts": 22.441, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 8.356, "gpu_utilization_percent_mean": 74.881}, "timestamp": "2026-01-30T12:47:40.844247"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3799.278, "latencies_ms": [3799.278], "images_per_second": 0.263, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black and white photo of a clock on a pole with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.2, "ram_available_mb": 48766.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.742}, "power_stats": {"power_gpu_soc_mean_watts": 25.613, "power_cpu_cv_mean_watts": 1.007, "power_sys_5v0_mean_watts": 8.54, "gpu_utilization_percent_mean": 78.742}, "timestamp": "2026-01-30T12:47:46.677366"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3450.969, "latencies_ms": [3450.969], "images_per_second": 0.29, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The clock is black and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14074.2, "ram_available_mb": 48766.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.643}, "power_stats": {"power_gpu_soc_mean_watts": 26.368, "power_cpu_cv_mean_watts": 0.886, "power_sys_5v0_mean_watts": 8.605, "gpu_utilization_percent_mean": 78.643}, "timestamp": "2026-01-30T12:47:52.162380"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3301.211, "latencies_ms": [3301.211], "images_per_second": 0.303, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a black shirt and a cap is riding a skateboard on a red and gray surface.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 14074.2, "ram_available_mb": 48766.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.176, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.205, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-30T12:47:57.513011"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5465.993, "latencies_ms": [5465.993], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. cap: 1\n4. pants: 1\n5. shoes: 1\n6. trees: 1\n7. ground: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.022}, "power_stats": {"power_gpu_soc_mean_watts": 18.896, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 69.022}, "timestamp": "2026-01-30T12:48:04.998388"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3763.048, "latencies_ms": [3763.048], "images_per_second": 0.266, "prompt_tokens": 1118, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on the skateboard. The background features a park with trees and a building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.419}, "power_stats": {"power_gpu_soc_mean_watts": 21.826, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 70.419}, "timestamp": "2026-01-30T12:48:10.777598"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3656.81, "latencies_ms": [3656.81], "images_per_second": 0.273, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young man wearing a black t-shirt and a blue baseball cap is skateboarding on a red and gray concrete surface in a park.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.167}, "power_stats": {"power_gpu_soc_mean_watts": 22.246, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.211, "gpu_utilization_percent_mean": 75.167}, "timestamp": "2026-01-30T12:48:16.459237"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3670.434, "latencies_ms": [3670.434], "images_per_second": 0.272, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a red and gray concrete surface, with a backdrop of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.7}, "power_stats": {"power_gpu_soc_mean_watts": 22.459, "power_cpu_cv_mean_watts": 1.254, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 75.7}, "timestamp": "2026-01-30T12:48:22.149420"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3073.58, "latencies_ms": [3073.58], "images_per_second": 0.325, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A white plate filled with orange carrots and green beans is placed on a kitchen counter.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14073.4, "ram_available_mb": 48767.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.762, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 73.36}, "timestamp": "2026-01-30T12:48:27.251252"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4879.071, "latencies_ms": [4879.071], "images_per_second": 0.205, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10, carrot: 10", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14073.4, "ram_available_mb": 48767.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.366}, "power_stats": {"power_gpu_soc_mean_watts": 19.647, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.366}, "timestamp": "2026-01-30T12:48:34.169892"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4540.087, "latencies_ms": [4540.087], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The carrots are in the foreground, with the blue scissors and the white container in the background. The carrots are to the left of the scissors, and the white container is to the right of the scissors.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.125, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 67.5}, "timestamp": "2026-01-30T12:48:40.740879"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4673.486, "latencies_ms": [4673.486], "images_per_second": 0.214, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In a kitchen, a white plate is filled with fresh carrots and beets, ready to be cooked. The carrots are bright orange and the beets are a deep red, indicating they are ripe and ready to be used.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.154}, "power_stats": {"power_gpu_soc_mean_watts": 19.926, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 70.154}, "timestamp": "2026-01-30T12:48:47.450769"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4131.162, "latencies_ms": [4131.162], "images_per_second": 0.242, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a white plate filled with orange carrots and green beans, placed on a kitchen counter. The lighting is bright and natural, illuminating the vibrant colors of the vegetables.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.161, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.138, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-30T12:48:53.602353"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3306.416, "latencies_ms": [3306.416], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit and tie is giving a presentation on a large screen in front of an audience.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.963}, "power_stats": {"power_gpu_soc_mean_watts": 22.987, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 72.963}, "timestamp": "2026-01-30T12:48:58.949850"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5439.188, "latencies_ms": [5439.188], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. head: 2\n4. neck: 1\n5. shoulder: 1\n6. arm: 1\n7. hand: 1\n8. screen: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.578}, "power_stats": {"power_gpu_soc_mean_watts": 18.676, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 67.578}, "timestamp": "2026-01-30T12:49:06.424305"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5304.982, "latencies_ms": [5304.982], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man is standing in front of a large screen, which is positioned to the left of the image. The audience is seated in front of the screen, with their heads visible in the foreground. The stage is located in the background, with the man standing on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.909}, "power_stats": {"power_gpu_soc_mean_watts": 18.93, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 68.909}, "timestamp": "2026-01-30T12:49:13.777307"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3425.142, "latencies_ms": [3425.142], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a suit is giving a presentation on a large screen. People are watching him from the audience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.592, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.168, "gpu_utilization_percent_mean": 73.536}, "timestamp": "2026-01-30T12:49:19.245349"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5249.202, "latencies_ms": [5249.202], "images_per_second": 0.191, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a man in a suit and tie standing on a stage, with a large screen behind him displaying a presentation. The lighting is bright and focused on the speaker, while the audience is seated in front of the screen, with their heads visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.091}, "power_stats": {"power_gpu_soc_mean_watts": 19.098, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 69.091}, "timestamp": "2026-01-30T12:49:26.549553"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3767.138, "latencies_ms": [3767.138], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, with a motorcycle parked nearby, and a billboard with Chinese text in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.774}, "power_stats": {"power_gpu_soc_mean_watts": 22.047, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.157, "gpu_utilization_percent_mean": 73.774}, "timestamp": "2026-01-30T12:49:32.387666"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5953.376, "latencies_ms": [5953.376], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Scooters: 3\n2. Motorcycles: 2\n3. Banners: 2\n4. Posters: 1\n5. Signboards: 2\n6. People: 3\n7. Banners: 1\n8. Banners: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.8}, "power_stats": {"power_gpu_soc_mean_watts": 17.937, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 69.8}, "timestamp": "2026-01-30T12:49:40.366539"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5359.785, "latencies_ms": [5359.785], "images_per_second": 0.187, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The three men are standing on the sidewalk, with the motorcycles parked on the left side of the image. The motorcycles are positioned in the foreground, while the men are in the middle ground. The men are standing near the motorcycles, and the motorcycles are near the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.556}, "power_stats": {"power_gpu_soc_mean_watts": 18.604, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 71.556}, "timestamp": "2026-01-30T12:49:47.774207"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3103.491, "latencies_ms": [3103.491], "images_per_second": 0.322, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Three workers in blue uniforms are standing on a street corner, talking to each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.572, "power_cpu_cv_mean_watts": 0.928, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 79.28}, "timestamp": "2026-01-30T12:49:52.904563"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4738.666, "latencies_ms": [4738.666], "images_per_second": 0.211, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image depicts a group of three individuals dressed in blue uniforms, standing on a street corner. The sky is overcast, and the lighting is natural, suggesting it is daytime. The pavement is wet, indicating recent rain.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.718}, "power_stats": {"power_gpu_soc_mean_watts": 20.039, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 71.718}, "timestamp": "2026-01-30T12:49:59.667920"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4660.442, "latencies_ms": [4660.442], "images_per_second": 0.215, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A black plastic container filled with a green and yellow mixture of vegetables and meat is placed on a white paper plate, which is also holding a pile of shredded chicken.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.641}, "power_stats": {"power_gpu_soc_mean_watts": 22.944, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.408, "gpu_utilization_percent_mean": 76.641}, "timestamp": "2026-01-30T12:50:06.383662"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6161.143, "latencies_ms": [6161.143], "images_per_second": 0.162, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bowl: 1\n3. fork: 1\n4. shredded chicken: 1\n5. broccoli: 1\n6. mashed potatoes: 1\n7. sauce: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.231}, "power_stats": {"power_gpu_soc_mean_watts": 20.574, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.28, "gpu_utilization_percent_mean": 72.231}, "timestamp": "2026-01-30T12:50:14.578448"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6034.231, "latencies_ms": [6034.231], "images_per_second": 0.166, "prompt_tokens": 1450, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The black bowl of food is located in the upper left corner of the image, while the white plate with shredded chicken is situated in the lower right corner. The shredded chicken is placed directly in front of the bowl, and the plate is positioned slightly to the right of the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.827, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T12:50:22.629592"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3743.555, "latencies_ms": [3743.555], "images_per_second": 0.267, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate with a bowl of food and a fork on it is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.323}, "power_stats": {"power_gpu_soc_mean_watts": 25.716, "power_cpu_cv_mean_watts": 0.943, "power_sys_5v0_mean_watts": 8.537, "gpu_utilization_percent_mean": 80.323}, "timestamp": "2026-01-30T12:50:28.419308"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5661.804, "latencies_ms": [5661.804], "images_per_second": 0.177, "prompt_tokens": 1442, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a black plastic container filled with a green and yellow mixture of vegetables and chicken, placed on a white paper plate. The food is served on a beige carpeted floor, and the lighting is natural, coming from an unseen source.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.604}, "power_stats": {"power_gpu_soc_mean_watts": 21.378, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 72.604}, "timestamp": "2026-01-30T12:50:36.128233"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3047.461, "latencies_ms": [3047.461], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man with glasses and a plaid hat is smiling in front of a building.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.68}, "power_stats": {"power_gpu_soc_mean_watts": 23.734, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 75.68}, "timestamp": "2026-01-30T12:50:41.231278"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5396.999, "latencies_ms": [5396.999], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. glasses: 1\n3. tie: 1\n4. shirt: 1\n5. cap: 1\n6. building: 1\n7. window: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.913}, "power_stats": {"power_gpu_soc_mean_watts": 18.731, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 68.913}, "timestamp": "2026-01-30T12:50:48.666818"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4736.279, "latencies_ms": [4736.279], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the background consisting of a building and a pool. The man is wearing a blue shirt and a red tie, and he is also wearing a plaid hat.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.875}, "power_stats": {"power_gpu_soc_mean_watts": 19.69, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 68.875}, "timestamp": "2026-01-30T12:50:55.445154"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3124.082, "latencies_ms": [3124.082], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing a plaid hat and glasses is standing in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.8}, "power_stats": {"power_gpu_soc_mean_watts": 23.399, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.2, "gpu_utilization_percent_mean": 76.8}, "timestamp": "2026-01-30T12:51:00.584679"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3311.589, "latencies_ms": [3311.589], "images_per_second": 0.302, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and a red tie, and the picture was taken in bright daylight.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14072.9, "ram_available_mb": 48768.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.192, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 73.815}, "timestamp": "2026-01-30T12:51:05.920896"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4614.191, "latencies_ms": [4614.191], "images_per_second": 0.217, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza, with the top left photo being the most detailed and the bottom right photo being the least detailed.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.079}, "power_stats": {"power_gpu_soc_mean_watts": 23.026, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.433, "gpu_utilization_percent_mean": 76.079}, "timestamp": "2026-01-30T12:51:12.590914"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2876.889, "latencies_ms": [2876.889], "images_per_second": 0.348, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pizza: 6", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.696}, "power_stats": {"power_gpu_soc_mean_watts": 27.558, "power_cpu_cv_mean_watts": 0.591, "power_sys_5v0_mean_watts": 8.685, "gpu_utilization_percent_mean": 87.696}, "timestamp": "2026-01-30T12:51:17.493073"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6206.608, "latencies_ms": [6206.608], "images_per_second": 0.161, "prompt_tokens": 1450, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The main objects are arranged in a grid pattern, with the largest image in the top left corner and the smallest in the bottom right. The slices of pizza are positioned in a way that creates a sense of depth, with the largest slice in the top left and the smallest in the bottom right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.623}, "power_stats": {"power_gpu_soc_mean_watts": 20.581, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 8.25, "gpu_utilization_percent_mean": 72.623}, "timestamp": "2026-01-30T12:51:25.740686"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3481.587, "latencies_ms": [3481.587], "images_per_second": 0.287, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The image is a collage of six photos showing different slices of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.069}, "power_stats": {"power_gpu_soc_mean_watts": 26.315, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.604, "gpu_utilization_percent_mean": 81.069}, "timestamp": "2026-01-30T12:51:31.281384"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3542.071, "latencies_ms": [3542.071], "images_per_second": 0.282, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The pizza has a yellow and orange color, and the lighting is bright.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.172}, "power_stats": {"power_gpu_soc_mean_watts": 26.216, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.611, "gpu_utilization_percent_mean": 81.172}, "timestamp": "2026-01-30T12:51:36.855308"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3042.545, "latencies_ms": [3042.545], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.04}, "power_stats": {"power_gpu_soc_mean_watts": 23.893, "power_cpu_cv_mean_watts": 1.009, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 77.04}, "timestamp": "2026-01-30T12:51:41.968933"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3190.149, "latencies_ms": [3190.149], "images_per_second": 0.313, "prompt_tokens": 1113, "response_tokens_est": 19, "n_tiles": 1, "output_text": " goat: 2, girl: 2, fence: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.487, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.25, "gpu_utilization_percent_mean": 74.269}, "timestamp": "2026-01-30T12:51:47.186367"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5670.696, "latencies_ms": [5670.696], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The two girls are standing on the left side of the image, with the goat in the middle and the other goat on the right side. The goat on the left is being petted by the girl in the pink dress, while the girl in the blue dress is petting the goat on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.477, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T12:51:54.880299"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3040.173, "latencies_ms": [3040.173], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two young girls are petting a goat and a sheep in a fenced area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.44}, "power_stats": {"power_gpu_soc_mean_watts": 23.943, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 78.44}, "timestamp": "2026-01-30T12:51:59.955211"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3867.859, "latencies_ms": [3867.859], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in bright daylight with a clear blue sky in the background. The girls are wearing colorful dresses, and the goats are black and white.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.25}, "power_stats": {"power_gpu_soc_mean_watts": 21.847, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 73.25}, "timestamp": "2026-01-30T12:52:05.850447"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4400.836, "latencies_ms": [4400.836], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a nighttime scene at a street intersection, where a traffic light is illuminated by a green light, and a street sign is visible in the background, indicating the name of the street.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.649}, "power_stats": {"power_gpu_soc_mean_watts": 20.302, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.649}, "timestamp": "2026-01-30T12:52:12.319543"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5699.208, "latencies_ms": [5699.208], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. traffic light: 2\n2. street sign: 1\n3. street light: 1\n4. car: 1\n5. mountain: 1\n6. road: 1\n7. sky: 1\n8. road sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.75}, "power_stats": {"power_gpu_soc_mean_watts": 18.294, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 66.75}, "timestamp": "2026-01-30T12:52:20.073761"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5435.62, "latencies_ms": [5435.62], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The traffic light is on the left side of the image, while the street sign is on the right side. The traffic light is closer to the viewer, while the street sign is farther away. The traffic light is in the foreground, while the street sign is in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.283}, "power_stats": {"power_gpu_soc_mean_watts": 18.601, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 68.283}, "timestamp": "2026-01-30T12:52:27.542834"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5404.528, "latencies_ms": [5404.528], "images_per_second": 0.185, "prompt_tokens": 1111, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a night scene at a street intersection, where a traffic light is illuminated by a green light, signaling vehicles to proceed. The sky is dark, suggesting it is either early morning or late evening, and the street is lined with buildings and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.37}, "power_stats": {"power_gpu_soc_mean_watts": 18.489, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 69.37}, "timestamp": "2026-01-30T12:52:34.984167"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6875.028, "latencies_ms": [6875.028], "images_per_second": 0.145, "prompt_tokens": 1109, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The image captures a serene night scene at a street intersection, where the sky is painted in hues of deep blue, and the moon is partially visible. The traffic lights, glowing in a soft green, stand as silent sentinels guiding the flow of vehicles. The street, bathed in the glow of streetlights, is lined with buildings and trees, their silhouettes adding depth to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.103}, "power_stats": {"power_gpu_soc_mean_watts": 17.024, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 68.103}, "timestamp": "2026-01-30T12:52:43.904128"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3321.305, "latencies_ms": [3321.305], "images_per_second": 0.301, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a patterned dress stands in front of a building with a bunch of bananas in front of her.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.481}, "power_stats": {"power_gpu_soc_mean_watts": 23.384, "power_cpu_cv_mean_watts": 1.142, "power_sys_5v0_mean_watts": 8.25, "gpu_utilization_percent_mean": 73.481}, "timestamp": "2026-01-30T12:52:49.266345"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5503.63, "latencies_ms": [5503.63], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. bananas: 2\n3. building: 1\n4. door: 1\n5. wall: 1\n6. window: 1\n7. sign: 1\n8. wall decoration: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.505, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 68.043}, "timestamp": "2026-01-30T12:52:56.793922"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4054.436, "latencies_ms": [4054.436], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bananas are in the foreground, with the woman standing behind them. The woman is positioned to the right of the bananas, and the building is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.265}, "power_stats": {"power_gpu_soc_mean_watts": 21.127, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 71.265}, "timestamp": "2026-01-30T12:53:02.888213"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2911.428, "latencies_ms": [2911.428], "images_per_second": 0.343, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman is standing in front of a building with bananas on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.833}, "power_stats": {"power_gpu_soc_mean_watts": 24.271, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.302, "gpu_utilization_percent_mean": 76.833}, "timestamp": "2026-01-30T12:53:07.853916"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3668.533, "latencies_ms": [3668.533], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken in a sunny day with a warm color tone. The woman is wearing a colorful dress and the bananas are yellow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.313, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 69.233}, "timestamp": "2026-01-30T12:53:13.536267"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6848.145, "latencies_ms": [6848.145], "images_per_second": 0.146, "prompt_tokens": 1432, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, featuring a red brick building adorned with a green awning and a green fire escape. The building's facade is a canvas of graffiti, with various tags and markings adorning the shuttered windows and doors. A fire hydrant stands guard on the sidewalk, adding a touch of urban grit to the scene.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.228}, "power_stats": {"power_gpu_soc_mean_watts": 19.655, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 71.228}, "timestamp": "2026-01-30T12:53:22.436954"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3948.583, "latencies_ms": [3948.583], "images_per_second": 0.253, "prompt_tokens": 1446, "response_tokens_est": 20, "n_tiles": 1, "output_text": " fire hydrant: 1\nbike rack: 1\ngraffiti: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.333}, "power_stats": {"power_gpu_soc_mean_watts": 24.569, "power_cpu_cv_mean_watts": 1.055, "power_sys_5v0_mean_watts": 8.454, "gpu_utilization_percent_mean": 77.333}, "timestamp": "2026-01-30T12:53:28.423166"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5991.655, "latencies_ms": [5991.655], "images_per_second": 0.167, "prompt_tokens": 1450, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The fire hydrant is located on the left side of the image, in the foreground. The building is in the background, with the sidewalk in front of it. The graffiti on the shutters is located in the middle ground, between the fire hydrant and the building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.975, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T12:53:36.459171"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7442.477, "latencies_ms": [7442.477], "images_per_second": 0.134, "prompt_tokens": 1444, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The image captures a vibrant urban scene, where a red brick building stands proudly on a city street corner. The building's green awning and shuttered windows add a splash of color to the otherwise monochrome facade. A fire hydrant, a common sight on city streets, stands guard on the sidewalk, while a tree in the background adds a touch of nature to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.937}, "power_stats": {"power_gpu_soc_mean_watts": 19.15, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 69.937}, "timestamp": "2026-01-30T12:53:45.941132"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4584.614, "latencies_ms": [4584.614], "images_per_second": 0.218, "prompt_tokens": 1442, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a red brick building with green shutters and a fire escape. The building is covered in graffiti, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.289}, "power_stats": {"power_gpu_soc_mean_watts": 23.631, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 8.416, "gpu_utilization_percent_mean": 75.289}, "timestamp": "2026-01-30T12:53:52.572124"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3275.135, "latencies_ms": [3275.135], "images_per_second": 0.305, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man wearing a blue and white striped beanie is holding a yellow frisbee in his hand.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.266, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.246, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-30T12:53:57.889695"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5771.806, "latencies_ms": [5771.806], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. head: 1\n3. hair: 1\n4. shirt: 1\n5. hand: 1\n6. frisbee: 1\n7. ceiling: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14070.1, "ram_available_mb": 48770.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.898}, "power_stats": {"power_gpu_soc_mean_watts": 17.609, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.867, "gpu_utilization_percent_mean": 66.898}, "timestamp": "2026-01-30T12:54:05.688471"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4777.103, "latencies_ms": [4777.103], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee in his hand. The frisbee is in front of him, and the background is blurred, indicating that the focus is on the man and the frisbee.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14070.1, "ram_available_mb": 48770.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.858, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-30T12:54:12.484492"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3253.026, "latencies_ms": [3253.026], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing a blue hat and a black shirt is playing frisbee in a dark room.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.852}, "power_stats": {"power_gpu_soc_mean_watts": 23.264, "power_cpu_cv_mean_watts": 1.052, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 71.852}, "timestamp": "2026-01-30T12:54:17.791681"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3776.796, "latencies_ms": [3776.796], "images_per_second": 0.265, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is a black and white photo with a blue and white striped hat. The lighting is dim, and the subject is in the foreground.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.682, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 73.031}, "timestamp": "2026-01-30T12:54:23.615458"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3458.078, "latencies_ms": [3458.078], "images_per_second": 0.289, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A group of people are sitting around a table with laptops and books, and they are all looking at the laptop screens.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14069.5, "ram_available_mb": 48771.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.863, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 74.893}, "timestamp": "2026-01-30T12:54:29.103650"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4114.249, "latencies_ms": [4114.249], "images_per_second": 0.243, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 3, keyboard: 1, mouse: 1, cup: 1, bottle: 1, book: 1, person: 4", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14069.5, "ram_available_mb": 48771.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14069.3, "ram_available_mb": 48771.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.941}, "power_stats": {"power_gpu_soc_mean_watts": 21.02, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 70.941}, "timestamp": "2026-01-30T12:54:35.232609"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5357.019, "latencies_ms": [5357.019], "images_per_second": 0.187, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the woman is on the right side of the table, and the man is in the middle of the table. The laptop is in the foreground, the woman is in the middle, and the man is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.3, "ram_available_mb": 48771.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.733}, "power_stats": {"power_gpu_soc_mean_watts": 18.774, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.733}, "timestamp": "2026-01-30T12:54:42.617173"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3079.732, "latencies_ms": [3079.732], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, working on their laptops.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14068.8, "ram_available_mb": 48772.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.96}, "power_stats": {"power_gpu_soc_mean_watts": 24.118, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.284, "gpu_utilization_percent_mean": 75.96}, "timestamp": "2026-01-30T12:54:47.741699"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5046.995, "latencies_ms": [5046.995], "images_per_second": 0.198, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm yellow light. The people are using laptops and computers, and there are many objects on the table, including a glass of water, a cup, and a bottle of ketchup.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14068.8, "ram_available_mb": 48772.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14069.0, "ram_available_mb": 48771.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.286}, "power_stats": {"power_gpu_soc_mean_watts": 19.298, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 69.286}, "timestamp": "2026-01-30T12:54:54.825766"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3920.792, "latencies_ms": [3920.792], "images_per_second": 0.255, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is holding a brown teddy bear and a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 14069.0, "ram_available_mb": 48771.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14069.0, "ram_available_mb": 48771.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.6, "power_cpu_cv_mean_watts": 0.988, "power_sys_5v0_mean_watts": 8.513, "gpu_utilization_percent_mean": 79.75}, "timestamp": "2026-01-30T12:55:00.785899"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6833.062, "latencies_ms": [6833.062], "images_per_second": 0.146, "prompt_tokens": 1446, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. girl: 1\n2. blue umbrella: 1\n3. girl's hand: 1\n4. girl's leg: 1\n5. girl's foot: 1\n6. girl's hand: 1\n7. girl's leg: 1\n8. girl's foot: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.0, "ram_available_mb": 48771.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.93}, "power_stats": {"power_gpu_soc_mean_watts": 20.065, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.221, "gpu_utilization_percent_mean": 68.93}, "timestamp": "2026-01-30T12:55:09.660750"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4429.968, "latencies_ms": [4429.968], "images_per_second": 0.226, "prompt_tokens": 1450, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding the umbrella in her right hand. The umbrella is positioned above her, providing shade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14067.8, "ram_available_mb": 48773.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.27}, "power_stats": {"power_gpu_soc_mean_watts": 23.892, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.464, "gpu_utilization_percent_mean": 76.27}, "timestamp": "2026-01-30T12:55:16.119383"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3939.209, "latencies_ms": [3939.209], "images_per_second": 0.254, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl wearing a pink jacket and blue jeans is standing on a gravel surface holding a blue umbrella.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14067.8, "ram_available_mb": 48773.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14068.4, "ram_available_mb": 48772.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.969}, "power_stats": {"power_gpu_soc_mean_watts": 25.261, "power_cpu_cv_mean_watts": 1.076, "power_sys_5v0_mean_watts": 8.547, "gpu_utilization_percent_mean": 75.969}, "timestamp": "2026-01-30T12:55:22.088483"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4347.131, "latencies_ms": [4347.131], "images_per_second": 0.23, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The girl is wearing a pink jacket and blue jeans, and the umbrella is blue. The lighting is natural and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14068.4, "ram_available_mb": 48772.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14068.7, "ram_available_mb": 48772.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.611}, "power_stats": {"power_gpu_soc_mean_watts": 24.021, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 8.404, "gpu_utilization_percent_mean": 76.611}, "timestamp": "2026-01-30T12:55:28.446930"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4094.003, "latencies_ms": [4094.003], "images_per_second": 0.244, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A man in a suit stands in front of a window with a reflection of another man in it, with a desk in front of him that has a computer monitor and keyboard.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14068.7, "ram_available_mb": 48772.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14068.7, "ram_available_mb": 48772.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.088}, "power_stats": {"power_gpu_soc_mean_watts": 21.196, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.132, "gpu_utilization_percent_mean": 73.088}, "timestamp": "2026-01-30T12:55:34.584748"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4474.431, "latencies_ms": [4474.431], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " man: 1, chair: 1, computer: 2, monitor: 1, keyboard: 1, mouse: 1, tv: 1, tv screen: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.73}, "power_stats": {"power_gpu_soc_mean_watts": 20.288, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 69.73}, "timestamp": "2026-01-30T12:55:41.074727"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4346.965, "latencies_ms": [4346.965], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing to the left of the desk, which is in the foreground of the image. The desk is positioned in front of a window, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14069.3, "ram_available_mb": 48771.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.128, "gpu_utilization_percent_mean": 72.667}, "timestamp": "2026-01-30T12:55:47.451409"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3248.761, "latencies_ms": [3248.761], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a suit is standing in front of a window with a computer setup on a desk.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14069.3, "ram_available_mb": 48771.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.037}, "power_stats": {"power_gpu_soc_mean_watts": 23.177, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.228, "gpu_utilization_percent_mean": 74.037}, "timestamp": "2026-01-30T12:55:52.740202"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3451.757, "latencies_ms": [3451.757], "images_per_second": 0.29, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming from a window. The man is wearing a black suit and tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14068.9, "ram_available_mb": 48772.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.429}, "power_stats": {"power_gpu_soc_mean_watts": 23.077, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.208, "gpu_utilization_percent_mean": 72.429}, "timestamp": "2026-01-30T12:55:58.205594"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3582.021, "latencies_ms": [3582.021], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A group of people are sitting around a table in a room with wooden walls and a window with curtains, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14068.9, "ram_available_mb": 48772.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.533}, "power_stats": {"power_gpu_soc_mean_watts": 22.326, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.173, "gpu_utilization_percent_mean": 74.533}, "timestamp": "2026-01-30T12:56:03.843299"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4582.899, "latencies_ms": [4582.899], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " table: 1\nclock: 1\nwindow: 1\ncurtain: 1\ncup: 1\nbottle: 1\nbowl: 1\nplate: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.579}, "power_stats": {"power_gpu_soc_mean_watts": 20.125, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 69.579}, "timestamp": "2026-01-30T12:56:10.450933"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4537.561, "latencies_ms": [4537.561], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The window is in the background, and the clock is on the wall above the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14068.4, "ram_available_mb": 48772.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.395}, "power_stats": {"power_gpu_soc_mean_watts": 20.124, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 70.395}, "timestamp": "2026-01-30T12:56:17.031466"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4210.731, "latencies_ms": [4210.731], "images_per_second": 0.237, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A group of friends are gathered around a wooden table in a cozy room with a large window. They are enjoying a meal together, with plates of food and drinks on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.4, "ram_available_mb": 48772.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.559}, "power_stats": {"power_gpu_soc_mean_watts": 21.247, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.155, "gpu_utilization_percent_mean": 71.559}, "timestamp": "2026-01-30T12:56:23.257589"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3487.212, "latencies_ms": [3487.212], "images_per_second": 0.287, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is dimly lit with natural light coming through the window, and the wooden table is made of dark wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.479, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.188, "gpu_utilization_percent_mean": 73.172}, "timestamp": "2026-01-30T12:56:28.785826"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3477.1, "latencies_ms": [3477.1], "images_per_second": 0.288, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A red truck with a snow plow attached to the front is driving down a snowy street, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14068.5, "ram_available_mb": 48772.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.31}, "power_stats": {"power_gpu_soc_mean_watts": 22.614, "power_cpu_cv_mean_watts": 1.215, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 73.31}, "timestamp": "2026-01-30T12:56:34.316841"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5552.517, "latencies_ms": [5552.517], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. red truck: 1\n2. snowplow: 1\n3. snow: 1\n4. house: 1\n5. tree: 1\n6. person: 1\n7. road: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.5, "ram_available_mb": 48772.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.809}, "power_stats": {"power_gpu_soc_mean_watts": 18.553, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 68.809}, "timestamp": "2026-01-30T12:56:41.918201"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5385.132, "latencies_ms": [5385.132], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The red truck is in the foreground, driving down the street. The snowplow is attached to the front of the truck, and it is in the middle of the image. The houses are in the background, and the trees are on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14068.5, "ram_available_mb": 48772.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.156}, "power_stats": {"power_gpu_soc_mean_watts": 18.8, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.156}, "timestamp": "2026-01-30T12:56:49.325530"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3861.355, "latencies_ms": [3861.355], "images_per_second": 0.259, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A red truck is driving down a snowy street with a snowplow attached to the front. The truck is passing by a row of houses and trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14068.5, "ram_available_mb": 48772.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14068.7, "ram_available_mb": 48772.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.938}, "power_stats": {"power_gpu_soc_mean_watts": 21.821, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 70.938}, "timestamp": "2026-01-30T12:56:55.243553"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4516.5, "latencies_ms": [4516.5], "images_per_second": 0.221, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a red truck with a snowplow attached to the front, driving down a snowy street. The sky is overcast, and the snow is piled up on the sides of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.7, "ram_available_mb": 48772.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.29, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 70.838}, "timestamp": "2026-01-30T12:57:01.784839"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4294.673, "latencies_ms": [4294.673], "images_per_second": 0.233, "prompt_tokens": 1432, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a luxurious bathroom with a large mirror, a television mounted on the wall, and a sink with a green soap dispenser.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.822, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.492, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-30T12:57:08.142347"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6134.819, "latencies_ms": [6134.819], "images_per_second": 0.163, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. mirror: 2\n2. television: 1\n3. towel: 3\n4. bath tub: 1\n5. sink: 2\n6. counter: 1\n7. wall: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14068.2, "ram_available_mb": 48772.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.118}, "power_stats": {"power_gpu_soc_mean_watts": 20.709, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 73.118}, "timestamp": "2026-01-30T12:57:16.296330"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6867.234, "latencies_ms": [6867.234], "images_per_second": 0.146, "prompt_tokens": 1450, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The sink is located in the center of the bathroom, with the mirror above it reflecting the person taking the photo. The towels are hanging on the wall to the left of the sink, while the television is mounted on the wall above the sink. The person is standing in front of the mirror, which is positioned to the right of the sink.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14068.2, "ram_available_mb": 48772.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.431}, "power_stats": {"power_gpu_soc_mean_watts": 19.716, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 71.431}, "timestamp": "2026-01-30T12:57:25.200070"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3493.667, "latencies_ms": [3493.667], "images_per_second": 0.286, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A man is taking a picture of himself in a bathroom mirror.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14068.5, "ram_available_mb": 48772.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.448}, "power_stats": {"power_gpu_soc_mean_watts": 25.792, "power_cpu_cv_mean_watts": 0.883, "power_sys_5v0_mean_watts": 8.566, "gpu_utilization_percent_mean": 84.448}, "timestamp": "2026-01-30T12:57:30.713779"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5576.26, "latencies_ms": [5576.26], "images_per_second": 0.179, "prompt_tokens": 1442, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The bathroom is well-lit with warm lighting, and the walls are adorned with a mix of beige and white tiles. The countertop is made of dark green marble, and the floor is covered with a white and red patterned rug.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14068.5, "ram_available_mb": 48772.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14068.0, "ram_available_mb": 48772.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.543}, "power_stats": {"power_gpu_soc_mean_watts": 21.534, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 8.305, "gpu_utilization_percent_mean": 72.543}, "timestamp": "2026-01-30T12:57:38.330236"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2919.57, "latencies_ms": [2919.57], "images_per_second": 0.343, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two men are unloading luggage from a cart in an airport parking garage.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14067.9, "ram_available_mb": 48773.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14067.6, "ram_available_mb": 48773.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.708}, "power_stats": {"power_gpu_soc_mean_watts": 24.19, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 75.708}, "timestamp": "2026-01-30T12:57:43.280704"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5368.591, "latencies_ms": [5368.591], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. luggage: 4\n2. luggage: 1\n3. luggage: 1\n4. luggage: 1\n5. luggage: 1\n6. luggage: 1\n7. luggage: 1\n8. luggage: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14067.6, "ram_available_mb": 48773.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14067.4, "ram_available_mb": 48773.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.178}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 70.178}, "timestamp": "2026-01-30T12:57:50.668579"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4887.13, "latencies_ms": [4887.13], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man with the luggage is positioned in the foreground, while the man with the shopping cart is in the background. The luggage is placed near the man with the shopping cart, and the car is positioned further back in the parking lot.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14067.4, "ram_available_mb": 48773.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14069.2, "ram_available_mb": 48771.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.496, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 70.195}, "timestamp": "2026-01-30T12:57:57.588133"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2947.268, "latencies_ms": [2947.268], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two men are unloading luggage from a car in an airport parking garage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.2, "ram_available_mb": 48771.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.333}, "power_stats": {"power_gpu_soc_mean_watts": 24.023, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 77.333}, "timestamp": "2026-01-30T12:58:02.580454"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3992.141, "latencies_ms": [3992.141], "images_per_second": 0.25, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image depicts a man in a parking garage with a white car and a black suitcase. The lighting is dim, and the man is wearing a brown shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.909}, "power_stats": {"power_gpu_soc_mean_watts": 21.475, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.133, "gpu_utilization_percent_mean": 72.909}, "timestamp": "2026-01-30T12:58:08.606514"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3130.777, "latencies_ms": [3130.777], "images_per_second": 0.319, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A plate with a sandwich, fries, and a side of ketchup and onions.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.439, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 76.731}, "timestamp": "2026-01-30T12:58:13.784011"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3866.283, "latencies_ms": [3866.283], "images_per_second": 0.259, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " chicken sandwich: 2\nfries: 1\nlettuce: 1\nonion: 1\nketchup: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14068.9, "ram_available_mb": 48772.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.645, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 70.125}, "timestamp": "2026-01-30T12:58:19.709217"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4525.456, "latencies_ms": [4525.456], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the plate, with the fries and ketchup in the background. The lettuce and onion are placed near the sandwich, while the knife is positioned near the fries.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14068.9, "ram_available_mb": 48772.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.649}, "power_stats": {"power_gpu_soc_mean_watts": 20.236, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 66.649}, "timestamp": "2026-01-30T12:58:26.268282"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3141.074, "latencies_ms": [3141.074], "images_per_second": 0.318, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A plate of food with a sandwich, fries, and ketchup is on a table.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.73, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 73.385}, "timestamp": "2026-01-30T12:58:31.432720"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3341.315, "latencies_ms": [3341.315], "images_per_second": 0.299, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The plate is white and the food is colorful. The lighting is bright and the food is well-lit.", "error": null, "sys_before": {"cpu_percent": 53.8, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.16, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.265, "gpu_utilization_percent_mean": 76.667}, "timestamp": "2026-01-30T12:58:36.814962"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3774.254, "latencies_ms": [3774.254], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed covered by a green mosquito net, a wooden table with a candle, and a window with curtains.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14068.0, "ram_available_mb": 48772.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.419}, "power_stats": {"power_gpu_soc_mean_watts": 22.306, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 72.419}, "timestamp": "2026-01-30T12:58:42.620318"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5424.293, "latencies_ms": [5424.293], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. curtains: 2\n3. table: 1\n4. chair: 1\n5. floor: 1\n6. wall: 1\n7. candle: 1\n8. painting: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.0, "ram_available_mb": 48772.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14067.9, "ram_available_mb": 48773.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.326}, "power_stats": {"power_gpu_soc_mean_watts": 18.635, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 69.326}, "timestamp": "2026-01-30T12:58:50.093052"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6358.029, "latencies_ms": [6358.029], "images_per_second": 0.157, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the mosquito net draped over it, creating a sense of intimacy and seclusion. The table and chairs are situated in the foreground, providing a comfortable seating area for guests. The windows and paintings are located in the background, allowing natural light to flood the room and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14067.9, "ram_available_mb": 48773.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.451, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.945, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T12:58:58.494550"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5674.567, "latencies_ms": [5674.567], "images_per_second": 0.176, "prompt_tokens": 1111, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image captures a serene bedroom bathed in natural light, with a large bed draped in a green mosquito net, a wooden table and chairs, and a candle on a side table. The room is adorned with yellow walls and a thatched roof, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14068.6, "ram_available_mb": 48772.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.688}, "power_stats": {"power_gpu_soc_mean_watts": 18.126, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 70.688}, "timestamp": "2026-01-30T12:59:06.193759"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4164.251, "latencies_ms": [4164.251], "images_per_second": 0.24, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The room is bathed in warm yellow light, with a canopy of green fabric draped over the bed, and the walls are adorned with paintings of trees and plants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.1, "ram_available_mb": 48771.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.171}, "power_stats": {"power_gpu_soc_mean_watts": 20.922, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 72.171}, "timestamp": "2026-01-30T12:59:12.383332"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3365.218, "latencies_ms": [3365.218], "images_per_second": 0.297, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A gray and white cat with a blue collar is standing on the hood of a black car in a garage.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.838, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.2, "gpu_utilization_percent_mean": 73.179}, "timestamp": "2026-01-30T12:59:17.790867"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5431.431, "latencies_ms": [5431.431], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. lamp: 1\n4. box: 1\n5. bicycle: 1\n6. gas cylinder: 1\n7. floor: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.435}, "power_stats": {"power_gpu_soc_mean_watts": 18.723, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 68.435}, "timestamp": "2026-01-30T12:59:25.268878"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4765.628, "latencies_ms": [4765.628], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The cat is positioned in the foreground, near the center of the image, on top of the car. The lamp is located to the left of the cat, while the box is situated in the background, behind the cat.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14070.2, "ram_available_mb": 48770.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.05}, "power_stats": {"power_gpu_soc_mean_watts": 19.841, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 71.05}, "timestamp": "2026-01-30T12:59:32.064368"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3086.966, "latencies_ms": [3086.966], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A cat with a collar is standing on the hood of a car in a garage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.2, "ram_available_mb": 48770.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14069.9, "ram_available_mb": 48771.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.472, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 73.923}, "timestamp": "2026-01-30T12:59:37.188363"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3390.264, "latencies_ms": [3390.264], "images_per_second": 0.295, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The cat is gray and white, and the car is black. The room is well-lit with natural light.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14069.9, "ram_available_mb": 48771.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.071}, "power_stats": {"power_gpu_soc_mean_watts": 23.139, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 74.071}, "timestamp": "2026-01-30T12:59:42.605477"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3447.912, "latencies_ms": [3447.912], "images_per_second": 0.29, "prompt_tokens": 1432, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food with a knife on it is on a table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14069.2, "ram_available_mb": 48771.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.536}, "power_stats": {"power_gpu_soc_mean_watts": 26.011, "power_cpu_cv_mean_watts": 0.858, "power_sys_5v0_mean_watts": 8.644, "gpu_utilization_percent_mean": 83.536}, "timestamp": "2026-01-30T12:59:48.086861"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6017.206, "latencies_ms": [6017.206], "images_per_second": 0.166, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. knife: 1\n3. food: 1\n4. table: 1\n5. fork: 1\n6. sandwich: 1\n7. sauce: 1\n8. bread: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 14069.2, "ram_available_mb": 48771.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14066.9, "ram_available_mb": 48774.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.941}, "power_stats": {"power_gpu_soc_mean_watts": 20.805, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 8.286, "gpu_utilization_percent_mean": 72.941}, "timestamp": "2026-01-30T12:59:56.139013"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4631.994, "latencies_ms": [4631.994], "images_per_second": 0.216, "prompt_tokens": 1450, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The plate with the food is in the foreground, and the knife is on the plate. The food is on the plate, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14066.9, "ram_available_mb": 48774.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.974}, "power_stats": {"power_gpu_soc_mean_watts": 23.481, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.413, "gpu_utilization_percent_mean": 74.974}, "timestamp": "2026-01-30T13:00:02.793305"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3469.556, "latencies_ms": [3469.556], "images_per_second": 0.288, "prompt_tokens": 1444, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate of food is on a table with a knife on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.1, "ram_available_mb": 48772.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.034}, "power_stats": {"power_gpu_soc_mean_watts": 26.494, "power_cpu_cv_mean_watts": 0.883, "power_sys_5v0_mean_watts": 8.639, "gpu_utilization_percent_mean": 81.034}, "timestamp": "2026-01-30T13:00:08.279305"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5707.284, "latencies_ms": [5707.284], "images_per_second": 0.175, "prompt_tokens": 1442, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image has a warm and inviting atmosphere, with the colors of the food and the table contrasting nicely. The lighting is natural, coming from the window in the background, and the table is made of metal with a black and white checkered pattern.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.583}, "power_stats": {"power_gpu_soc_mean_watts": 21.39, "power_cpu_cv_mean_watts": 1.493, "power_sys_5v0_mean_watts": 8.303, "gpu_utilization_percent_mean": 72.583}, "timestamp": "2026-01-30T13:00:16.016562"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4629.945, "latencies_ms": [4629.945], "images_per_second": 0.216, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the image, there are three men in a living room, with one man standing and the other two sitting on a couch. The standing man is holding a camera, while the two seated men are holding cans.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.359}, "power_stats": {"power_gpu_soc_mean_watts": 19.845, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 69.359}, "timestamp": "2026-01-30T13:00:22.673757"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4226.772, "latencies_ms": [4226.772], "images_per_second": 0.237, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " table: 1\ncouch: 1\nwindow: 1\nlamp: 1\ntable: 1\nsofa: 1\nperson: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14068.3, "ram_available_mb": 48772.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14069.0, "ram_available_mb": 48771.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.086}, "power_stats": {"power_gpu_soc_mean_watts": 21.104, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.145, "gpu_utilization_percent_mean": 73.086}, "timestamp": "2026-01-30T13:00:28.934852"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6164.457, "latencies_ms": [6164.457], "images_per_second": 0.162, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The man in the white shirt is standing to the right of the man in the blue shirt, who is sitting on the couch. The man in the white shirt is also standing closer to the camera than the man in the blue shirt. The man in the blue shirt is sitting on the couch, while the man in the white shirt is standing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.0, "ram_available_mb": 48771.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.173}, "power_stats": {"power_gpu_soc_mean_watts": 17.863, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 69.173}, "timestamp": "2026-01-30T13:00:37.118669"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4471.572, "latencies_ms": [4471.572], "images_per_second": 0.224, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " A group of friends are gathered in a living room, enjoying a casual get-together. The room is furnished with a comfortable couch, a coffee table, and a lamp, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.31, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 71.892}, "timestamp": "2026-01-30T13:00:43.630540"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3545.615, "latencies_ms": [3545.615], "images_per_second": 0.282, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is lit by a lamp and has a warm yellow light. The walls are painted white and the floor is wooden.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.586}, "power_stats": {"power_gpu_soc_mean_watts": 22.696, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.195, "gpu_utilization_percent_mean": 74.586}, "timestamp": "2026-01-30T13:00:49.229693"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4511.479, "latencies_ms": [4511.479], "images_per_second": 0.222, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a baseball catcher in a crouched position, wearing a black helmet, black and white uniform, and a black and yellow glove, poised to catch a ball during a game.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14070.5, "ram_available_mb": 48770.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.421}, "power_stats": {"power_gpu_soc_mean_watts": 19.965, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 72.421}, "timestamp": "2026-01-30T13:00:55.800969"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7287.574, "latencies_ms": [7287.574], "images_per_second": 0.137, "prompt_tokens": 1113, "response_tokens_est": 86, "n_tiles": 1, "output_text": " 1. catcher's mitt: 1\n2. catcher's helmet: 1\n3. catcher's mask: 1\n4. catcher's chest protector: 1\n5. catcher's leg guards: 1\n6. catcher's leg pads: 1\n7. catcher's leg guards: 1\n8. catcher's leg pads: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.5, "ram_available_mb": 48770.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.129}, "power_stats": {"power_gpu_soc_mean_watts": 16.657, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.928, "gpu_utilization_percent_mean": 67.129}, "timestamp": "2026-01-30T13:01:05.121032"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5341.903, "latencies_ms": [5341.903], "images_per_second": 0.187, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The catcher is positioned in the foreground, squatting behind home plate, while the batter is in the background, standing in the batter's box. The catcher's glove is near the catcher, and the batter's bat is far away from the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.57, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T13:01:12.497763"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3440.382, "latencies_ms": [3440.382], "images_per_second": 0.291, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A baseball player is crouched in the batter's box, wearing a black helmet and catcher's gear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.379}, "power_stats": {"power_gpu_soc_mean_watts": 22.602, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.158, "gpu_utilization_percent_mean": 71.379}, "timestamp": "2026-01-30T13:01:17.981935"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6711.047, "latencies_ms": [6711.047], "images_per_second": 0.149, "prompt_tokens": 1109, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image captures a moment of intense focus and concentration, with the catcher crouched in the batter's box, his body poised and ready for action. The warm glow of the stadium lights illuminates the scene, casting long shadows and highlighting the vibrant colors of the catcher's uniform. The grass surrounding the field is a lush green, contrasting with the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.368}, "power_stats": {"power_gpu_soc_mean_watts": 17.295, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 67.368}, "timestamp": "2026-01-30T13:01:26.707831"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3807.639, "latencies_ms": [3807.639], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a bathroom with a pink and white color scheme, featuring a bathtub, a toilet, and a wooden vanity with a mirror above it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.438}, "power_stats": {"power_gpu_soc_mean_watts": 21.871, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 74.438}, "timestamp": "2026-01-30T13:01:32.543026"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4246.145, "latencies_ms": [4246.145], "images_per_second": 0.236, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " 1. Bathtub\n2. Toilet\n3. Window\n4. Shower curtain\n5. Sink\n6. Counter\n7. Mirror\n8. Door", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.056}, "power_stats": {"power_gpu_soc_mean_watts": 20.743, "power_cpu_cv_mean_watts": 1.435, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 72.056}, "timestamp": "2026-01-30T13:01:38.828355"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6010.701, "latencies_ms": [6010.701], "images_per_second": 0.166, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The shower curtain is located in the middle of the bathroom, with the sink and toilet positioned to the right of it. The bathtub is situated on the left side of the room, with the window above it. The door is located on the left side of the room, with the sink and toilet positioned to the right of it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.039}, "power_stats": {"power_gpu_soc_mean_watts": 17.893, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 68.039}, "timestamp": "2026-01-30T13:01:46.865965"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2946.56, "latencies_ms": [2946.56], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A bathroom with pink tiles and a white toilet is shown in the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.583}, "power_stats": {"power_gpu_soc_mean_watts": 24.141, "power_cpu_cv_mean_watts": 1.034, "power_sys_5v0_mean_watts": 8.273, "gpu_utilization_percent_mean": 75.583}, "timestamp": "2026-01-30T13:01:51.844449"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4195.507, "latencies_ms": [4195.507], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bathroom is painted in a light blue color with pink tiles on the walls and floor. The lighting is bright and natural, coming from a window above the bathtub.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.456, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 71.4}, "timestamp": "2026-01-30T13:01:58.087923"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4874.601, "latencies_ms": [4874.601], "images_per_second": 0.205, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid bedspread, positioned in the center of the room, and a window with a white curtain on the left side, allowing natural light to enter the room.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.513, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T13:02:05.004802"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5632.273, "latencies_ms": [5632.273], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. bed: 1\n2. window: 1\n3. curtain: 2\n4. wall: 1\n5. lamp: 1\n6. bedside table: 1\n7. bed sheet: 1\n8. bed frame: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14069.2, "ram_available_mb": 48771.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.938}, "power_stats": {"power_gpu_soc_mean_watts": 18.369, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 69.938}, "timestamp": "2026-01-30T13:02:12.665577"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4513.216, "latencies_ms": [4513.216], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The bed is located in the foreground of the image, with the window and curtains in the background. The lamp is positioned on the right side of the bed, while the window is on the left side.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14069.2, "ram_available_mb": 48771.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14069.3, "ram_available_mb": 48771.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.274, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 68.5}, "timestamp": "2026-01-30T13:02:19.200105"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5402.127, "latencies_ms": [5402.127], "images_per_second": 0.185, "prompt_tokens": 1111, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a yellow and white plaid bedspread, positioned in the center of the room. The room is illuminated by natural light coming through a window with white curtains, and there is a lamp on a nightstand next to the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.3, "ram_available_mb": 48771.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.913}, "power_stats": {"power_gpu_soc_mean_watts": 18.655, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 69.913}, "timestamp": "2026-01-30T13:02:26.638971"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3439.31, "latencies_ms": [3439.31], "images_per_second": 0.291, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is dimly lit with a yellow wall and a bed with a yellow and white plaid comforter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.6, "ram_available_mb": 48771.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.828}, "power_stats": {"power_gpu_soc_mean_watts": 22.769, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 72.828}, "timestamp": "2026-01-30T13:02:32.099434"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3775.545, "latencies_ms": [3775.545], "images_per_second": 0.265, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman in a black dress is pinning a white flower to a man's suit jacket.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14069.5, "ram_available_mb": 48771.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.355}, "power_stats": {"power_gpu_soc_mean_watts": 25.096, "power_cpu_cv_mean_watts": 0.994, "power_sys_5v0_mean_watts": 8.527, "gpu_utilization_percent_mean": 80.355}, "timestamp": "2026-01-30T13:02:37.910912"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6172.966, "latencies_ms": [6172.966], "images_per_second": 0.162, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. Man: 1\n2. Woman: 1\n3. Flower: 1\n4. Tie: 1\n5. Suit: 1\n6. Dress: 1\n7. Shoes: 1\n8. Wall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14069.5, "ram_available_mb": 48771.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.327}, "power_stats": {"power_gpu_soc_mean_watts": 20.737, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 71.327}, "timestamp": "2026-01-30T13:02:46.095826"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5316.24, "latencies_ms": [5316.24], "images_per_second": 0.188, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The woman is standing to the right of the man, and she is closer to the camera than the man. The woman is holding the man's tie, and the tie is positioned in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.956}, "power_stats": {"power_gpu_soc_mean_watts": 21.782, "power_cpu_cv_mean_watts": 1.405, "power_sys_5v0_mean_watts": 8.302, "gpu_utilization_percent_mean": 73.956}, "timestamp": "2026-01-30T13:02:53.440523"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4431.363, "latencies_ms": [4431.363], "images_per_second": 0.226, "prompt_tokens": 1444, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a suit and tie is getting a boutonniere pinned to his lapel by a woman in a black dress.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14069.4, "ram_available_mb": 48771.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.622}, "power_stats": {"power_gpu_soc_mean_watts": 23.384, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.372, "gpu_utilization_percent_mean": 74.622}, "timestamp": "2026-01-30T13:02:59.918348"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5250.544, "latencies_ms": [5250.544], "images_per_second": 0.19, "prompt_tokens": 1442, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is well-lit with natural light, and the colors are vibrant and warm. The man is wearing a black suit and tie, while the woman is dressed in a black dress with a beige ribbon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.4, "ram_available_mb": 48771.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14069.5, "ram_available_mb": 48771.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.75}, "power_stats": {"power_gpu_soc_mean_watts": 22.04, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 8.338, "gpu_utilization_percent_mean": 72.75}, "timestamp": "2026-01-30T13:03:07.192056"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3924.153, "latencies_ms": [3924.153], "images_per_second": 0.255, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image shows a chain-link fence with a stop sign attached to it, situated in a grassy area with palm trees and a building in the background.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 14069.5, "ram_available_mb": 48771.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.608, "power_cpu_cv_mean_watts": 1.238, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 69.125}, "timestamp": "2026-01-30T13:03:13.149767"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4420.421, "latencies_ms": [4420.421], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " 1. chain link fence\n2. stop sign\n3. palm tree\n4. building\n5. trash\n6. sidewalk\n7. green bush\n8. chain link fence", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.568}, "power_stats": {"power_gpu_soc_mean_watts": 20.269, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 73.568}, "timestamp": "2026-01-30T13:03:19.603543"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4593.17, "latencies_ms": [4593.17], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The stop sign is located in the foreground of the image, on the left side, and is positioned near a chain link fence. The background of the image features a grassy area with palm trees and a building.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14070.4, "ram_available_mb": 48770.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.051, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 69.789}, "timestamp": "2026-01-30T13:03:26.232063"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5247.833, "latencies_ms": [5247.833], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image captures a scene of a chain-link fence with a stop sign attached to it, set against a backdrop of a grassy area and palm trees. The stop sign, with its bold red color and white letters, stands out prominently against the natural surroundings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14070.4, "ram_available_mb": 48770.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.364}, "power_stats": {"power_gpu_soc_mean_watts": 18.872, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 71.364}, "timestamp": "2026-01-30T13:03:33.537972"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4215.413, "latencies_ms": [4215.413], "images_per_second": 0.237, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a red and white stop sign, a chain link fence, and a grassy area with palm trees. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.579, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 71.057}, "timestamp": "2026-01-30T13:03:39.787986"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4182.771, "latencies_ms": [4182.771], "images_per_second": 0.239, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A man wearing a helmet is riding a motorcycle next to a black bicycle with a basket on the back, while a man in a gray shirt and khaki shorts stands nearby.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.94, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 68.676}, "timestamp": "2026-01-30T13:03:45.991645"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4612.331, "latencies_ms": [4612.331], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. yellow bicycle\n2. black bicycle\n3. motorcycle\n4. person\n5. person's hand\n6. person's leg\n7. person's foot\n8. person's shoe", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.632}, "power_stats": {"power_gpu_soc_mean_watts": 20.114, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 68.632}, "timestamp": "2026-01-30T13:03:52.637912"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5001.759, "latencies_ms": [5001.759], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The yellow bicycle is positioned to the left of the black bicycle, which is in the foreground of the image. The person standing next to the black bicycle is positioned in the background, while the motorcycle is positioned to the left of the bicycles.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.756}, "power_stats": {"power_gpu_soc_mean_watts": 19.326, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 70.756}, "timestamp": "2026-01-30T13:03:59.655382"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2771.687, "latencies_ms": [2771.687], "images_per_second": 0.361, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A man is standing next to a bike and a motorcycle.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.696, "power_cpu_cv_mean_watts": 0.837, "power_sys_5v0_mean_watts": 8.286, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-30T13:04:04.446807"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5363.421, "latencies_ms": [5363.421], "images_per_second": 0.186, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a man wearing a helmet and a black leather jacket, standing next to a black bicycle with a brown basket on the back. The bicycle is parked on a street with a yellow bicycle parked next to it. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.578}, "power_stats": {"power_gpu_soc_mean_watts": 18.896, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 68.578}, "timestamp": "2026-01-30T13:04:11.837221"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4003.665, "latencies_ms": [4003.665], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there are two people standing on the sidewalk, with a traffic light and a street sign nearby, and a red car parked on the street.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.939}, "power_stats": {"power_gpu_soc_mean_watts": 21.304, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 72.939}, "timestamp": "2026-01-30T13:04:17.876658"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4482.224, "latencies_ms": [4482.224], "images_per_second": 0.223, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. black pole\n2. yellow sign\n3. black trash can\n4. traffic light\n5. street sign\n6. pedestrian crossing\n7. red car\n8. person", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.342, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 69.351}, "timestamp": "2026-01-30T13:04:24.373175"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4604.054, "latencies_ms": [4604.054], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The two individuals are standing on the sidewalk, which is located in the foreground of the image. The traffic light is positioned in the background, and the street sign is situated to the left of the traffic light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.395}, "power_stats": {"power_gpu_soc_mean_watts": 20.197, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 69.395}, "timestamp": "2026-01-30T13:04:31.006690"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4568.219, "latencies_ms": [4568.219], "images_per_second": 0.219, "prompt_tokens": 1111, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a bustling city intersection with two pedestrians standing on the sidewalk, engaged in conversation. The street is lined with buildings and trees, and there are traffic lights and street signs visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.156, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.474}, "timestamp": "2026-01-30T13:04:37.607746"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5619.723, "latencies_ms": [5619.723], "images_per_second": 0.178, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image depicts a city street with a mix of natural and artificial lighting. The colors are predominantly muted with the exception of the red car and the yellow sign, which stand out against the urban backdrop. The weather appears to be overcast, as there are no strong shadows cast on the ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.404}, "power_stats": {"power_gpu_soc_mean_watts": 18.579, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 70.404}, "timestamp": "2026-01-30T13:04:45.262226"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3758.394, "latencies_ms": [3758.394], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A bronze statue of two people sitting on a bench with a handbag next to them is in front of a building with a closed shutter.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.258}, "power_stats": {"power_gpu_soc_mean_watts": 21.955, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.149, "gpu_utilization_percent_mean": 71.258}, "timestamp": "2026-01-30T13:04:51.045840"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5446.215, "latencies_ms": [5446.215], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. statue: 2\n2. bench: 1\n3. bag: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.178}, "power_stats": {"power_gpu_soc_mean_watts": 18.772, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 67.178}, "timestamp": "2026-01-30T13:04:58.525142"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5029.436, "latencies_ms": [5029.436], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The statue of two people is positioned on the left side of the image, with the bench and handbag placed in the foreground. The background features a group of people standing near a closed shop, with the statue's shadow cast on the ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.429}, "power_stats": {"power_gpu_soc_mean_watts": 19.418, "power_cpu_cv_mean_watts": 1.554, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 70.429}, "timestamp": "2026-01-30T13:05:05.571181"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3418.41, "latencies_ms": [3418.41], "images_per_second": 0.293, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A bronze statue of two people sitting on a bench, with a handbag on the ground next to them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.649, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.173, "gpu_utilization_percent_mean": 75.214}, "timestamp": "2026-01-30T13:05:11.005634"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3566.848, "latencies_ms": [3566.848], "images_per_second": 0.28, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The statue is made of bronze and is located in a public square. The lighting is natural and the weather is overcast.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.222, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.133, "gpu_utilization_percent_mean": 71.8}, "timestamp": "2026-01-30T13:05:16.605006"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5041.526, "latencies_ms": [5041.526], "images_per_second": 0.198, "prompt_tokens": 1100, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image shows a series of road signs, including a blue sign with white text and symbols, a green sign with white text and symbols, a red and white circular sign with a truck symbol, and a blue and white sign with a parking symbol.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.286}, "power_stats": {"power_gpu_soc_mean_watts": 19.313, "power_cpu_cv_mean_watts": 1.554, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 69.286}, "timestamp": "2026-01-30T13:05:23.682460"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4581.173, "latencies_ms": [4581.173], "images_per_second": 0.218, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. signpost\n2. blue sign\n3. green sign\n4. white sign\n5. red and blue sign\n6. white arrow\n7. blue arrow\n8. white text", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.421}, "power_stats": {"power_gpu_soc_mean_watts": 20.104, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 68.421}, "timestamp": "2026-01-30T13:05:30.281182"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5427.058, "latencies_ms": [5427.058], "images_per_second": 0.184, "prompt_tokens": 1118, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The blue sign is on the left, the green sign is in the middle, and the red and blue signs are on the right. The blue sign is in the foreground, while the green sign is in the middle ground, and the red and blue signs are in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14074.3, "ram_available_mb": 48766.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.109}, "power_stats": {"power_gpu_soc_mean_watts": 18.617, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 70.109}, "timestamp": "2026-01-30T13:05:37.762933"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6848.33, "latencies_ms": [6848.33], "images_per_second": 0.146, "prompt_tokens": 1112, "response_tokens_est": 80, "n_tiles": 1, "output_text": " The image captures a scene of a road signpost, standing tall against the backdrop of a cloudy sky. The signpost, adorned with four distinct signs, each with its own unique color and symbol, guides travelers on their journey. The signs, in German, read \"Severins-br\u00fccke\" and \"Koelnnesse,\" indicating the names of nearby bridges and roads.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14075.0, "ram_available_mb": 48765.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.897}, "power_stats": {"power_gpu_soc_mean_watts": 17.015, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 67.897}, "timestamp": "2026-01-30T13:05:46.621759"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5074.517, "latencies_ms": [5074.517], "images_per_second": 0.197, "prompt_tokens": 1110, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a blue and white sign with a yellow truck icon, a green and white sign with a yellow bus icon, and a red and white sign with a blue truck icon. The signs are set against a cloudy sky and surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14075.0, "ram_available_mb": 48765.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14075.0, "ram_available_mb": 48765.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.488}, "power_stats": {"power_gpu_soc_mean_watts": 19.115, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 67.488}, "timestamp": "2026-01-30T13:05:53.746674"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3999.137, "latencies_ms": [3999.137], "images_per_second": 0.25, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " Two women, one in a red shirt and the other in a blue shirt, are standing on a train platform with their luggage, with a woman in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14075.0, "ram_available_mb": 48765.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14075.5, "ram_available_mb": 48765.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.523, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.14, "gpu_utilization_percent_mean": 73.576}, "timestamp": "2026-01-30T13:05:59.783583"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5619.094, "latencies_ms": [5619.094], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. woman: 2\n3. girl: 1\n4. backpack: 1\n5. handbag: 1\n6. suitcase tag: 1\n7. platform: 1\n8. train: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14075.5, "ram_available_mb": 48765.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14076.7, "ram_available_mb": 48764.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.492, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 67.667}, "timestamp": "2026-01-30T13:06:07.415053"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7711.507, "latencies_ms": [7711.507], "images_per_second": 0.13, "prompt_tokens": 1118, "response_tokens_est": 94, "n_tiles": 1, "output_text": " The woman in the red shirt is standing to the left of the woman in the blue shirt, with the woman in the blue shirt being closer to the camera. The woman in the blue shirt is standing in front of the woman in the red shirt, with the woman in the blue shirt being closer to the camera. The woman in the blue shirt is standing in front of the woman in the red shirt, with the woman in the blue shirt being closer to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.7, "ram_available_mb": 48764.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.455}, "power_stats": {"power_gpu_soc_mean_watts": 16.513, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 7.92, "gpu_utilization_percent_mean": 67.455}, "timestamp": "2026-01-30T13:06:17.155482"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3052.749, "latencies_ms": [3052.749], "images_per_second": 0.328, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two women are standing on a train platform, one of them is holding a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.68}, "power_stats": {"power_gpu_soc_mean_watts": 23.974, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.301, "gpu_utilization_percent_mean": 75.68}, "timestamp": "2026-01-30T13:06:22.248874"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4524.67, "latencies_ms": [4524.67], "images_per_second": 0.221, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image is taken during daytime with natural light illuminating the scene. The colors in the image are vibrant, with the red of the woman's shirt standing out against the blue of the girl's t-shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14076.9, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.358, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 68.974}, "timestamp": "2026-01-30T13:06:28.795053"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3316.125, "latencies_ms": [3316.125], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Three zebras with black and white stripes are walking on a dirt path in a forest with purple flowers.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14076.9, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14076.9, "ram_available_mb": 48764.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.237, "power_cpu_cv_mean_watts": 1.127, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 72.37}, "timestamp": "2026-01-30T13:06:34.144638"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2269.782, "latencies_ms": [2269.782], "images_per_second": 0.441, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.9, "ram_available_mb": 48764.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 14077.4, "ram_available_mb": 48763.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.444}, "power_stats": {"power_gpu_soc_mean_watts": 25.221, "power_cpu_cv_mean_watts": 0.622, "power_sys_5v0_mean_watts": 8.254, "gpu_utilization_percent_mean": 87.444}, "timestamp": "2026-01-30T13:06:38.451703"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4933.216, "latencies_ms": [4933.216], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the trees and bushes serving as a backdrop in the background. The zebras are facing the camera, with the tree with purple flowers located to the right of the zebras.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.4, "ram_available_mb": 48763.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14077.4, "ram_available_mb": 48763.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.463}, "power_stats": {"power_gpu_soc_mean_watts": 19.62, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 69.463}, "timestamp": "2026-01-30T13:06:45.400374"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3302.75, "latencies_ms": [3302.75], "images_per_second": 0.303, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Three zebras are walking in a line on a dirt path, surrounded by trees with purple flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.4, "ram_available_mb": 48763.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.074}, "power_stats": {"power_gpu_soc_mean_watts": 22.805, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.158, "gpu_utilization_percent_mean": 76.074}, "timestamp": "2026-01-30T13:06:50.754060"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4212.653, "latencies_ms": [4212.653], "images_per_second": 0.237, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features three zebras with black and white stripes walking on a dirt path. The zebras are surrounded by trees with purple flowers, and the lighting is bright and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.886}, "power_stats": {"power_gpu_soc_mean_watts": 21.036, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-30T13:06:57.007232"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3431.667, "latencies_ms": [3431.667], "images_per_second": 0.291, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A camera is mounted on a tripod in a room with a vending machine and a laptop on a table.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.663, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.149, "gpu_utilization_percent_mean": 71.536}, "timestamp": "2026-01-30T13:07:02.487868"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2351.021, "latencies_ms": [2351.021], "images_per_second": 0.425, "prompt_tokens": 1114, "response_tokens_est": 5, "n_tiles": 1, "output_text": " tripod: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.632}, "power_stats": {"power_gpu_soc_mean_watts": 25.012, "power_cpu_cv_mean_watts": 0.59, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 84.632}, "timestamp": "2026-01-30T13:07:06.872588"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4868.51, "latencies_ms": [4868.51], "images_per_second": 0.205, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The camera is positioned to the right of the tripod, which is in the foreground of the image. The laptop is placed on the tripod, and the vending machine is located in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.688, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 70.341}, "timestamp": "2026-01-30T13:07:13.774616"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3143.894, "latencies_ms": [3143.894], "images_per_second": 0.318, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A camera is on a tripod in a room with a vending machine and a laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14079.3, "ram_available_mb": 48761.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.077}, "power_stats": {"power_gpu_soc_mean_watts": 23.467, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 75.077}, "timestamp": "2026-01-30T13:07:18.978724"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3852.587, "latencies_ms": [3852.587], "images_per_second": 0.26, "prompt_tokens": 1110, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image is taken in a room with a blue and white vending machine in the background. The lighting is natural, and the colors are muted.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14079.3, "ram_available_mb": 48761.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14079.2, "ram_available_mb": 48761.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.406}, "power_stats": {"power_gpu_soc_mean_watts": 21.958, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.154, "gpu_utilization_percent_mean": 71.406}, "timestamp": "2026-01-30T13:07:24.866565"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3908.72, "latencies_ms": [3908.72], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A sheep with a white wool coat is standing in a pen with a pile of wool on the ground, and there is a metal fence in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14079.2, "ram_available_mb": 48761.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.694, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 69.344}, "timestamp": "2026-01-30T13:07:30.830914"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4257.398, "latencies_ms": [4257.398], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " sheep: 1, fence: 1, ball: 1, metal: 1, ground: 1, sheep's wool: 1, fence post: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.933, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 71.571}, "timestamp": "2026-01-30T13:07:37.099186"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4203.113, "latencies_ms": [4203.113], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sheep is in the foreground, standing in front of a metal fence. The sheep is eating the wool, which is in the middle ground. The background is a concrete surface.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14078.4, "ram_available_mb": 48762.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.457}, "power_stats": {"power_gpu_soc_mean_watts": 21.013, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 73.457}, "timestamp": "2026-01-30T13:07:43.331464"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2967.195, "latencies_ms": [2967.195], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A sheep is eating a pile of wool in a fenced-in area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.36}, "power_stats": {"power_gpu_soc_mean_watts": 24.149, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 77.36}, "timestamp": "2026-01-30T13:07:48.335812"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3223.362, "latencies_ms": [3223.362], "images_per_second": 0.31, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sheep is white and the fence is grey. The lighting is natural and the weather is cloudy.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14077.2, "ram_available_mb": 48763.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.074}, "power_stats": {"power_gpu_soc_mean_watts": 23.25, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.231, "gpu_utilization_percent_mean": 75.074}, "timestamp": "2026-01-30T13:07:53.582240"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6592.85, "latencies_ms": [6592.85], "images_per_second": 0.152, "prompt_tokens": 1099, "response_tokens_est": 75, "n_tiles": 1, "output_text": " In the image, a tennis match is taking place on a blue court, with a player in a pink outfit preparing to serve the ball, while the opposing team, wearing red, is positioned near the net. The court is surrounded by a crowd of spectators, and various advertisements are visible in the background, including those for Lexus, Mirvac, and Sony Ericsson.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14077.2, "ram_available_mb": 48763.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.054}, "power_stats": {"power_gpu_soc_mean_watts": 17.273, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.929, "gpu_utilization_percent_mean": 68.054}, "timestamp": "2026-01-30T13:08:02.225569"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4512.752, "latencies_ms": [4512.752], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " 1. tennis court\n2. net\n3. ball\n4. racket\n5. player\n6. player's outfit\n7. player's shoes\n8. player's hair", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.135}, "power_stats": {"power_gpu_soc_mean_watts": 20.213, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 72.135}, "timestamp": "2026-01-30T13:08:08.757454"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5191.23, "latencies_ms": [5191.23], "images_per_second": 0.193, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground, with the net and the ball in the middle ground, and the crowd in the background. The player is near the net, while the ball is in the air, and the crowd is far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.05, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T13:08:15.993725"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3336.915, "latencies_ms": [3336.915], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A tennis match is taking place in a large stadium with a blue court, surrounded by spectators and advertisements.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.407}, "power_stats": {"power_gpu_soc_mean_watts": 23.041, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.186, "gpu_utilization_percent_mean": 73.407}, "timestamp": "2026-01-30T13:08:21.369677"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3282.19, "latencies_ms": [3282.19], "images_per_second": 0.305, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The court is blue, the players are wearing red and pink, and the crowd is watching intently.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14077.8, "ram_available_mb": 48763.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.027, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 72.815}, "timestamp": "2026-01-30T13:08:26.663603"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3783.257, "latencies_ms": [3783.257], "images_per_second": 0.264, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase, and there are signs for the escalator and other directions on the walls.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 14077.8, "ram_available_mb": 48763.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14077.8, "ram_available_mb": 48763.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.032}, "power_stats": {"power_gpu_soc_mean_watts": 21.876, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.141, "gpu_utilization_percent_mean": 73.032}, "timestamp": "2026-01-30T13:08:32.506310"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5546.687, "latencies_ms": [5546.687], "images_per_second": 0.18, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. suitcase: 1\n3. glass door: 1\n4. pillar: 1\n5. sign: 1\n6. wall: 1\n7. floor: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.8, "ram_available_mb": 48763.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.457}, "power_stats": {"power_gpu_soc_mean_watts": 18.609, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 69.457}, "timestamp": "2026-01-30T13:08:40.084141"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5261.774, "latencies_ms": [5261.774], "images_per_second": 0.19, "prompt_tokens": 1118, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main object, a person, is positioned in the foreground, walking towards the camera. The glass door is located in the middle ground, partially obscuring the view of the person. The escalator is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.841}, "power_stats": {"power_gpu_soc_mean_watts": 18.845, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 70.841}, "timestamp": "2026-01-30T13:08:47.365529"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2792.035, "latencies_ms": [2792.035], "images_per_second": 0.358, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is walking through a modern airport terminal with a suitcase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14079.5, "ram_available_mb": 48761.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.043}, "power_stats": {"power_gpu_soc_mean_watts": 24.631, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.348, "gpu_utilization_percent_mean": 78.043}, "timestamp": "2026-01-30T13:08:52.175180"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3944.085, "latencies_ms": [3944.085], "images_per_second": 0.254, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken in a well-lit indoor space with a grey floor and white walls. The lighting is bright and natural, coming from the ceiling lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14079.5, "ram_available_mb": 48761.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.939}, "power_stats": {"power_gpu_soc_mean_watts": 21.597, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 70.939}, "timestamp": "2026-01-30T13:08:58.141990"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3505.02, "latencies_ms": [3505.02], "images_per_second": 0.285, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A dining table is set with two large pizzas, a few glasses of water, and a few forks and knives.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.862}, "power_stats": {"power_gpu_soc_mean_watts": 22.768, "power_cpu_cv_mean_watts": 1.215, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 73.862}, "timestamp": "2026-01-30T13:09:03.714065"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4064.881, "latencies_ms": [4064.881], "images_per_second": 0.246, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " pizza: 2, glasses: 2, fork: 1, knife: 1, spoon: 1, television: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.6, "ram_available_mb": 48762.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14078.8, "ram_available_mb": 48762.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.618}, "power_stats": {"power_gpu_soc_mean_watts": 21.219, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-30T13:09:09.812775"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6253.532, "latencies_ms": [6253.532], "images_per_second": 0.16, "prompt_tokens": 1118, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The large pizza boxes are placed on the table, with one box in the foreground and the other in the background. The glasses of water are positioned near the pizza boxes, with one glass closer to the foreground and the other further back. The fork and knife are placed on the table, with the fork closer to the foreground and the knife further back.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14078.8, "ram_available_mb": 48762.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14079.2, "ram_available_mb": 48761.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.302}, "power_stats": {"power_gpu_soc_mean_watts": 17.827, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 68.302}, "timestamp": "2026-01-30T13:09:18.084925"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3530.334, "latencies_ms": [3530.334], "images_per_second": 0.283, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A dining room with a table set for a pizza party, with two large pizzas and a few glasses of water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14079.2, "ram_available_mb": 48761.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.28, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.175, "gpu_utilization_percent_mean": 72.172}, "timestamp": "2026-01-30T13:09:23.631550"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4835.698, "latencies_ms": [4835.698], "images_per_second": 0.207, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm and cozy atmosphere. The colors in the image are vibrant and inviting, with the red of the pizza boxes standing out against the blue of the television screen in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.15}, "power_stats": {"power_gpu_soc_mean_watts": 19.776, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 70.15}, "timestamp": "2026-01-30T13:09:30.491255"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5197.347, "latencies_ms": [5197.347], "images_per_second": 0.192, "prompt_tokens": 1100, "response_tokens_est": 49, "n_tiles": 1, "output_text": " A young boy wearing a helmet and a gray shirt is standing at home plate, holding a baseball bat, while a catcher in a red shirt and a catcher's mitt is crouched behind him, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14079.0, "ram_available_mb": 48761.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.907}, "power_stats": {"power_gpu_soc_mean_watts": 18.379, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.895, "gpu_utilization_percent_mean": 65.907}, "timestamp": "2026-01-30T13:09:37.730086"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6034.955, "latencies_ms": [6034.955], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball glove: 1\n3. baseball: 1\n4. baseball player: 1\n5. catcher: 1\n6. umpire: 1\n7. spectator: 1\n8. spectator chair: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.68}, "power_stats": {"power_gpu_soc_mean_watts": 17.913, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.932, "gpu_utilization_percent_mean": 70.68}, "timestamp": "2026-01-30T13:09:45.794555"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4252.748, "latencies_ms": [4252.748], "images_per_second": 0.235, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14078.4, "ram_available_mb": 48762.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.842, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 68.286}, "timestamp": "2026-01-30T13:09:52.071663"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2965.166, "latencies_ms": [2965.166], "images_per_second": 0.337, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young boy is playing baseball in a park with a group of people watching.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.4, "ram_available_mb": 48762.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.792}, "power_stats": {"power_gpu_soc_mean_watts": 23.988, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 76.792}, "timestamp": "2026-01-30T13:09:57.055969"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4228.088, "latencies_ms": [4228.088], "images_per_second": 0.237, "prompt_tokens": 1110, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken during a sunny day with clear blue skies. The colors in the image are vibrant, with the green of the grass and trees contrasting against the blue of the sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.094, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.132, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T13:10:03.298465"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2801.067, "latencies_ms": [2801.067], "images_per_second": 0.357, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A banana is on top of a black phone on a desk.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14078.3, "ram_available_mb": 48762.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14078.2, "ram_available_mb": 48762.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.419, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.286, "gpu_utilization_percent_mean": 77.652}, "timestamp": "2026-01-30T13:10:08.139884"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2223.368, "latencies_ms": [2223.368], "images_per_second": 0.45, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.2, "ram_available_mb": 48762.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 14079.2, "ram_available_mb": 48761.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.389}, "power_stats": {"power_gpu_soc_mean_watts": 25.818, "power_cpu_cv_mean_watts": 0.622, "power_sys_5v0_mean_watts": 8.35, "gpu_utilization_percent_mean": 83.389}, "timestamp": "2026-01-30T13:10:12.421534"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4362.21, "latencies_ms": [4362.21], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The banana is located in the foreground, to the right of the phone, and the phone is on the desk. The banana is near the phone, and the desk is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14079.2, "ram_available_mb": 48761.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14078.5, "ram_available_mb": 48762.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.553, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 71.306}, "timestamp": "2026-01-30T13:10:18.807972"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2950.483, "latencies_ms": [2950.483], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A banana is on top of a phone and a computer is on a desk.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14078.5, "ram_available_mb": 48762.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14078.4, "ram_available_mb": 48762.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.583}, "power_stats": {"power_gpu_soc_mean_watts": 24.421, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.31, "gpu_utilization_percent_mean": 78.583}, "timestamp": "2026-01-30T13:10:23.785351"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3677.336, "latencies_ms": [3677.336], "images_per_second": 0.272, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image has a white desk with a black phone and a yellow banana on it. The lighting is natural and the banana is ripe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.4, "ram_available_mb": 48762.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14078.1, "ram_available_mb": 48762.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.967}, "power_stats": {"power_gpu_soc_mean_watts": 22.207, "power_cpu_cv_mean_watts": 1.147, "power_sys_5v0_mean_watts": 8.127, "gpu_utilization_percent_mean": 70.967}, "timestamp": "2026-01-30T13:10:29.474928"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5738.192, "latencies_ms": [5738.192], "images_per_second": 0.174, "prompt_tokens": 1099, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a bustling scene of a crowd of people gathered in a public space, with individuals of various ages and attires, including a woman in a green jacket and a man in a red shirt, among others, all engaged in different activities, with a prominent presence of a woman holding a teddy bear.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14077.5, "ram_available_mb": 48763.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.854}, "power_stats": {"power_gpu_soc_mean_watts": 18.401, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 69.854}, "timestamp": "2026-01-30T13:10:37.267941"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5973.778, "latencies_ms": [5973.778], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. People: 10\n2. Green bag: 1\n3. Red bag: 1\n4. Blue scarf: 1\n5. Red shirt: 1\n6. Green jacket: 1\n7. Black jacket: 1\n8. Gray jacket: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14078.2, "ram_available_mb": 48762.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.74}, "power_stats": {"power_gpu_soc_mean_watts": 18.194, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 67.74}, "timestamp": "2026-01-30T13:10:45.257016"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6344.124, "latencies_ms": [6344.124], "images_per_second": 0.158, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The main objects are the crowd of people, the bus stop sign, and the trees in the background. The crowd of people is in the foreground, the bus stop sign is in the middle ground, and the trees are in the background. The crowd of people is in front of the bus stop sign, and the trees are behind the crowd of people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14078.2, "ram_available_mb": 48762.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.075}, "power_stats": {"power_gpu_soc_mean_watts": 17.647, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 68.075}, "timestamp": "2026-01-30T13:10:53.622368"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4391.394, "latencies_ms": [4391.394], "images_per_second": 0.228, "prompt_tokens": 1111, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A large crowd of people are gathered in a public space, possibly a park or plaza, and they are all engaged in various activities such as talking, laughing, and looking at their phones.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.9, "ram_available_mb": 48763.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.806}, "power_stats": {"power_gpu_soc_mean_watts": 20.63, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 70.806}, "timestamp": "2026-01-30T13:11:00.039492"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3223.853, "latencies_ms": [3223.853], "images_per_second": 0.31, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image is taken during the day with natural lighting, and the colors are vibrant and varied.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.252, "power_cpu_cv_mean_watts": 1.031, "power_sys_5v0_mean_watts": 8.174, "gpu_utilization_percent_mean": 71.385}, "timestamp": "2026-01-30T13:11:05.303519"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3428.199, "latencies_ms": [3428.199], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a red shirt is holding a baby in his arms while a horse nuzzles the baby's hand.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14077.7, "ram_available_mb": 48763.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.705, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 70.357}, "timestamp": "2026-01-30T13:11:10.768287"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6006.969, "latencies_ms": [6006.969], "images_per_second": 0.166, "prompt_tokens": 1114, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. horse: 1\n2. man: 1\n3. baby: 1\n4. man's shirt: 1\n5. man's pants: 1\n6. man's shoes: 1\n7. man's hair: 1\n8. man's face: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14078.0, "ram_available_mb": 48762.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.32}, "power_stats": {"power_gpu_soc_mean_watts": 18.114, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 69.32}, "timestamp": "2026-01-30T13:11:18.788269"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4654.302, "latencies_ms": [4654.302], "images_per_second": 0.215, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is standing to the left of the horse, and the baby is in his arms, which are positioned in the foreground. The horse is in the background, and the man is in front of the horse.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14077.0, "ram_available_mb": 48763.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14076.6, "ram_available_mb": 48764.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.165, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 70.237}, "timestamp": "2026-01-30T13:11:25.468312"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3415.911, "latencies_ms": [3415.911], "images_per_second": 0.293, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man in a red shirt is holding a baby in his arms while a horse nuzzles the baby's hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14076.6, "ram_available_mb": 48764.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14075.6, "ram_available_mb": 48765.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.763, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 71.179}, "timestamp": "2026-01-30T13:11:30.901125"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5321.827, "latencies_ms": [5321.827], "images_per_second": 0.188, "prompt_tokens": 1110, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image features a man wearing a red shirt and a baby in his arms. The man is holding the baby close to a brown horse, which is standing in front of a brick wall. The lighting in the image is natural, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14075.6, "ram_available_mb": 48765.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14075.7, "ram_available_mb": 48765.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.841}, "power_stats": {"power_gpu_soc_mean_watts": 18.88, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 69.841}, "timestamp": "2026-01-30T13:11:38.243958"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2973.841, "latencies_ms": [2973.841], "images_per_second": 0.336, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A white plate with a banana and a small amount of peanut butter on it.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14075.7, "ram_available_mb": 48765.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14075.1, "ram_available_mb": 48765.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.255, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 77.75}, "timestamp": "2026-01-30T13:11:43.240881"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2967.836, "latencies_ms": [2967.836], "images_per_second": 0.337, "prompt_tokens": 1114, "response_tokens_est": 15, "n_tiles": 1, "output_text": " banana: 1, plate: 1, peanut butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14075.1, "ram_available_mb": 48765.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14074.8, "ram_available_mb": 48766.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.583}, "power_stats": {"power_gpu_soc_mean_watts": 23.923, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 71.583}, "timestamp": "2026-01-30T13:11:48.225865"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4151.431, "latencies_ms": [4151.431], "images_per_second": 0.241, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The banana is on the left side of the plate, and the peanut butter is in the center. The plate is in the foreground, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.8, "ram_available_mb": 48766.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14074.9, "ram_available_mb": 48766.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.882}, "power_stats": {"power_gpu_soc_mean_watts": 21.174, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 69.882}, "timestamp": "2026-01-30T13:11:54.394944"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2977.69, "latencies_ms": [2977.69], "images_per_second": 0.336, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A banana and a bowl of peanut butter are on a plate on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.9, "ram_available_mb": 48766.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.958}, "power_stats": {"power_gpu_soc_mean_watts": 23.938, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 74.958}, "timestamp": "2026-01-30T13:11:59.406985"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3457.061, "latencies_ms": [3457.061], "images_per_second": 0.289, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image shows a white plate with a banana and peanut butter on it. The plate is placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.536}, "power_stats": {"power_gpu_soc_mean_watts": 23.032, "power_cpu_cv_mean_watts": 1.172, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 74.536}, "timestamp": "2026-01-30T13:12:04.877067"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3374.774, "latencies_ms": [3374.774], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man in a green shirt and glasses is working on a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.806, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.149, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-30T13:12:10.291291"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5503.112, "latencies_ms": [5503.112], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. motorcycle: 1\n3. bicycle: 1\n4. wheel: 1\n5. tool: 1\n6. tire: 1\n7. chain: 1\n8. chain link: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.522}, "power_stats": {"power_gpu_soc_mean_watts": 18.566, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 67.522}, "timestamp": "2026-01-30T13:12:17.853783"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4892.701, "latencies_ms": [4892.701], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man is kneeling on the left side of the image, with the motorcycle on the right side. The motorcycle is in the foreground, while the bicycle is in the background. The man is closer to the camera than the bicycle.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.171}, "power_stats": {"power_gpu_soc_mean_watts": 19.473, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 71.171}, "timestamp": "2026-01-30T13:12:24.793604"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3014.329, "latencies_ms": [3014.329], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man is fixing a bicycle wheel on the ground next to a motorcycle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.375}, "power_stats": {"power_gpu_soc_mean_watts": 23.821, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 81.375}, "timestamp": "2026-01-30T13:12:29.818029"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4460.232, "latencies_ms": [4460.232], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a man wearing a green shirt and blue pants, kneeling on the ground while working on a bicycle wheel. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.8, "ram_available_mb": 48768.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.147, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T13:12:36.292351"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3011.599, "latencies_ms": [3011.599], "images_per_second": 0.332, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man with long hair is riding a skateboard and jumping in the air.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.04}, "power_stats": {"power_gpu_soc_mean_watts": 23.719, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 75.04}, "timestamp": "2026-01-30T13:12:41.356465"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5502.215, "latencies_ms": [5502.215], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. grass: 1\n4. fence: 1\n5. building: 1\n6. tree: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.13}, "power_stats": {"power_gpu_soc_mean_watts": 18.532, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 68.13}, "timestamp": "2026-01-30T13:12:48.880631"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5319.422, "latencies_ms": [5319.422], "images_per_second": 0.188, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on a ramp. The ramp is located in the middle ground, with the skateboarder's body positioned above it. The background features a fence and trees, providing a natural setting for the skateboarding activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.6, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.882, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 69.25}, "timestamp": "2026-01-30T13:12:56.226389"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2974.527, "latencies_ms": [2974.527], "images_per_second": 0.336, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.375}, "power_stats": {"power_gpu_soc_mean_watts": 23.572, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.197, "gpu_utilization_percent_mean": 79.375}, "timestamp": "2026-01-30T13:13:01.231550"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4598.931, "latencies_ms": [4598.931], "images_per_second": 0.217, "prompt_tokens": 1110, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with the skateboarder wearing a black t-shirt and black pants. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.263}, "power_stats": {"power_gpu_soc_mean_watts": 20.272, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 72.263}, "timestamp": "2026-01-30T13:13:07.859329"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3774.72, "latencies_ms": [3774.72], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of five people are posing for a photo on a grassy field at sunset, each holding a frisbee with different colored designs.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.699, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T13:13:13.687042"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2544.08, "latencies_ms": [2544.08], "images_per_second": 0.393, "prompt_tokens": 1113, "response_tokens_est": 9, "n_tiles": 1, "output_text": " 1. frisbee: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14070.9, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.952}, "power_stats": {"power_gpu_soc_mean_watts": 25.148, "power_cpu_cv_mean_watts": 0.743, "power_sys_5v0_mean_watts": 8.3, "gpu_utilization_percent_mean": 82.952}, "timestamp": "2026-01-30T13:13:18.271632"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6856.296, "latencies_ms": [6856.296], "images_per_second": 0.146, "prompt_tokens": 1117, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The frisbee is held by the person on the left, the person in the middle is holding a frisbee, and the person on the right is holding a frisbee. The frisbee is in the foreground, and the person on the left is in the foreground. The person in the middle is in the middle, and the person on the right is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.9, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.339}, "power_stats": {"power_gpu_soc_mean_watts": 17.026, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 7.908, "gpu_utilization_percent_mean": 69.339}, "timestamp": "2026-01-30T13:13:27.158253"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3084.939, "latencies_ms": [3084.939], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of five people are posing for a picture on a grassy field at sunset.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.622, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.213, "gpu_utilization_percent_mean": 75.88}, "timestamp": "2026-01-30T13:13:32.258140"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6412.604, "latencies_ms": [6412.604], "images_per_second": 0.156, "prompt_tokens": 1109, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a group of five people posing for a photo on a grassy field at sunset. The sky is painted with hues of orange and blue, and the sun is setting behind the horizon, casting a warm glow over the scene. The people are holding frisbees, which are white with green and red designs, and they are all wearing casual athletic clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.7, "ram_available_mb": 48770.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.527}, "power_stats": {"power_gpu_soc_mean_watts": 17.602, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.936, "gpu_utilization_percent_mean": 68.527}, "timestamp": "2026-01-30T13:13:40.716657"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4312.151, "latencies_ms": [4312.151], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A large white airplane with red and black accents is parked at an airport gate, surrounded by a few vehicles and equipment, with a clear blue sky and a few clouds in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.611}, "power_stats": {"power_gpu_soc_mean_watts": 20.407, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 68.611}, "timestamp": "2026-01-30T13:13:47.064185"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4162.892, "latencies_ms": [4162.892], "images_per_second": 0.24, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " airplane: 1, clouds: 1, runway: 1, terminal: 1, luggage cart: 1, palm tree: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.882}, "power_stats": {"power_gpu_soc_mean_watts": 21.265, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.114, "gpu_utilization_percent_mean": 71.882}, "timestamp": "2026-01-30T13:13:53.243745"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5014.916, "latencies_ms": [5014.916], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The airplane is positioned on the left side of the image, with the terminal building located in the background. The airplane is situated in the foreground, with the terminal building in the background. The airplane is closer to the viewer than the terminal building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.322, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T13:14:00.283723"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5749.418, "latencies_ms": [5749.418], "images_per_second": 0.174, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a moment at an airport where a large airplane, adorned with a red and white logo, is parked at a gate. The sky above is a clear blue, dotted with fluffy white clouds, and the ground below is marked with yellow arrows and lines, indicating the path for the airplane's movement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.562}, "power_stats": {"power_gpu_soc_mean_watts": 18.457, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 68.562}, "timestamp": "2026-01-30T13:14:08.075016"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3236.421, "latencies_ms": [3236.421], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The airplane is white with red and black accents, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.159, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.172, "gpu_utilization_percent_mean": 75.538}, "timestamp": "2026-01-30T13:14:13.344247"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3234.886, "latencies_ms": [3234.886], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man wearing a yellow shirt and black pants is skateboarding on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.865, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 76.667}, "timestamp": "2026-01-30T13:14:18.625685"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5551.027, "latencies_ms": [5551.027], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. skateboard: 1\n3. bench: 1\n4. trash can: 1\n5. fence: 1\n6. bench: 1\n7. person: 1\n8. graffiti: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.915}, "power_stats": {"power_gpu_soc_mean_watts": 18.503, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 69.915}, "timestamp": "2026-01-30T13:14:26.223533"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4287.588, "latencies_ms": [4287.588], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick on a ramp, while the bench is in the background. The skateboarder is closer to the camera than the bench.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.705, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 70.5}, "timestamp": "2026-01-30T13:14:32.540941"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2969.428, "latencies_ms": [2969.428], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a park.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.003, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.273, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T13:14:37.551858"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6131.061, "latencies_ms": [6131.061], "images_per_second": 0.163, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a concrete ramp, with a vibrant green grass field in the background. The lighting is bright and sunny, casting a clear shadow of the skateboarder on the ramp. The skateboarder is wearing a yellow shirt and black pants, and the ramp is covered in graffiti.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.269}, "power_stats": {"power_gpu_soc_mean_watts": 17.656, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 7.862, "gpu_utilization_percent_mean": 65.269}, "timestamp": "2026-01-30T13:14:45.735719"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3167.71, "latencies_ms": [3167.71], "images_per_second": 0.316, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle sits on a white plate with gold designs.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.205, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.174, "gpu_utilization_percent_mean": 73.654}, "timestamp": "2026-01-30T13:14:50.965408"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5634.461, "latencies_ms": [5634.461], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. plate: 1\n2. cake: 1\n3. syrup: 1\n4. chocolate: 1\n5. chocolate syrup: 1\n6. caramel: 1\n7. caramel sauce: 1\n8. chocolate drizzle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.809}, "power_stats": {"power_gpu_soc_mean_watts": 18.586, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 68.809}, "timestamp": "2026-01-30T13:14:58.663256"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4351.77, "latencies_ms": [4351.77], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The slice of chocolate cake is positioned in the foreground, with the plate and the caramel sauce in the background. The cake is placed on the plate, which is resting on a wooden surface.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.518, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.861}, "timestamp": "2026-01-30T13:15:05.037023"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3175.403, "latencies_ms": [3175.403], "images_per_second": 0.315, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A slice of chocolate cake with caramel drizzle is on a white plate with gold designs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.173, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.156, "gpu_utilization_percent_mean": 75.654}, "timestamp": "2026-01-30T13:15:10.272420"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4350.696, "latencies_ms": [4350.696], "images_per_second": 0.23, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The slice of chocolate cake is on a white plate with gold designs, and the plate is on a wooden table. The lighting is bright and natural, and the cake is shiny and moist.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.597, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-30T13:15:16.648235"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3149.174, "latencies_ms": [3149.174], "images_per_second": 0.318, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man is sitting at a desk with a laptop and a computer in front of him.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.298, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.175, "gpu_utilization_percent_mean": 73.923}, "timestamp": "2026-01-30T13:15:21.843131"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5433.1, "latencies_ms": [5433.1], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. laptop: 2\n2. chair: 3\n3. person: 2\n4. box: 1\n5. bottle: 1\n6. computer: 2\n7. table: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.87}, "power_stats": {"power_gpu_soc_mean_watts": 18.661, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 69.87}, "timestamp": "2026-01-30T13:15:29.318246"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3788.416, "latencies_ms": [3788.416], "images_per_second": 0.264, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The man is sitting in the foreground, working on his laptop. The boxes are in the background, and the people are standing around the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.657, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 72.125}, "timestamp": "2026-01-30T13:15:35.146639"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3014.543, "latencies_ms": [3014.543], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are working in a cluttered office with computers and laptops.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.96}, "power_stats": {"power_gpu_soc_mean_watts": 23.812, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 70.96}, "timestamp": "2026-01-30T13:15:40.172715"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3382.068, "latencies_ms": [3382.068], "images_per_second": 0.296, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is lit with fluorescent lighting, and the walls are painted white. The floor is covered with yellow paint.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.107}, "power_stats": {"power_gpu_soc_mean_watts": 23.062, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.199, "gpu_utilization_percent_mean": 75.107}, "timestamp": "2026-01-30T13:15:45.594959"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3882.807, "latencies_ms": [3882.807], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room, with a woman holding a Wii remote and a man holding a Wii controller.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.656}, "power_stats": {"power_gpu_soc_mean_watts": 21.646, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.094, "gpu_utilization_percent_mean": 71.656}, "timestamp": "2026-01-30T13:15:51.506460"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6627.285, "latencies_ms": [6627.285], "images_per_second": 0.151, "prompt_tokens": 1113, "response_tokens_est": 77, "n_tiles": 1, "output_text": " 1. Wii remote: 2\n2. Wii controller: 1\n3. Wii game: 1\n4. Wii console: 1\n5. Wii remote holder: 1\n6. Wii game case: 1\n7. Wii game disc: 1\n8. Wii game disc case: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.309}, "power_stats": {"power_gpu_soc_mean_watts": 17.666, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 69.309}, "timestamp": "2026-01-30T13:16:00.146308"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7167.976, "latencies_ms": [7167.976], "images_per_second": 0.14, "prompt_tokens": 1117, "response_tokens_est": 84, "n_tiles": 1, "output_text": " The woman is standing to the left of the man in the blue shirt, who is standing to the right of the man in the white shirt. The woman is in the foreground, while the man in the blue shirt is in the background. The man in the green shirt is standing in the middle of the room, with the man in the white shirt to his left and the man in the blue shirt to his right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.25}, "power_stats": {"power_gpu_soc_mean_watts": 16.996, "power_cpu_cv_mean_watts": 1.801, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 66.25}, "timestamp": "2026-01-30T13:16:09.330351"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2853.753, "latencies_ms": [2853.753], "images_per_second": 0.35, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of people are playing a video game in a living room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.826}, "power_stats": {"power_gpu_soc_mean_watts": 24.681, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.267, "gpu_utilization_percent_mean": 78.826}, "timestamp": "2026-01-30T13:16:14.202664"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3318.678, "latencies_ms": [3318.678], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is well lit with natural light coming from the windows, and the carpet is a light gray color.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.519}, "power_stats": {"power_gpu_soc_mean_watts": 23.398, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.246, "gpu_utilization_percent_mean": 74.519}, "timestamp": "2026-01-30T13:16:19.539718"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3250.609, "latencies_ms": [3250.609], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person stands on a frozen lake at sunset, with a frisbee in the air above them.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.037}, "power_stats": {"power_gpu_soc_mean_watts": 23.353, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 76.037}, "timestamp": "2026-01-30T13:16:24.818627"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5494.259, "latencies_ms": [5494.259], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. sun: 1\n3. sky: 2\n4. water: 1\n5. ice: 1\n6. frisbee: 1\n7. shadow: 1\n8. reflection: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.717}, "power_stats": {"power_gpu_soc_mean_watts": 18.791, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.717}, "timestamp": "2026-01-30T13:16:32.327972"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4605.113, "latencies_ms": [4605.113], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The person is standing on the left side of the image, with the sun in the center and the horizon line in the background. The person is in the foreground, with the sun and horizon line in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14070.4, "ram_available_mb": 48770.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.053}, "power_stats": {"power_gpu_soc_mean_watts": 20.24, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 68.053}, "timestamp": "2026-01-30T13:16:38.954604"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3366.12, "latencies_ms": [3366.12], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person stands on a frozen lake at sunset, with a frisbee in the air above them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.296}, "power_stats": {"power_gpu_soc_mean_watts": 22.792, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 73.296}, "timestamp": "2026-01-30T13:16:44.339635"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4858.423, "latencies_ms": [4858.423], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person standing on a frozen lake at sunset, with the sun casting a warm glow on the ice and the person's shadow. The sky is a gradient of orange and blue, with the sun positioned near the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14069.9, "ram_available_mb": 48771.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.125}, "power_stats": {"power_gpu_soc_mean_watts": 19.728, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.125}, "timestamp": "2026-01-30T13:16:51.227690"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4361.994, "latencies_ms": [4361.994], "images_per_second": 0.229, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a well-lit living room with a white sofa, a dining table with chairs, a television on a stand, and a variety of decorative items on the walls and shelves.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14069.9, "ram_available_mb": 48771.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.617, "power_cpu_cv_mean_watts": 1.389, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 72.417}, "timestamp": "2026-01-30T13:16:57.641188"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4259.94, "latencies_ms": [4259.94], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " sofa: 1, chair: 2, table: 1, vase: 1, television: 1, rug: 1, wall art: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.857}, "power_stats": {"power_gpu_soc_mean_watts": 20.75, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 69.857}, "timestamp": "2026-01-30T13:17:03.925642"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5470.913, "latencies_ms": [5470.913], "images_per_second": 0.183, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The white sofa is positioned to the left of the television, which is situated in the middle of the room. The dining table is located in the foreground, with the red chairs placed around it. The living room extends into the background, with the large window providing natural light.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14069.8, "ram_available_mb": 48771.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.675, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 68.333}, "timestamp": "2026-01-30T13:17:11.424422"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3374.458, "latencies_ms": [3374.458], "images_per_second": 0.296, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A living room with a white couch, red chairs, and a dining table with a vase of flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14069.9, "ram_available_mb": 48771.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.786}, "power_stats": {"power_gpu_soc_mean_watts": 22.49, "power_cpu_cv_mean_watts": 1.058, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 78.786}, "timestamp": "2026-01-30T13:17:16.834770"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3725.781, "latencies_ms": [3725.781], "images_per_second": 0.268, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the windows. The walls are painted white and the furniture is mostly black and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14069.9, "ram_available_mb": 48771.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.904, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.108, "gpu_utilization_percent_mean": 74.161}, "timestamp": "2026-01-30T13:17:22.609847"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2991.229, "latencies_ms": [2991.229], "images_per_second": 0.334, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A cat is standing on top of a blue refrigerator, looking out the window.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14070.3, "ram_available_mb": 48770.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.989, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T13:17:27.634381"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5660.99, "latencies_ms": [5660.99], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. refrigerator: 1\n3. cabinet: 1\n4. shelf: 1\n5. light: 1\n6. door: 1\n7. wall: 1\n8. ceiling: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.745}, "power_stats": {"power_gpu_soc_mean_watts": 17.965, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.832, "gpu_utilization_percent_mean": 67.745}, "timestamp": "2026-01-30T13:17:35.337523"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4936.264, "latencies_ms": [4936.264], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The cat is positioned on the right side of the refrigerator, which is located in the foreground of the image. The refrigerator is situated in the middle of the image, with the cat's head and body occupying a significant portion of the frame.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14070.0, "ram_available_mb": 48770.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14070.2, "ram_available_mb": 48770.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.024}, "power_stats": {"power_gpu_soc_mean_watts": 19.62, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 69.024}, "timestamp": "2026-01-30T13:17:42.302735"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2861.011, "latencies_ms": [2861.011], "images_per_second": 0.35, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A cat is standing on top of a refrigerator in a kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.2, "ram_available_mb": 48770.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14070.1, "ram_available_mb": 48770.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.522}, "power_stats": {"power_gpu_soc_mean_watts": 24.074, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 75.522}, "timestamp": "2026-01-30T13:17:47.178544"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3364.784, "latencies_ms": [3364.784], "images_per_second": 0.297, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The cat is brown and black, the refrigerator is blue, and the room is lit by a fluorescent light.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14070.1, "ram_available_mb": 48770.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.429}, "power_stats": {"power_gpu_soc_mean_watts": 22.778, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 72.429}, "timestamp": "2026-01-30T13:17:52.559197"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4377.577, "latencies_ms": [4377.577], "images_per_second": 0.228, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a room with a wooden floor, a white ceiling, and a yellow wall, adorned with various decorations such as balloons, a smiley face balloon, and a chandelier.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.552, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 67.278}, "timestamp": "2026-01-30T13:17:58.976914"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5922.45, "latencies_ms": [5922.45], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Balloons: 4\n2. Balloons: 2\n3. Balloons: 1\n4. Balloons: 1\n5. Balloons: 1\n6. Balloons: 1\n7. Balloons: 1\n8. Balloons: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.184}, "power_stats": {"power_gpu_soc_mean_watts": 18.181, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 66.184}, "timestamp": "2026-01-30T13:18:06.943576"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7237.122, "latencies_ms": [7237.122], "images_per_second": 0.138, "prompt_tokens": 1117, "response_tokens_est": 86, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the foreground is dominated by the wooden table and the balloons, while the background features the refrigerator, the wall, and the bookshelf. The balloons are positioned in the foreground, with the refrigerator and the wall in the background. The wooden table is located in the middle of the room, with the balloons and the refrigerator on the left side, and the bookshelf on the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.705}, "power_stats": {"power_gpu_soc_mean_watts": 16.976, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.904, "gpu_utilization_percent_mean": 66.705}, "timestamp": "2026-01-30T13:18:16.223975"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2960.671, "latencies_ms": [2960.671], "images_per_second": 0.338, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A room with balloons and a smiley face balloon is decorated for a party.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.917}, "power_stats": {"power_gpu_soc_mean_watts": 24.325, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 79.917}, "timestamp": "2026-01-30T13:18:21.214774"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2846.017, "latencies_ms": [2846.017], "images_per_second": 0.351, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The room is lit by a chandelier and has wooden floors.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.783}, "power_stats": {"power_gpu_soc_mean_watts": 24.705, "power_cpu_cv_mean_watts": 0.888, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 77.783}, "timestamp": "2026-01-30T13:18:26.098012"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3539.946, "latencies_ms": [3539.946], "images_per_second": 0.282, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man wearing headphones is sitting at a table with a laptop in front of him, and there is a window in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.828}, "power_stats": {"power_gpu_soc_mean_watts": 22.737, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.184, "gpu_utilization_percent_mean": 73.828}, "timestamp": "2026-01-30T13:18:31.671987"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5559.36, "latencies_ms": [5559.36], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. laptop: 1\n3. chair: 1\n4. window: 1\n5. train: 1\n6. train tracks: 1\n7. headset: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.461, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 66.66}, "timestamp": "2026-01-30T13:18:39.242791"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4434.332, "latencies_ms": [4434.332], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, with the laptop in front of him. The laptop is on the right side of the image, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.703}, "power_stats": {"power_gpu_soc_mean_watts": 20.192, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 68.703}, "timestamp": "2026-01-30T13:18:45.695833"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3021.749, "latencies_ms": [3021.749], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man wearing headphones is sitting at a table in a train, using a laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.04}, "power_stats": {"power_gpu_soc_mean_watts": 24.039, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 76.04}, "timestamp": "2026-01-30T13:18:50.731120"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3434.412, "latencies_ms": [3434.412], "images_per_second": 0.291, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The man is wearing a green shirt and has red hair. The laptop is silver and has an Apple logo on it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.464}, "power_stats": {"power_gpu_soc_mean_watts": 23.049, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 75.464}, "timestamp": "2026-01-30T13:18:56.190763"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6217.048, "latencies_ms": [6217.048], "images_per_second": 0.161, "prompt_tokens": 1099, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image captures a striking white cable-stayed bridge with a unique, pointed design, spanning across a bustling train station with multiple tracks and platforms. The sky above is a clear blue, dotted with fluffy white clouds, and the cityscape in the background is a mix of buildings and trees, adding depth and context to the scene.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.189}, "power_stats": {"power_gpu_soc_mean_watts": 17.42, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.879, "gpu_utilization_percent_mean": 68.189}, "timestamp": "2026-01-30T13:19:04.470495"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5644.622, "latencies_ms": [5644.622], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. train tracks: 4\n3. train: 1\n4. train station: 1\n5. platform: 1\n6. platform sign: 1\n7. fence: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.646}, "power_stats": {"power_gpu_soc_mean_watts": 18.364, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.947, "gpu_utilization_percent_mean": 68.646}, "timestamp": "2026-01-30T13:19:12.132254"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4785.525, "latencies_ms": [4785.525], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The train station is located in the foreground, with the bridge stretching across the image, and the city skyline is visible in the background. The train tracks are parallel to each other, and the bridge is positioned above them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.575}, "power_stats": {"power_gpu_soc_mean_watts": 19.648, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.575}, "timestamp": "2026-01-30T13:19:18.944404"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4182.704, "latencies_ms": [4182.704], "images_per_second": 0.239, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a modern white bridge with a unique triangular design, spanning over a bustling train station. The station is filled with multiple tracks and platforms, indicating a busy transportation hub.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.829}, "power_stats": {"power_gpu_soc_mean_watts": 20.944, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 68.829}, "timestamp": "2026-01-30T13:19:25.175372"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4961.445, "latencies_ms": [4961.445], "images_per_second": 0.202, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a white bridge with a unique triangular design, set against a backdrop of a clear blue sky with scattered clouds. The bridge is situated over a train station with multiple tracks and platforms, and the train tracks are visible beneath the bridge.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.357}, "power_stats": {"power_gpu_soc_mean_watts": 19.503, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.357}, "timestamp": "2026-01-30T13:19:32.169323"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3423.787, "latencies_ms": [3423.787], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of people are flying a large kite with a purple and yellow design on a sunny day in a park.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.786}, "power_stats": {"power_gpu_soc_mean_watts": 22.82, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.152, "gpu_utilization_percent_mean": 71.786}, "timestamp": "2026-01-30T13:19:37.643077"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4077.425, "latencies_ms": [4077.425], "images_per_second": 0.245, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " kite: 1, person: 2, ball: 1, chair: 1, backpack: 1, person: 1, tree: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.235}, "power_stats": {"power_gpu_soc_mean_watts": 21.267, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.119, "gpu_utilization_percent_mean": 69.235}, "timestamp": "2026-01-30T13:19:43.759398"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4871.926, "latencies_ms": [4871.926], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the people are in the background, walking around the park. The kite is positioned to the left of the people, and the park is spread out in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.075}, "power_stats": {"power_gpu_soc_mean_watts": 19.748, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 70.075}, "timestamp": "2026-01-30T13:19:50.663171"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2787.037, "latencies_ms": [2787.037], "images_per_second": 0.359, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are flying a large kite in a park.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.522}, "power_stats": {"power_gpu_soc_mean_watts": 24.68, "power_cpu_cv_mean_watts": 0.905, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 80.522}, "timestamp": "2026-01-30T13:19:55.479717"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4800.946, "latencies_ms": [4800.946], "images_per_second": 0.208, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The kite is a vibrant mix of blue, purple, and yellow, with a long tail that trails behind it. The sky is clear and blue, and the sun is shining brightly, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.625}, "power_stats": {"power_gpu_soc_mean_watts": 19.566, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 67.625}, "timestamp": "2026-01-30T13:20:02.336385"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4820.887, "latencies_ms": [4820.887], "images_per_second": 0.207, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a miniature model of a train station with a red and black train, a red and white train, and a red and black train on the tracks, with workers in orange uniforms and white helmets walking along the tracks.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.716, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T13:20:09.183613"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4087.679, "latencies_ms": [4087.679], "images_per_second": 0.245, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " train: 1, workers: 4, tracks: 3, wires: 2, fence: 1, grass: 1, hills: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.676}, "power_stats": {"power_gpu_soc_mean_watts": 21.147, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 67.676}, "timestamp": "2026-01-30T13:20:15.332293"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4888.693, "latencies_ms": [4888.693], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The train is positioned on the right side of the image, with the workers on the left. The train is in the foreground, while the workers are in the background. The train is closer to the viewer than the workers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.8, "ram_available_mb": 48770.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.39}, "power_stats": {"power_gpu_soc_mean_watts": 19.199, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 72.39}, "timestamp": "2026-01-30T13:20:22.278831"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4316.055, "latencies_ms": [4316.055], "images_per_second": 0.232, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A model train is traveling on a track, passing by a group of people who are working on the track. The train is red and black, and the people are wearing orange uniforms.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.167}, "power_stats": {"power_gpu_soc_mean_watts": 20.431, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 71.167}, "timestamp": "2026-01-30T13:20:28.612505"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3571.918, "latencies_ms": [3571.918], "images_per_second": 0.28, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The train is red and black, and the workers are wearing orange. The lighting is natural, and the weather is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.419, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.152, "gpu_utilization_percent_mean": 75.621}, "timestamp": "2026-01-30T13:20:34.199605"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4273.269, "latencies_ms": [4273.269], "images_per_second": 0.234, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image shows a close-up view of a cat's fur, which is a mix of brown and white colors, and the cat is lying on a textured, light-colored blanket.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.257}, "power_stats": {"power_gpu_soc_mean_watts": 20.988, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 70.257}, "timestamp": "2026-01-30T13:20:40.521039"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5366.461, "latencies_ms": [5366.461], "images_per_second": 0.186, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. fur: 1\n3. blanket: 1\n4. fabric: 1\n5. pattern: 1\n6. texture: 1\n7. surface: 1\n8. background: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.156}, "power_stats": {"power_gpu_soc_mean_watts": 18.969, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 72.156}, "timestamp": "2026-01-30T13:20:47.906436"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4462.735, "latencies_ms": [4462.735], "images_per_second": 0.224, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The cat's fur is in the foreground, while the patterned fabric is in the background. The cat's fur is on the left side of the image, and the fabric is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.29, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 70.838}, "timestamp": "2026-01-30T13:20:54.392508"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2840.837, "latencies_ms": [2840.837], "images_per_second": 0.352, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is laying on a bed with a brown and white fur coat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.217}, "power_stats": {"power_gpu_soc_mean_watts": 24.735, "power_cpu_cv_mean_watts": 0.922, "power_sys_5v0_mean_watts": 8.364, "gpu_utilization_percent_mean": 78.217}, "timestamp": "2026-01-30T13:20:59.268522"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5045.94, "latencies_ms": [5045.94], "images_per_second": 0.198, "prompt_tokens": 1110, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a close-up of a cat's fur, which is a mix of brown and white colors. The lighting appears to be natural, coming from the left side of the image, and the cat's fur is soft and fluffy.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.429}, "power_stats": {"power_gpu_soc_mean_watts": 19.257, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 68.429}, "timestamp": "2026-01-30T13:21:06.350239"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4329.982, "latencies_ms": [4329.982], "images_per_second": 0.231, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a close-up view of a cow's udder, which is attached to a black and yellow object, possibly a milking machine, with red caps on the tubes.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 14070.6, "ram_available_mb": 48770.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.809, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.861}, "timestamp": "2026-01-30T13:21:12.729376"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4791.615, "latencies_ms": [4791.615], "images_per_second": 0.209, "prompt_tokens": 1113, "response_tokens_est": 45, "n_tiles": 1, "output_text": " cow: 1, black: 1, white: 1, red: 1, black and white: 1, black carbon fiber: 1, yellow sticker: 1, metal pipe: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.541, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 69.341}, "timestamp": "2026-01-30T13:21:19.565779"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5062.375, "latencies_ms": [5062.375], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The cow's udder is positioned in the foreground, with the black and white cow's legs and the black object in the background. The cow's udder is near the black object, and the cow's legs are near the black object.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.548}, "power_stats": {"power_gpu_soc_mean_watts": 19.487, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.548}, "timestamp": "2026-01-30T13:21:26.648381"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3315.804, "latencies_ms": [3315.804], "images_per_second": 0.302, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cow is milking itself in a barn, with a black and white cow standing next to it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.044, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.183, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-30T13:21:31.990482"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5012.835, "latencies_ms": [5012.835], "images_per_second": 0.199, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a black and white cow with red and white tubes attached to its udder, standing on a dirty floor. The lighting is dim, and the cow is positioned in a stall with a black and yellow label on the wall.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.333}, "power_stats": {"power_gpu_soc_mean_watts": 19.238, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 66.333}, "timestamp": "2026-01-30T13:21:39.028852"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3212.467, "latencies_ms": [3212.467], "images_per_second": 0.311, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A sandwich with a bite taken out of it is on a plate with a knife beside it.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.255, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.163, "gpu_utilization_percent_mean": 74.885}, "timestamp": "2026-01-30T13:21:44.276000"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3460.869, "latencies_ms": [3460.869], "images_per_second": 0.289, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " plate: 1, knife: 1, sandwich: 1, bread: 2, butter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.214}, "power_stats": {"power_gpu_soc_mean_watts": 22.906, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.177, "gpu_utilization_percent_mean": 74.214}, "timestamp": "2026-01-30T13:21:49.752495"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4739.437, "latencies_ms": [4739.437], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the image, with the knife placed to the right of it. The plate is situated in the middle ground, with the sandwich and knife appearing to be in close proximity to each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.128}, "power_stats": {"power_gpu_soc_mean_watts": 19.971, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 70.128}, "timestamp": "2026-01-30T13:21:56.515192"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2896.358, "latencies_ms": [2896.358], "images_per_second": 0.345, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A plate with a sandwich and a knife on a green tablecloth.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.826}, "power_stats": {"power_gpu_soc_mean_watts": 24.509, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.294, "gpu_utilization_percent_mean": 75.826}, "timestamp": "2026-01-30T13:22:01.451718"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3914.268, "latencies_ms": [3914.268], "images_per_second": 0.255, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The sandwich is on a plate with a knife and the plate is on a green tablecloth. The lighting is dim and the sandwich is in the foreground.", "error": null, "sys_before": {"cpu_percent": 54.5, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.594}, "power_stats": {"power_gpu_soc_mean_watts": 21.534, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 71.594}, "timestamp": "2026-01-30T13:22:07.383824"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4510.037, "latencies_ms": [4510.037], "images_per_second": 0.222, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image shows a colorful and well-organized meal in a purple divided container, featuring a variety of food items such as a salad, pasta with cheese, and grapes, all neatly arranged in separate compartments.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.73}, "power_stats": {"power_gpu_soc_mean_watts": 20.366, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 68.73}, "timestamp": "2026-01-30T13:22:13.936730"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4323.881, "latencies_ms": [4323.881], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " 1. purple tray\n2. orange container\n3. green container\n4. red container\n5. blue container\n6. carrots\n7. grapes\n8. salad", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.431, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 72.639}, "timestamp": "2026-01-30T13:22:20.290966"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6950.414, "latencies_ms": [6950.414], "images_per_second": 0.144, "prompt_tokens": 1117, "response_tokens_est": 81, "n_tiles": 1, "output_text": " The main objects are arranged in a square pattern with the carrots in the top right corner, the salad in the top left corner, the pasta in the bottom left corner, and the grapes in the bottom right corner. The carrots are positioned in the top right corner, the salad is in the top left corner, the pasta is in the bottom left corner, and the grapes are in the bottom right corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.5, "ram_available_mb": 48768.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.724}, "power_stats": {"power_gpu_soc_mean_watts": 17.231, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.906, "gpu_utilization_percent_mean": 67.724}, "timestamp": "2026-01-30T13:22:29.254543"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3569.192, "latencies_ms": [3569.192], "images_per_second": 0.28, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A colorful meal is served in a purple divided container, with a variety of food items including pasta, vegetables, and fruit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.589, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 74.207}, "timestamp": "2026-01-30T13:22:34.844861"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6282.196, "latencies_ms": [6282.196], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image features a vibrant and colorful meal in a purple divided container, with a variety of food items including pasta, vegetables, and fruits. The lighting is bright and even, illuminating the food items and creating a visually appealing presentation. The container is made of plastic, and the food is fresh and healthy, suggesting a well-balanced and nutritious meal.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.792}, "power_stats": {"power_gpu_soc_mean_watts": 17.716, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.938, "gpu_utilization_percent_mean": 68.792}, "timestamp": "2026-01-30T13:22:43.149456"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2943.978, "latencies_ms": [2943.978], "images_per_second": 0.34, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A traffic light hangs above a street with cherry blossoms in full bloom.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 14073.0, "ram_available_mb": 48767.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.873, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 79.333}, "timestamp": "2026-01-30T13:22:48.135095"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2473.524, "latencies_ms": [2473.524], "images_per_second": 0.404, "prompt_tokens": 1114, "response_tokens_est": 8, "n_tiles": 1, "output_text": " 1. traffic light: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.9, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.15}, "power_stats": {"power_gpu_soc_mean_watts": 25.583, "power_cpu_cv_mean_watts": 0.72, "power_sys_5v0_mean_watts": 8.342, "gpu_utilization_percent_mean": 82.15}, "timestamp": "2026-01-30T13:22:52.635339"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4766.855, "latencies_ms": [4766.855], "images_per_second": 0.21, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The traffic light is positioned to the left of the cherry blossoms, and the traffic light is in the foreground of the image. The cherry blossoms are in the background of the image, and they are positioned behind the traffic light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.6, "ram_available_mb": 48768.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.975}, "power_stats": {"power_gpu_soc_mean_watts": 19.841, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 68.975}, "timestamp": "2026-01-30T13:22:59.425035"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5377.376, "latencies_ms": [5377.376], "images_per_second": 0.186, "prompt_tokens": 1112, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image captures a serene scene of a cherry blossom tree in full bloom, with its branches adorned with delicate pink and white flowers. The tree is situated in a park, and a traffic light is visible in the background, adding a touch of urbanity to the otherwise natural setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.326}, "power_stats": {"power_gpu_soc_mean_watts": 18.679, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 68.326}, "timestamp": "2026-01-30T13:23:06.823353"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3985.831, "latencies_ms": [3985.831], "images_per_second": 0.251, "prompt_tokens": 1110, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image features a cherry blossom tree with pink flowers and a traffic light with red and green lights. The sky is clear and blue, and the light is bright.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14073.5, "ram_available_mb": 48767.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.515}, "power_stats": {"power_gpu_soc_mean_watts": 21.673, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 71.515}, "timestamp": "2026-01-30T13:23:12.824246"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3651.016, "latencies_ms": [3651.016], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a plate with a serving of broccoli and a piece of salmon, with the broccoli being the main focus of the dish.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.252, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 73.6}, "timestamp": "2026-01-30T13:23:18.511852"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6409.148, "latencies_ms": [6409.148], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 72, "n_tiles": 1, "output_text": " 1. Broccoli florets: 12\n2. Salmon: 1\n3. Plate: 1\n4. Sauce: 1\n5. Dried herbs: 1\n6. Chopped garlic: 1\n7. Chopped red pepper: 1\n8. Broth: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.444}, "power_stats": {"power_gpu_soc_mean_watts": 17.669, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 68.444}, "timestamp": "2026-01-30T13:23:26.941649"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4116.173, "latencies_ms": [4116.173], "images_per_second": 0.243, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The broccoli is in the foreground, while the salmon is in the background. The broccoli is on the left side of the plate, and the salmon is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.353}, "power_stats": {"power_gpu_soc_mean_watts": 21.293, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 71.353}, "timestamp": "2026-01-30T13:23:33.081210"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4574.903, "latencies_ms": [4574.903], "images_per_second": 0.219, "prompt_tokens": 1111, "response_tokens_est": 42, "n_tiles": 1, "output_text": " In the image, there is a plate of food that includes a piece of salmon and broccoli. The salmon is cooked and has a golden-brown color, while the broccoli is green and appears to be steamed.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.263}, "power_stats": {"power_gpu_soc_mean_watts": 20.2, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.263}, "timestamp": "2026-01-30T13:23:39.668065"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6172.898, "latencies_ms": [6172.898], "images_per_second": 0.162, "prompt_tokens": 1109, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a plate of food with a vibrant green broccoli dish and a piece of grilled salmon. The broccoli is cooked to a tender consistency, and the salmon is seasoned with a light glaze. The plate is white, and the food is placed on a white tablecloth. The lighting is bright and even, highlighting the colors of the food.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.654}, "power_stats": {"power_gpu_soc_mean_watts": 17.994, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 68.654}, "timestamp": "2026-01-30T13:23:47.899756"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3424.317, "latencies_ms": [3424.317], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A man and two women are sitting at a table in a restaurant, with a man wearing a gray shirt.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.679}, "power_stats": {"power_gpu_soc_mean_watts": 22.537, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 73.679}, "timestamp": "2026-01-30T13:23:53.374644"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5396.14, "latencies_ms": [5396.14], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 3\n2. chair: 1\n3. table: 1\n4. person: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.556}, "power_stats": {"power_gpu_soc_mean_watts": 18.97, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 69.556}, "timestamp": "2026-01-30T13:24:00.790926"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5614.935, "latencies_ms": [5614.935], "images_per_second": 0.178, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The person on the left is sitting next to the person in the middle, who is sitting next to the person on the right. The person on the left is closer to the camera than the person in the middle. The person on the right is sitting in front of the person in the middle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.191}, "power_stats": {"power_gpu_soc_mean_watts": 18.52, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 67.191}, "timestamp": "2026-01-30T13:24:08.439843"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2838.65, "latencies_ms": [2838.65], "images_per_second": 0.352, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 14074.1, "ram_available_mb": 48766.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.174}, "power_stats": {"power_gpu_soc_mean_watts": 24.249, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.225, "gpu_utilization_percent_mean": 76.174}, "timestamp": "2026-01-30T13:24:13.320007"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4284.531, "latencies_ms": [4284.531], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a dimly lit restaurant with warm lighting. The colors in the image are mostly warm tones, with the brown of the wood and the red of the wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.114}, "power_stats": {"power_gpu_soc_mean_watts": 20.865, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 71.114}, "timestamp": "2026-01-30T13:24:19.623363"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4569.286, "latencies_ms": [4569.286], "images_per_second": 0.219, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a bustling city street with a yellow bus parked on the side of the road, a white van and a white bus in the background, and a large building with a modern design in the background.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.211}, "power_stats": {"power_gpu_soc_mean_watts": 20.093, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 69.211}, "timestamp": "2026-01-30T13:24:26.262038"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5820.313, "latencies_ms": [5820.313], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Bus: 2\n2. Street: 1\n3. Building: 1\n4. Trees: 3\n5. Benches: 1\n6. Streetlamp: 1\n7. Sidewalk: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.02}, "power_stats": {"power_gpu_soc_mean_watts": 18.236, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 69.02}, "timestamp": "2026-01-30T13:24:34.120700"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4379.828, "latencies_ms": [4379.828], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The yellow bus is parked on the side of the road, while the white bus is driving down the road. The building is located in the background, and the trees are in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14073.6, "ram_available_mb": 48767.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.417}, "power_stats": {"power_gpu_soc_mean_watts": 20.431, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 67.417}, "timestamp": "2026-01-30T13:24:40.536121"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5555.807, "latencies_ms": [5555.807], "images_per_second": 0.18, "prompt_tokens": 1111, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures a bustling city street with a large building in the background. A yellow bus is driving down the road, while a white bus is parked on the side of the street. The scene is set in a modern city, with trees lining the sidewalk and a clear blue sky overhead.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14073.3, "ram_available_mb": 48767.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.191}, "power_stats": {"power_gpu_soc_mean_watts": 18.503, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 68.191}, "timestamp": "2026-01-30T13:24:48.124150"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4213.916, "latencies_ms": [4213.916], "images_per_second": 0.237, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a vibrant yellow bus parked on the side of the road, with a white building in the background. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.2, "ram_available_mb": 48767.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.762, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 72.4}, "timestamp": "2026-01-30T13:24:54.360480"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4240.057, "latencies_ms": [4240.057], "images_per_second": 0.236, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a stop sign with a sun flare effect, set against a backdrop of a cityscape with buildings and parked cars, all bathed in the warm glow of the sun.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14073.1, "ram_available_mb": 48767.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.343}, "power_stats": {"power_gpu_soc_mean_watts": 21.012, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 69.343}, "timestamp": "2026-01-30T13:25:00.634760"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5759.194, "latencies_ms": [5759.194], "images_per_second": 0.174, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. stop sign: 1\n2. pole: 1\n3. railing: 1\n4. building: 1\n5. car: 1\n6. street: 1\n7. sidewalk: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.49}, "power_stats": {"power_gpu_soc_mean_watts": 17.738, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.88, "gpu_utilization_percent_mean": 67.49}, "timestamp": "2026-01-30T13:25:08.419737"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5121.084, "latencies_ms": [5121.084], "images_per_second": 0.195, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The stop sign is positioned to the left of the pole, with the pole being in the foreground and the background featuring a parking lot and buildings. The stop sign is also near the pole, while the parking lot and buildings are far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.651}, "power_stats": {"power_gpu_soc_mean_watts": 19.209, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 69.651}, "timestamp": "2026-01-30T13:25:15.574005"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6328.135, "latencies_ms": [6328.135], "images_per_second": 0.158, "prompt_tokens": 1112, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a serene urban scene during sunset, where a stop sign stands prominently in the foreground, casting a warm glow on the surroundings. In the background, a parking lot is visible, with a few cars parked neatly, and a building with a sign that reads \"\u041c\u0410\u0420\u041a\u0415\u0422\" can be seen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.528}, "power_stats": {"power_gpu_soc_mean_watts": 17.497, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.933, "gpu_utilization_percent_mean": 67.528}, "timestamp": "2026-01-30T13:25:23.943056"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5421.629, "latencies_ms": [5421.629], "images_per_second": 0.184, "prompt_tokens": 1110, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a red stop sign with a white \"STOP\" written on it, standing on a metal pole. The sun is shining brightly, casting a warm glow on the scene. The background includes a parking lot with cars and buildings, and the ground is covered with gravel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.565}, "power_stats": {"power_gpu_soc_mean_watts": 18.765, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 67.565}, "timestamp": "2026-01-30T13:25:31.384496"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3279.196, "latencies_ms": [3279.196], "images_per_second": 0.305, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A cat with a white and brown coat is lying on a black surface next to a white computer mouse.", "error": null, "sys_before": {"cpu_percent": 54.5, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.25, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 76.37}, "timestamp": "2026-01-30T13:25:36.698701"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4188.854, "latencies_ms": [4188.854], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " cat: 1, mouse: 1, cord: 1, black: 1, white: 1, brown: 1, black and white: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14071.3, "ram_available_mb": 48769.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.933, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.097, "gpu_utilization_percent_mean": 71.629}, "timestamp": "2026-01-30T13:25:42.915504"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4511.367, "latencies_ms": [4511.367], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The cat is in the foreground, lying on a black surface. The mouse is in the foreground, to the left of the cat. The cord is in the foreground, to the right of the cat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.316}, "power_stats": {"power_gpu_soc_mean_watts": 20.219, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 68.316}, "timestamp": "2026-01-30T13:25:49.448218"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2922.964, "latencies_ms": [2922.964], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is lying on a bed with a computer mouse next to it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.375}, "power_stats": {"power_gpu_soc_mean_watts": 24.272, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 76.375}, "timestamp": "2026-01-30T13:25:54.421867"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2945.928, "latencies_ms": [2945.928], "images_per_second": 0.339, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The cat is white and brown with green eyes, and the mouse is white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.792}, "power_stats": {"power_gpu_soc_mean_watts": 24.471, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.327, "gpu_utilization_percent_mean": 76.792}, "timestamp": "2026-01-30T13:25:59.405109"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3838.245, "latencies_ms": [3838.245], "images_per_second": 0.261, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large parking lot filled with buses, a prominent white building, and a clear blue sky dotted with clouds.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.29}, "power_stats": {"power_gpu_soc_mean_watts": 21.788, "power_cpu_cv_mean_watts": 1.304, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 72.29}, "timestamp": "2026-01-30T13:26:05.274474"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5392.869, "latencies_ms": [5392.869], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Bus: 3\n2. Bus: 2\n3. Bus: 1\n4. Bus: 1\n5. Bus: 1\n6. Bus: 1\n7. Bus: 1\n8. Bus: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.413}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 68.413}, "timestamp": "2026-01-30T13:26:12.692117"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3982.967, "latencies_ms": [3982.967], "images_per_second": 0.251, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The buses are positioned in the foreground, with the buildings in the background. The trees are located near the buses, while the overpass is situated further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.451, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 72.182}, "timestamp": "2026-01-30T13:26:18.696306"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3707.41, "latencies_ms": [3707.41], "images_per_second": 0.27, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image captures a bustling cityscape with a large parking lot filled with buses and cars, surrounded by tall buildings and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.032}, "power_stats": {"power_gpu_soc_mean_watts": 21.947, "power_cpu_cv_mean_watts": 1.266, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 73.032}, "timestamp": "2026-01-30T13:26:24.427797"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4087.071, "latencies_ms": [4087.071], "images_per_second": 0.245, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features a vibrant cityscape with a mix of green and white buildings, a clear blue sky with white clouds, and a bustling street with several buses and cars.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.471}, "power_stats": {"power_gpu_soc_mean_watts": 21.125, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 71.471}, "timestamp": "2026-01-30T13:26:30.573815"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3825.889, "latencies_ms": [3825.889], "images_per_second": 0.261, "prompt_tokens": 1100, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A man wearing a cowboy hat and shorts is riding a skateboard on a ramp in a skate park, with a large tent in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.721, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.119, "gpu_utilization_percent_mean": 71.031}, "timestamp": "2026-01-30T13:26:36.461853"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5439.047, "latencies_ms": [5439.047], "images_per_second": 0.184, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. hat: 1\n3. shorts: 1\n4. skateboard: 1\n5. ramp: 1\n6. shadow: 1\n7. tent: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.37}, "power_stats": {"power_gpu_soc_mean_watts": 18.886, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 69.37}, "timestamp": "2026-01-30T13:26:43.932117"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5486.966, "latencies_ms": [5486.966], "images_per_second": 0.182, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, performing a trick on the ramp, while the tents are located in the background, providing a contrast between the foreground and background elements. The shadow of the skateboarder is cast on the ramp, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.0, "ram_available_mb": 48768.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.626, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T13:26:51.443947"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3368.068, "latencies_ms": [3368.068], "images_per_second": 0.297, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is riding a skateboard on a ramp. There are tents in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.848, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 74.821}, "timestamp": "2026-01-30T13:26:56.853121"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4598.384, "latencies_ms": [4598.384], "images_per_second": 0.217, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick on a ramp, with a clear blue sky in the background. The skateboarder is wearing a hat and shorts, and the ramp is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.5, "ram_available_mb": 48769.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.132}, "power_stats": {"power_gpu_soc_mean_watts": 20.115, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.132}, "timestamp": "2026-01-30T13:27:03.491305"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3777.054, "latencies_ms": [3777.054], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is standing on a surfboard with a windsurfing board attached to it, and there are several kites flying in the sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.484}, "power_stats": {"power_gpu_soc_mean_watts": 21.917, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.114, "gpu_utilization_percent_mean": 72.484}, "timestamp": "2026-01-30T13:27:09.305000"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5675.863, "latencies_ms": [5675.863], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 1\n2. windsurf board: 1\n3. kite: 2\n4. ocean: 1\n5. sky: 2\n6. waves: 1\n7. water: 1\n8. kite string: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.383}, "power_stats": {"power_gpu_soc_mean_watts": 18.469, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 67.383}, "timestamp": "2026-01-30T13:27:17.007168"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4441.901, "latencies_ms": [4441.901], "images_per_second": 0.225, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The kiteboarder is positioned in the foreground, with the ocean and sky in the background. The kites are flying in the sky, with the kiteboarder being closer to the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.2, "ram_available_mb": 48769.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.568}, "power_stats": {"power_gpu_soc_mean_watts": 20.354, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 69.568}, "timestamp": "2026-01-30T13:27:23.510138"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3682.508, "latencies_ms": [3682.508], "images_per_second": 0.272, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man is windsurfing in the ocean with a kite. The sky is blue and there are other people in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.233}, "power_stats": {"power_gpu_soc_mean_watts": 21.926, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 75.233}, "timestamp": "2026-01-30T13:27:29.233658"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5364.426, "latencies_ms": [5364.426], "images_per_second": 0.186, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a vibrant scene with a clear blue sky and a vast ocean. The water is a deep blue, and the sky is a bright blue with a few white clouds. The windsurfer is wearing a red shirt and is holding onto a blue and white sail.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14071.7, "ram_available_mb": 48769.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.422}, "power_stats": {"power_gpu_soc_mean_watts": 18.853, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 70.422}, "timestamp": "2026-01-30T13:27:36.634671"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3198.184, "latencies_ms": [3198.184], "images_per_second": 0.313, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " An old red fire hydrant is in the grass in front of a house with purple flowers.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 14071.0, "ram_available_mb": 48769.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.192}, "power_stats": {"power_gpu_soc_mean_watts": 23.513, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 76.192}, "timestamp": "2026-01-30T13:27:41.875787"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5582.935, "latencies_ms": [5582.935], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Fire hydrant: 1\n2. Grass: 1\n3. Flowers: 2\n4. Tree: 1\n5. House: 1\n6. Window: 1\n7. Roof: 1\n8. Purple flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14070.9, "ram_available_mb": 48770.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.149}, "power_stats": {"power_gpu_soc_mean_watts": 18.706, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.149}, "timestamp": "2026-01-30T13:27:49.485777"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4631.308, "latencies_ms": [4631.308], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with the house and trees in the background. The hydrant is positioned to the left of the house, and the grass is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.1, "ram_available_mb": 48769.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 19.854, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T13:27:56.158012"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2870.643, "latencies_ms": [2870.643], "images_per_second": 0.348, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A red fire hydrant is in the grass in front of a house.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.417}, "power_stats": {"power_gpu_soc_mean_watts": 24.238, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.332, "gpu_utilization_percent_mean": 78.417}, "timestamp": "2026-01-30T13:28:01.071017"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3215.699, "latencies_ms": [3215.699], "images_per_second": 0.311, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The fire hydrant is red and black, and it is in a grassy area with dandelions.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.704}, "power_stats": {"power_gpu_soc_mean_watts": 23.459, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 74.704}, "timestamp": "2026-01-30T13:28:06.326058"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3313.608, "latencies_ms": [3313.608], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A bird is flying over a roof with a blue hue, while other birds are on the ground nearby.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.429}, "power_stats": {"power_gpu_soc_mean_watts": 22.877, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 73.429}, "timestamp": "2026-01-30T13:28:11.689026"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4332.688, "latencies_ms": [4332.688], "images_per_second": 0.231, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " bird: 1, roof: 1, bird: 1, roof: 1, bird: 1, roof: 1, bird: 1, roof: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.896, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 70.639}, "timestamp": "2026-01-30T13:28:18.065109"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4490.042, "latencies_ms": [4490.042], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The main object, a bird, is located in the foreground, flying towards the right side of the image. The bird is near the edge of the roof, which is the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.297}, "power_stats": {"power_gpu_soc_mean_watts": 20.268, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 68.297}, "timestamp": "2026-01-30T13:28:24.586093"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3019.089, "latencies_ms": [3019.089], "images_per_second": 0.331, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is flying over a roof, while other birds are on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.6, "ram_available_mb": 48769.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.7, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 74.4}, "timestamp": "2026-01-30T13:28:29.634307"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4178.51, "latencies_ms": [4178.51], "images_per_second": 0.239, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a bird with a blue and black body, flying over a wooden surface with a blue hue. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.704, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 72.629}, "timestamp": "2026-01-30T13:28:35.841240"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3563.012, "latencies_ms": [3563.012], "images_per_second": 0.281, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a person is walking a horse in a barn, with a red door and a ladder visible in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.419, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.143, "gpu_utilization_percent_mean": 71.233}, "timestamp": "2026-01-30T13:28:41.455558"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4077.127, "latencies_ms": [4077.127], "images_per_second": 0.245, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " horse: 1, person: 1, door: 1, ladder: 1, bucket: 1, wall: 1, window: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.353}, "power_stats": {"power_gpu_soc_mean_watts": 21.23, "power_cpu_cv_mean_watts": 1.318, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 71.353}, "timestamp": "2026-01-30T13:28:47.565868"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4820.514, "latencies_ms": [4820.514], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, with the person walking beside it. The person is standing in the middle of the image, with the horse to their left. The horse is in the background, with the person in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.7, "ram_available_mb": 48767.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14074.4, "ram_available_mb": 48766.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.928, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 71.775}, "timestamp": "2026-01-30T13:28:54.396505"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2621.299, "latencies_ms": [2621.299], "images_per_second": 0.381, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is walking a horse in a barn.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14073.8, "ram_available_mb": 48767.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.857}, "power_stats": {"power_gpu_soc_mean_watts": 25.164, "power_cpu_cv_mean_watts": 0.762, "power_sys_5v0_mean_watts": 8.334, "gpu_utilization_percent_mean": 83.857}, "timestamp": "2026-01-30T13:28:59.032157"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4585.669, "latencies_ms": [4585.669], "images_per_second": 0.218, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is taken in a stable with a brown horse and a woman walking in it. The horse is wearing a red harness and the woman is wearing blue jeans. The lighting is natural and the colors are warm.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.949}, "power_stats": {"power_gpu_soc_mean_watts": 20.087, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 70.949}, "timestamp": "2026-01-30T13:29:05.660157"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3940.3, "latencies_ms": [3940.3], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of animals, including zebras and sheep, are grazing in a grassy field, with trees and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.255, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 70.273}, "timestamp": "2026-01-30T13:29:11.658945"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5393.616, "latencies_ms": [5393.616], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. tree: 1\n2. zebra: 2\n3. sheep: 4\n4. grass: 1\n5. rocks: 1\n6. fence: 1\n7. water: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.7, "ram_available_mb": 48766.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.87, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T13:29:19.100769"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5120.698, "latencies_ms": [5120.698], "images_per_second": 0.195, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground, with the sheep grazing in the background. The zebras are closer to the camera than the sheep, which are further away. The zebras are near the pond, while the sheep are grazing on the grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.86}, "power_stats": {"power_gpu_soc_mean_watts": 19.182, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 70.86}, "timestamp": "2026-01-30T13:29:26.267023"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4240.9, "latencies_ms": [4240.9], "images_per_second": 0.236, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In this image, we can see a herd of animals, including zebras and sheep, grazing in a grassy field. In the background, we can see trees and a pond.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14074.6, "ram_available_mb": 48766.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.876, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.062, "gpu_utilization_percent_mean": 70.886}, "timestamp": "2026-01-30T13:29:32.544962"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4462.928, "latencies_ms": [4462.928], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a grassy field with a variety of animals, including zebras, sheep, and deer. The sky is blue with some clouds, and the trees in the background are tall and green.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14079.1, "ram_available_mb": 48761.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14078.9, "ram_available_mb": 48762.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.29, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.892}, "timestamp": "2026-01-30T13:29:39.068333"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3661.027, "latencies_ms": [3661.027], "images_per_second": 0.273, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A vintage trolley car with a green and gold body and a red roof is being pulled by two white horses in a park.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14078.9, "ram_available_mb": 48762.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14075.4, "ram_available_mb": 48765.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.94, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 75.6}, "timestamp": "2026-01-30T13:29:44.753757"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4192.348, "latencies_ms": [4192.348], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " trolley: 1, horse: 2, carriage: 1, people: 1, bench: 1, trees: 1, umbrella: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14075.4, "ram_available_mb": 48765.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14075.4, "ram_available_mb": 48765.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.543}, "power_stats": {"power_gpu_soc_mean_watts": 20.704, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 73.543}, "timestamp": "2026-01-30T13:29:51.004358"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6003.338, "latencies_ms": [6003.338], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The horse-drawn trolley is positioned in the foreground of the image, with the passengers seated inside. The trolley is moving towards the right side of the image, while the people are standing on the left side. The background features a park with trees and benches, indicating that the trolley is passing through a public area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14075.4, "ram_available_mb": 48765.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 18.193, "power_cpu_cv_mean_watts": 1.681, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T13:29:59.037456"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3565.044, "latencies_ms": [3565.044], "images_per_second": 0.281, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A horse-drawn trolley car is driving down a street in a park, with people walking around and sitting on benches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14073.9, "ram_available_mb": 48767.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.477, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 74.69}, "timestamp": "2026-01-30T13:30:04.626035"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5612.622, "latencies_ms": [5612.622], "images_per_second": 0.178, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features a vibrant scene with a green and red trolley car, white horses pulling it, and a yellow canopy overhead. The trolley car is adorned with gold accents and has a sign that reads \"DINING CAR\". The sky is clear and blue, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14072.3, "ram_available_mb": 48768.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.064}, "power_stats": {"power_gpu_soc_mean_watts": 18.435, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.942, "gpu_utilization_percent_mean": 68.064}, "timestamp": "2026-01-30T13:30:12.265406"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4401.317, "latencies_ms": [4401.317], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " An elderly man sits on a green bench reading a newspaper while a group of people sit on benches in front of a building with a sign that says \"S.C.C.C.\"", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14072.7, "ram_available_mb": 48768.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.111}, "power_stats": {"power_gpu_soc_mean_watts": 20.386, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 73.111}, "timestamp": "2026-01-30T13:30:18.690289"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5442.597, "latencies_ms": [5442.597], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. bench: 4\n3. man: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14072.4, "ram_available_mb": 48768.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.065}, "power_stats": {"power_gpu_soc_mean_watts": 18.581, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 69.065}, "timestamp": "2026-01-30T13:30:26.174908"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5641.048, "latencies_ms": [5641.048], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man on the left is sitting on a green bench, while the man on the right is sitting on a red bench. The man on the left is closer to the camera than the man on the right. The man on the left is sitting in front of the man on the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.8, "ram_available_mb": 48769.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.553}, "power_stats": {"power_gpu_soc_mean_watts": 18.239, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-30T13:30:33.842279"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5963.944, "latencies_ms": [5963.944], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a serene scene of a group of people enjoying a sunny day on a city sidewalk. The individuals are seated on green metal benches, each engrossed in their own world. The backdrop is a bustling cityscape with a prominent building adorned with a maroon sign that reads \"S.C.C.C.\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.2, "ram_available_mb": 48768.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.673}, "power_stats": {"power_gpu_soc_mean_watts": 18.032, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 68.673}, "timestamp": "2026-01-30T13:30:41.829365"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4260.938, "latencies_ms": [4260.938], "images_per_second": 0.235, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is taken during the day with natural light, and the ground is paved with concrete. The color of the benches is green, and the man is wearing a gray suit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.715, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 72.229}, "timestamp": "2026-01-30T13:30:48.105617"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3171.325, "latencies_ms": [3171.325], "images_per_second": 0.315, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A black desk with a laptop, a lamp, and a glass of orange juice on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14072.1, "ram_available_mb": 48768.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.403, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.225, "gpu_utilization_percent_mean": 73.423}, "timestamp": "2026-01-30T13:30:53.335303"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4473.576, "latencies_ms": [4473.576], "images_per_second": 0.224, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. black laptop\n2. white telephone\n3. black lamp\n4. glass of orange juice\n5. book\n6. white paper\n7. black pen\n8. black chair", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.595}, "power_stats": {"power_gpu_soc_mean_watts": 20.471, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 71.595}, "timestamp": "2026-01-30T13:30:59.838128"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4254.754, "latencies_ms": [4254.754], "images_per_second": 0.235, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The laptop is positioned to the left of the desk, with the lamp and telephone to its right. The desk is situated in the foreground, with the wall and painting in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.91, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 70.486}, "timestamp": "2026-01-30T13:31:06.104777"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3679.262, "latencies_ms": [3679.262], "images_per_second": 0.272, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A desk with a laptop computer, a lamp, and a glass of orange juice is in a room with a painting on the wall.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.4}, "power_stats": {"power_gpu_soc_mean_watts": 22.124, "power_cpu_cv_mean_watts": 1.147, "power_sys_5v0_mean_watts": 8.127, "gpu_utilization_percent_mean": 73.4}, "timestamp": "2026-01-30T13:31:11.799859"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3286.214, "latencies_ms": [3286.214], "images_per_second": 0.304, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is well-lit with a warm yellow light, and the desk is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14071.9, "ram_available_mb": 48769.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.0, "power_cpu_cv_mean_watts": 0.978, "power_sys_5v0_mean_watts": 8.145, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-30T13:31:17.129726"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5644.122, "latencies_ms": [5644.122], "images_per_second": 0.177, "prompt_tokens": 1432, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a blue and white striped towel, a pink and white surfboard, and a blue surfboard resting on the sand, with a beach umbrella and chairs nearby, and a person enjoying the ocean waves in the distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14071.4, "ram_available_mb": 48769.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14070.5, "ram_available_mb": 48770.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.979}, "power_stats": {"power_gpu_soc_mean_watts": 21.286, "power_cpu_cv_mean_watts": 1.465, "power_sys_5v0_mean_watts": 8.287, "gpu_utilization_percent_mean": 72.979}, "timestamp": "2026-01-30T13:31:24.840674"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4666.315, "latencies_ms": [4666.315], "images_per_second": 0.214, "prompt_tokens": 1446, "response_tokens_est": 33, "n_tiles": 1, "output_text": " beach chair: 2\nsurfboard: 3\nbag: 1\numbrella: 1\nsand: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14070.5, "ram_available_mb": 48770.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14065.5, "ram_available_mb": 48775.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.239, "power_cpu_cv_mean_watts": 1.314, "power_sys_5v0_mean_watts": 8.369, "gpu_utilization_percent_mean": 76.462}, "timestamp": "2026-01-30T13:31:31.540358"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6686.021, "latencies_ms": [6686.021], "images_per_second": 0.15, "prompt_tokens": 1450, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The blue and white striped towel is positioned to the left of the blue surfboard, which is closer to the camera than the pink and white surfboard. The red cooler is located in the foreground, near the beach chairs and umbrellas, while the person in the water is situated in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14065.5, "ram_available_mb": 48775.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14066.4, "ram_available_mb": 48774.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.696}, "power_stats": {"power_gpu_soc_mean_watts": 20.053, "power_cpu_cv_mean_watts": 1.594, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 69.696}, "timestamp": "2026-01-30T13:31:40.277635"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4882.972, "latencies_ms": [4882.972], "images_per_second": 0.205, "prompt_tokens": 1444, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image captures a serene beach scene with a clear blue sky and calm ocean waves. People are enjoying the beach, with some relaxing on the sand and others swimming in the water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14066.4, "ram_available_mb": 48774.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14065.7, "ram_available_mb": 48775.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.575}, "power_stats": {"power_gpu_soc_mean_watts": 22.92, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.367, "gpu_utilization_percent_mean": 76.575}, "timestamp": "2026-01-30T13:31:47.171777"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3728.012, "latencies_ms": [3728.012], "images_per_second": 0.268, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The beach is covered in sand, the sky is blue, and the ocean is blue.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14065.7, "ram_available_mb": 48775.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14066.4, "ram_available_mb": 48774.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.733}, "power_stats": {"power_gpu_soc_mean_watts": 25.863, "power_cpu_cv_mean_watts": 0.88, "power_sys_5v0_mean_watts": 8.575, "gpu_utilization_percent_mean": 79.733}, "timestamp": "2026-01-30T13:31:52.930008"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3219.75, "latencies_ms": [3219.75], "images_per_second": 0.311, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A sheep with a black face is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14066.4, "ram_available_mb": 48774.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14066.4, "ram_available_mb": 48774.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.468, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 73.923}, "timestamp": "2026-01-30T13:31:58.170496"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5704.997, "latencies_ms": [5704.997], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. rock: 1\n3. grass: 1\n4. sky: 1\n5. clouds: 1\n6. cloud: 1\n7. sheep's head: 1\n8. sheep's body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14066.4, "ram_available_mb": 48774.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14065.9, "ram_available_mb": 48775.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.812}, "power_stats": {"power_gpu_soc_mean_watts": 18.2, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 66.812}, "timestamp": "2026-01-30T13:32:05.909715"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4432.189, "latencies_ms": [4432.189], "images_per_second": 0.226, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The sheep is positioned on the left side of the image, with the sky occupying the majority of the background. The sheep is in the foreground, with the grass and rocks in the middle ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14065.9, "ram_available_mb": 48775.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14065.9, "ram_available_mb": 48775.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.027}, "power_stats": {"power_gpu_soc_mean_watts": 20.256, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 70.027}, "timestamp": "2026-01-30T13:32:12.361966"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3147.399, "latencies_ms": [3147.399], "images_per_second": 0.318, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A sheep with a black face is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14065.9, "ram_available_mb": 48775.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14065.5, "ram_available_mb": 48775.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.646, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.295, "gpu_utilization_percent_mean": 73.731}, "timestamp": "2026-01-30T13:32:17.561004"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3439.988, "latencies_ms": [3439.988], "images_per_second": 0.291, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The sheep is white with a black face and is standing on a rocky hill under a blue sky with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14065.5, "ram_available_mb": 48775.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14065.3, "ram_available_mb": 48775.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.715, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.137, "gpu_utilization_percent_mean": 70.25}, "timestamp": "2026-01-30T13:32:23.018075"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2856.112, "latencies_ms": [2856.112], "images_per_second": 0.35, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person with blue hair is taking a selfie in the mirror.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14065.3, "ram_available_mb": 48775.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14065.6, "ram_available_mb": 48775.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.042}, "power_stats": {"power_gpu_soc_mean_watts": 24.368, "power_cpu_cv_mean_watts": 0.95, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 78.042}, "timestamp": "2026-01-30T13:32:27.934471"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5393.862, "latencies_ms": [5393.862], "images_per_second": 0.185, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. phone: 1\n3. shirt: 1\n4. tie: 1\n5. wall: 1\n6. ring: 1\n7. mirror: 1\n8. blue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14065.6, "ram_available_mb": 48775.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14064.1, "ram_available_mb": 48776.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.283}, "power_stats": {"power_gpu_soc_mean_watts": 18.834, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 69.283}, "timestamp": "2026-01-30T13:32:35.352669"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5288.316, "latencies_ms": [5288.316], "images_per_second": 0.189, "prompt_tokens": 1118, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The person is in the foreground of the image, taking a selfie with a phone. The phone is held up to the camera, and the person's reflection is visible in the mirror. The mirror is located in the background, reflecting the person and the phone.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14064.1, "ram_available_mb": 48776.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14064.1, "ram_available_mb": 48776.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.5}, "power_stats": {"power_gpu_soc_mean_watts": 18.889, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 68.5}, "timestamp": "2026-01-30T13:32:42.684932"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2858.488, "latencies_ms": [2858.488], "images_per_second": 0.35, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman with blue hair is taking a selfie in the mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14064.1, "ram_available_mb": 48776.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14063.8, "ram_available_mb": 48777.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.245, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-30T13:32:47.568759"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3557.238, "latencies_ms": [3557.238], "images_per_second": 0.281, "prompt_tokens": 1110, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The woman has blue hair and is wearing a blue shirt. The lighting is bright and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.8, "ram_available_mb": 48777.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14064.0, "ram_available_mb": 48776.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.058, "power_cpu_cv_mean_watts": 1.104, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.69}, "timestamp": "2026-01-30T13:32:53.142810"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3991.775, "latencies_ms": [3991.775], "images_per_second": 0.251, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden cabinet, a table, and chairs, all arranged in a way that suggests a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14064.0, "ram_available_mb": 48776.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14063.4, "ram_available_mb": 48777.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.879}, "power_stats": {"power_gpu_soc_mean_watts": 21.243, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 71.879}, "timestamp": "2026-01-30T13:32:59.181791"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4159.892, "latencies_ms": [4159.892], "images_per_second": 0.24, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " fireplace: 1, table: 1, chair: 2, bookshelf: 1, painting: 2, vase: 2, floor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14063.4, "ram_available_mb": 48777.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14062.9, "ram_available_mb": 48778.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.829}, "power_stats": {"power_gpu_soc_mean_watts": 20.807, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 70.829}, "timestamp": "2026-01-30T13:33:05.380263"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5264.556, "latencies_ms": [5264.556], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The fireplace is located on the left side of the room, with the wooden cabinet positioned against the right wall. The round wooden table is situated in the foreground, with the chairs placed in the background. The bookshelf is positioned in the background, behind the wooden cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.9, "ram_available_mb": 48778.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14062.8, "ram_available_mb": 48778.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.711}, "power_stats": {"power_gpu_soc_mean_watts": 19.014, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.711}, "timestamp": "2026-01-30T13:33:12.665147"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3236.822, "latencies_ms": [3236.822], "images_per_second": 0.309, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The image depicts a room with a fireplace, a wooden cabinet, and a table with chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.8, "ram_available_mb": 48778.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14063.3, "ram_available_mb": 48777.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.444}, "power_stats": {"power_gpu_soc_mean_watts": 22.967, "power_cpu_cv_mean_watts": 1.052, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 76.444}, "timestamp": "2026-01-30T13:33:17.931805"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4102.244, "latencies_ms": [4102.244], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white. The furniture is made of wood, and the floor is covered with a patterned carpet.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14063.3, "ram_available_mb": 48777.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14064.0, "ram_available_mb": 48776.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.029}, "power_stats": {"power_gpu_soc_mean_watts": 21.102, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T13:33:24.055292"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3589.019, "latencies_ms": [3589.019], "images_per_second": 0.279, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A brown dog is jumping in the air to catch a red frisbee.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 14064.0, "ram_available_mb": 48776.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14063.7, "ram_available_mb": 48777.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.567}, "power_stats": {"power_gpu_soc_mean_watts": 25.371, "power_cpu_cv_mean_watts": 0.907, "power_sys_5v0_mean_watts": 8.532, "gpu_utilization_percent_mean": 80.567}, "timestamp": "2026-01-30T13:33:29.677408"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4527.376, "latencies_ms": [4527.376], "images_per_second": 0.221, "prompt_tokens": 1446, "response_tokens_est": 31, "n_tiles": 1, "output_text": " dog: 1, frisbee: 1, car: 1, tree: 1, grass: 1, mulch: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14063.7, "ram_available_mb": 48777.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.316}, "power_stats": {"power_gpu_soc_mean_watts": 23.601, "power_cpu_cv_mean_watts": 1.243, "power_sys_5v0_mean_watts": 8.399, "gpu_utilization_percent_mean": 75.316}, "timestamp": "2026-01-30T13:33:36.243706"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5067.563, "latencies_ms": [5067.563], "images_per_second": 0.197, "prompt_tokens": 1450, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The dog is in the foreground, jumping up to catch the frisbee, which is in the middle ground. The frisbee is in the air, and the car is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14063.7, "ram_available_mb": 48777.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.952}, "power_stats": {"power_gpu_soc_mean_watts": 22.614, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 8.368, "gpu_utilization_percent_mean": 72.952}, "timestamp": "2026-01-30T13:33:43.327996"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3896.891, "latencies_ms": [3896.891], "images_per_second": 0.257, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog is playing frisbee in a yard with a tree and a car in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.7, "ram_available_mb": 48777.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14064.1, "ram_available_mb": 48776.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.341, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.532, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-30T13:33:49.258037"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4927.196, "latencies_ms": [4927.196], "images_per_second": 0.203, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a black dog with a red frisbee in its mouth, jumping in the air in a grassy yard. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14064.1, "ram_available_mb": 48776.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14064.4, "ram_available_mb": 48776.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.073}, "power_stats": {"power_gpu_soc_mean_watts": 22.948, "power_cpu_cv_mean_watts": 1.269, "power_sys_5v0_mean_watts": 8.364, "gpu_utilization_percent_mean": 75.073}, "timestamp": "2026-01-30T13:33:56.227837"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3609.108, "latencies_ms": [3609.108], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image captures a giraffe in a natural setting, with its head and neck prominently displayed, and the background filled with lush greenery.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14064.4, "ram_available_mb": 48776.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14064.4, "ram_available_mb": 48776.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.274, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 75.133}, "timestamp": "2026-01-30T13:34:01.876608"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4090.939, "latencies_ms": [4090.939], "images_per_second": 0.244, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " giraffe: 1, ear: 2, eye: 2, nose: 1, mouth: 1, horn: 1, tail: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14064.4, "ram_available_mb": 48776.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14064.4, "ram_available_mb": 48776.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.206}, "power_stats": {"power_gpu_soc_mean_watts": 21.101, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 69.206}, "timestamp": "2026-01-30T13:34:08.000405"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4044.445, "latencies_ms": [4044.445], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The giraffe is in the foreground, with its head and neck prominently displayed. The background is filled with green foliage, suggesting that the giraffe is in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14064.4, "ram_available_mb": 48776.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14064.6, "ram_available_mb": 48776.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.218, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 71.324}, "timestamp": "2026-01-30T13:34:14.090238"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5085.437, "latencies_ms": [5085.437], "images_per_second": 0.197, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " In the heart of a verdant forest, a majestic giraffe stands tall and proud, its long neck reaching towards the sky. The giraffe's coat, a beautiful mosaic of brown and white spots, contrasts beautifully with the lush greenery of the trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14064.6, "ram_available_mb": 48776.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14064.3, "ram_available_mb": 48776.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.69}, "power_stats": {"power_gpu_soc_mean_watts": 19.294, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 68.69}, "timestamp": "2026-01-30T13:34:21.188679"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3939.628, "latencies_ms": [3939.628], "images_per_second": 0.254, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The giraffe's coat is a rich brown with white spots, and the sunlight filters through the green leaves of the trees, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14064.3, "ram_available_mb": 48776.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14064.3, "ram_available_mb": 48776.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.697}, "power_stats": {"power_gpu_soc_mean_watts": 21.306, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 71.697}, "timestamp": "2026-01-30T13:34:27.147587"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3480.21, "latencies_ms": [3480.21], "images_per_second": 0.287, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two zebras with black and white stripes are standing in a fenced area with a chain link fence in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14064.3, "ram_available_mb": 48776.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14064.8, "ram_available_mb": 48776.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.622, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.145, "gpu_utilization_percent_mean": 73.103}, "timestamp": "2026-01-30T13:34:32.698312"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5521.695, "latencies_ms": [5521.695], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. zebra: 2\n2. fence: 1\n3. ground: 1\n4. rocks: 1\n5. trees: 1\n6. leaves: 1\n7. grass: 1\n8. zebra's tail: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14064.8, "ram_available_mb": 48776.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14064.2, "ram_available_mb": 48776.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.597, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 70.043}, "timestamp": "2026-01-30T13:34:40.243333"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5591.598, "latencies_ms": [5591.598], "images_per_second": 0.179, "prompt_tokens": 1118, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the fence serving as a boundary between them and the background. The zebras are facing away from the camera, with their tails prominently displayed, and the fence is located behind them, separating them from the rest of the environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14064.2, "ram_available_mb": 48776.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14064.3, "ram_available_mb": 48776.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.085}, "power_stats": {"power_gpu_soc_mean_watts": 18.536, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 70.085}, "timestamp": "2026-01-30T13:34:47.869006"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3373.272, "latencies_ms": [3373.272], "images_per_second": 0.296, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two zebras are standing in a fenced enclosure, their black and white stripes contrasting against the brown dirt ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14064.3, "ram_available_mb": 48776.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14063.4, "ram_available_mb": 48777.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.748, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 75.179}, "timestamp": "2026-01-30T13:34:53.290154"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4707.379, "latencies_ms": [4707.379], "images_per_second": 0.212, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features two zebras with their backs to the camera, standing in a grassy area with a chain link fence in the background. The zebras have black and white stripes, and the lighting appears to be natural daylight.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14063.4, "ram_available_mb": 48777.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.1}, "power_stats": {"power_gpu_soc_mean_watts": 19.949, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 70.1}, "timestamp": "2026-01-30T13:35:00.039074"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3929.701, "latencies_ms": [3929.701], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of horses is walking down a road, with a car parked on the side, and a pile of poop on the ground.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14063.4, "ram_available_mb": 48777.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.062}, "power_stats": {"power_gpu_soc_mean_watts": 21.495, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 69.062}, "timestamp": "2026-01-30T13:35:05.999509"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5438.668, "latencies_ms": [5438.668], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 4\n2. car: 1\n3. horse: 2\n4. horse: 1\n5. horse: 1\n6. horse: 1\n7. horse: 1\n8. horse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.4, "ram_available_mb": 48777.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14062.6, "ram_available_mb": 48778.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.622}, "power_stats": {"power_gpu_soc_mean_watts": 18.845, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 67.622}, "timestamp": "2026-01-30T13:35:13.464688"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5360.087, "latencies_ms": [5360.087], "images_per_second": 0.187, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The horses are positioned in the middle of the road, with the car parked on the right side of the street. The car is relatively close to the camera, while the horses are farther away. The horses are near the car, but not directly in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.6, "ram_available_mb": 48778.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14062.6, "ram_available_mb": 48778.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.289}, "power_stats": {"power_gpu_soc_mean_watts": 18.694, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 70.289}, "timestamp": "2026-01-30T13:35:20.861006"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5481.283, "latencies_ms": [5481.283], "images_per_second": 0.182, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " In a serene suburban setting, a group of horses, their coats a mix of brown and black, are peacefully grazing on the lush green grass along a quiet street. A silver car is parked on the side of the road, its presence adding a touch of modernity to the tranquil scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14062.6, "ram_available_mb": 48778.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14063.0, "ram_available_mb": 48777.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.348}, "power_stats": {"power_gpu_soc_mean_watts": 18.644, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 69.348}, "timestamp": "2026-01-30T13:35:28.359743"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4802.906, "latencies_ms": [4802.906], "images_per_second": 0.208, "prompt_tokens": 1109, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a group of horses walking down a tree-lined street, with a silver car parked on the side of the road. The horses are brown and black, and the trees are green, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14063.0, "ram_available_mb": 48777.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14063.0, "ram_available_mb": 48777.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.85}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.85}, "timestamp": "2026-01-30T13:35:35.186091"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3677.872, "latencies_ms": [3677.872], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In the image, there is a wooden desk with a blue book and a red apple on it, and a blackboard behind it.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14063.0, "ram_available_mb": 48777.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.194, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 74.233}, "timestamp": "2026-01-30T13:35:40.905282"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3863.502, "latencies_ms": [3863.502], "images_per_second": 0.259, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " desk: 1\nbooks: 1\napple: 1\nblackboard: 1\nchair: 1\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14062.8, "ram_available_mb": 48778.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.688}, "power_stats": {"power_gpu_soc_mean_watts": 21.557, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 71.688}, "timestamp": "2026-01-30T13:35:46.815192"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5685.034, "latencies_ms": [5685.034], "images_per_second": 0.176, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The desk is positioned to the left of the chalkboard, with the chair in front of it. The books are placed on the desk, with the apple on top of the books. The chalkboard is located behind the desk, and the picture is on the wall to the right of the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.8, "ram_available_mb": 48778.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.376, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T13:35:54.542635"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2845.482, "latencies_ms": [2845.482], "images_per_second": 0.351, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A classroom with a desk, books, and a chalkboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.913}, "power_stats": {"power_gpu_soc_mean_watts": 24.178, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 76.913}, "timestamp": "2026-01-30T13:35:59.416209"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3288.451, "latencies_ms": [3288.451], "images_per_second": 0.304, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted in a warm brown color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.5, "ram_available_mb": 48777.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.194, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 73.815}, "timestamp": "2026-01-30T13:36:04.738920"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3290.287, "latencies_ms": [3290.287], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A yellow and white bus with the number 475 on the back is parked on the street.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14062.9, "ram_available_mb": 48778.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.178, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 74.815}, "timestamp": "2026-01-30T13:36:10.075979"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3481.72, "latencies_ms": [3481.72], "images_per_second": 0.287, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " bus: 1, car: 1, truck: 1, road: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.9, "ram_available_mb": 48778.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.49, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.159, "gpu_utilization_percent_mean": 73.724}, "timestamp": "2026-01-30T13:36:15.599606"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4286.588, "latencies_ms": [4286.588], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bus is parked on the left side of the road, while the white van is parked on the right side. The bus is in the foreground, while the van is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14062.5, "ram_available_mb": 48778.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.798, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.088, "gpu_utilization_percent_mean": 71.972}, "timestamp": "2026-01-30T13:36:21.922036"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3089.7, "latencies_ms": [3089.7], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A yellow bus is driving down a busy street with other cars and a white van.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.5, "ram_available_mb": 48778.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14062.4, "ram_available_mb": 48778.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.846, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 76.24}, "timestamp": "2026-01-30T13:36:27.032230"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3429.511, "latencies_ms": [3429.511], "images_per_second": 0.292, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken during the day with a lot of sunlight. The colors in the image are vibrant and bright.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.4, "ram_available_mb": 48778.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14062.3, "ram_available_mb": 48778.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.749, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T13:36:32.480618"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3931.968, "latencies_ms": [3931.968], "images_per_second": 0.254, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image depicts a bathroom with a large mirror that reflects a television screen showing a football game, and two sinks with faucets on either side of the mirror.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14062.3, "ram_available_mb": 48778.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14062.3, "ram_available_mb": 48778.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.062}, "power_stats": {"power_gpu_soc_mean_watts": 21.785, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 72.062}, "timestamp": "2026-01-30T13:36:38.447820"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2994.81, "latencies_ms": [2994.81], "images_per_second": 0.334, "prompt_tokens": 1114, "response_tokens_est": 16, "n_tiles": 1, "output_text": " television: 1\nmirror: 1\nsink: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.3, "ram_available_mb": 48778.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14062.2, "ram_available_mb": 48778.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 23.976, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.231, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T13:36:43.492256"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4536.25, "latencies_ms": [4536.25], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The television is positioned above the sink, with the mirror reflecting the television's image. The sink is located to the left of the television, and the trash can is situated to the right of the television.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14062.2, "ram_available_mb": 48778.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14062.3, "ram_available_mb": 48778.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.842}, "power_stats": {"power_gpu_soc_mean_watts": 20.063, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 69.842}, "timestamp": "2026-01-30T13:36:50.075508"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3360.413, "latencies_ms": [3360.413], "images_per_second": 0.298, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A bathroom with a large mirror and two sinks, a television mounted on the wall, and a trash can.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14062.3, "ram_available_mb": 48778.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14061.8, "ram_available_mb": 48779.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.926}, "power_stats": {"power_gpu_soc_mean_watts": 22.928, "power_cpu_cv_mean_watts": 1.083, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 73.926}, "timestamp": "2026-01-30T13:36:55.461795"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3689.455, "latencies_ms": [3689.455], "images_per_second": 0.271, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The bathroom has a beige tiled wall and a brown countertop. The television is turned on and is showing a football game.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14061.8, "ram_available_mb": 48779.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14062.6, "ram_available_mb": 48778.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.333}, "power_stats": {"power_gpu_soc_mean_watts": 22.128, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 72.333}, "timestamp": "2026-01-30T13:37:01.161418"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3613.426, "latencies_ms": [3613.426], "images_per_second": 0.277, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man sits on a bench in a park with a church in the background.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 14061.9, "ram_available_mb": 48779.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.833}, "power_stats": {"power_gpu_soc_mean_watts": 25.197, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.529, "gpu_utilization_percent_mean": 79.833}, "timestamp": "2026-01-30T13:37:06.817823"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5024.457, "latencies_ms": [5024.457], "images_per_second": 0.199, "prompt_tokens": 1446, "response_tokens_est": 38, "n_tiles": 1, "output_text": " 1. man sitting on bench\n2. bench\n3. street lamp\n4. tree\n5. building\n6. clock on tower\n7. bushes\n8. clouds", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14063.2, "ram_available_mb": 48777.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14062.5, "ram_available_mb": 48778.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.405}, "power_stats": {"power_gpu_soc_mean_watts": 22.45, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.294, "gpu_utilization_percent_mean": 75.405}, "timestamp": "2026-01-30T13:37:13.871609"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4935.627, "latencies_ms": [4935.627], "images_per_second": 0.203, "prompt_tokens": 1450, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the left side of the bench, which is positioned in the foreground of the image. The church steeple is located in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.5, "ram_available_mb": 48778.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14062.8, "ram_available_mb": 48778.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.905}, "power_stats": {"power_gpu_soc_mean_watts": 22.73, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 8.342, "gpu_utilization_percent_mean": 74.905}, "timestamp": "2026-01-30T13:37:20.832562"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3611.628, "latencies_ms": [3611.628], "images_per_second": 0.277, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man sits on a bench in a park with a church in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.8, "ram_available_mb": 48778.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14062.1, "ram_available_mb": 48778.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.6}, "power_stats": {"power_gpu_soc_mean_watts": 26.09, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 8.558, "gpu_utilization_percent_mean": 78.6}, "timestamp": "2026-01-30T13:37:26.485669"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4786.768, "latencies_ms": [4786.768], "images_per_second": 0.209, "prompt_tokens": 1442, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the man and the background. The sky is cloudy, and the man is sitting on a bench in a park.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14062.1, "ram_available_mb": 48778.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14062.1, "ram_available_mb": 48778.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.146}, "power_stats": {"power_gpu_soc_mean_watts": 23.182, "power_cpu_cv_mean_watts": 1.328, "power_sys_5v0_mean_watts": 8.4, "gpu_utilization_percent_mean": 75.146}, "timestamp": "2026-01-30T13:37:33.302800"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5308.343, "latencies_ms": [5308.343], "images_per_second": 0.188, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a city, with a variety of vehicles parked and moving along the road, including a white car with a blue and yellow sign on top, a black car, and a green car, all under the watchful eye of a traffic light.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14061.8, "ram_available_mb": 48779.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14061.6, "ram_available_mb": 48779.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.205}, "power_stats": {"power_gpu_soc_mean_watts": 18.999, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 70.205}, "timestamp": "2026-01-30T13:37:40.661319"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5532.503, "latencies_ms": [5532.503], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. car: 4\n2. street light: 1\n3. bus stop: 1\n4. sign: 1\n5. building: 1\n6. tree: 1\n7. person: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14061.6, "ram_available_mb": 48779.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14061.8, "ram_available_mb": 48779.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.745}, "power_stats": {"power_gpu_soc_mean_watts": 18.537, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 70.745}, "timestamp": "2026-01-30T13:37:48.226283"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4286.448, "latencies_ms": [4286.448], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The cars are parked on the right side of the street, while the street is on the left side. The cars are parked in front of a building, which is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14061.8, "ram_available_mb": 48779.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14062.1, "ram_available_mb": 48778.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.439, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T13:37:54.541449"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4797.773, "latencies_ms": [4797.773], "images_per_second": 0.208, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a city, with a variety of vehicles parked and moving along the road. The buildings in the background suggest an urban setting, and the presence of a bus stop indicates a public transportation system.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14062.1, "ram_available_mb": 48778.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14061.4, "ram_available_mb": 48779.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.2}, "power_stats": {"power_gpu_soc_mean_watts": 19.765, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-30T13:38:01.365246"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4757.56, "latencies_ms": [4757.56], "images_per_second": 0.21, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features a clear blue sky with a few clouds, and the sun is shining brightly, casting a warm glow on the scene. The cars are parked in a row, and the buildings in the background are made of stone.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14061.4, "ram_available_mb": 48779.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14061.2, "ram_available_mb": 48779.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.1}, "power_stats": {"power_gpu_soc_mean_watts": 19.826, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 71.1}, "timestamp": "2026-01-30T13:38:08.167718"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4903.854, "latencies_ms": [4903.854], "images_per_second": 0.204, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a top-down view of a wooden table adorned with a white plate holding a half-eaten omelette, a cup of tea, a small bowl of sugar, and a plate of sliced fruits and vegetables.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14061.2, "ram_available_mb": 48779.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14060.9, "ram_available_mb": 48780.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.902}, "power_stats": {"power_gpu_soc_mean_watts": 19.315, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 66.902}, "timestamp": "2026-01-30T13:38:15.120970"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4397.533, "latencies_ms": [4397.533], "images_per_second": 0.227, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " plate: 1, cup: 1, fork: 2, knife: 1, banana: 1, watermelon: 1, cucumber: 1, fruit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14060.9, "ram_available_mb": 48780.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14060.8, "ram_available_mb": 48780.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.622}, "power_stats": {"power_gpu_soc_mean_watts": 20.352, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 70.622}, "timestamp": "2026-01-30T13:38:21.561359"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4770.575, "latencies_ms": [4770.575], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The plate of food is located in the foreground, with the cup of tea and sugar bowl placed in the middle ground. The shadow of the table is cast on the floor, indicating the light source is coming from above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14060.8, "ram_available_mb": 48780.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14060.8, "ram_available_mb": 48780.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.615}, "power_stats": {"power_gpu_soc_mean_watts": 19.812, "power_cpu_cv_mean_watts": 1.437, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 71.615}, "timestamp": "2026-01-30T13:38:28.350748"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2844.084, "latencies_ms": [2844.084], "images_per_second": 0.352, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A wooden table with a plate of food and a cup of coffee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14060.8, "ram_available_mb": 48780.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14060.7, "ram_available_mb": 48780.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.957}, "power_stats": {"power_gpu_soc_mean_watts": 24.644, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.289, "gpu_utilization_percent_mean": 75.957}, "timestamp": "2026-01-30T13:38:33.210966"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5587.702, "latencies_ms": [5587.702], "images_per_second": 0.179, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features a wooden table with a white plate of food, a cup of tea, and a bowl of fruit. The table is set in a room with white tiled floors and a window with a view of trees outside. The lighting is natural and bright, casting shadows on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14060.7, "ram_available_mb": 48780.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14060.6, "ram_available_mb": 48780.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.217}, "power_stats": {"power_gpu_soc_mean_watts": 18.642, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 67.217}, "timestamp": "2026-01-30T13:38:40.819811"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4210.33, "latencies_ms": [4210.33], "images_per_second": 0.238, "prompt_tokens": 1100, "response_tokens_est": 36, "n_tiles": 1, "output_text": " An elderly woman wearing a green and white striped shirt and a pink apron is preparing food on a table with a variety of baked goods, including cookies, bread, and pastries.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 14060.6, "ram_available_mb": 48780.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14059.8, "ram_available_mb": 48781.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.738, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 70.571}, "timestamp": "2026-01-30T13:38:47.077694"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4460.654, "latencies_ms": [4460.654], "images_per_second": 0.224, "prompt_tokens": 1114, "response_tokens_est": 40, "n_tiles": 1, "output_text": " person: 1, apron: 1, table: 1, glass: 1, bread: 1, milk: 1, cookies: 1, door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14059.8, "ram_available_mb": 48781.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.811}, "power_stats": {"power_gpu_soc_mean_watts": 20.353, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 69.811}, "timestamp": "2026-01-30T13:38:53.570971"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4122.645, "latencies_ms": [4122.645], "images_per_second": 0.243, "prompt_tokens": 1118, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The person is standing to the left of the table, with the table being in the foreground. The person is near the table, with the door being in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14059.0, "ram_available_mb": 48781.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.088}, "power_stats": {"power_gpu_soc_mean_watts": 20.934, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 70.088}, "timestamp": "2026-01-30T13:38:59.733415"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3288.615, "latencies_ms": [3288.615], "images_per_second": 0.304, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " An elderly woman wearing a green and white striped shirt and a pink apron is preparing food on a table.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14059.0, "ram_available_mb": 48781.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.074}, "power_stats": {"power_gpu_soc_mean_watts": 23.263, "power_cpu_cv_mean_watts": 1.141, "power_sys_5v0_mean_watts": 8.227, "gpu_utilization_percent_mean": 75.074}, "timestamp": "2026-01-30T13:39:05.061627"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4045.857, "latencies_ms": [4045.857], "images_per_second": 0.247, "prompt_tokens": 1110, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming through the window. The colors in the image are vibrant and the materials are mostly wood and fabric.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.471}, "power_stats": {"power_gpu_soc_mean_watts": 21.451, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 70.471}, "timestamp": "2026-01-30T13:39:11.128682"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4330.321, "latencies_ms": [4330.321], "images_per_second": 0.231, "prompt_tokens": 1100, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man stands in front of a traffic light and a sign that says \"AUSTRALIA MOST BAD TRAFFIC LIGHT\" with a red traffic light on it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.572, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.306}, "timestamp": "2026-01-30T13:39:17.494138"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5497.366, "latencies_ms": [5497.366], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. traffic light: 1\n3. sign: 1\n4. pole: 1\n5. tree: 1\n6. flower: 1\n7. rock: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.022}, "power_stats": {"power_gpu_soc_mean_watts": 18.605, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 68.022}, "timestamp": "2026-01-30T13:39:25.011057"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5979.184, "latencies_ms": [5979.184], "images_per_second": 0.167, "prompt_tokens": 1118, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The man is standing to the left of the traffic light, which is positioned in the middle of the image. The traffic light is in front of the man, and the sign is to the right of the man. The man is standing closer to the camera than the traffic light, which is farther away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.74}, "power_stats": {"power_gpu_soc_mean_watts": 17.958, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.937, "gpu_utilization_percent_mean": 70.74}, "timestamp": "2026-01-30T13:39:33.043776"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3218.864, "latencies_ms": [3218.864], "images_per_second": 0.311, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man stands in front of a traffic light and a sign that says \"Australia Most Dangerous Road\".", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14059.2, "ram_available_mb": 48781.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14058.9, "ram_available_mb": 48782.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.28, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 71.808}, "timestamp": "2026-01-30T13:39:38.305693"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3881.276, "latencies_ms": [3881.276], "images_per_second": 0.258, "prompt_tokens": 1110, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The man is wearing a white t-shirt and khaki shorts. The traffic light is red, yellow, and green. The sky is overcast.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 14058.9, "ram_available_mb": 48782.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14058.5, "ram_available_mb": 48782.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.344}, "power_stats": {"power_gpu_soc_mean_watts": 21.805, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 71.344}, "timestamp": "2026-01-30T13:39:44.249682"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3677.397, "latencies_ms": [3677.397], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A large group of people are gathered in a park to fly a variety of kites, including a large red and white fish kite.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14058.5, "ram_available_mb": 48782.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14058.7, "ram_available_mb": 48782.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.967}, "power_stats": {"power_gpu_soc_mean_watts": 22.177, "power_cpu_cv_mean_watts": 1.254, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 71.967}, "timestamp": "2026-01-30T13:39:49.950676"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6481.459, "latencies_ms": [6481.459], "images_per_second": 0.154, "prompt_tokens": 1113, "response_tokens_est": 74, "n_tiles": 1, "output_text": " 1. Kites: 12\n2. People: 10\n3. Trees: 10\n4. Buildings: 1\n5. Kite String: 1\n6. Kite String Ties: 1\n7. Kite String Ties: 1\n8. Kite String Ties: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14058.7, "ram_available_mb": 48782.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14058.7, "ram_available_mb": 48782.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.891}, "power_stats": {"power_gpu_soc_mean_watts": 17.613, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 68.891}, "timestamp": "2026-01-30T13:39:58.473673"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6518.982, "latencies_ms": [6518.982], "images_per_second": 0.153, "prompt_tokens": 1117, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The kites are positioned in the foreground, with the largest and most prominent one being in the center. The kites are arranged in a semi-circle formation, with the largest one at the front and the smaller ones behind it. The kites are flying at varying heights, with the largest one being at the highest point and the smaller ones at lower levels.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.7, "ram_available_mb": 48782.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14058.7, "ram_available_mb": 48782.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.611}, "power_stats": {"power_gpu_soc_mean_watts": 17.488, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.906, "gpu_utilization_percent_mean": 69.611}, "timestamp": "2026-01-30T13:40:07.013750"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3855.858, "latencies_ms": [3855.858], "images_per_second": 0.259, "prompt_tokens": 1111, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A large group of people are gathered in a park to fly kites. The kites are shaped like fish and are flying high in the sky.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14058.7, "ram_available_mb": 48782.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.718, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 73.156}, "timestamp": "2026-01-30T13:40:12.904908"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3123.79, "latencies_ms": [3123.79], "images_per_second": 0.32, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The sky is overcast, and the kite is red, orange, and black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14058.5, "ram_available_mb": 48782.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.171, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 79.385}, "timestamp": "2026-01-30T13:40:18.063880"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3188.193, "latencies_ms": [3188.193], "images_per_second": 0.314, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a blue jacket is giving a slice of pizza to a young boy with curly hair.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14058.5, "ram_available_mb": 48782.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14058.4, "ram_available_mb": 48782.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.308}, "power_stats": {"power_gpu_soc_mean_watts": 23.724, "power_cpu_cv_mean_watts": 1.062, "power_sys_5v0_mean_watts": 8.241, "gpu_utilization_percent_mean": 75.308}, "timestamp": "2026-01-30T13:40:23.293122"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5438.288, "latencies_ms": [5438.288], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. boy: 1\n3. pizza: 1\n4. box: 1\n5. blanket: 1\n6. chair: 1\n7. window: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.4, "ram_available_mb": 48782.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14056.3, "ram_available_mb": 48784.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.111}, "power_stats": {"power_gpu_soc_mean_watts": 18.851, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 67.111}, "timestamp": "2026-01-30T13:40:30.750206"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4644.586, "latencies_ms": [4644.586], "images_per_second": 0.215, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, while the child is on the right side. The pizza is in the middle of the image, and the man is holding it with his right hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.3, "ram_available_mb": 48784.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14056.8, "ram_available_mb": 48784.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.667}, "power_stats": {"power_gpu_soc_mean_watts": 19.769, "power_cpu_cv_mean_watts": 1.467, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T13:40:37.434669"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3318.46, "latencies_ms": [3318.46], "images_per_second": 0.301, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man and a child are sitting on the floor in a living room, sharing a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14056.8, "ram_available_mb": 48784.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14057.5, "ram_available_mb": 48783.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.111}, "power_stats": {"power_gpu_soc_mean_watts": 23.219, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 74.111}, "timestamp": "2026-01-30T13:40:42.789742"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5156.135, "latencies_ms": [5156.135], "images_per_second": 0.194, "prompt_tokens": 1109, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image is taken in a room with a warm and cozy atmosphere, with the man and the boy sitting on a red and white checkered blanket. The lighting is natural, coming from a window in the background, and the colors are vibrant and inviting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14057.5, "ram_available_mb": 48783.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14058.0, "ram_available_mb": 48782.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.068}, "power_stats": {"power_gpu_soc_mean_watts": 19.099, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.068}, "timestamp": "2026-01-30T13:40:49.985715"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3033.347, "latencies_ms": [3033.347], "images_per_second": 0.33, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman wearing a striped shirt is eating a hot dog while sitting in a chair.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 14058.0, "ram_available_mb": 48782.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14057.7, "ram_available_mb": 48783.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.988, "power_cpu_cv_mean_watts": 0.928, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 77.56}, "timestamp": "2026-01-30T13:40:55.082562"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5646.242, "latencies_ms": [5646.242], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. chair: 1\n3. plate: 1\n4. food: 1\n5. bag: 1\n6. chair leg: 1\n7. ground: 1\n8. rock: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14057.7, "ram_available_mb": 48783.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.312}, "power_stats": {"power_gpu_soc_mean_watts": 17.833, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.91, "gpu_utilization_percent_mean": 69.312}, "timestamp": "2026-01-30T13:41:02.753845"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5248.631, "latencies_ms": [5248.631], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The person is sitting on the left side of the image, with the plate of food placed in front of them on the right side. The plate of food is positioned closer to the camera than the person, and the person is eating the food while sitting on the chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.568}, "power_stats": {"power_gpu_soc_mean_watts": 19.098, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 69.568}, "timestamp": "2026-01-30T13:41:10.049948"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2880.418, "latencies_ms": [2880.418], "images_per_second": 0.347, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A woman is sitting in a chair and eating a sandwich while camping.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14058.9, "ram_available_mb": 48782.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.208}, "power_stats": {"power_gpu_soc_mean_watts": 24.119, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 77.208}, "timestamp": "2026-01-30T13:41:14.970605"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4059.103, "latencies_ms": [4059.103], "images_per_second": 0.246, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken at night, with the subject illuminated by a flashlight. The subject is wearing a green and white striped shirt and is seated on a blue camping chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.9, "ram_available_mb": 48782.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.971}, "power_stats": {"power_gpu_soc_mean_watts": 21.088, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 72.971}, "timestamp": "2026-01-30T13:41:21.070447"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3204.743, "latencies_ms": [3204.743], "images_per_second": 0.312, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A family of 12 is gathered around a long dining table, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14058.6, "ram_available_mb": 48782.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14058.0, "ram_available_mb": 48782.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.283, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 75.731}, "timestamp": "2026-01-30T13:41:26.303307"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4463.719, "latencies_ms": [4463.719], "images_per_second": 0.224, "prompt_tokens": 1113, "response_tokens_est": 40, "n_tiles": 1, "output_text": " tablecloth: 1, plates: 10, cups: 10, glasses: 10, food: 10, chairs: 4, people: 14", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14058.0, "ram_available_mb": 48782.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14058.4, "ram_available_mb": 48782.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.473, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.676}, "timestamp": "2026-01-30T13:41:32.806661"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5786.291, "latencies_ms": [5786.291], "images_per_second": 0.173, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the table is in the foreground, with the people sitting around it. The people are positioned in the middle of the image, with the table being the central focus. The background includes a doorway and a painting on the wall, which are relatively far from the camera.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14058.4, "ram_available_mb": 48782.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14058.2, "ram_available_mb": 48782.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.625}, "power_stats": {"power_gpu_soc_mean_watts": 18.358, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 69.625}, "timestamp": "2026-01-30T13:41:40.606851"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3234.768, "latencies_ms": [3234.768], "images_per_second": 0.309, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered around a long table in a dining room, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14058.2, "ram_available_mb": 48782.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14057.2, "ram_available_mb": 48783.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.231}, "power_stats": {"power_gpu_soc_mean_watts": 23.559, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.202, "gpu_utilization_percent_mean": 75.231}, "timestamp": "2026-01-30T13:41:45.863426"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4281.843, "latencies_ms": [4281.843], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is well-lit with natural light coming from the windows, and the colors are vibrant and warm. The tablecloth is purple, and the food is colorful and appetizing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14057.2, "ram_available_mb": 48783.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14057.5, "ram_available_mb": 48783.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.596, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-30T13:41:52.193025"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3866.966, "latencies_ms": [3866.966], "images_per_second": 0.259, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A baseball game is taking place with players on the field, including a player sliding into a base, and a catcher and umpire standing nearby.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14057.5, "ram_available_mb": 48783.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14056.9, "ram_available_mb": 48784.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.845, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 8.144, "gpu_utilization_percent_mean": 71.031}, "timestamp": "2026-01-30T13:41:58.107832"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5707.487, "latencies_ms": [5707.487], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. baseball player: 2\n2. catcher: 1\n3. umpire: 1\n4. batter: 1\n5. field: 1\n6. fence: 1\n7. bench: 1\n8. spectators: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.9, "ram_available_mb": 48784.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14056.8, "ram_available_mb": 48784.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.417}, "power_stats": {"power_gpu_soc_mean_watts": 18.216, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 7.936, "gpu_utilization_percent_mean": 70.417}, "timestamp": "2026-01-30T13:42:05.862620"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4420.202, "latencies_ms": [4420.202], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The baseball player is in the foreground, sliding into the base. The catcher is in the background, behind the batter. The umpire is also in the background, behind the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.8, "ram_available_mb": 48784.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14057.1, "ram_available_mb": 48783.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.639}, "power_stats": {"power_gpu_soc_mean_watts": 20.817, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 72.639}, "timestamp": "2026-01-30T13:42:12.316163"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3659.877, "latencies_ms": [3659.877], "images_per_second": 0.273, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A baseball game is taking place on a field with a fence in the background, and a group of people are watching the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.9, "ram_available_mb": 48784.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14056.6, "ram_available_mb": 48784.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.6}, "power_stats": {"power_gpu_soc_mean_watts": 22.007, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 73.6}, "timestamp": "2026-01-30T13:42:18.019559"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3854.427, "latencies_ms": [3854.427], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with players in action on a field bathed in sunlight, and spectators watching from the stands.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.4, "ram_available_mb": 48785.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14055.6, "ram_available_mb": 48785.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.607, "power_cpu_cv_mean_watts": 1.238, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 73.125}, "timestamp": "2026-01-30T13:42:23.902224"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4096.154, "latencies_ms": [4096.154], "images_per_second": 0.244, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person wearing a black helmet and black clothing is skateboarding on a ramp, with their shadow visible on the ramp.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14055.6, "ram_available_mb": 48785.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14056.2, "ram_available_mb": 48784.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.206}, "power_stats": {"power_gpu_soc_mean_watts": 24.22, "power_cpu_cv_mean_watts": 1.095, "power_sys_5v0_mean_watts": 8.453, "gpu_utilization_percent_mean": 76.206}, "timestamp": "2026-01-30T13:42:30.046336"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6230.326, "latencies_ms": [6230.326], "images_per_second": 0.161, "prompt_tokens": 1446, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. knee pads: 2\n4. elbow pads: 1\n5. skateboard: 1\n6. rail: 1\n7. shadow: 1\n8. grass: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14056.2, "ram_available_mb": 48784.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14056.8, "ram_available_mb": 48784.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.558}, "power_stats": {"power_gpu_soc_mean_watts": 20.712, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 70.558}, "timestamp": "2026-01-30T13:42:38.295653"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5734.432, "latencies_ms": [5734.432], "images_per_second": 0.174, "prompt_tokens": 1450, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground, performing a trick on the ramp, while the background features a grassy area with trees and a fence. The shadow of the skateboarder is cast on the ramp, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14056.8, "ram_available_mb": 48784.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14056.7, "ram_available_mb": 48784.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.292}, "power_stats": {"power_gpu_soc_mean_watts": 21.328, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 8.271, "gpu_utilization_percent_mean": 71.292}, "timestamp": "2026-01-30T13:42:46.072826"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3697.456, "latencies_ms": [3697.456], "images_per_second": 0.27, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A skateboarder is performing a trick on a ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14056.7, "ram_available_mb": 48784.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14056.1, "ram_available_mb": 48784.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.4}, "power_stats": {"power_gpu_soc_mean_watts": 25.344, "power_cpu_cv_mean_watts": 0.854, "power_sys_5v0_mean_watts": 8.502, "gpu_utilization_percent_mean": 79.4}, "timestamp": "2026-01-30T13:42:51.806560"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5331.669, "latencies_ms": [5331.669], "images_per_second": 0.188, "prompt_tokens": 1442, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a skateboarder in action, wearing a black helmet and protective gear, with a concrete ramp in the background. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.1, "ram_available_mb": 48784.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14056.0, "ram_available_mb": 48784.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.178}, "power_stats": {"power_gpu_soc_mean_watts": 21.959, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.286, "gpu_utilization_percent_mean": 70.178}, "timestamp": "2026-01-30T13:42:59.197778"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4259.372, "latencies_ms": [4259.372], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image displays a dining table with a variety of food items, including a plate of fries, a sandwich, a salad, and a drink, all arranged neatly on white plates.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14056.0, "ram_available_mb": 48784.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14056.2, "ram_available_mb": 48784.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.2}, "power_stats": {"power_gpu_soc_mean_watts": 20.591, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-30T13:43:05.504452"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5566.071, "latencies_ms": [5566.071], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. plate: 2\n2. fries: 1\n3. burger: 1\n4. tomato: 1\n5. lettuce: 1\n6. pickles: 1\n7. condiment: 1\n8. glass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.2, "ram_available_mb": 48784.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14055.8, "ram_available_mb": 48785.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.872}, "power_stats": {"power_gpu_soc_mean_watts": 18.477, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 67.872}, "timestamp": "2026-01-30T13:43:13.119349"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5432.059, "latencies_ms": [5432.059], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The plate of fries is located to the left of the plate with the sandwich, and the plate with the salad is positioned in the background. The sandwich is situated in the middle of the table, with the fries and salad plates placed to the left and right of it, respectively.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14055.8, "ram_available_mb": 48785.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14055.5, "ram_available_mb": 48785.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.533}, "power_stats": {"power_gpu_soc_mean_watts": 18.907, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 68.533}, "timestamp": "2026-01-30T13:43:20.565680"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2939.697, "latencies_ms": [2939.697], "images_per_second": 0.34, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A meal is set on a table with a drink and condiments.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14055.5, "ram_available_mb": 48785.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.083}, "power_stats": {"power_gpu_soc_mean_watts": 23.954, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 75.083}, "timestamp": "2026-01-30T13:43:25.555069"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6304.451, "latencies_ms": [6304.451], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image features a white plate with a variety of food items, including a sandwich, fries, and a salad. The food is arranged on a table with a white tablecloth, and there are several condiments placed on the table. The lighting in the image is bright and even, and the colors of the food items are vibrant and appetizing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14054.3, "ram_available_mb": 48786.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.491}, "power_stats": {"power_gpu_soc_mean_watts": 17.737, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.925, "gpu_utilization_percent_mean": 68.491}, "timestamp": "2026-01-30T13:43:33.873361"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2983.302, "latencies_ms": [2983.302], "images_per_second": 0.335, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red motorcycle is parked on a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14054.3, "ram_available_mb": 48786.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.167}, "power_stats": {"power_gpu_soc_mean_watts": 24.12, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 76.167}, "timestamp": "2026-01-30T13:43:38.904397"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6057.16, "latencies_ms": [6057.16], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. Motorcycle: 1\n2. Tires: 2\n3. Seat: 1\n4. Handlebars: 1\n5. Windshield: 1\n6. Rear fender: 1\n7. Front fender: 1\n8. Chain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.725}, "power_stats": {"power_gpu_soc_mean_watts": 17.983, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 68.725}, "timestamp": "2026-01-30T13:43:46.986426"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4413.816, "latencies_ms": [4413.816], "images_per_second": 0.227, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the beach and palm trees in the background. The motorcycle is in the foreground, with the beach and palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.528}, "power_stats": {"power_gpu_soc_mean_watts": 20.54, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.528}, "timestamp": "2026-01-30T13:43:53.429548"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3009.587, "latencies_ms": [3009.587], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red motorcycle is parked on a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14055.7, "ram_available_mb": 48785.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.022, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 78.75}, "timestamp": "2026-01-30T13:43:58.453483"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2804.23, "latencies_ms": [2804.23], "images_per_second": 0.357, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The motorcycle is red and black, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14055.7, "ram_available_mb": 48785.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.13}, "power_stats": {"power_gpu_soc_mean_watts": 24.51, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 78.13}, "timestamp": "2026-01-30T13:44:03.274151"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3221.16, "latencies_ms": [3221.16], "images_per_second": 0.31, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a suit and tie is standing in front of a dark wall with a white switch.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.42, "power_cpu_cv_mean_watts": 1.031, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 73.808}, "timestamp": "2026-01-30T13:44:08.529403"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5440.417, "latencies_ms": [5440.417], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. suit: 1\n3. tie: 1\n4. shirt: 1\n5. wall: 1\n6. light switch: 1\n7. door: 1\n8. floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.578}, "power_stats": {"power_gpu_soc_mean_watts": 18.923, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 67.578}, "timestamp": "2026-01-30T13:44:15.991309"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4017.189, "latencies_ms": [4017.189], "images_per_second": 0.249, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The man is positioned to the left of the wall, with the wall being the background. The man is in the foreground, with the wall being the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.304, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 72.667}, "timestamp": "2026-01-30T13:44:22.030998"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2967.338, "latencies_ms": [2967.338], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A man in a suit and tie is standing in front of a wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.699, "power_cpu_cv_mean_watts": 0.928, "power_sys_5v0_mean_watts": 8.196, "gpu_utilization_percent_mean": 78.52}, "timestamp": "2026-01-30T13:44:27.053292"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3800.682, "latencies_ms": [3800.682], "images_per_second": 0.263, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The man is wearing a black suit with a white shirt and a black tie. The lighting is dim and the man's face is not visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14053.9, "ram_available_mb": 48787.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.188}, "power_stats": {"power_gpu_soc_mean_watts": 21.631, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 70.188}, "timestamp": "2026-01-30T13:44:32.881582"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3236.984, "latencies_ms": [3236.984], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A cat is sleeping on a pair of shoes, with its head resting on one of the shoes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14053.9, "ram_available_mb": 48787.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14054.1, "ram_available_mb": 48786.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.444}, "power_stats": {"power_gpu_soc_mean_watts": 23.132, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.168, "gpu_utilization_percent_mean": 74.444}, "timestamp": "2026-01-30T13:44:38.155799"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5749.477, "latencies_ms": [5749.477], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Cat: 1\n2. Sneakers: 2\n3. Wall: 1\n4. Floor: 1\n5. Shoe: 1\n6. Laces: 1\n7. Nose: 1\n8. Paw: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14054.1, "ram_available_mb": 48786.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.729}, "power_stats": {"power_gpu_soc_mean_watts": 18.31, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.938, "gpu_utilization_percent_mean": 69.729}, "timestamp": "2026-01-30T13:44:45.922779"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4298.92, "latencies_ms": [4298.92], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The cat is sleeping on the left side of the shoe, which is on the right side of the image. The cat is in the foreground, while the shoe is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.762, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 68.286}, "timestamp": "2026-01-30T13:44:52.240089"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2658.469, "latencies_ms": [2658.469], "images_per_second": 0.376, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A cat is sleeping on a pair of shoes.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.818}, "power_stats": {"power_gpu_soc_mean_watts": 24.475, "power_cpu_cv_mean_watts": 0.782, "power_sys_5v0_mean_watts": 8.24, "gpu_utilization_percent_mean": 78.818}, "timestamp": "2026-01-30T13:44:56.926334"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3236.49, "latencies_ms": [3236.49], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The cat is brown and white, the shoes are white and blue, and the wall is white.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.63}, "power_stats": {"power_gpu_soc_mean_watts": 23.22, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.208, "gpu_utilization_percent_mean": 76.63}, "timestamp": "2026-01-30T13:45:02.193314"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4143.533, "latencies_ms": [4143.533], "images_per_second": 0.241, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A green Isuzu truck with a red and white striped front is parked on the side of the road, with two workers in green uniforms standing on the back of the truck.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.4}, "power_stats": {"power_gpu_soc_mean_watts": 21.094, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 72.4}, "timestamp": "2026-01-30T13:45:08.383219"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5940.152, "latencies_ms": [5940.152], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. truck: 1\n2. people: 2\n3. building: 1\n4. license plate: 1\n5. truck's front: 1\n6. truck's side: 1\n7. truck's back: 1\n8. truck's rear: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.86}, "power_stats": {"power_gpu_soc_mean_watts": 18.17, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 67.86}, "timestamp": "2026-01-30T13:45:16.367375"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4622.987, "latencies_ms": [4622.987], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The green truck is in the foreground, parked on the street. The two men are sitting on the back of the truck, which is parked on the street. The building in the background is far away from the truck.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.316}, "power_stats": {"power_gpu_soc_mean_watts": 20.378, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 71.316}, "timestamp": "2026-01-30T13:45:23.028460"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3082.61, "latencies_ms": [3082.61], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A green truck with a white logo on the front is driving down a street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.557, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.188, "gpu_utilization_percent_mean": 75.36}, "timestamp": "2026-01-30T13:45:28.160452"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2833.975, "latencies_ms": [2833.975], "images_per_second": 0.353, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The truck is green and white, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.174}, "power_stats": {"power_gpu_soc_mean_watts": 24.264, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.233, "gpu_utilization_percent_mean": 79.174}, "timestamp": "2026-01-30T13:45:33.020815"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3184.412, "latencies_ms": [3184.412], "images_per_second": 0.314, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A person is standing on a rocky riverbank, with a bridge and greenery in the background.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.374, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.186, "gpu_utilization_percent_mean": 76.731}, "timestamp": "2026-01-30T13:45:38.267001"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5459.127, "latencies_ms": [5459.127], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. rocks: 20\n3. water: 1\n4. bridge: 1\n5. trees: 1\n6. bushes: 1\n7. grass: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14052.3, "ram_available_mb": 48788.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.721, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 68.957}, "timestamp": "2026-01-30T13:45:45.787335"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4098.13, "latencies_ms": [4098.13], "images_per_second": 0.244, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The person is standing on the left side of the river, with the bridge and greenery in the background. The person is closer to the camera than the bridge and greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14052.3, "ram_available_mb": 48788.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14052.3, "ram_available_mb": 48788.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.559}, "power_stats": {"power_gpu_soc_mean_watts": 21.163, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.102, "gpu_utilization_percent_mean": 71.559}, "timestamp": "2026-01-30T13:45:51.915784"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4011.165, "latencies_ms": [4011.165], "images_per_second": 0.249, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A person is standing on a rocky riverbank, looking at the water. The river is flowing over the rocks, and there is a bridge in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14052.3, "ram_available_mb": 48788.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14051.8, "ram_available_mb": 48789.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.232, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 72.182}, "timestamp": "2026-01-30T13:45:57.956382"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3867.845, "latencies_ms": [3867.845], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image features a river with a person standing on the rocks, the water is clear and blue, and the sky is clear with a few clouds.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14051.8, "ram_available_mb": 48789.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14052.4, "ram_available_mb": 48788.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.25}, "power_stats": {"power_gpu_soc_mean_watts": 21.618, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 69.25}, "timestamp": "2026-01-30T13:46:03.862889"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5831.291, "latencies_ms": [5831.291], "images_per_second": 0.171, "prompt_tokens": 1099, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a bustling street scene in Paris, France, where a row of parked scooters lines the sidewalk in front of a row of shops, including a green-roofed newsstand and a red-roofed barber shop, with a prominent advertisement for \"PARIS\" in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14052.4, "ram_available_mb": 48788.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.204}, "power_stats": {"power_gpu_soc_mean_watts": 18.236, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 68.204}, "timestamp": "2026-01-30T13:46:11.735423"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5795.755, "latencies_ms": [5795.755], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Motorcycles: 12\n2. People: 4\n3. Street: 1\n4. Building: 1\n5. Sign: 1\n6. Awning: 1\n7. Streetlight: 1\n8. Poster: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.542}, "power_stats": {"power_gpu_soc_mean_watts": 18.383, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 68.542}, "timestamp": "2026-01-30T13:46:19.543281"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5892.487, "latencies_ms": [5892.487], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The motorcycles are parked on the street, with the closest ones being in the foreground and the farthest ones being in the background. The buildings are on the right side of the street, with the closest one being the one with the red awning and the farthest one being the one with the green awning.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14052.8, "ram_available_mb": 48788.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.38}, "power_stats": {"power_gpu_soc_mean_watts": 18.032, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 69.38}, "timestamp": "2026-01-30T13:46:27.491890"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7323.626, "latencies_ms": [7323.626], "images_per_second": 0.137, "prompt_tokens": 1111, "response_tokens_est": 85, "n_tiles": 1, "output_text": " The image captures a bustling street scene in Paris, France, where a row of parked scooters lines the sidewalk in front of a row of shops. The scooters, mostly black and silver, are parked neatly in front of a variety of shops, including a barber shop and a pharmacy. The buildings are adorned with ornate details, and the street is lined with trees, adding a touch of greenery to the urban setting.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14052.8, "ram_available_mb": 48788.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.032}, "power_stats": {"power_gpu_soc_mean_watts": 16.612, "power_cpu_cv_mean_watts": 1.804, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 68.032}, "timestamp": "2026-01-30T13:46:36.842629"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5860.52, "latencies_ms": [5860.52], "images_per_second": 0.171, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a vibrant scene on a sunny day, with the motorbikes parked in front of the building bathed in the warm glow of the sunlight. The motorbikes, in their various shades of black and silver, stand out against the backdrop of the building's red awning and green roof.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.171, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T13:46:44.716329"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3041.039, "latencies_ms": [3041.039], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is holding a piece of broccoli with a small brown seed on it.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14051.4, "ram_available_mb": 48789.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.411, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.195, "gpu_utilization_percent_mean": 77.08}, "timestamp": "2026-01-30T13:46:49.792094"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2256.815, "latencies_ms": [2256.815], "images_per_second": 0.443, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " broccoli: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14051.4, "ram_available_mb": 48789.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 14050.6, "ram_available_mb": 48790.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.611}, "power_stats": {"power_gpu_soc_mean_watts": 25.439, "power_cpu_cv_mean_watts": 0.6, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 87.611}, "timestamp": "2026-01-30T13:46:54.071860"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3694.056, "latencies_ms": [3694.056], "images_per_second": 0.271, "prompt_tokens": 1117, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The broccoli is in the foreground, with the hand holding it. The broccoli is in front of the stove, which is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14050.6, "ram_available_mb": 48790.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.323}, "power_stats": {"power_gpu_soc_mean_watts": 22.16, "power_cpu_cv_mean_watts": 1.265, "power_sys_5v0_mean_watts": 8.163, "gpu_utilization_percent_mean": 72.323}, "timestamp": "2026-01-30T13:46:59.793400"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2948.879, "latencies_ms": [2948.879], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is holding a piece of broccoli with a small brown seed on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14052.1, "ram_available_mb": 48788.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.667}, "power_stats": {"power_gpu_soc_mean_watts": 24.368, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.294, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T13:47:04.763559"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2711.854, "latencies_ms": [2711.854], "images_per_second": 0.369, "prompt_tokens": 1109, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The broccoli is green and the person's hand is pink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14052.1, "ram_available_mb": 48788.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14052.9, "ram_available_mb": 48788.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.364}, "power_stats": {"power_gpu_soc_mean_watts": 25.073, "power_cpu_cv_mean_watts": 0.764, "power_sys_5v0_mean_watts": 8.309, "gpu_utilization_percent_mean": 80.364}, "timestamp": "2026-01-30T13:47:09.508832"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3978.099, "latencies_ms": [3978.099], "images_per_second": 0.251, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " Two people are standing close to each other, one of them is wearing a black jacket with a fur hood, and they are both looking up with their mouths open.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14052.9, "ram_available_mb": 48788.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.606}, "power_stats": {"power_gpu_soc_mean_watts": 21.531, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 72.606}, "timestamp": "2026-01-30T13:47:15.544652"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5361.638, "latencies_ms": [5361.638], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. jacket: 2\n3. hood: 1\n4. hat: 1\n5. person: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14051.3, "ram_available_mb": 48789.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.889}, "power_stats": {"power_gpu_soc_mean_watts": 19.037, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 69.889}, "timestamp": "2026-01-30T13:47:22.920589"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5420.917, "latencies_ms": [5420.917], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The person on the left is closer to the camera than the person on the right. The person on the right is in the background, while the person on the left is in the foreground. The person on the left is also closer to the camera than the person on the right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14051.3, "ram_available_mb": 48789.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14051.2, "ram_available_mb": 48789.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.556}, "power_stats": {"power_gpu_soc_mean_watts": 18.853, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 69.556}, "timestamp": "2026-01-30T13:47:30.353314"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3034.201, "latencies_ms": [3034.201], "images_per_second": 0.33, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " Two people are standing close together in a room with a window in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14051.2, "ram_available_mb": 48789.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14051.7, "ram_available_mb": 48789.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.604, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 70.84}, "timestamp": "2026-01-30T13:47:35.443572"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3378.586, "latencies_ms": [3378.586], "images_per_second": 0.296, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is taken in a dimly lit environment with a yellowish hue, and the subjects are wearing winter clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.7, "ram_available_mb": 48789.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14051.6, "ram_available_mb": 48789.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.857}, "power_stats": {"power_gpu_soc_mean_watts": 23.191, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 73.857}, "timestamp": "2026-01-30T13:47:40.860067"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2938.04, "latencies_ms": [2938.04], "images_per_second": 0.34, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man with long hair is playing tennis on a blue court with white lines.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14051.6, "ram_available_mb": 48789.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.333}, "power_stats": {"power_gpu_soc_mean_watts": 24.62, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.306, "gpu_utilization_percent_mean": 80.333}, "timestamp": "2026-01-30T13:47:45.830710"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5796.773, "latencies_ms": [5796.773], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. chair: 1\n5. tennis court: 1\n6. white chair: 1\n7. white wall: 1\n8. green fence: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14050.8, "ram_available_mb": 48790.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.959}, "power_stats": {"power_gpu_soc_mean_watts": 18.337, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 68.959}, "timestamp": "2026-01-30T13:47:53.675123"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4677.326, "latencies_ms": [4677.326], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball in the center and the chairs on the right side. The player is closer to the camera than the chairs, which are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14050.8, "ram_available_mb": 48790.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14049.6, "ram_available_mb": 48791.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 19.977, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 8.101, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-30T13:48:00.397784"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2968.364, "latencies_ms": [2968.364], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man with long hair is playing tennis on a blue court with white lines.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14049.6, "ram_available_mb": 48791.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14050.1, "ram_available_mb": 48790.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.792}, "power_stats": {"power_gpu_soc_mean_watts": 24.305, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.267, "gpu_utilization_percent_mean": 75.792}, "timestamp": "2026-01-30T13:48:05.389753"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3082.695, "latencies_ms": [3082.695], "images_per_second": 0.324, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The tennis player is wearing a white shirt and black shorts, and the court is blue.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14050.1, "ram_available_mb": 48790.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.72}, "power_stats": {"power_gpu_soc_mean_watts": 24.082, "power_cpu_cv_mean_watts": 0.976, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 75.72}, "timestamp": "2026-01-30T13:48:10.493607"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2943.364, "latencies_ms": [2943.364], "images_per_second": 0.34, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A red glass vase with a white candle and string lights on a wooden shelf.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14050.1, "ram_available_mb": 48790.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.453, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.306, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T13:48:15.464812"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5548.851, "latencies_ms": [5548.851], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. candle: 1\n2. glass: 1\n3. vase: 1\n4. wooden frame: 1\n5. string lights: 1\n6. mirror: 1\n7. table: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14050.1, "ram_available_mb": 48790.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14054.6, "ram_available_mb": 48786.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.826}, "power_stats": {"power_gpu_soc_mean_watts": 18.539, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 68.826}, "timestamp": "2026-01-30T13:48:23.049005"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4233.243, "latencies_ms": [4233.243], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The candle is positioned to the left of the vase, which is placed in the center of the image. The vase is situated in the background, with the candle in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.6, "ram_available_mb": 48786.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.783, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 71.571}, "timestamp": "2026-01-30T13:48:29.317237"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3257.804, "latencies_ms": [3257.804], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A red glass vase with a white candle sits on a wooden shelf, surrounded by white string lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.077}, "power_stats": {"power_gpu_soc_mean_watts": 23.466, "power_cpu_cv_mean_watts": 1.108, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 76.077}, "timestamp": "2026-01-30T13:48:34.588298"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2640.376, "latencies_ms": [2640.376], "images_per_second": 0.379, "prompt_tokens": 1109, "response_tokens_est": 10, "n_tiles": 1, "output_text": " The vase is orange and the candle is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 14054.4, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.524}, "power_stats": {"power_gpu_soc_mean_watts": 24.821, "power_cpu_cv_mean_watts": 0.724, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 80.524}, "timestamp": "2026-01-30T13:48:39.255094"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3596.387, "latencies_ms": [3596.387], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a gray shirt is bending over in front of a camera, while another man in a green shirt stands behind him.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14052.9, "ram_available_mb": 48788.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14053.2, "ram_available_mb": 48787.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.7}, "power_stats": {"power_gpu_soc_mean_watts": 22.154, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 73.7}, "timestamp": "2026-01-30T13:48:44.888301"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5496.634, "latencies_ms": [5496.634], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 2\n2. suitcase: 1\n3. laptop: 1\n4. couch: 1\n5. jacket: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14053.2, "ram_available_mb": 48787.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14052.6, "ram_available_mb": 48788.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.652}, "power_stats": {"power_gpu_soc_mean_watts": 18.607, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 67.652}, "timestamp": "2026-01-30T13:48:52.431547"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5875.625, "latencies_ms": [5875.625], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The man in the gray shirt is standing in the foreground, bending over to look at the camera. The man in the green shirt is standing in the background, with a brown jacket hanging on a coat rack behind him. The silver suitcase is located on the floor near the man in the gray shirt.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14052.6, "ram_available_mb": 48788.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14052.1, "ram_available_mb": 48788.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.48}, "power_stats": {"power_gpu_soc_mean_watts": 18.013, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 7.898, "gpu_utilization_percent_mean": 70.48}, "timestamp": "2026-01-30T13:49:00.329889"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3765.11, "latencies_ms": [3765.11], "images_per_second": 0.266, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " Two men are in a room with a couch and a laptop. One man is holding a camera and the other is standing in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14052.1, "ram_available_mb": 48788.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.097}, "power_stats": {"power_gpu_soc_mean_watts": 21.953, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 8.137, "gpu_utilization_percent_mean": 71.097}, "timestamp": "2026-01-30T13:49:06.110282"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5287.223, "latencies_ms": [5287.223], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a man wearing a gray shirt and jeans, standing in a room with a brown couch and a silver suitcase nearby. The lighting in the room is bright, and the colors are warm, with the brown couch and the gray shirt of the man standing out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.356}, "power_stats": {"power_gpu_soc_mean_watts": 19.048, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 70.356}, "timestamp": "2026-01-30T13:49:13.425022"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3688.072, "latencies_ms": [3688.072], "images_per_second": 0.271, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman wearing a hat and a striped shirt is holding a cigarette in her hand.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.097}, "power_stats": {"power_gpu_soc_mean_watts": 24.873, "power_cpu_cv_mean_watts": 0.994, "power_sys_5v0_mean_watts": 8.513, "gpu_utilization_percent_mean": 79.097}, "timestamp": "2026-01-30T13:49:19.169566"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6076.719, "latencies_ms": [6076.719], "images_per_second": 0.165, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. hat: 1\n2. woman: 1\n3. cigarette: 1\n4. necklace: 1\n5. bracelet: 1\n6. necklace: 1\n7. necklace: 1\n8. necklace: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.588}, "power_stats": {"power_gpu_soc_mean_watts": 20.967, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 71.588}, "timestamp": "2026-01-30T13:49:27.260169"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4748.076, "latencies_ms": [4748.076], "images_per_second": 0.211, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The woman is in the foreground, wearing a hat and a striped shirt. The cigarette is in her hand, and she is smiling. The background is plain and white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14054.0, "ram_available_mb": 48786.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.99, "power_cpu_cv_mean_watts": 1.311, "power_sys_5v0_mean_watts": 8.349, "gpu_utilization_percent_mean": 73.1}, "timestamp": "2026-01-30T13:49:34.041316"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3635.314, "latencies_ms": [3635.314], "images_per_second": 0.275, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A woman wearing a hat and a striped shirt is holding a cigarette and smiling.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.967}, "power_stats": {"power_gpu_soc_mean_watts": 25.889, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.552, "gpu_utilization_percent_mean": 77.967}, "timestamp": "2026-01-30T13:49:39.727092"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4174.696, "latencies_ms": [4174.696], "images_per_second": 0.24, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a black and white photograph with a high contrast, and the subject is wearing a hat and a striped shirt.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 24.364, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.448, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T13:49:45.940299"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3020.527, "latencies_ms": [3020.527], "images_per_second": 0.331, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two zebras are grazing in a grassy enclosure with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.44}, "power_stats": {"power_gpu_soc_mean_watts": 24.07, "power_cpu_cv_mean_watts": 1.009, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 76.44}, "timestamp": "2026-01-30T13:49:50.998312"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2311.848, "latencies_ms": [2311.848], "images_per_second": 0.433, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 14051.6, "ram_available_mb": 48789.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.158}, "power_stats": {"power_gpu_soc_mean_watts": 24.901, "power_cpu_cv_mean_watts": 0.611, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 89.158}, "timestamp": "2026-01-30T13:49:55.374129"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6542.163, "latencies_ms": [6542.163], "images_per_second": 0.153, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The zebra on the left is positioned slightly behind the one on the right, creating a sense of depth in the image. The foreground zebra is closer to the camera, while the background zebra is farther away, giving a sense of distance. The zebra on the right is positioned near the center of the image, while the one on the left is positioned more towards the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.6, "ram_available_mb": 48789.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14052.0, "ram_available_mb": 48788.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.357}, "power_stats": {"power_gpu_soc_mean_watts": 17.522, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.942, "gpu_utilization_percent_mean": 68.357}, "timestamp": "2026-01-30T13:50:03.948623"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3091.774, "latencies_ms": [3091.774], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two zebras are grazing in a grassy enclosure with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14052.0, "ram_available_mb": 48788.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14052.5, "ram_available_mb": 48788.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.635, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 76.36}, "timestamp": "2026-01-30T13:50:09.065459"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5253.287, "latencies_ms": [5253.287], "images_per_second": 0.19, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features two zebras grazing in a grassy enclosure with a rocky wall in the background. The zebras are black and white, with the grass being a vibrant green. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 14052.5, "ram_available_mb": 48788.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14052.4, "ram_available_mb": 48788.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.5}, "power_stats": {"power_gpu_soc_mean_watts": 18.933, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 67.5}, "timestamp": "2026-01-30T13:50:16.354383"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3154.354, "latencies_ms": [3154.354], "images_per_second": 0.317, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " An old, rusted fire hydrant with a chain on top is sitting on a sidewalk.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14052.4, "ram_available_mb": 48788.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.308}, "power_stats": {"power_gpu_soc_mean_watts": 23.573, "power_cpu_cv_mean_watts": 1.093, "power_sys_5v0_mean_watts": 8.241, "gpu_utilization_percent_mean": 74.308}, "timestamp": "2026-01-30T13:50:21.563979"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2917.558, "latencies_ms": [2917.558], "images_per_second": 0.343, "prompt_tokens": 1114, "response_tokens_est": 15, "n_tiles": 1, "output_text": " hydrant: 1\nchain: 2\nflowers: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14052.6, "ram_available_mb": 48788.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.042}, "power_stats": {"power_gpu_soc_mean_watts": 24.352, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 78.042}, "timestamp": "2026-01-30T13:50:26.538086"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4952.457, "latencies_ms": [4952.457], "images_per_second": 0.202, "prompt_tokens": 1118, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The fire hydrant is located in the foreground of the image, with a stone wall and a garden in the background. The fire hydrant is positioned to the left of the stone wall, and the garden is located behind the stone wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14052.6, "ram_available_mb": 48788.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14052.0, "ram_available_mb": 48788.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.78}, "power_stats": {"power_gpu_soc_mean_watts": 19.509, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 69.78}, "timestamp": "2026-01-30T13:50:33.532797"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2974.807, "latencies_ms": [2974.807], "images_per_second": 0.336, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A rusted fire hydrant sits on the ground next to a stone wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14052.0, "ram_available_mb": 48788.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14051.5, "ram_available_mb": 48789.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.95, "power_cpu_cv_mean_watts": 0.9, "power_sys_5v0_mean_watts": 8.252, "gpu_utilization_percent_mean": 74.417}, "timestamp": "2026-01-30T13:50:38.542818"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3027.17, "latencies_ms": [3027.17], "images_per_second": 0.33, "prompt_tokens": 1110, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The fire hydrant is rusted and dirty, with a chain attached to it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.5, "ram_available_mb": 48789.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14050.2, "ram_available_mb": 48790.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.84}, "power_stats": {"power_gpu_soc_mean_watts": 24.066, "power_cpu_cv_mean_watts": 0.96, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 76.84}, "timestamp": "2026-01-30T13:50:43.592789"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3951.599, "latencies_ms": [3951.599], "images_per_second": 0.253, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there are two brown bears walking on a road, one of them is a cub, and they are surrounded by a dry, grassy landscape.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14050.2, "ram_available_mb": 48790.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14051.4, "ram_available_mb": 48789.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.41, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 71.242}, "timestamp": "2026-01-30T13:50:49.601485"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5550.256, "latencies_ms": [5550.256], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bear: 2\n2. road: 1\n3. grass: 1\n4. dirt: 1\n5. road surface: 1\n6. bear: 1\n7. bear: 1\n8. bear: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14051.4, "ram_available_mb": 48789.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14050.4, "ram_available_mb": 48790.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.609}, "power_stats": {"power_gpu_soc_mean_watts": 18.561, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.944, "gpu_utilization_percent_mean": 71.609}, "timestamp": "2026-01-30T13:50:57.170673"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4770.308, "latencies_ms": [4770.308], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The brown bear in the foreground is walking towards the camera, while the brown bear in the background is walking away from the camera. The brown bear in the foreground is closer to the camera than the brown bear in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14050.4, "ram_available_mb": 48790.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14051.9, "ram_available_mb": 48789.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.897}, "power_stats": {"power_gpu_soc_mean_watts": 19.934, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 68.897}, "timestamp": "2026-01-30T13:51:03.957790"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3085.9, "latencies_ms": [3085.9], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two brown bears are walking on a dirt road, one of them is a cub.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.9, "ram_available_mb": 48789.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14051.3, "ram_available_mb": 48789.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.962}, "power_stats": {"power_gpu_soc_mean_watts": 23.436, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.174, "gpu_utilization_percent_mean": 78.962}, "timestamp": "2026-01-30T13:51:09.078296"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4874.442, "latencies_ms": [4874.442], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features two brown bears walking on a dirt road, with the larger bear in the foreground and the smaller bear in the background. The bears are surrounded by a dry, grassy landscape, and the lighting suggests it is daytime.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14051.3, "ram_available_mb": 48789.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.293}, "power_stats": {"power_gpu_soc_mean_watts": 19.46, "power_cpu_cv_mean_watts": 1.493, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 71.293}, "timestamp": "2026-01-30T13:51:15.969112"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3429.362, "latencies_ms": [3429.362], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young child with blonde hair is kneeling on the ground next to a metal bucket filled with dirt.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14050.1, "ram_available_mb": 48790.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.561, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 77.464}, "timestamp": "2026-01-30T13:51:21.444905"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5416.776, "latencies_ms": [5416.776], "images_per_second": 0.185, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. child: 1\n2. shirt: 1\n3. tie: 1\n4. pants: 1\n5. shoes: 1\n6. bucket: 1\n7. gravel: 1\n8. leaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14050.1, "ram_available_mb": 48790.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14051.5, "ram_available_mb": 48789.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.933}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 68.933}, "timestamp": "2026-01-30T13:51:28.876370"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4301.667, "latencies_ms": [4301.667], "images_per_second": 0.232, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The child is in the foreground, kneeling on the ground, and the bucket is in the middle ground. The child is looking at the bucket, and the bucket is on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.5, "ram_available_mb": 48789.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.556}, "power_stats": {"power_gpu_soc_mean_watts": 20.741, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 72.556}, "timestamp": "2026-01-30T13:51:35.214308"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3336.352, "latencies_ms": [3336.352], "images_per_second": 0.3, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A young child is playing in a dirt area with a bucket, wearing a white shirt and a colorful tie.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14054.8, "ram_available_mb": 48786.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.012, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 76.222}, "timestamp": "2026-01-30T13:51:40.585082"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3831.498, "latencies_ms": [3831.498], "images_per_second": 0.261, "prompt_tokens": 1110, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image is a black and white photo with a child wearing a white shirt and a colorful tie, and the child is kneeling on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.8, "ram_available_mb": 48786.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.755, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T13:51:46.458611"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4055.879, "latencies_ms": [4055.879], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A collection of stuffed animals, including a teddy bear, are placed on a makeshift bed, surrounded by various items such as bottles and flowers, in a barren, sandy landscape.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14054.6, "ram_available_mb": 48786.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14054.1, "ram_available_mb": 48786.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.412}, "power_stats": {"power_gpu_soc_mean_watts": 21.407, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 8.14, "gpu_utilization_percent_mean": 73.412}, "timestamp": "2026-01-30T13:51:52.557033"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3634.013, "latencies_ms": [3634.013], "images_per_second": 0.275, "prompt_tokens": 1113, "response_tokens_est": 26, "n_tiles": 1, "output_text": " teddy bear: 2\nbottle: 3\nflowers: 2\ntable: 1\nbed: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.1, "ram_available_mb": 48786.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.933}, "power_stats": {"power_gpu_soc_mean_watts": 22.046, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 73.933}, "timestamp": "2026-01-30T13:51:58.252166"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4675.155, "latencies_ms": [4675.155], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The teddy bear is positioned to the left of the table, which is situated in the foreground of the image. The table is located near the center of the image, with the teddy bear and other objects arranged around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.795}, "power_stats": {"power_gpu_soc_mean_watts": 20.047, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 69.795}, "timestamp": "2026-01-30T13:52:04.978238"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3742.253, "latencies_ms": [3742.253], "images_per_second": 0.267, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " In a barren, dry landscape, a makeshift bed is set up with a teddy bear and other stuffed animals, surrounded by bottles and flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14055.3, "ram_available_mb": 48785.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.097}, "power_stats": {"power_gpu_soc_mean_watts": 21.995, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 73.097}, "timestamp": "2026-01-30T13:52:10.746636"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5626.49, "latencies_ms": [5626.49], "images_per_second": 0.178, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a table with a red cross on it, surrounded by various items, including bottles and stuffed animals. The scene is set in a dry, sandy environment, with the ground covered in dirt and sparse vegetation. The lighting is natural, likely from the sun, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14055.3, "ram_available_mb": 48785.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14056.0, "ram_available_mb": 48784.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.106}, "power_stats": {"power_gpu_soc_mean_watts": 18.602, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 68.106}, "timestamp": "2026-01-30T13:52:18.419919"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 10033.705, "latencies_ms": [10033.705], "images_per_second": 0.1, "prompt_tokens": 1432, "response_tokens_est": 122, "n_tiles": 1, "output_text": " The image captures a serene harbor scene, where a green fishing boat named \"JAMIE\" is docked, surrounded by other boats and a bustling harbor filled with people and equipment. The boats are moored to a sturdy wooden pier, which is adorned with a variety of colorful buoys and life jackets, adding a vibrant touch to the otherwise tranquil setting. In the background, a picturesque landscape of rolling hills and lush greenery stretches out, providing a stark contrast to the industrial harbor scene. The sky overhead is overcast, casting a soft light over the entire scene and enhancing the overall mood of the image.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14056.0, "ram_available_mb": 48784.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.952}, "power_stats": {"power_gpu_soc_mean_watts": 17.138, "power_cpu_cv_mean_watts": 1.901, "power_sys_5v0_mean_watts": 8.088, "gpu_utilization_percent_mean": 68.952}, "timestamp": "2026-01-30T13:52:30.488168"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6061.664, "latencies_ms": [6061.664], "images_per_second": 0.165, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Boat: 3\n2. Boat: 2\n3. Boat: 1\n4. Boat: 1\n5. Boat: 1\n6. Boat: 1\n7. Boat: 1\n8. Boat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.902}, "power_stats": {"power_gpu_soc_mean_watts": 20.804, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.227, "gpu_utilization_percent_mean": 71.902}, "timestamp": "2026-01-30T13:52:38.571451"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5515.191, "latencies_ms": [5515.191], "images_per_second": 0.181, "prompt_tokens": 1450, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The main objects are located in the foreground, with the fishing boats and the dock being the closest to the viewer. The boats are positioned to the left of the dock, and the background features a calm body of water and distant hills.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.087}, "power_stats": {"power_gpu_soc_mean_watts": 21.739, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 8.28, "gpu_utilization_percent_mean": 72.087}, "timestamp": "2026-01-30T13:52:46.117785"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6273.511, "latencies_ms": [6273.511], "images_per_second": 0.159, "prompt_tokens": 1444, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a serene harbor scene where several fishing boats are docked at a pier. The boats, painted in hues of green and white, are adorned with various equipment and equipment, suggesting a bustling fishing operation. The harbor is nestled amidst lush green hills, providing a picturesque backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.585}, "power_stats": {"power_gpu_soc_mean_watts": 20.667, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 70.585}, "timestamp": "2026-01-30T13:52:54.415525"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5418.203, "latencies_ms": [5418.203], "images_per_second": 0.185, "prompt_tokens": 1442, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features a harbor with boats docked at the pier, the water is calm and the sky is cloudy. The boats are painted in various colors, including green, blue, and red, and are equipped with fishing equipment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14054.8, "ram_available_mb": 48786.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.826}, "power_stats": {"power_gpu_soc_mean_watts": 21.776, "power_cpu_cv_mean_watts": 1.436, "power_sys_5v0_mean_watts": 8.295, "gpu_utilization_percent_mean": 72.826}, "timestamp": "2026-01-30T13:53:01.875407"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2948.377, "latencies_ms": [2948.377], "images_per_second": 0.339, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman with a black scarf is eating a hot dog at night.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14054.8, "ram_available_mb": 48786.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.987, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T13:53:06.868897"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5449.104, "latencies_ms": [5449.104], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. hand: 1\n3. food: 1\n4. mouth: 1\n5. nose: 1\n6. eyes: 1\n7. hair: 1\n8. scarf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14053.9, "ram_available_mb": 48787.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.859, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-30T13:53:14.349019"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4118.032, "latencies_ms": [4118.032], "images_per_second": 0.243, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The woman is in the foreground, with the hot dog in her mouth, and the background is blurred, indicating that the focus is on the woman and the hot dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.9, "ram_available_mb": 48787.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.882}, "power_stats": {"power_gpu_soc_mean_watts": 21.17, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 69.882}, "timestamp": "2026-01-30T13:53:20.481031"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2599.166, "latencies_ms": [2599.166], "images_per_second": 0.385, "prompt_tokens": 1111, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A woman is eating a hot dog at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.2, "ram_available_mb": 48786.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.524}, "power_stats": {"power_gpu_soc_mean_watts": 25.277, "power_cpu_cv_mean_watts": 0.743, "power_sys_5v0_mean_watts": 8.343, "gpu_utilization_percent_mean": 79.524}, "timestamp": "2026-01-30T13:53:25.113257"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4439.375, "latencies_ms": [4439.375], "images_per_second": 0.225, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image is taken at night, with a warm yellow light illuminating the scene. The woman is wearing a black jacket and a scarf, and she is holding a hot dog in her mouth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14053.3, "ram_available_mb": 48787.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14053.7, "ram_available_mb": 48787.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.181, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 70.838}, "timestamp": "2026-01-30T13:53:31.614206"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3716.855, "latencies_ms": [3716.855], "images_per_second": 0.269, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man and a woman are standing in a room, the man is holding a glass of wine and the woman is wearing a dress.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14053.7, "ram_available_mb": 48787.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14056.1, "ram_available_mb": 48784.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.967, "power_cpu_cv_mean_watts": 1.134, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T13:53:37.369085"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5380.679, "latencies_ms": [5380.679], "images_per_second": 0.186, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. glass: 1\n4. curtain: 1\n5. door: 1\n6. wall: 1\n7. shelf: 1\n8. vase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.1, "ram_available_mb": 48784.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14056.6, "ram_available_mb": 48784.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.822}, "power_stats": {"power_gpu_soc_mean_watts": 18.961, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 70.822}, "timestamp": "2026-01-30T13:53:44.787531"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6846.841, "latencies_ms": [6846.841], "images_per_second": 0.146, "prompt_tokens": 1118, "response_tokens_est": 79, "n_tiles": 1, "output_text": " The man is standing to the right of the woman, and the woman is standing to the left of the man. The man is holding a glass of wine in his right hand, and the woman is holding a glass of wine in her left hand. The man is wearing a black suit with a white shirt and a black tie, and the woman is wearing a black dress with a long sleeve.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.6, "ram_available_mb": 48784.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.719}, "power_stats": {"power_gpu_soc_mean_watts": 17.244, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.903, "gpu_utilization_percent_mean": 69.719}, "timestamp": "2026-01-30T13:53:53.677935"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3642.796, "latencies_ms": [3642.796], "images_per_second": 0.275, "prompt_tokens": 1112, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man and a woman are standing in a room, the man is holding a glass of wine and the woman is looking at him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.633}, "power_stats": {"power_gpu_soc_mean_watts": 22.061, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.163, "gpu_utilization_percent_mean": 73.633}, "timestamp": "2026-01-30T13:53:59.371729"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4842.732, "latencies_ms": [4842.732], "images_per_second": 0.206, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a warm and cozy atmosphere. The man is wearing a black suit with a white shirt and a black tie, while the woman is dressed in a black dress with a long sleeve.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.425}, "power_stats": {"power_gpu_soc_mean_watts": 19.876, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 68.425}, "timestamp": "2026-01-30T13:54:06.242254"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 9618.902, "latencies_ms": [9618.902], "images_per_second": 0.104, "prompt_tokens": 1099, "response_tokens_est": 128, "n_tiles": 1, "output_text": " The image captures a scene of a vintage blue wooden cabinet, adorned with a variety of items, including a silver teapot, a silver vase, and several small metal cups, all arranged on its shelves. The cabinet, with its open door revealing its interior, stands against a backdrop of a white wall, adding a stark contrast to the blue hue of the cabinet. The items on the shelves are scattered, with some placed closer to the front and others further back, creating a sense of depth and dimension. The overall composition of the image suggests a sense of organized chaos, with each item having its own space yet contributing to the overall aesthetic", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.654}, "power_stats": {"power_gpu_soc_mean_watts": 15.682, "power_cpu_cv_mean_watts": 1.971, "power_sys_5v0_mean_watts": 7.891, "gpu_utilization_percent_mean": 66.654}, "timestamp": "2026-01-30T13:54:17.894792"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4608.302, "latencies_ms": [4608.302], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. silver teapot\n2. silver vase\n3. silver pitcher\n4. silver cup\n5. silver bowl\n6. silver spoon\n7. silver knife\n8. silver fork", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.015, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 72.789}, "timestamp": "2026-01-30T13:54:24.534502"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5658.173, "latencies_ms": [5658.173], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The blue cabinet is positioned in the foreground, with the green and white table to its right. The silver teapot is placed on the left side of the cabinet, while the silver vase is situated on the right side. The green and white table is located in the background, behind the cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.277}, "power_stats": {"power_gpu_soc_mean_watts": 18.646, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 69.277}, "timestamp": "2026-01-30T13:54:32.243734"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5800.788, "latencies_ms": [5800.788], "images_per_second": 0.172, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a scene of a vintage blue cabinet, adorned with various items, including a silver teapot, a vase, and several small containers. The cabinet is situated in a room with a concrete floor, and the items on it are arranged in a way that suggests a sense of order and organization.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.521}, "power_stats": {"power_gpu_soc_mean_watts": 18.399, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 69.521}, "timestamp": "2026-01-30T13:54:40.070963"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6277.77, "latencies_ms": [6277.77], "images_per_second": 0.159, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image depicts a blue wooden cabinet with a white top, situated in a room with a concrete floor. The cabinet is adorned with various items, including a silver teapot, a silver vase, and several small metal cups. The lighting in the room is natural, coming from a window out of frame, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14055.5, "ram_available_mb": 48785.4, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.755}, "power_stats": {"power_gpu_soc_mean_watts": 17.714, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 67.755}, "timestamp": "2026-01-30T13:54:48.362233"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2806.827, "latencies_ms": [2806.827], "images_per_second": 0.356, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A plate of bread with butter on it is on a table.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14055.5, "ram_available_mb": 48785.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14055.8, "ram_available_mb": 48785.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.609}, "power_stats": {"power_gpu_soc_mean_watts": 24.419, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 77.609}, "timestamp": "2026-01-30T13:54:53.200666"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4100.696, "latencies_ms": [4100.696], "images_per_second": 0.244, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bread: 6, butter: 6, plate: 1, remote: 1, keyboard: 1, jar: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14055.8, "ram_available_mb": 48785.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.529}, "power_stats": {"power_gpu_soc_mean_watts": 21.064, "power_cpu_cv_mean_watts": 1.283, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 71.529}, "timestamp": "2026-01-30T13:54:59.324108"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4281.895, "latencies_ms": [4281.895], "images_per_second": 0.234, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The plate of bread and butter is located in the foreground, with the keyboard and remote control in the background. The butter is spread on the bread slices, which are placed on the plate.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14055.0, "ram_available_mb": 48785.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14055.4, "ram_available_mb": 48785.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.314}, "power_stats": {"power_gpu_soc_mean_watts": 20.999, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 69.314}, "timestamp": "2026-01-30T13:55:05.625516"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3070.669, "latencies_ms": [3070.669], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A plate of cheese and bread is on a desk with a keyboard and a remote.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14055.4, "ram_available_mb": 48785.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14055.8, "ram_available_mb": 48785.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.96}, "power_stats": {"power_gpu_soc_mean_watts": 23.636, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.211, "gpu_utilization_percent_mean": 74.96}, "timestamp": "2026-01-30T13:55:10.734517"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4219.276, "latencies_ms": [4219.276], "images_per_second": 0.237, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a plate of bread with butter on it, placed on a table with a yellow background. The lighting is bright and natural, and the bread appears to be freshly made.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.8, "ram_available_mb": 48785.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14056.2, "ram_available_mb": 48784.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.571}, "power_stats": {"power_gpu_soc_mean_watts": 21.147, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 71.571}, "timestamp": "2026-01-30T13:55:16.985158"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4177.034, "latencies_ms": [4177.034], "images_per_second": 0.239, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man in a suit and tie is adjusting his tie, which has a pattern of red lights along the length of the tie.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.2, "ram_available_mb": 48784.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14056.7, "ram_available_mb": 48784.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.529}, "power_stats": {"power_gpu_soc_mean_watts": 24.277, "power_cpu_cv_mean_watts": 1.154, "power_sys_5v0_mean_watts": 8.48, "gpu_utilization_percent_mean": 76.529}, "timestamp": "2026-01-30T13:55:23.197298"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4773.18, "latencies_ms": [4773.18], "images_per_second": 0.21, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " tie: 1, glasses: 1, suit: 1, shirt: 1, tie clip: 1, tie: 1, man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14056.7, "ram_available_mb": 48784.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.513}, "power_stats": {"power_gpu_soc_mean_watts": 23.291, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 8.395, "gpu_utilization_percent_mean": 71.513}, "timestamp": "2026-01-30T13:55:29.998479"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6642.891, "latencies_ms": [6642.891], "images_per_second": 0.151, "prompt_tokens": 1450, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The man is positioned in the foreground of the image, with the tie being the central object. The tie is located in the middle ground, with the man's face and glasses being the closest objects to the camera. The background is a dark, neutral color, providing a contrast to the man's tie and making it stand out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14055.1, "ram_available_mb": 48785.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.327}, "power_stats": {"power_gpu_soc_mean_watts": 20.264, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 69.327}, "timestamp": "2026-01-30T13:55:38.668250"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3384.117, "latencies_ms": [3384.117], "images_per_second": 0.295, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A man in a suit and tie is adjusting his tie.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.036}, "power_stats": {"power_gpu_soc_mean_watts": 26.521, "power_cpu_cv_mean_watts": 0.815, "power_sys_5v0_mean_watts": 8.597, "gpu_utilization_percent_mean": 79.036}, "timestamp": "2026-01-30T13:55:44.074110"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4155.449, "latencies_ms": [4155.449], "images_per_second": 0.241, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The man is wearing a black suit and tie with red and green lights. The lighting is dim and the background is dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.7, "ram_available_mb": 48786.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.914}, "power_stats": {"power_gpu_soc_mean_watts": 24.465, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.458, "gpu_utilization_percent_mean": 76.914}, "timestamp": "2026-01-30T13:55:50.280794"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3422.417, "latencies_ms": [3422.417], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is walking across the street in front of a building with a sign that says \"TAFARINA\".", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14053.4, "ram_available_mb": 48787.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.571}, "power_stats": {"power_gpu_soc_mean_watts": 22.819, "power_cpu_cv_mean_watts": 1.043, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 72.571}, "timestamp": "2026-01-30T13:55:55.758464"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5818.616, "latencies_ms": [5818.616], "images_per_second": 0.172, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. person: 1\n2. traffic light: 1\n3. street light: 1\n4. building: 1\n5. sign: 1\n6. car: 1\n7. person's handbag: 1\n8. person's hand: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.184}, "power_stats": {"power_gpu_soc_mean_watts": 18.245, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 69.184}, "timestamp": "2026-01-30T13:56:03.591947"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4257.354, "latencies_ms": [4257.354], "images_per_second": 0.235, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The person is in the foreground, walking on the sidewalk, while the building is in the background. The traffic light is also in the background, and the street is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.971}, "power_stats": {"power_gpu_soc_mean_watts": 20.946, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 70.971}, "timestamp": "2026-01-30T13:56:09.862346"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3359.468, "latencies_ms": [3359.468], "images_per_second": 0.298, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is walking across the street in front of a building with a sign that says \"TAFARINA\".", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14054.9, "ram_available_mb": 48786.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14055.3, "ram_available_mb": 48785.6, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.82, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 75.464}, "timestamp": "2026-01-30T13:56:15.258275"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3984.152, "latencies_ms": [3984.152], "images_per_second": 0.251, "prompt_tokens": 1110, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken at night, with the sky being dark blue and the street being lit by streetlights. The building is white and has a curved facade.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14055.3, "ram_available_mb": 48785.6, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14055.2, "ram_available_mb": 48785.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.305, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 71.182}, "timestamp": "2026-01-30T13:56:21.292351"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5426.291, "latencies_ms": [5426.291], "images_per_second": 0.184, "prompt_tokens": 1099, "response_tokens_est": 56, "n_tiles": 1, "output_text": " In the image, a young girl is skillfully riding a wave on a blue surfboard, while a man in a black wetsuit and a woman in a black bikini are also enjoying the water, with a man in a red and black wetsuit swimming nearby.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14054.5, "ram_available_mb": 48786.4, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14054.8, "ram_available_mb": 48786.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.72, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T13:56:28.786285"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5599.734, "latencies_ms": [5599.734], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. girl: 1\n2. surfboard: 1\n3. wave: 1\n4. person: 1\n5. surfboard: 1\n6. person: 1\n7. surfboard: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14054.8, "ram_available_mb": 48786.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.52, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 69.957}, "timestamp": "2026-01-30T13:56:36.426100"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5217.758, "latencies_ms": [5217.758], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main object, a girl, is in the foreground, riding a wave on a blue surfboard. The wave is in the middle ground, while the other people are in the background, with one person on a surfboard and another on a paddleboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14054.4, "ram_available_mb": 48786.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14053.7, "ram_available_mb": 48787.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.136}, "power_stats": {"power_gpu_soc_mean_watts": 18.893, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 69.136}, "timestamp": "2026-01-30T13:56:43.691918"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4016.199, "latencies_ms": [4016.199], "images_per_second": 0.249, "prompt_tokens": 1111, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, a young girl is surfing on a blue surfboard in the ocean, while other people are swimming and paddling in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14053.7, "ram_available_mb": 48787.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.242}, "power_stats": {"power_gpu_soc_mean_watts": 20.722, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 69.242}, "timestamp": "2026-01-30T13:56:49.720652"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4987.87, "latencies_ms": [4987.87], "images_per_second": 0.2, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a young girl surfing on a blue surfboard in the ocean. The water is a deep blue, reflecting the clear sky above. The sunlight filters through the water, creating a shimmering effect on the waves.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14053.6, "ram_available_mb": 48787.3, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.048}, "power_stats": {"power_gpu_soc_mean_watts": 19.4, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 68.048}, "timestamp": "2026-01-30T13:56:56.732572"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3723.661, "latencies_ms": [3723.661], "images_per_second": 0.269, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a white shirt and beige pants is feeding an elephant with a stick in a fenced area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 14053.8, "ram_available_mb": 48787.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14052.0, "ram_available_mb": 48788.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.226}, "power_stats": {"power_gpu_soc_mean_watts": 22.097, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.144, "gpu_utilization_percent_mean": 72.226}, "timestamp": "2026-01-30T13:57:02.505484"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3433.81, "latencies_ms": [3433.81], "images_per_second": 0.291, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " elephant: 1, man: 1, fence: 1, tree: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14052.0, "ram_available_mb": 48788.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.393}, "power_stats": {"power_gpu_soc_mean_watts": 23.163, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 73.393}, "timestamp": "2026-01-30T13:57:07.956256"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5267.817, "latencies_ms": [5267.817], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, while the elephant is on the right side. The man is in the foreground, while the elephant is in the background. The man is holding the food out to the elephant, which is reaching out to take it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14052.2, "ram_available_mb": 48788.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14051.8, "ram_available_mb": 48789.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.682}, "power_stats": {"power_gpu_soc_mean_watts": 19.219, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 69.682}, "timestamp": "2026-01-30T13:57:15.277990"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3261.213, "latencies_ms": [3261.213], "images_per_second": 0.307, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a white shirt and beige pants is feeding an elephant in a fenced enclosure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.8, "ram_available_mb": 48789.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14051.7, "ram_available_mb": 48789.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.519}, "power_stats": {"power_gpu_soc_mean_watts": 23.012, "power_cpu_cv_mean_watts": 1.052, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 72.519}, "timestamp": "2026-01-30T13:57:20.569034"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3058.512, "latencies_ms": [3058.512], "images_per_second": 0.327, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephant is gray, the man is wearing white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14051.7, "ram_available_mb": 48789.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 23.827, "power_cpu_cv_mean_watts": 0.928, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T13:57:25.646106"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3284.297, "latencies_ms": [3284.297], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog sits on a bed covered in clothes and other items, with a box of tissues nearby.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 14050.9, "ram_available_mb": 48790.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14049.8, "ram_available_mb": 48791.1, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.259}, "power_stats": {"power_gpu_soc_mean_watts": 23.161, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 74.259}, "timestamp": "2026-01-30T13:57:30.980393"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4098.488, "latencies_ms": [4098.488], "images_per_second": 0.244, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " dog: 1, box: 1, clothes: 1, bag: 1, blanket: 1, pillow: 1, curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14049.8, "ram_available_mb": 48791.1, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.102, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T13:57:37.135595"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4864.435, "latencies_ms": [4864.435], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The dog is sitting on the bed, which is in the foreground of the image. The bed is covered with clothes and a box, which are in the middle of the image. The curtain is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.125}, "power_stats": {"power_gpu_soc_mean_watts": 19.648, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 73.125}, "timestamp": "2026-01-30T13:57:44.015028"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2992.068, "latencies_ms": [2992.068], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A brown dog sits on a bed with clothes and a box on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14049.7, "ram_available_mb": 48791.2, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14050.4, "ram_available_mb": 48790.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.583}, "power_stats": {"power_gpu_soc_mean_watts": 23.79, "power_cpu_cv_mean_watts": 0.967, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 80.583}, "timestamp": "2026-01-30T13:57:49.047368"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2937.199, "latencies_ms": [2937.199], "images_per_second": 0.34, "prompt_tokens": 1109, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The dog is brown and white, and the room is well-lit.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 14050.4, "ram_available_mb": 48790.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14050.4, "ram_available_mb": 48790.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.004, "power_cpu_cv_mean_watts": 0.817, "power_sys_5v0_mean_watts": 8.23, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T13:57:54.007698"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4339.122, "latencies_ms": [4339.122], "images_per_second": 0.23, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man wearing a blue tie and a white shirt is sitting at a desk with a laptop and a pen in his hand, and he is looking at the laptop screen with a thoughtful expression.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 14050.4, "ram_available_mb": 48790.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14048.2, "ram_available_mb": 48792.7, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.574, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 68.861}, "timestamp": "2026-01-30T13:58:00.401147"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4213.669, "latencies_ms": [4213.669], "images_per_second": 0.237, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " laptop: 1, pen: 1, paper: 1, glasses: 1, shirt: 1, tie: 1, man: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14048.2, "ram_available_mb": 48792.7, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14048.9, "ram_available_mb": 48792.0, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.571}, "power_stats": {"power_gpu_soc_mean_watts": 20.648, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.571}, "timestamp": "2026-01-30T13:58:06.638445"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6117.464, "latencies_ms": [6117.464], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man is seated at a desk with a laptop in front of him, which is to his left. The laptop is positioned in the foreground of the image, while the man is in the background. The man is also holding a pen in his right hand, which is near the laptop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14048.9, "ram_available_mb": 48792.0, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 20.8, "ram_used_mb": 14107.4, "ram_available_mb": 48733.5, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.462}, "power_stats": {"power_gpu_soc_mean_watts": 19.348, "power_cpu_cv_mean_watts": 3.442, "power_sys_5v0_mean_watts": 7.866, "gpu_utilization_percent_mean": 76.462}, "timestamp": "2026-01-30T13:58:14.788623"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4686.275, "latencies_ms": [4686.275], "images_per_second": 0.213, "prompt_tokens": 1111, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A man wearing a blue tie and a white shirt is sitting at a desk with a laptop and a pen in his hand. He is looking at the laptop screen with a thoughtful expression.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 14107.4, "ram_available_mb": 48733.5, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 14115.0, "ram_available_mb": 48725.9, "ram_percent": 22.5}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.282}, "power_stats": {"power_gpu_soc_mean_watts": 20.349, "power_cpu_cv_mean_watts": 2.32, "power_sys_5v0_mean_watts": 7.84, "gpu_utilization_percent_mean": 74.282}, "timestamp": "2026-01-30T13:58:21.527864"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3684.976, "latencies_ms": [3684.976], "images_per_second": 0.271, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The man is wearing a blue tie and a white shirt. The background is a light blue color.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 14115.0, "ram_available_mb": 48725.9, "ram_percent": 22.5}, "sys_after": {"cpu_percent": 9.8, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.333}, "power_stats": {"power_gpu_soc_mean_watts": 21.659, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.946, "gpu_utilization_percent_mean": 80.333}, "timestamp": "2026-01-30T13:58:27.243851"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3837.717, "latencies_ms": [3837.717], "images_per_second": 0.261, "prompt_tokens": 1432, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large airplane is flying in the sky with a moon in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14053.0, "ram_available_mb": 48787.9, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 14058.1, "ram_available_mb": 48782.8, "ram_percent": 22.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.188}, "power_stats": {"power_gpu_soc_mean_watts": 24.308, "power_cpu_cv_mean_watts": 1.238, "power_sys_5v0_mean_watts": 8.344, "gpu_utilization_percent_mean": 87.188}, "timestamp": "2026-01-30T13:58:33.125064"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2946.807, "latencies_ms": [2946.807], "images_per_second": 0.339, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " airplane: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14058.1, "ram_available_mb": 48782.8, "ram_percent": 22.4}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 89.458}, "power_stats": {"power_gpu_soc_mean_watts": 27.189, "power_cpu_cv_mean_watts": 0.767, "power_sys_5v0_mean_watts": 8.616, "gpu_utilization_percent_mean": 89.458}, "timestamp": "2026-01-30T13:58:38.101514"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5797.673, "latencies_ms": [5797.673], "images_per_second": 0.172, "prompt_tokens": 1450, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The airplane is in the background, flying high in the sky, while the moon is in the foreground, closer to the camera. The airplane is flying above the moon, and both celestial bodies are positioned in the same direction.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.312}, "power_stats": {"power_gpu_soc_mean_watts": 21.103, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 8.136, "gpu_utilization_percent_mean": 75.312}, "timestamp": "2026-01-30T13:58:45.934357"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3471.005, "latencies_ms": [3471.005], "images_per_second": 0.288, "prompt_tokens": 1444, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A large airplane is flying in the sky above a moon.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.75}, "power_stats": {"power_gpu_soc_mean_watts": 26.176, "power_cpu_cv_mean_watts": 0.815, "power_sys_5v0_mean_watts": 8.532, "gpu_utilization_percent_mean": 81.75}, "timestamp": "2026-01-30T13:58:51.417625"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3790.318, "latencies_ms": [3790.318], "images_per_second": 0.264, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The airplane is white with red and blue on the tail, and the moon is orange.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.903}, "power_stats": {"power_gpu_soc_mean_watts": 25.401, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.487, "gpu_utilization_percent_mean": 78.903}, "timestamp": "2026-01-30T13:58:57.243927"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4183.048, "latencies_ms": [4183.048], "images_per_second": 0.239, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young man wearing a tie-dye shirt and black pants is performing a trick on a skateboard in a skate park.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.971}, "power_stats": {"power_gpu_soc_mean_watts": 23.919, "power_cpu_cv_mean_watts": 1.178, "power_sys_5v0_mean_watts": 8.468, "gpu_utilization_percent_mean": 76.971}, "timestamp": "2026-01-30T13:59:03.468785"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6355.905, "latencies_ms": [6355.905], "images_per_second": 0.157, "prompt_tokens": 1446, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. palm tree: 2\n4. building: 1\n5. playground equipment: 1\n6. skateboard ramp: 1\n7. clouds: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.943}, "power_stats": {"power_gpu_soc_mean_watts": 20.613, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 69.943}, "timestamp": "2026-01-30T13:59:11.868386"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5251.714, "latencies_ms": [5251.714], "images_per_second": 0.19, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the air, while the skate park and palm trees are in the background. The skateboarder is closer to the camera than the palm trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13980.8, "ram_available_mb": 48860.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.159}, "power_stats": {"power_gpu_soc_mean_watts": 21.993, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 8.294, "gpu_utilization_percent_mean": 73.159}, "timestamp": "2026-01-30T13:59:19.146888"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3653.514, "latencies_ms": [3653.514], "images_per_second": 0.274, "prompt_tokens": 1444, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young man wearing a tie dye shirt is skateboarding in a skate park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.8, "ram_available_mb": 48860.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13980.4, "ram_available_mb": 48860.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.7}, "power_stats": {"power_gpu_soc_mean_watts": 25.65, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 8.512, "gpu_utilization_percent_mean": 81.7}, "timestamp": "2026-01-30T13:59:24.837328"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4295.34, "latencies_ms": [4295.34], "images_per_second": 0.233, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The skateboarder is wearing a tie-dye shirt and black pants. The skate park is surrounded by palm trees and buildings.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 13980.4, "ram_available_mb": 48860.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.056}, "power_stats": {"power_gpu_soc_mean_watts": 24.287, "power_cpu_cv_mean_watts": 1.19, "power_sys_5v0_mean_watts": 8.426, "gpu_utilization_percent_mean": 77.056}, "timestamp": "2026-01-30T13:59:31.178430"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3526.982, "latencies_ms": [3526.982], "images_per_second": 0.284, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a sheep with a fluffy white coat is standing in a grassy field, surrounded by trees and a wire fence.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13981.4, "ram_available_mb": 48859.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.759}, "power_stats": {"power_gpu_soc_mean_watts": 22.805, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 73.759}, "timestamp": "2026-01-30T13:59:36.746863"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5339.31, "latencies_ms": [5339.31], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 1\n2. wire: 1\n3. grass: 1\n4. trees: 1\n5. fence: 1\n6. wire: 1\n7. grass: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.4, "ram_available_mb": 48859.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13981.5, "ram_available_mb": 48859.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.422}, "power_stats": {"power_gpu_soc_mean_watts": 18.968, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.422}, "timestamp": "2026-01-30T13:59:44.116350"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3832.215, "latencies_ms": [3832.215], "images_per_second": 0.261, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The sheep is in the foreground, with the wire fence in front of it. The sheep is behind the wire fence, with the trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.5, "ram_available_mb": 48859.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.062}, "power_stats": {"power_gpu_soc_mean_watts": 21.957, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 74.062}, "timestamp": "2026-01-30T13:59:49.990282"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3306.596, "latencies_ms": [3306.596], "images_per_second": 0.302, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A sheep with a fluffy coat is standing in a fenced-in area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13983.0, "ram_available_mb": 48857.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.111}, "power_stats": {"power_gpu_soc_mean_watts": 23.072, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.175, "gpu_utilization_percent_mean": 75.111}, "timestamp": "2026-01-30T13:59:55.316443"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3002.528, "latencies_ms": [3002.528], "images_per_second": 0.333, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The sheep is white and fluffy, and the photo was taken on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.9, "ram_available_mb": 48857.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13983.9, "ram_available_mb": 48857.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.96}, "power_stats": {"power_gpu_soc_mean_watts": 24.133, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.284, "gpu_utilization_percent_mean": 77.96}, "timestamp": "2026-01-30T14:00:00.352674"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4495.232, "latencies_ms": [4495.232], "images_per_second": 0.222, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image shows a close-up of a silver electronic device with a circular button, a directional pad, and a red button, all with a red outline, and a red logo on the bottom right corner.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 13983.9, "ram_available_mb": 48857.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.865}, "power_stats": {"power_gpu_soc_mean_watts": 20.527, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 69.865}, "timestamp": "2026-01-30T14:00:06.890127"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6287.962, "latencies_ms": [6287.962], "images_per_second": 0.159, "prompt_tokens": 1113, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. white button: 2\n2. red button: 1\n3. silver button: 1\n4. black button: 1\n5. white arrow button: 1\n6. silver circle button: 1\n7. red circle button: 1\n8. silver circle button with red outline: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13984.7, "ram_available_mb": 48856.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.943}, "power_stats": {"power_gpu_soc_mean_watts": 17.638, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 68.943}, "timestamp": "2026-01-30T14:00:15.220970"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4849.266, "latencies_ms": [4849.266], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the left side of the device being closer to the camera than the right side. The device is positioned on a dark surface, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13984.7, "ram_available_mb": 48856.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.925}, "power_stats": {"power_gpu_soc_mean_watts": 19.748, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 67.925}, "timestamp": "2026-01-30T14:00:22.109949"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2887.134, "latencies_ms": [2887.134], "images_per_second": 0.346, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A close up of a silver device with buttons and a red button.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.251, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.273, "gpu_utilization_percent_mean": 76.652}, "timestamp": "2026-01-30T14:00:27.006472"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3293.93, "latencies_ms": [3293.93], "images_per_second": 0.304, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The device is silver with a red button and a white button. The device is illuminated by a bright light.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13984.3, "ram_available_mb": 48856.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.222}, "power_stats": {"power_gpu_soc_mean_watts": 23.415, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 75.222}, "timestamp": "2026-01-30T14:00:32.343751"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4003.586, "latencies_ms": [4003.586], "images_per_second": 0.25, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A woman in a black dress and high heels is standing in a kitchen with a glass of orange juice in her hand.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13984.3, "ram_available_mb": 48856.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13985.0, "ram_available_mb": 48855.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.879}, "power_stats": {"power_gpu_soc_mean_watts": 24.809, "power_cpu_cv_mean_watts": 1.092, "power_sys_5v0_mean_watts": 8.518, "gpu_utilization_percent_mean": 79.879}, "timestamp": "2026-01-30T14:00:38.382810"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6062.172, "latencies_ms": [6062.172], "images_per_second": 0.165, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. glass: 1\n3. refrigerator: 1\n4. bottle: 1\n5. cupboard: 1\n6. floor: 1\n7. wall: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13985.0, "ram_available_mb": 48855.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13985.2, "ram_available_mb": 48855.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.48}, "power_stats": {"power_gpu_soc_mean_watts": 21.003, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 8.278, "gpu_utilization_percent_mean": 69.48}, "timestamp": "2026-01-30T14:00:46.464775"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5172.428, "latencies_ms": [5172.428], "images_per_second": 0.193, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the refrigerator in the background. The woman is holding a glass of orange juice in her right hand, and the refrigerator is positioned to her left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13985.2, "ram_available_mb": 48855.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13985.4, "ram_available_mb": 48855.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.465}, "power_stats": {"power_gpu_soc_mean_watts": 22.205, "power_cpu_cv_mean_watts": 1.331, "power_sys_5v0_mean_watts": 8.322, "gpu_utilization_percent_mean": 73.465}, "timestamp": "2026-01-30T14:00:53.683788"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3734.529, "latencies_ms": [3734.529], "images_per_second": 0.268, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a black dress is standing in a kitchen holding a glass of champagne.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13985.4, "ram_available_mb": 48855.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13985.5, "ram_available_mb": 48855.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.699, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.554, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T14:00:59.434853"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4162.186, "latencies_ms": [4162.186], "images_per_second": 0.24, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The woman is wearing a black dress with sparkles and black shoes. The kitchen has wooden cabinets and a stainless steel refrigerator.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13985.5, "ram_available_mb": 48855.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13985.6, "ram_available_mb": 48855.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.143}, "power_stats": {"power_gpu_soc_mean_watts": 24.322, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.466, "gpu_utilization_percent_mean": 80.143}, "timestamp": "2026-01-30T14:01:05.635705"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3750.133, "latencies_ms": [3750.133], "images_per_second": 0.267, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image features a round mirror reflecting a yellow school bus and a silver car on a street, with a building and a sign in the background.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13985.6, "ram_available_mb": 48855.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13984.9, "ram_available_mb": 48856.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.065}, "power_stats": {"power_gpu_soc_mean_watts": 21.982, "power_cpu_cv_mean_watts": 1.265, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 71.065}, "timestamp": "2026-01-30T14:01:11.460203"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3809.227, "latencies_ms": [3809.227], "images_per_second": 0.263, "prompt_tokens": 1113, "response_tokens_est": 29, "n_tiles": 1, "output_text": " mirror: 1\nbus: 1\npole: 1\nsign: 1\nbuilding: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13984.9, "ram_available_mb": 48856.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13984.8, "ram_available_mb": 48856.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.607, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.094, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T14:01:17.310109"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4298.254, "latencies_ms": [4298.254], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The mirror is positioned in the foreground, reflecting the yellow school bus in the background. The bus is located to the left of the mirror, while the traffic light is situated to the right.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13984.8, "ram_available_mb": 48856.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13984.8, "ram_available_mb": 48856.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.718, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.114, "gpu_utilization_percent_mean": 72.444}, "timestamp": "2026-01-30T14:01:23.642604"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5952.694, "latencies_ms": [5952.694], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures a scene of a yellow school bus parked on the side of a road, with its reflection visible in a convex mirror. The background features a building with a sign that reads \"Harley-Davidson,\" suggesting that the location might be near a Harley-Davidson dealership or a similar establishment.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13984.8, "ram_available_mb": 48856.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13984.4, "ram_available_mb": 48856.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.84}, "power_stats": {"power_gpu_soc_mean_watts": 17.937, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 69.84}, "timestamp": "2026-01-30T14:01:31.609862"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3856.995, "latencies_ms": [3856.995], "images_per_second": 0.259, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image features a round mirror with a yellow school bus reflected in it, set against a backdrop of a cloudy sky and a building with a sign.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13984.4, "ram_available_mb": 48856.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13984.1, "ram_available_mb": 48856.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.906}, "power_stats": {"power_gpu_soc_mean_watts": 21.72, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 73.906}, "timestamp": "2026-01-30T14:01:37.491779"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3386.228, "latencies_ms": [3386.228], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A gray cat is sitting on a table next to a window, looking outside at a dog standing on the grass.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13984.1, "ram_available_mb": 48856.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.321}, "power_stats": {"power_gpu_soc_mean_watts": 23.02, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.196, "gpu_utilization_percent_mean": 74.321}, "timestamp": "2026-01-30T14:01:42.946830"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3606.945, "latencies_ms": [3606.945], "images_per_second": 0.277, "prompt_tokens": 1113, "response_tokens_est": 26, "n_tiles": 1, "output_text": " cat: 1, dog: 1, potted plant: 2, window: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.633}, "power_stats": {"power_gpu_soc_mean_watts": 22.287, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 71.633}, "timestamp": "2026-01-30T14:01:48.576672"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4211.367, "latencies_ms": [4211.367], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The cat is in the foreground, looking at the dog, which is in the background. The dog is standing on the grass outside, while the cat is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.486}, "power_stats": {"power_gpu_soc_mean_watts": 20.899, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 70.486}, "timestamp": "2026-01-30T14:01:54.837312"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3363.42, "latencies_ms": [3363.42], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A gray cat is sitting on a table next to a window, looking out at a dog standing outside.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.635, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.165, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T14:02:00.242968"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5788.513, "latencies_ms": [5788.513], "images_per_second": 0.173, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a gray cat and a brown dog, with the cat sitting on a wooden table and the dog standing outside the window. The lighting is natural, coming from the outside, and the colors are vibrant, with the green of the plants contrasting against the gray of the cat and the brown of the dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13983.6, "ram_available_mb": 48857.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.417}, "power_stats": {"power_gpu_soc_mean_watts": 18.435, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.417}, "timestamp": "2026-01-30T14:02:08.046848"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4315.929, "latencies_ms": [4315.929], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A female soccer player in a blue jersey with the word \"Acronis\" on it is dribbling a soccer ball while another player in a yellow jersey is in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13983.6, "ram_available_mb": 48857.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13983.7, "ram_available_mb": 48857.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.861}, "power_stats": {"power_gpu_soc_mean_watts": 20.82, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 71.861}, "timestamp": "2026-01-30T14:02:14.411899"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5815.793, "latencies_ms": [5815.793], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. person: 1\n2. jersey: 1\n3. ball: 1\n4. headband: 1\n5. shorts: 1\n6. socks: 1\n7. jersey logo: 1\n8. jersey number: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13983.7, "ram_available_mb": 48857.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.49}, "power_stats": {"power_gpu_soc_mean_watts": 18.026, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 69.49}, "timestamp": "2026-01-30T14:02:22.276495"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5163.786, "latencies_ms": [5163.786], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The main object is a woman wearing a blue jersey, positioned in the foreground of the image. The woman is holding a blue and white ball, which is in the foreground as well. In the background, there is another woman wearing a yellow jersey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.163}, "power_stats": {"power_gpu_soc_mean_watts": 19.143, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.163}, "timestamp": "2026-01-30T14:02:29.490657"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3824.037, "latencies_ms": [3824.037], "images_per_second": 0.262, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A female athlete in a blue jersey is playing a game of soccer, while another player in a yellow jersey is standing in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.688}, "power_stats": {"power_gpu_soc_mean_watts": 21.521, "power_cpu_cv_mean_watts": 1.213, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 72.688}, "timestamp": "2026-01-30T14:02:35.353924"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7091.829, "latencies_ms": [7091.829], "images_per_second": 0.141, "prompt_tokens": 1109, "response_tokens_est": 84, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a grassy field, where a female athlete in a vibrant blue jersey is in the midst of a powerful kick, her body language suggesting intense focus and determination. The lighting is natural and bright, casting soft shadows and highlighting the texture of the grass beneath her feet. The colors are vivid and saturated, with the blue of her jersey standing out against the earthy tones of the field.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.475}, "power_stats": {"power_gpu_soc_mean_watts": 16.946, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.895, "gpu_utilization_percent_mean": 67.475}, "timestamp": "2026-01-30T14:02:44.460836"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3028.534, "latencies_ms": [3028.534], "images_per_second": 0.33, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two giraffes are standing in a fenced-in area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.861, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 74.88}, "timestamp": "2026-01-30T14:02:49.521975"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5592.794, "latencies_ms": [5592.794], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. giraffe: 2\n2. fence: 1\n3. tree: 1\n4. grass: 1\n5. dirt: 1\n6. dirt patch: 1\n7. fence post: 1\n8. giraffe's tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.83}, "power_stats": {"power_gpu_soc_mean_watts": 18.639, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 66.83}, "timestamp": "2026-01-30T14:02:57.178314"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4904.681, "latencies_ms": [4904.681], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The giraffe on the left is positioned closer to the camera than the one on the right, which is farther away. The giraffe on the right is standing near the fence, while the one on the left is bending down to eat grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13983.6, "ram_available_mb": 48857.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.394, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 69.244}, "timestamp": "2026-01-30T14:03:04.119687"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3192.956, "latencies_ms": [3192.956], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two giraffes are in a fenced-in area, one eating grass and the other standing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.6, "ram_available_mb": 48857.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13983.7, "ram_available_mb": 48857.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.077}, "power_stats": {"power_gpu_soc_mean_watts": 23.282, "power_cpu_cv_mean_watts": 0.954, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 73.077}, "timestamp": "2026-01-30T14:03:09.351206"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3733.617, "latencies_ms": [3733.617], "images_per_second": 0.268, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The giraffes are brown and white, and the grass is green. The giraffes are standing in a fenced area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13983.7, "ram_available_mb": 48857.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.806}, "power_stats": {"power_gpu_soc_mean_watts": 21.994, "power_cpu_cv_mean_watts": 1.162, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 73.806}, "timestamp": "2026-01-30T14:03:15.109801"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3924.416, "latencies_ms": [3924.416], "images_per_second": 0.255, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A suitcase, a plastic bag, and a black bag are placed on the floor in front of a curtain.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.656}, "power_stats": {"power_gpu_soc_mean_watts": 25.097, "power_cpu_cv_mean_watts": 1.026, "power_sys_5v0_mean_watts": 8.579, "gpu_utilization_percent_mean": 77.656}, "timestamp": "2026-01-30T14:03:21.079147"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2955.868, "latencies_ms": [2955.868], "images_per_second": 0.338, "prompt_tokens": 1446, "response_tokens_est": 5, "n_tiles": 1, "output_text": " suitcase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.292}, "power_stats": {"power_gpu_soc_mean_watts": 27.439, "power_cpu_cv_mean_watts": 0.617, "power_sys_5v0_mean_watts": 8.646, "gpu_utilization_percent_mean": 87.292}, "timestamp": "2026-01-30T14:03:26.059827"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4304.811, "latencies_ms": [4304.811], "images_per_second": 0.232, "prompt_tokens": 1450, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The suitcase is on the left, the backpack is on the right, and the trash bag is in front of the suitcase.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.806}, "power_stats": {"power_gpu_soc_mean_watts": 24.133, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.434, "gpu_utilization_percent_mean": 78.806}, "timestamp": "2026-01-30T14:03:32.398905"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3888.247, "latencies_ms": [3888.247], "images_per_second": 0.257, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A suitcase, a plastic bag, and a backpack are on the floor in front of a curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.25}, "power_stats": {"power_gpu_soc_mean_watts": 25.488, "power_cpu_cv_mean_watts": 0.988, "power_sys_5v0_mean_watts": 8.544, "gpu_utilization_percent_mean": 78.25}, "timestamp": "2026-01-30T14:03:38.317776"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3996.74, "latencies_ms": [3996.74], "images_per_second": 0.25, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image is in black and white, and the lighting is dim. The materials of the objects are not clear.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.879}, "power_stats": {"power_gpu_soc_mean_watts": 25.127, "power_cpu_cv_mean_watts": 1.055, "power_sys_5v0_mean_watts": 8.513, "gpu_utilization_percent_mean": 78.879}, "timestamp": "2026-01-30T14:03:44.350463"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3630.551, "latencies_ms": [3630.551], "images_per_second": 0.275, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a blue shirt and a red bandana is standing on a rocky trail in the woods, observing two people riding horses.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.342, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T14:03:50.047553"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5373.247, "latencies_ms": [5373.247], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. horse: 2\n3. saddle: 1\n4. backpack: 1\n5. rock: 1\n6. tree: 1\n7. man: 1\n8. hat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.844}, "power_stats": {"power_gpu_soc_mean_watts": 18.978, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 69.844}, "timestamp": "2026-01-30T14:03:57.474997"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5376.918, "latencies_ms": [5376.918], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The man in the blue shirt is standing to the right of the man in the cowboy hat, and the horses are walking in front of the man in the blue shirt. The man in the blue shirt is standing closer to the camera than the man in the cowboy hat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.489}, "power_stats": {"power_gpu_soc_mean_watts": 18.96, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 68.489}, "timestamp": "2026-01-30T14:04:04.870026"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3351.296, "latencies_ms": [3351.296], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a blue shirt and a man in a red bandana are riding horses through a forest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13982.9, "ram_available_mb": 48858.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.111}, "power_stats": {"power_gpu_soc_mean_watts": 22.94, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.205, "gpu_utilization_percent_mean": 76.111}, "timestamp": "2026-01-30T14:04:10.243141"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5414.602, "latencies_ms": [5414.602], "images_per_second": 0.185, "prompt_tokens": 1109, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image features a man wearing a blue shirt and a red bandana, standing on a rocky trail surrounded by trees. The lighting is natural, and the colors are vibrant, with the blue of the shirt standing out against the green of the trees and the brown of the rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.9, "ram_available_mb": 48858.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.756}, "power_stats": {"power_gpu_soc_mean_watts": 18.819, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 70.756}, "timestamp": "2026-01-30T14:04:17.672831"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3503.399, "latencies_ms": [3503.399], "images_per_second": 0.285, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing a sweater with the word \"Russia\" on it is riding a horse in a black and white photo.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.631, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 74.207}, "timestamp": "2026-01-30T14:04:23.240115"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5762.886, "latencies_ms": [5762.886], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. man: 1\n2. horse: 1\n3. saddle: 1\n4. bridle: 1\n5. reins: 1\n6. man's hand: 1\n7. man's leg: 1\n8. man's foot: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.388}, "power_stats": {"power_gpu_soc_mean_watts": 18.37, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 68.388}, "timestamp": "2026-01-30T14:04:31.031399"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5113.194, "latencies_ms": [5113.194], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The man is positioned in the foreground, riding a horse that is in motion, while the background features a blurred building. The man is holding the reins of the horse, which is moving forward, and the horse is positioned in the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.581}, "power_stats": {"power_gpu_soc_mean_watts": 19.126, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 69.581}, "timestamp": "2026-01-30T14:04:38.170893"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3391.274, "latencies_ms": [3391.274], "images_per_second": 0.295, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is riding a horse in a race, wearing a sweater with the word \"Russia\" on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.3, "ram_available_mb": 48857.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.286}, "power_stats": {"power_gpu_soc_mean_watts": 23.022, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.2, "gpu_utilization_percent_mean": 75.286}, "timestamp": "2026-01-30T14:04:43.621107"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4693.565, "latencies_ms": [4693.565], "images_per_second": 0.213, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image is in black and white, with a blurred background that suggests motion. The lighting is natural, likely from the sun, and the material of the horse and rider is not clearly visible due to the motion blur.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.897}, "power_stats": {"power_gpu_soc_mean_watts": 19.855, "power_cpu_cv_mean_watts": 1.437, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 69.897}, "timestamp": "2026-01-30T14:04:50.374704"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3010.548, "latencies_ms": [3010.548], "images_per_second": 0.332, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of geese are swimming in a pond surrounded by tall grass and trees.", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 13983.8, "ram_available_mb": 48857.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13984.1, "ram_available_mb": 48856.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.606, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 73.08}, "timestamp": "2026-01-30T14:04:55.436104"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2268.227, "latencies_ms": [2268.227], "images_per_second": 0.441, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " goose: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13984.1, "ram_available_mb": 48856.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 13984.1, "ram_available_mb": 48856.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.944}, "power_stats": {"power_gpu_soc_mean_watts": 25.267, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.282, "gpu_utilization_percent_mean": 85.944}, "timestamp": "2026-01-30T14:04:59.733396"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4826.783, "latencies_ms": [4826.783], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The geese are positioned in the middle of the pond, with the vegetation on the left side of the image and the trees on the right side. The geese are relatively close to the camera, while the vegetation and trees are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13984.1, "ram_available_mb": 48856.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.725}, "power_stats": {"power_gpu_soc_mean_watts": 19.919, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 69.725}, "timestamp": "2026-01-30T14:05:06.586989"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3015.231, "latencies_ms": [3015.231], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of geese are swimming in a lake surrounded by tall grass and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.704, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 77.24}, "timestamp": "2026-01-30T14:05:11.663705"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6683.65, "latencies_ms": [6683.65], "images_per_second": 0.15, "prompt_tokens": 1109, "response_tokens_est": 74, "n_tiles": 1, "output_text": " The image features a serene scene of a group of geese swimming in a body of water, with the geese displaying a variety of colors including shades of brown, white, and black. The lighting in the image is natural and bright, suggesting that the photo was taken during the day. The water appears calm and reflective, with the geese creating ripples as they move through it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.75}, "power_stats": {"power_gpu_soc_mean_watts": 17.039, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.874, "gpu_utilization_percent_mean": 67.75}, "timestamp": "2026-01-30T14:05:20.397126"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3688.272, "latencies_ms": [3688.272], "images_per_second": 0.271, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A cat is sitting on the hood of a black Mercedes-Benz car, with its reflection visible in the car's shiny surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13983.2, "ram_available_mb": 48857.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.867}, "power_stats": {"power_gpu_soc_mean_watts": 22.33, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 72.867}, "timestamp": "2026-01-30T14:05:26.102127"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5401.804, "latencies_ms": [5401.804], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. cat: 1\n2. car: 1\n3. house: 1\n4. window: 1\n5. door: 1\n6. fence: 1\n7. plant: 1\n8. flower: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13983.2, "ram_available_mb": 48857.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13982.4, "ram_available_mb": 48858.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.644}, "power_stats": {"power_gpu_soc_mean_watts": 18.82, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 70.644}, "timestamp": "2026-01-30T14:05:33.535253"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4371.354, "latencies_ms": [4371.354], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The cat is sitting on the hood of the car, which is in the foreground of the image. The car is parked in front of a house, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.4, "ram_available_mb": 48858.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.944}, "power_stats": {"power_gpu_soc_mean_watts": 20.644, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 70.944}, "timestamp": "2026-01-30T14:05:39.943520"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3794.026, "latencies_ms": [3794.026], "images_per_second": 0.264, "prompt_tokens": 1111, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A cat is sitting on the hood of a black car, looking at the camera. The car is parked in front of a house with a garden.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.258}, "power_stats": {"power_gpu_soc_mean_watts": 22.074, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.184, "gpu_utilization_percent_mean": 74.258}, "timestamp": "2026-01-30T14:05:45.760297"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3966.902, "latencies_ms": [3966.902], "images_per_second": 0.252, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The car is black and the cat is orange and white. The car is parked in front of a house and the cat is sitting on the hood of the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.485}, "power_stats": {"power_gpu_soc_mean_watts": 21.686, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 73.485}, "timestamp": "2026-01-30T14:05:51.768362"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3646.817, "latencies_ms": [3646.817], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man is snowboarding in the air with his arms outstretched, wearing a brown jacket, yellow pants, and a black hat.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13980.9, "ram_available_mb": 48859.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.528, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.197, "gpu_utilization_percent_mean": 71.233}, "timestamp": "2026-01-30T14:05:57.445738"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6011.925, "latencies_ms": [6011.925], "images_per_second": 0.166, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " snowboard: 1, snowboarder: 1, snowboarder's pants: 1, snowboarder's jacket: 1, snowboarder's hat: 1, snowboarder's gloves: 1, snowboarder's boots: 1, snowboarder's goggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.9, "ram_available_mb": 48859.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13980.6, "ram_available_mb": 48860.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.58}, "power_stats": {"power_gpu_soc_mean_watts": 18.044, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 67.58}, "timestamp": "2026-01-30T14:06:05.481291"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4240.753, "latencies_ms": [4240.753], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The snowboarder is in the foreground, jumping over a snow-covered slope. The snowboarder is in the middle of the image, with the sky in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13980.6, "ram_available_mb": 48860.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13980.6, "ram_available_mb": 48860.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.286}, "power_stats": {"power_gpu_soc_mean_watts": 20.718, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 71.286}, "timestamp": "2026-01-30T14:06:11.771751"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3361.537, "latencies_ms": [3361.537], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is snowboarding in the air with his arms outstretched, wearing a brown jacket and yellow pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.6, "ram_available_mb": 48860.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13980.1, "ram_available_mb": 48860.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.084, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T14:06:17.164761"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3261.3, "latencies_ms": [3261.3], "images_per_second": 0.307, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The snowboarder is wearing a brown jacket and yellow pants, and the sky is clear blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.1, "ram_available_mb": 48860.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13979.7, "ram_available_mb": 48861.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.407}, "power_stats": {"power_gpu_soc_mean_watts": 23.031, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.175, "gpu_utilization_percent_mean": 72.407}, "timestamp": "2026-01-30T14:06:22.449128"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3103.254, "latencies_ms": [3103.254], "images_per_second": 0.322, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A small bathroom with a toilet, a bathtub, and a pipe hanging from the ceiling.", "error": null, "sys_before": {"cpu_percent": 15.0, "ram_used_mb": 13979.7, "ram_available_mb": 48861.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13979.6, "ram_available_mb": 48861.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.452, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.218, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T14:06:27.607375"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4075.083, "latencies_ms": [4075.083], "images_per_second": 0.245, "prompt_tokens": 1114, "response_tokens_est": 34, "n_tiles": 1, "output_text": " toilet: 1, bathtub: 1, pipe: 1, towel: 1, door: 1, wall: 1, floor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13979.6, "ram_available_mb": 48861.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13980.6, "ram_available_mb": 48860.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.765}, "power_stats": {"power_gpu_soc_mean_watts": 21.166, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 69.765}, "timestamp": "2026-01-30T14:06:33.702775"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4501.442, "latencies_ms": [4501.442], "images_per_second": 0.222, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the bathtub situated in the background. The pipes run vertically from the ceiling to the floor, creating a sense of depth and perspective in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13980.6, "ram_available_mb": 48860.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.595}, "power_stats": {"power_gpu_soc_mean_watts": 20.454, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 71.595}, "timestamp": "2026-01-30T14:06:40.221210"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3013.656, "latencies_ms": [3013.656], "images_per_second": 0.332, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small bathroom with a toilet and a bathtub, with pipes running along the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.12}, "power_stats": {"power_gpu_soc_mean_watts": 23.718, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 78.12}, "timestamp": "2026-01-30T14:06:45.274508"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2636.043, "latencies_ms": [2636.043], "images_per_second": 0.379, "prompt_tokens": 1110, "response_tokens_est": 11, "n_tiles": 1, "output_text": " The bathroom is painted white and has a wooden floor.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.136}, "power_stats": {"power_gpu_soc_mean_watts": 25.295, "power_cpu_cv_mean_watts": 0.819, "power_sys_5v0_mean_watts": 8.387, "gpu_utilization_percent_mean": 82.136}, "timestamp": "2026-01-30T14:06:49.960171"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3181.982, "latencies_ms": [3181.982], "images_per_second": 0.314, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A statue of two people holding a kite with a colorful pattern is on top of a building.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.5, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 77.269}, "timestamp": "2026-01-30T14:06:55.182920"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2590.608, "latencies_ms": [2590.608], "images_per_second": 0.386, "prompt_tokens": 1114, "response_tokens_est": 10, "n_tiles": 1, "output_text": " kite: 1\nstatue: 2", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.381}, "power_stats": {"power_gpu_soc_mean_watts": 25.298, "power_cpu_cv_mean_watts": 0.762, "power_sys_5v0_mean_watts": 8.338, "gpu_utilization_percent_mean": 81.381}, "timestamp": "2026-01-30T14:06:59.814063"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4987.508, "latencies_ms": [4987.508], "images_per_second": 0.201, "prompt_tokens": 1118, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the statue is in the background, situated on a building. The kite is positioned to the left of the statue, and the statue is located on the right side of the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13982.0, "ram_available_mb": 48858.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.854}, "power_stats": {"power_gpu_soc_mean_watts": 19.755, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 69.854}, "timestamp": "2026-01-30T14:07:06.813413"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3122.144, "latencies_ms": [3122.144], "images_per_second": 0.32, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A kite with a colorful pattern is flying high in the sky above a statue of two people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.0, "ram_available_mb": 48858.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13981.5, "ram_available_mb": 48859.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.28}, "power_stats": {"power_gpu_soc_mean_watts": 23.813, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.284, "gpu_utilization_percent_mean": 76.28}, "timestamp": "2026-01-30T14:07:11.946502"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3423.592, "latencies_ms": [3423.592], "images_per_second": 0.292, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The kite is colorful and has a long tail. The sculpture is made of metal and is located on a building.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13981.5, "ram_available_mb": 48859.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.643}, "power_stats": {"power_gpu_soc_mean_watts": 22.863, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 75.643}, "timestamp": "2026-01-30T14:07:17.389850"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3793.53, "latencies_ms": [3793.53], "images_per_second": 0.264, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image displays a variety of fresh vegetables, including strawberries, broccoli, radishes, carrots, and green beans, arranged in a visually appealing manner.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.226}, "power_stats": {"power_gpu_soc_mean_watts": 22.123, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.154, "gpu_utilization_percent_mean": 72.226}, "timestamp": "2026-01-30T14:07:23.217932"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4268.587, "latencies_ms": [4268.587], "images_per_second": 0.234, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " strawberries: 10, broccoli: 1, radishes: 1, carrots: 1, green beans: 1, asparagus: 1, potatoes: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.143}, "power_stats": {"power_gpu_soc_mean_watts": 20.9, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 69.143}, "timestamp": "2026-01-30T14:07:29.520439"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4535.686, "latencies_ms": [4535.686], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The strawberries are located in the left foreground, while the broccoli is situated in the upper left background. The radishes are positioned in the upper right background, and the carrots are located in the lower right foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.358, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 70.789}, "timestamp": "2026-01-30T14:07:36.093530"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5501.363, "latencies_ms": [5501.363], "images_per_second": 0.182, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce, including strawberries, broccoli, radishes, carrots, and green beans, arranged in a rustic wooden crate. The setting appears to be a market or a farm stand, where the produce is being sold or displayed for customers to purchase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.584, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 69.957}, "timestamp": "2026-01-30T14:07:43.633529"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5661.664, "latencies_ms": [5661.664], "images_per_second": 0.177, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a variety of fresh vegetables, including strawberries, broccoli, radishes, carrots, and potatoes, all displayed in a rustic wooden crate. The lighting is natural and bright, highlighting the vibrant colors of the produce. The vegetables are arranged in a way that showcases their freshness and abundance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13981.8, "ram_available_mb": 48859.1, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13981.0, "ram_available_mb": 48859.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.191}, "power_stats": {"power_gpu_soc_mean_watts": 18.409, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 69.191}, "timestamp": "2026-01-30T14:07:51.341021"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3402.932, "latencies_ms": [3402.932], "images_per_second": 0.294, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Three people are sitting on a couch playing a video game, with a projector projecting onto the wall behind them.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13981.0, "ram_available_mb": 48859.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13981.0, "ram_available_mb": 48859.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.55, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 74.857}, "timestamp": "2026-01-30T14:07:56.787576"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2877.581, "latencies_ms": [2877.581], "images_per_second": 0.348, "prompt_tokens": 1113, "response_tokens_est": 14, "n_tiles": 1, "output_text": " projector: 1, couch: 1, person: 3", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13981.0, "ram_available_mb": 48859.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.387, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.25, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-30T14:08:01.701706"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5618.54, "latencies_ms": [5618.54], "images_per_second": 0.178, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the projector and the two men in the background. The projector is located on the left side of the image, while the two men are sitting on the right side. The man on the left is closer to the camera than the man on the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.447}, "power_stats": {"power_gpu_soc_mean_watts": 18.58, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 69.447}, "timestamp": "2026-01-30T14:08:09.333396"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2754.789, "latencies_ms": [2754.789], "images_per_second": 0.363, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Three men are sitting on a couch playing a video game.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.957}, "power_stats": {"power_gpu_soc_mean_watts": 24.423, "power_cpu_cv_mean_watts": 0.783, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 76.957}, "timestamp": "2026-01-30T14:08:14.111600"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3934.023, "latencies_ms": [3934.023], "images_per_second": 0.254, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a projector on the table. The colors in the image are mostly dark with some blue and green hues.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13980.7, "ram_available_mb": 48860.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13981.5, "ram_available_mb": 48859.4, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.758}, "power_stats": {"power_gpu_soc_mean_watts": 21.512, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.136, "gpu_utilization_percent_mean": 70.758}, "timestamp": "2026-01-30T14:08:20.105713"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4000.619, "latencies_ms": [4000.619], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a group of sheep are resting in a lush green field, with a tree providing shade and a distant herd of cows grazing peacefully in the background.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13981.5, "ram_available_mb": 48859.4, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.97}, "power_stats": {"power_gpu_soc_mean_watts": 21.377, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 70.97}, "timestamp": "2026-01-30T14:08:26.153429"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2212.625, "latencies_ms": [2212.625], "images_per_second": 0.452, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13981.7, "ram_available_mb": 48859.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.712, "power_cpu_cv_mean_watts": 0.622, "power_sys_5v0_mean_watts": 8.333, "gpu_utilization_percent_mean": 87.0}, "timestamp": "2026-01-30T14:08:30.418037"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4563.689, "latencies_ms": [4563.689], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground, with the tree trunk to their right. The cows are located in the background, with the tree trunk to their left. The sheep are closer to the camera than the cows.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13981.7, "ram_available_mb": 48859.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.605}, "power_stats": {"power_gpu_soc_mean_watts": 20.42, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 72.605}, "timestamp": "2026-01-30T14:08:36.996482"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5646.541, "latencies_ms": [5646.541], "images_per_second": 0.177, "prompt_tokens": 1111, "response_tokens_est": 61, "n_tiles": 1, "output_text": " In a serene rural setting, a group of sheep are peacefully grazing in a lush green field. The sheep, varying in shades of white and brown, are scattered across the field, some lying down while others are standing. In the background, a tree stands tall, providing a natural boundary to the field.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13981.4, "ram_available_mb": 48859.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.362}, "power_stats": {"power_gpu_soc_mean_watts": 18.64, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 69.362}, "timestamp": "2026-01-30T14:08:44.658924"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5721.785, "latencies_ms": [5721.785], "images_per_second": 0.175, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a lush green field with a tree trunk in the foreground, and a herd of cows grazing in the background. The lighting is natural and bright, suggesting it is daytime. The colors are vibrant, with the green grass contrasting against the brown tree trunk and the white and black coats of the cows.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13981.4, "ram_available_mb": 48859.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13985.5, "ram_available_mb": 48855.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.319}, "power_stats": {"power_gpu_soc_mean_watts": 18.554, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 71.319}, "timestamp": "2026-01-30T14:08:52.390692"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5218.925, "latencies_ms": [5218.925], "images_per_second": 0.192, "prompt_tokens": 1099, "response_tokens_est": 53, "n_tiles": 1, "output_text": " A large group of people, including both boys and men, are posing together in front of a building, with the text \"GOODMAYES BOYS SCHOOL: APRIL 1929\" visible at the bottom of the image.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13985.5, "ram_available_mb": 48855.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13986.7, "ram_available_mb": 48854.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.302}, "power_stats": {"power_gpu_soc_mean_watts": 19.181, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 68.302}, "timestamp": "2026-01-30T14:08:59.650224"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 7394.445, "latencies_ms": [7394.445], "images_per_second": 0.135, "prompt_tokens": 1113, "response_tokens_est": 89, "n_tiles": 1, "output_text": " 1. group of boys: 100\n2. boys in suits: 10\n3. boys in school uniforms: 10\n4. boys in shorts: 10\n5. boys in ties: 10\n6. boys in ties and suits: 10\n7. boys in ties and school uniforms: 10\n8. boys in ties and shorts: 10", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13986.7, "ram_available_mb": 48854.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13986.6, "ram_available_mb": 48854.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.629}, "power_stats": {"power_gpu_soc_mean_watts": 16.669, "power_cpu_cv_mean_watts": 1.801, "power_sys_5v0_mean_watts": 7.922, "gpu_utilization_percent_mean": 69.629}, "timestamp": "2026-01-30T14:09:09.091587"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4084.777, "latencies_ms": [4084.777], "images_per_second": 0.245, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The group of people is in the foreground, with the building in the background. The people are standing and sitting in a group, with some people sitting on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13986.6, "ram_available_mb": 48854.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13986.4, "ram_available_mb": 48854.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.941}, "power_stats": {"power_gpu_soc_mean_watts": 21.196, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 70.941}, "timestamp": "2026-01-30T14:09:15.210525"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3470.231, "latencies_ms": [3470.231], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A large group of people, including both boys and men, are posing for a picture in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13986.4, "ram_available_mb": 48854.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13987.6, "ram_available_mb": 48853.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.071}, "power_stats": {"power_gpu_soc_mean_watts": 22.578, "power_cpu_cv_mean_watts": 1.058, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 73.071}, "timestamp": "2026-01-30T14:09:20.698457"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4078.828, "latencies_ms": [4078.828], "images_per_second": 0.245, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is in black and white, and the lighting is even, with no shadows or highlights. The material of the photograph is paper, and the weather is clear.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13987.6, "ram_available_mb": 48853.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13988.1, "ram_available_mb": 48852.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.676}, "power_stats": {"power_gpu_soc_mean_watts": 21.126, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 69.676}, "timestamp": "2026-01-30T14:09:26.788680"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3422.903, "latencies_ms": [3422.903], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A colorful kite with a long tail is flying high in the sky, with a building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13988.1, "ram_available_mb": 48852.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.429}, "power_stats": {"power_gpu_soc_mean_watts": 22.707, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.176, "gpu_utilization_percent_mean": 71.429}, "timestamp": "2026-01-30T14:09:32.249794"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5673.492, "latencies_ms": [5673.492], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Kite: 1\n2. Sky: 2\n3. Clouds: 2\n4. Trees: 2\n5. Buildings: 1\n6. People: 1\n7. Kite string: 1\n8. Kite tail: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.574}, "power_stats": {"power_gpu_soc_mean_watts": 18.486, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 67.574}, "timestamp": "2026-01-30T14:09:39.959842"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4507.654, "latencies_ms": [4507.654], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the buildings are in the background. The kite is positioned to the left of the buildings, and the sky is to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.235, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 66.892}, "timestamp": "2026-01-30T14:09:46.486034"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3181.037, "latencies_ms": [3181.037], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A colorful kite is flying high in the sky over a park with trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.758, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 75.385}, "timestamp": "2026-01-30T14:09:51.701059"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4796.915, "latencies_ms": [4796.915], "images_per_second": 0.208, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The kite is a vibrant mix of colors, with a long tail that trails behind it. The sky is a clear blue with fluffy white clouds, and the kite is flying high above a park with trees and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.875}, "power_stats": {"power_gpu_soc_mean_watts": 19.659, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 67.875}, "timestamp": "2026-01-30T14:09:58.516516"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3169.185, "latencies_ms": [3169.185], "images_per_second": 0.316, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A large pizza with a generous amount of cheese and tomato sauce is sitting in a cardboard box.", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.468, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.205, "gpu_utilization_percent_mean": 74.885}, "timestamp": "2026-01-30T14:10:03.753713"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4203.663, "latencies_ms": [4203.663], "images_per_second": 0.238, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " pizza: 1, box: 1, pizza box: 1, pizza crust: 1, cheese: 1, sauce: 1, pepperoni: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.171}, "power_stats": {"power_gpu_soc_mean_watts": 21.151, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.127, "gpu_utilization_percent_mean": 69.171}, "timestamp": "2026-01-30T14:10:09.983512"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4110.396, "latencies_ms": [4110.396], "images_per_second": 0.243, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the cardboard box in the background. The pizza is on the left side of the box, and the box is on the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.588}, "power_stats": {"power_gpu_soc_mean_watts": 21.337, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 71.588}, "timestamp": "2026-01-30T14:10:16.126917"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2898.861, "latencies_ms": [2898.861], "images_per_second": 0.345, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A large pizza with cheese and tomato sauce is sitting in a cardboard box.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.625}, "power_stats": {"power_gpu_soc_mean_watts": 24.505, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.293, "gpu_utilization_percent_mean": 76.625}, "timestamp": "2026-01-30T14:10:21.050299"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3844.586, "latencies_ms": [3844.586], "images_per_second": 0.26, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The pizza is in a cardboard box with a white and brown color scheme. The lighting is natural and the pizza is in a room with a black background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.969}, "power_stats": {"power_gpu_soc_mean_watts": 21.91, "power_cpu_cv_mean_watts": 1.314, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 73.969}, "timestamp": "2026-01-30T14:10:26.924442"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3586.836, "latencies_ms": [3586.836], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A woman sits on the edge of an open refrigerator, talking on her cell phone, while a man sits on the curb nearby.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.759}, "power_stats": {"power_gpu_soc_mean_watts": 22.464, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 70.759}, "timestamp": "2026-01-30T14:10:32.561820"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5358.248, "latencies_ms": [5358.248], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. jacket: 1\n3. pants: 1\n4. shoes: 1\n5. refrigerator: 1\n6. cup: 2\n7. glass: 1\n8. door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.205}, "power_stats": {"power_gpu_soc_mean_watts": 19.111, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 71.205}, "timestamp": "2026-01-30T14:10:39.937891"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4928.493, "latencies_ms": [4928.493], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The woman is sitting on the open door of the refrigerator, which is located on the right side of the image. The refrigerator is situated on the left side of the image, and the woman is positioned closer to the camera than the refrigerator.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.61}, "power_stats": {"power_gpu_soc_mean_watts": 19.523, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 67.61}, "timestamp": "2026-01-30T14:10:46.927917"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3488.778, "latencies_ms": [3488.778], "images_per_second": 0.287, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A woman sits on the edge of an open refrigerator on a city street, while a man sits on a bench nearby.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.103}, "power_stats": {"power_gpu_soc_mean_watts": 22.534, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.168, "gpu_utilization_percent_mean": 70.103}, "timestamp": "2026-01-30T14:10:52.450452"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5330.355, "latencies_ms": [5330.355], "images_per_second": 0.188, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image depicts a woman sitting on an open refrigerator door, with a man smoking a cigarette nearby. The refrigerator is white, and the woman is wearing a blue jacket. The weather appears to be overcast, and the street is wet, suggesting it has recently rained.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.295}, "power_stats": {"power_gpu_soc_mean_watts": 18.973, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.295}, "timestamp": "2026-01-30T14:10:59.793935"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3513.886, "latencies_ms": [3513.886], "images_per_second": 0.285, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing a straw hat and a green shirt is sitting at a white table with a tray of hot dogs on it.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.034}, "power_stats": {"power_gpu_soc_mean_watts": 22.562, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 72.034}, "timestamp": "2026-01-30T14:11:05.383066"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5562.155, "latencies_ms": [5562.155], "images_per_second": 0.18, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. hat: 1\n3. shirt: 1\n4. chair: 1\n5. hotdogs: 12\n6. foil: 1\n7. grass: 1\n8. white: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.319}, "power_stats": {"power_gpu_soc_mean_watts": 18.455, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 69.319}, "timestamp": "2026-01-30T14:11:12.960008"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4428.739, "latencies_ms": [4428.739], "images_per_second": 0.226, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, with the hot dogs in the center. The hot dogs are placed on a white table, which is positioned in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.671, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.102, "gpu_utilization_percent_mean": 69.838}, "timestamp": "2026-01-30T14:11:19.404547"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3036.249, "latencies_ms": [3036.249], "images_per_second": 0.329, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a straw hat is sitting at a table with a tray of hot dogs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.862, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.301, "gpu_utilization_percent_mean": 77.56}, "timestamp": "2026-01-30T14:11:24.453807"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6392.129, "latencies_ms": [6392.129], "images_per_second": 0.156, "prompt_tokens": 1110, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a man wearing a straw hat and a green shirt, sitting at a white table with a tray of hot dogs. The hot dogs are placed on a piece of aluminum foil, and the man is holding a red hot dog in his hand. The lighting in the image is bright and natural, suggesting that the photo was taken outdoors on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.074}, "power_stats": {"power_gpu_soc_mean_watts": 17.664, "power_cpu_cv_mean_watts": 1.757, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 69.074}, "timestamp": "2026-01-30T14:11:32.866403"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4086.092, "latencies_ms": [4086.092], "images_per_second": 0.245, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image depicts a room with a desk, a chair, a bookshelf, and a couch, with a laptop on the desk and a star hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.973, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T14:11:39.015103"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4582.411, "latencies_ms": [4582.411], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " chair: 1, laptop: 1, bookshelf: 1, books: 1, blanket: 1, bookshelf: 1, books: 1, bookshelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.368}, "power_stats": {"power_gpu_soc_mean_watts": 20.126, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.368}, "timestamp": "2026-01-30T14:11:45.627662"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4676.594, "latencies_ms": [4676.594], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The laptop is on the left side of the room, the bookshelf is in the middle, and the couch is on the right side. The laptop is near the bookshelf, and the couch is near the bookshelf.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14002.6, "ram_available_mb": 48838.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.615}, "power_stats": {"power_gpu_soc_mean_watts": 20.235, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 71.615}, "timestamp": "2026-01-30T14:11:52.345224"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2822.952, "latencies_ms": [2822.952], "images_per_second": 0.354, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A room with a desk, bookshelf, and couch is shown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.6, "ram_available_mb": 48838.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14003.1, "ram_available_mb": 48837.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.913}, "power_stats": {"power_gpu_soc_mean_watts": 24.859, "power_cpu_cv_mean_watts": 0.887, "power_sys_5v0_mean_watts": 8.352, "gpu_utilization_percent_mean": 79.913}, "timestamp": "2026-01-30T14:11:57.199165"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3992.997, "latencies_ms": [3992.997], "images_per_second": 0.25, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The room is lit by a single light bulb and has a warm yellow hue. The walls are painted a light beige color and the furniture is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.1, "ram_available_mb": 48837.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14001.6, "ram_available_mb": 48839.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.303, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-30T14:12:03.232148"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3353.615, "latencies_ms": [3353.615], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " In the image, there are two elephants standing in a grassy field, with one of them wearing a hat.", "error": null, "sys_before": {"cpu_percent": 14.8, "ram_used_mb": 14001.6, "ram_available_mb": 48839.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14002.1, "ram_available_mb": 48838.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.444}, "power_stats": {"power_gpu_soc_mean_watts": 23.103, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 75.444}, "timestamp": "2026-01-30T14:12:08.617669"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2283.929, "latencies_ms": [2283.929], "images_per_second": 0.438, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " elephant: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.1, "ram_available_mb": 48838.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.7, "ram_used_mb": 14002.8, "ram_available_mb": 48838.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.778}, "power_stats": {"power_gpu_soc_mean_watts": 24.929, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.287, "gpu_utilization_percent_mean": 82.778}, "timestamp": "2026-01-30T14:12:12.915832"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6611.779, "latencies_ms": [6611.779], "images_per_second": 0.151, "prompt_tokens": 1117, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The two elephants are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the one on the right. The elephants are facing each other, with the one on the left appearing to be slightly larger in size. The background of the image features a hazy, green landscape with trees and bushes, suggesting a natural habitat for the elephants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.8, "ram_available_mb": 48838.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 14003.8, "ram_available_mb": 48837.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.745}, "power_stats": {"power_gpu_soc_mean_watts": 17.406, "power_cpu_cv_mean_watts": 1.761, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 67.745}, "timestamp": "2026-01-30T14:12:21.550393"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5250.192, "latencies_ms": [5250.192], "images_per_second": 0.19, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " In the heart of a verdant savannah, two majestic elephants engage in a tender moment, their trunks intertwined in a display of affection. The lush greenery of the surrounding landscape provides a stark contrast to the elephants' imposing presence, creating a serene and tranquil scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.8, "ram_available_mb": 48837.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14004.5, "ram_available_mb": 48836.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.795}, "power_stats": {"power_gpu_soc_mean_watts": 19.155, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.795}, "timestamp": "2026-01-30T14:12:28.820218"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3079.149, "latencies_ms": [3079.149], "images_per_second": 0.325, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The elephants are brown, the sky is overcast, and the vegetation is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.5, "ram_available_mb": 48836.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.782, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.233, "gpu_utilization_percent_mean": 73.52}, "timestamp": "2026-01-30T14:12:33.917493"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4231.543, "latencies_ms": [4231.543], "images_per_second": 0.236, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A shirtless man wearing a white baseball cap and sunglasses is holding a white frisbee in his right hand and a green bottle in his left hand while standing in a grassy field.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14006.0, "ram_available_mb": 48834.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.171}, "power_stats": {"power_gpu_soc_mean_watts": 20.911, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 69.171}, "timestamp": "2026-01-30T14:12:40.219097"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5570.858, "latencies_ms": [5570.858], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. man: 1\n2. cap: 1\n3. shorts: 1\n4. shirt: 1\n5. frisbee: 1\n6. bottle: 1\n7. grass: 1\n8. trees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14006.0, "ram_available_mb": 48834.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14006.5, "ram_available_mb": 48834.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.348}, "power_stats": {"power_gpu_soc_mean_watts": 18.513, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 68.348}, "timestamp": "2026-01-30T14:12:47.818460"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4941.94, "latencies_ms": [4941.94], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The man is in the foreground, holding a frisbee and wearing a cap. The frisbee is in the middle ground, and the man is in the background. The man is closer to the camera than the frisbee.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14006.5, "ram_available_mb": 48834.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14007.0, "ram_available_mb": 48833.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.854}, "power_stats": {"power_gpu_soc_mean_watts": 19.53, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 71.854}, "timestamp": "2026-01-30T14:12:54.798838"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3047.855, "latencies_ms": [3047.855], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is playing frisbee in a field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14007.0, "ram_available_mb": 48833.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14006.9, "ram_available_mb": 48834.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.492, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.205, "gpu_utilization_percent_mean": 79.08}, "timestamp": "2026-01-30T14:12:59.898245"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4138.115, "latencies_ms": [4138.115], "images_per_second": 0.242, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a man in a white cap and shorts, holding a frisbee in his hand, standing in a grassy field with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14006.9, "ram_available_mb": 48834.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14007.2, "ram_available_mb": 48833.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.086}, "power_stats": {"power_gpu_soc_mean_watts": 21.003, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 72.086}, "timestamp": "2026-01-30T14:13:06.073259"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3714.787, "latencies_ms": [3714.787], "images_per_second": 0.269, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young boy wearing a blue sports jersey is cutting a chocolate cake with a knife on a table with a colorful tablecloth.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 14007.2, "ram_available_mb": 48833.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14006.9, "ram_available_mb": 48834.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.71}, "power_stats": {"power_gpu_soc_mean_watts": 21.283, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 72.71}, "timestamp": "2026-01-30T14:13:11.826042"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5388.087, "latencies_ms": [5388.087], "images_per_second": 0.186, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. boy: 1\n2. knife: 1\n3. plate: 1\n4. cake: 1\n5. tablecloth: 1\n6. wall: 1\n7. chair: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14006.9, "ram_available_mb": 48834.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14005.7, "ram_available_mb": 48835.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.156}, "power_stats": {"power_gpu_soc_mean_watts": 19.057, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.156}, "timestamp": "2026-01-30T14:13:19.246073"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4411.303, "latencies_ms": [4411.303], "images_per_second": 0.227, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The boy is in the foreground, leaning over the table with a knife in his hand. The cake is in the middle of the table, and the plate is on the right side of the table.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14005.7, "ram_available_mb": 48835.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14005.9, "ram_available_mb": 48835.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.189}, "power_stats": {"power_gpu_soc_mean_watts": 20.558, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 72.189}, "timestamp": "2026-01-30T14:13:25.698985"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3672.566, "latencies_ms": [3672.566], "images_per_second": 0.272, "prompt_tokens": 1112, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A young boy wearing a blue shirt is cutting a cake with a knife. The cake is decorated with chocolate and has a toy car on top.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14005.9, "ram_available_mb": 48835.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14005.3, "ram_available_mb": 48835.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.194}, "power_stats": {"power_gpu_soc_mean_watts": 22.123, "power_cpu_cv_mean_watts": 1.317, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 72.194}, "timestamp": "2026-01-30T14:13:31.388661"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4496.081, "latencies_ms": [4496.081], "images_per_second": 0.222, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The boy is wearing a blue shirt and is cutting a cake with a knife. The cake is decorated with chocolate and has a chocolate roll on top. The cake is on a table with a colorful tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.3, "ram_available_mb": 48835.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14006.1, "ram_available_mb": 48834.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.811}, "power_stats": {"power_gpu_soc_mean_watts": 20.702, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 71.811}, "timestamp": "2026-01-30T14:13:37.924017"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4367.314, "latencies_ms": [4367.314], "images_per_second": 0.229, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a close-up of a zebra's face, showcasing its distinctive black and white stripes, with another zebra in the background, partially visible, and a metal fence separating them.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14006.1, "ram_available_mb": 48834.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14006.8, "ram_available_mb": 48834.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.463, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 68.444}, "timestamp": "2026-01-30T14:13:44.316469"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2280.597, "latencies_ms": [2280.597], "images_per_second": 0.438, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14006.8, "ram_available_mb": 48834.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 14005.9, "ram_available_mb": 48835.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.174, "power_cpu_cv_mean_watts": 0.556, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 83.0}, "timestamp": "2026-01-30T14:13:48.619644"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4451.656, "latencies_ms": [4451.656], "images_per_second": 0.225, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The zebra in the foreground is close to the camera, while the other zebra is farther away. The zebra in the foreground is eating from a food trough, while the other zebra is standing behind it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14005.9, "ram_available_mb": 48835.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14005.8, "ram_available_mb": 48835.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.189}, "power_stats": {"power_gpu_soc_mean_watts": 20.398, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 71.189}, "timestamp": "2026-01-30T14:13:55.095563"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3074.879, "latencies_ms": [3074.879], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of zebras are standing in a pen, eating grass and looking around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.8, "ram_available_mb": 48835.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14005.8, "ram_available_mb": 48835.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.749, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.211, "gpu_utilization_percent_mean": 77.16}, "timestamp": "2026-01-30T14:14:00.211298"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5451.229, "latencies_ms": [5451.229], "images_per_second": 0.183, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a close-up of a zebra's face, with its distinctive black and white stripes, and a background that includes a fence and some greenery. The lighting in the image is natural, likely from sunlight, and the zebra appears to be in a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14005.8, "ram_available_mb": 48835.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14005.8, "ram_available_mb": 48835.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.422}, "power_stats": {"power_gpu_soc_mean_watts": 18.774, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 70.422}, "timestamp": "2026-01-30T14:14:07.676655"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4474.84, "latencies_ms": [4474.84], "images_per_second": 0.223, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The black and white photo captures a train station with a sign that reads \"La Spezia Centrale\" and a train on the tracks, with a bench and a person sitting on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14005.8, "ram_available_mb": 48835.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14005.6, "ram_available_mb": 48835.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.243}, "power_stats": {"power_gpu_soc_mean_watts": 20.267, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 72.243}, "timestamp": "2026-01-30T14:14:14.195396"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5572.498, "latencies_ms": [5572.498], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. Train: 1\n2. Train tracks: 2\n3. Train station: 1\n4. Platform: 1\n5. Sign: 1\n6. Bench: 1\n7. People: 2\n8. Mountain: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14005.6, "ram_available_mb": 48835.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14004.9, "ram_available_mb": 48836.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.443, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 71.638}, "timestamp": "2026-01-30T14:14:21.791178"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4244.025, "latencies_ms": [4244.025], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The train station platform is located in the foreground, with the train tracks extending into the background. The sign is positioned above the platform, indicating the direction to the center of the station.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.9, "ram_available_mb": 48836.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.911, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.119, "gpu_utilization_percent_mean": 67.629}, "timestamp": "2026-01-30T14:14:28.096172"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3333.145, "latencies_ms": [3333.145], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white photo of a train station with a sign that says La Spezia Centrale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.407}, "power_stats": {"power_gpu_soc_mean_watts": 23.352, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.201, "gpu_utilization_percent_mean": 73.407}, "timestamp": "2026-01-30T14:14:33.441621"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4629.62, "latencies_ms": [4629.62], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is in black and white, with the train station and tracks being the main focus. The sky is overcast, and the station is well-lit, suggesting it is either early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.208, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 68.816}, "timestamp": "2026-01-30T14:14:40.081566"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3246.592, "latencies_ms": [3246.592], "images_per_second": 0.308, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is sitting on a red surfboard in the ocean, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 14004.4, "ram_available_mb": 48836.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.398, "power_cpu_cv_mean_watts": 1.127, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-30T14:14:45.353448"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5567.447, "latencies_ms": [5567.447], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. ocean: 1\n4. sky: 1\n5. clouds: 1\n6. horizon: 1\n7. water: 1\n8. surfboard logo: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.617}, "power_stats": {"power_gpu_soc_mean_watts": 18.511, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 67.617}, "timestamp": "2026-01-30T14:14:52.979659"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4233.429, "latencies_ms": [4233.429], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The person is sitting on the surfboard, which is in the foreground of the image. The ocean is in the background, and the sky is above the person and the ocean.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.114}, "power_stats": {"power_gpu_soc_mean_watts": 20.854, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 68.114}, "timestamp": "2026-01-30T14:14:59.226873"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2890.605, "latencies_ms": [2890.605], "images_per_second": 0.346, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is sitting on a surfboard in the ocean at sunset.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.375}, "power_stats": {"power_gpu_soc_mean_watts": 23.955, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.239, "gpu_utilization_percent_mean": 76.375}, "timestamp": "2026-01-30T14:15:04.137348"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5289.636, "latencies_ms": [5289.636], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a solitary figure perched on a vibrant red surfboard, set against the backdrop of a tumultuous sea. The sky, a canvas of dark clouds, is ablaze with hues of orange and yellow, casting an ethereal glow on the water's surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.8, "ram_available_mb": 48836.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.295}, "power_stats": {"power_gpu_soc_mean_watts": 19.099, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 71.295}, "timestamp": "2026-01-30T14:15:11.458153"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3238.286, "latencies_ms": [3238.286], "images_per_second": 0.309, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man and a woman are sitting at a table on a train, eating sushi and other food.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.308}, "power_stats": {"power_gpu_soc_mean_watts": 23.299, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 73.308}, "timestamp": "2026-01-30T14:15:16.730067"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5457.203, "latencies_ms": [5457.203], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. chopsticks: 2\n4. tray: 1\n5. food: 1\n6. plate: 1\n7. bag: 1\n8. seat: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.756}, "power_stats": {"power_gpu_soc_mean_watts": 18.81, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 68.756}, "timestamp": "2026-01-30T14:15:24.209212"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5101.697, "latencies_ms": [5101.697], "images_per_second": 0.196, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The man is sitting on the left side of the image, while the woman is on the right side. The man is closer to the camera than the woman. The food tray is in the middle of the image, and the window is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.907}, "power_stats": {"power_gpu_soc_mean_watts": 19.192, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.907}, "timestamp": "2026-01-30T14:15:31.347543"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3203.147, "latencies_ms": [3203.147], "images_per_second": 0.312, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A couple is enjoying a meal on a train, with a view of the tracks outside the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.39, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 74.385}, "timestamp": "2026-01-30T14:15:36.563238"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4091.81, "latencies_ms": [4091.81], "images_per_second": 0.244, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a well-lit train carriage with natural light coming through the windows. The colors in the image are vibrant and the materials are mostly plastic and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.7, "ram_available_mb": 48836.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.375, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 71.324}, "timestamp": "2026-01-30T14:15:42.677850"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3766.554, "latencies_ms": [3766.554], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " Two men are walking down the street at night, one in a white shirt and black tie, and the other in a pink shirt and black tie.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14005.0, "ram_available_mb": 48835.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14004.1, "ram_available_mb": 48836.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.774}, "power_stats": {"power_gpu_soc_mean_watts": 22.164, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 72.774}, "timestamp": "2026-01-30T14:15:48.493605"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5391.198, "latencies_ms": [5391.198], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 2\n2. tie: 1\n3. shirt: 1\n4. tie: 1\n5. pants: 1\n6. shoes: 1\n7. building: 1\n8. sign: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14004.1, "ram_available_mb": 48836.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14004.2, "ram_available_mb": 48836.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.222}, "power_stats": {"power_gpu_soc_mean_watts": 18.799, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 69.222}, "timestamp": "2026-01-30T14:15:55.898361"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5416.922, "latencies_ms": [5416.922], "images_per_second": 0.185, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The man on the left is standing closer to the camera than the man on the right. The man on the left is standing in front of the man on the right. The man on the left is standing on the sidewalk, while the man on the right is standing on the street.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14004.2, "ram_available_mb": 48836.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14003.9, "ram_available_mb": 48837.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.8}, "power_stats": {"power_gpu_soc_mean_watts": 18.903, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.8}, "timestamp": "2026-01-30T14:16:03.347123"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3427.255, "latencies_ms": [3427.255], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two men are walking down the street at night, one in a white shirt and the other in a pink shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14003.9, "ram_available_mb": 48837.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.791, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 74.286}, "timestamp": "2026-01-30T14:16:08.787099"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2887.727, "latencies_ms": [2887.727], "images_per_second": 0.346, "prompt_tokens": 1109, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The two men are wearing ties and standing on the sidewalk at night.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14003.3, "ram_available_mb": 48837.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14002.8, "ram_available_mb": 48838.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.417}, "power_stats": {"power_gpu_soc_mean_watts": 23.971, "power_cpu_cv_mean_watts": 0.85, "power_sys_5v0_mean_watts": 8.231, "gpu_utilization_percent_mean": 79.417}, "timestamp": "2026-01-30T14:16:13.730244"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3547.488, "latencies_ms": [3547.488], "images_per_second": 0.282, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man wearing glasses and a gray shirt is pouring wine into a glass at a bar while another person holds a wine glass.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14002.8, "ram_available_mb": 48838.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.31}, "power_stats": {"power_gpu_soc_mean_watts": 22.378, "power_cpu_cv_mean_watts": 1.118, "power_sys_5v0_mean_watts": 8.133, "gpu_utilization_percent_mean": 72.31}, "timestamp": "2026-01-30T14:16:19.332366"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5763.782, "latencies_ms": [5763.782], "images_per_second": 0.173, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. person: 1\n2. wine bottle: 1\n3. wine glass: 1\n4. wine rack: 1\n5. wine bottle: 1\n6. wine glass: 1\n7. wine bottle: 1\n8. wine glass: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.517, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 70.25}, "timestamp": "2026-01-30T14:16:27.121248"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5523.885, "latencies_ms": [5523.885], "images_per_second": 0.181, "prompt_tokens": 1118, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The man is standing to the left of the bar counter, with the wine bottle and glasses in front of him. The wine bottle is placed on the counter, while the glasses are held by the man. The background shows shelves with wine bottles, indicating that the bar is stocked with various wines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.9, "ram_available_mb": 48838.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14002.4, "ram_available_mb": 48838.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.304}, "power_stats": {"power_gpu_soc_mean_watts": 18.799, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 70.304}, "timestamp": "2026-01-30T14:16:34.667920"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3409.611, "latencies_ms": [3409.611], "images_per_second": 0.293, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man is standing behind a bar, pouring wine into a glass. There are wine bottles on the shelves behind him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.4, "ram_available_mb": 48838.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 14001.8, "ram_available_mb": 48839.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.321}, "power_stats": {"power_gpu_soc_mean_watts": 22.892, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 74.321}, "timestamp": "2026-01-30T14:16:40.109803"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3548.425, "latencies_ms": [3548.425], "images_per_second": 0.282, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with warm lighting, and the wooden wine rack is filled with bottles of wine.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14001.8, "ram_available_mb": 48839.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.276}, "power_stats": {"power_gpu_soc_mean_watts": 22.859, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 72.276}, "timestamp": "2026-01-30T14:16:45.695669"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4020.488, "latencies_ms": [4020.488], "images_per_second": 0.249, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A tennis player is in the middle of a powerful swing with a blue and white tennis racket, attempting to hit a yellow tennis ball that is in the air.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.848}, "power_stats": {"power_gpu_soc_mean_watts": 21.292, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 70.848}, "timestamp": "2026-01-30T14:16:51.762403"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6236.747, "latencies_ms": [6236.747], "images_per_second": 0.16, "prompt_tokens": 1114, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. tennis racket: 1\n2. tennis ball: 1\n3. grass court: 1\n4. player: 1\n5. white shirt: 1\n6. white shorts: 1\n7. blue and white striped tennis racket: 1\n8. white wristband: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.135}, "power_stats": {"power_gpu_soc_mean_watts": 17.854, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 69.135}, "timestamp": "2026-01-30T14:17:00.022519"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5281.308, "latencies_ms": [5281.308], "images_per_second": 0.189, "prompt_tokens": 1118, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The tennis player is in the foreground, with the tennis ball in the middle ground, and the green grass of the tennis court in the background. The player is positioned to the left of the tennis ball, and the tennis court extends to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13999.9, "ram_available_mb": 48841.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.409}, "power_stats": {"power_gpu_soc_mean_watts": 18.964, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 70.409}, "timestamp": "2026-01-30T14:17:07.336982"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3128.034, "latencies_ms": [3128.034], "images_per_second": 0.32, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A tennis player is playing on a grass court, swinging his racket to hit a ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.9, "ram_available_mb": 48841.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.345, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 75.538}, "timestamp": "2026-01-30T14:17:12.508870"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5584.71, "latencies_ms": [5584.71], "images_per_second": 0.179, "prompt_tokens": 1110, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a dynamic moment on a grass court, where a tennis player is in the midst of a powerful swing with a blue and white racket. The grass is a vibrant green, contrasting with the player's white attire. The lighting is natural and bright, suggesting it's a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.234}, "power_stats": {"power_gpu_soc_mean_watts": 18.639, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 68.234}, "timestamp": "2026-01-30T14:17:20.137142"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3388.555, "latencies_ms": [3388.555], "images_per_second": 0.295, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A cat is standing on a wooden shelf in front of a television, which is displaying a man in a suit.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.75}, "power_stats": {"power_gpu_soc_mean_watts": 22.949, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 72.75}, "timestamp": "2026-01-30T14:17:25.559464"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5460.855, "latencies_ms": [5460.855], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. cat: 1\n2. television: 1\n3. shelf: 1\n4. remote control: 1\n5. cup: 1\n6. bookshelf: 1\n7. wall: 1\n8. curtain: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.852, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.957}, "timestamp": "2026-01-30T14:17:33.053892"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4344.637, "latencies_ms": [4344.637], "images_per_second": 0.23, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The cat is positioned to the left of the television, which is located in the background. The television is situated on the right side of the wooden shelf, which is situated in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.694}, "power_stats": {"power_gpu_soc_mean_watts": 20.498, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 67.694}, "timestamp": "2026-01-30T14:17:39.410322"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2876.007, "latencies_ms": [2876.007], "images_per_second": 0.348, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cat is on top of a TV stand, looking at the TV.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.083}, "power_stats": {"power_gpu_soc_mean_watts": 24.524, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.298, "gpu_utilization_percent_mean": 78.083}, "timestamp": "2026-01-30T14:17:44.335772"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3125.5, "latencies_ms": [3125.5], "images_per_second": 0.32, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The cat is white and brown, the television is black, and the room is well lit.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.744, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-30T14:17:49.503514"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4849.706, "latencies_ms": [4849.706], "images_per_second": 0.206, "prompt_tokens": 1099, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a blue circular sign with a white silhouette of a person and a child riding a bicycle, and a white rectangular sign with black Chinese characters that read \"\u513f\u7ae5\u8def\" (children's road).", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.67, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 67.775}, "timestamp": "2026-01-30T14:17:56.388616"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5403.737, "latencies_ms": [5403.737], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sign: 3\n2. tree: 1\n3. bicycle: 1\n4. road sign: 1\n5. pole: 1\n6. sky: 1\n7. sun: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.978}, "power_stats": {"power_gpu_soc_mean_watts": 18.996, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 68.978}, "timestamp": "2026-01-30T14:18:03.837780"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4627.136, "latencies_ms": [4627.136], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sign is located in the foreground of the image, with the blue circle sign positioned above the white sign. The blue circle sign is to the left of the white sign, and the trees are in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.156, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 66.789}, "timestamp": "2026-01-30T14:18:10.494635"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5040.958, "latencies_ms": [5040.958], "images_per_second": 0.198, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a street scene with a blue and white sign featuring a family and a bicycle, indicating a pedestrian crossing. The sign is mounted on a metal pole, and the background reveals a clear blue sky and lush green trees, suggesting a pleasant day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.405}, "power_stats": {"power_gpu_soc_mean_watts": 19.485, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.405}, "timestamp": "2026-01-30T14:18:17.554921"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4618.434, "latencies_ms": [4618.434], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a blue and white sign with a symbol of a person and a child on it, and a white sign with Chinese characters on it. The sky is clear and blue, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.303, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 69.816}, "timestamp": "2026-01-30T14:18:24.209396"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3286.407, "latencies_ms": [3286.407], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young girl with black hair is sitting at a table in a restaurant, eating a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 10.7, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.073, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 74.37}, "timestamp": "2026-01-30T14:18:29.544683"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3765.658, "latencies_ms": [3765.658], "images_per_second": 0.266, "prompt_tokens": 1113, "response_tokens_est": 29, "n_tiles": 1, "output_text": " table: 1, chair: 1, pizza: 1, glass: 1, book: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.677}, "power_stats": {"power_gpu_soc_mean_watts": 22.008, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 71.677}, "timestamp": "2026-01-30T14:18:35.356200"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6153.452, "latencies_ms": [6153.452], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The girl is sitting at a table in the foreground, with a glass of water and a pizza on the table in front of her. The pizza is on the left side of the table, while the glass of water is on the right side. The background shows other tables and chairs, indicating that the girl is in a restaurant or cafe.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 17.978, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T14:18:43.529096"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3083.668, "latencies_ms": [3083.668], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl is sitting at a table in a restaurant, eating a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.974, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.252, "gpu_utilization_percent_mean": 74.52}, "timestamp": "2026-01-30T14:18:48.649925"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4295.297, "latencies_ms": [4295.297], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is taken in a dimly lit restaurant with warm lighting. The colors in the image are mostly muted with the exception of the girl's hair, which is a vibrant yellow.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.389}, "power_stats": {"power_gpu_soc_mean_watts": 20.676, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 71.389}, "timestamp": "2026-01-30T14:18:54.990834"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4652.283, "latencies_ms": [4652.283], "images_per_second": 0.215, "prompt_tokens": 1099, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image captures a meal spread out on a kitchen counter, featuring a variety of dishes including a bowl of broccoli, a plate of rice, and a plate of meat, all set against the backdrop of a wooden wall.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.154}, "power_stats": {"power_gpu_soc_mean_watts": 20.0, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.154}, "timestamp": "2026-01-30T14:19:01.686913"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4022.809, "latencies_ms": [4022.809], "images_per_second": 0.249, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bowl: 1, plate: 2, glass: 1, food: 1, broccoli: 1, cauliflower: 1, cauliflower: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.394}, "power_stats": {"power_gpu_soc_mean_watts": 21.669, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.156, "gpu_utilization_percent_mean": 73.394}, "timestamp": "2026-01-30T14:19:07.743841"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5579.675, "latencies_ms": [5579.675], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The main objects are arranged in a way that the plates of food are placed in the foreground, with the bowls of vegetables and the box of bread in the background. The plates of food are positioned to the left of the bowls, and the box of bread is located to the right of the bowls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.957}, "power_stats": {"power_gpu_soc_mean_watts": 18.827, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 70.957}, "timestamp": "2026-01-30T14:19:15.341236"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3124.308, "latencies_ms": [3124.308], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are gathered around a table in a kitchen, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.749, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.228, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T14:19:20.476480"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5659.689, "latencies_ms": [5659.689], "images_per_second": 0.177, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a variety of food items on a stainless steel countertop, with a wooden cabinet in the background. The lighting is natural, coming from a window out of frame, and the colors are vibrant and varied, with the food items displaying a range of greens, reds, and browns.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.367, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 68.021}, "timestamp": "2026-01-30T14:19:28.166790"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4292.264, "latencies_ms": [4292.264], "images_per_second": 0.233, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image captures a bustling city street with a green bus, a white truck, and a red car driving down the road, while a black car is parked on the side of the street.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.842, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 73.278}, "timestamp": "2026-01-30T14:19:34.504656"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5574.039, "latencies_ms": [5574.039], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Bus: 1\n2. Car: 4\n3. Truck: 1\n4. Van: 1\n5. Bus stop: 1\n6. Street sign: 1\n7. Building: 3\n8. Tree: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.319}, "power_stats": {"power_gpu_soc_mean_watts": 18.52, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 69.319}, "timestamp": "2026-01-30T14:19:42.120344"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4516.372, "latencies_ms": [4516.372], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The bus is positioned in the middle of the street, with the cars on the left and the sidewalk on the right. The bus is closer to the camera than the cars, and the sidewalk is farther away.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.553}, "power_stats": {"power_gpu_soc_mean_watts": 20.461, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-30T14:19:48.649758"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5085.074, "latencies_ms": [5085.074], "images_per_second": 0.197, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a bustling city street with a variety of vehicles, including cars, buses, and trucks, navigating through the traffic. The street is lined with tall buildings, and there are trees and street signs visible, indicating a well-developed urban area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.326}, "power_stats": {"power_gpu_soc_mean_watts": 19.172, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 69.326}, "timestamp": "2026-01-30T14:19:55.795514"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5050.035, "latencies_ms": [5050.035], "images_per_second": 0.198, "prompt_tokens": 1109, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a vibrant city street bathed in natural light, with the sun casting a warm glow on the buildings and trees. The colors are predominantly muted with the exception of the green and yellow bus, which stands out against the urban backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.429}, "power_stats": {"power_gpu_soc_mean_watts": 19.295, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 68.429}, "timestamp": "2026-01-30T14:20:02.864813"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3723.394, "latencies_ms": [3723.394], "images_per_second": 0.269, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A black laptop computer with a Toshiba brand name on it is sitting on a table with a cell phone and a remote control nearby.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.806}, "power_stats": {"power_gpu_soc_mean_watts": 22.1, "power_cpu_cv_mean_watts": 1.266, "power_sys_5v0_mean_watts": 8.172, "gpu_utilization_percent_mean": 72.806}, "timestamp": "2026-01-30T14:20:08.606828"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4246.476, "latencies_ms": [4246.476], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " laptop: 1, phone: 2, remote: 1, cell phone: 1, tv: 1, tv remote: 1, tv stand: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.229}, "power_stats": {"power_gpu_soc_mean_watts": 20.855, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 70.229}, "timestamp": "2026-01-30T14:20:14.888275"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3810.251, "latencies_ms": [3810.251], "images_per_second": 0.262, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The laptop is on the left side of the table, the cell phone is on the right side, and the remote is in front of the laptop.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.719}, "power_stats": {"power_gpu_soc_mean_watts": 21.796, "power_cpu_cv_mean_watts": 1.326, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 72.719}, "timestamp": "2026-01-30T14:20:20.734532"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3244.615, "latencies_ms": [3244.615], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person is sitting at a table with a laptop, a cell phone, and a remote control.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.852}, "power_stats": {"power_gpu_soc_mean_watts": 23.179, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 75.852}, "timestamp": "2026-01-30T14:20:26.018028"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3003.908, "latencies_ms": [3003.908], "images_per_second": 0.333, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The laptop is black, the phone is black, and the table is white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.622, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 74.56}, "timestamp": "2026-01-30T14:20:31.070593"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4210.297, "latencies_ms": [4210.297], "images_per_second": 0.238, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image shows a cluttered desk with a computer monitor, keyboard, and laptop, surrounded by books, a water bottle, and a pen, with a window in the background.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.029}, "power_stats": {"power_gpu_soc_mean_watts": 20.846, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T14:20:37.332880"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5729.633, "latencies_ms": [5729.633], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. monitor: 1\n2. keyboard: 1\n3. mouse: 1\n4. laptop: 1\n5. books: 10\n6. pen: 1\n7. water bottle: 1\n8. window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.938}, "power_stats": {"power_gpu_soc_mean_watts": 17.969, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 66.938}, "timestamp": "2026-01-30T14:20:45.072970"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5446.327, "latencies_ms": [5446.327], "images_per_second": 0.184, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The computer monitor is positioned to the left of the keyboard, with the laptop to its right. The books are stacked on the left side of the desk, while the water bottle is placed on the right side. The window is located behind the desk, providing natural light to the workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.652}, "power_stats": {"power_gpu_soc_mean_watts": 18.705, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 69.652}, "timestamp": "2026-01-30T14:20:52.535392"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3228.829, "latencies_ms": [3228.829], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A cluttered desk with a computer, books, and a laptop is in front of a window.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.485, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 74.731}, "timestamp": "2026-01-30T14:20:57.774139"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3302.675, "latencies_ms": [3302.675], "images_per_second": 0.303, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through a window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.148, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.197, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-30T14:21:03.118987"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3602.573, "latencies_ms": [3602.573], "images_per_second": 0.278, "prompt_tokens": 1100, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man in a helmet and black shirt is jumping in the air with his skateboard while a crowd of people watch from the stands.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.475, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 75.033}, "timestamp": "2026-01-30T14:21:08.781759"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5471.57, "latencies_ms": [5471.57], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. skateboard: 1\n4. crowd: 1\n5. camera: 1\n6. banner: 1\n7. railing: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.196}, "power_stats": {"power_gpu_soc_mean_watts": 18.767, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 71.196}, "timestamp": "2026-01-30T14:21:16.288896"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4287.662, "latencies_ms": [4287.662], "images_per_second": 0.233, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skateboarder is in the foreground, performing a trick in the air, while the crowd is in the background. The skateboarder is closer to the camera than the crowd.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.743}, "power_stats": {"power_gpu_soc_mean_watts": 20.981, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.743}, "timestamp": "2026-01-30T14:21:22.595793"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3150.121, "latencies_ms": [3150.121], "images_per_second": 0.317, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A skateboarder is performing a trick in the air while being filmed by a cameraman.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.687, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T14:21:27.799691"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4272.111, "latencies_ms": [4272.111], "images_per_second": 0.234, "prompt_tokens": 1110, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a skateboarder performing a trick in an indoor arena with a crowd of spectators. The lighting is dim, and the skateboarder is wearing a helmet and protective gear.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.543}, "power_stats": {"power_gpu_soc_mean_watts": 21.075, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 73.543}, "timestamp": "2026-01-30T14:21:34.114550"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3549.297, "latencies_ms": [3549.297], "images_per_second": 0.282, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A red fire hydrant with a smiley face and a smiley face on it is on the side of the road.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.241}, "power_stats": {"power_gpu_soc_mean_watts": 22.491, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.158, "gpu_utilization_percent_mean": 74.241}, "timestamp": "2026-01-30T14:21:39.690732"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4273.956, "latencies_ms": [4273.956], "images_per_second": 0.234, "prompt_tokens": 1114, "response_tokens_est": 37, "n_tiles": 1, "output_text": " hydrant: 1\nfire hydrant: 1\nstreet: 1\ntree: 1\ncar: 1\nbuilding: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.857}, "power_stats": {"power_gpu_soc_mean_watts": 20.87, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 71.857}, "timestamp": "2026-01-30T14:21:46.000234"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5073.174, "latencies_ms": [5073.174], "images_per_second": 0.197, "prompt_tokens": 1118, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The fire hydrant is located on the right side of the image, in the foreground, and is positioned near the edge of the frame. The street is in the background, with a car parked on the left side and a tree on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.3, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.476}, "power_stats": {"power_gpu_soc_mean_watts": 19.505, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.476}, "timestamp": "2026-01-30T14:21:53.089224"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3067.643, "latencies_ms": [3067.643], "images_per_second": 0.326, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A red fire hydrant with a smiley face is on the side of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.3, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.719, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.293, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T14:21:58.212053"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3551.084, "latencies_ms": [3551.084], "images_per_second": 0.282, "prompt_tokens": 1110, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The fire hydrant is bright red with black markings, and it is located on a sunny day with a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.828}, "power_stats": {"power_gpu_soc_mean_watts": 22.491, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 72.828}, "timestamp": "2026-01-30T14:22:03.786314"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3112.118, "latencies_ms": [3112.118], "images_per_second": 0.321, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A green cart with a bunch of old suitcases on it is sitting outside a building.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.783, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 76.24}, "timestamp": "2026-01-30T14:22:08.932852"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6266.257, "latencies_ms": [6266.257], "images_per_second": 0.16, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. green trolley - 1\n2. brown suitcase - 1\n3. blue suitcase - 1\n4. green suitcase - 1\n5. brown leather suitcase - 1\n6. green metal cart - 1\n7. green door - 1\n8. poster - 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.038}, "power_stats": {"power_gpu_soc_mean_watts": 17.727, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 68.038}, "timestamp": "2026-01-30T14:22:17.234594"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6317.901, "latencies_ms": [6317.901], "images_per_second": 0.158, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The green cart is positioned in the foreground, with the suitcases stacked on top of it. The suitcases are arranged in a haphazard manner, with some leaning against each other and others stacked on top of one another. The cart is located near a building with green doors and windows, and there is a poster on the wall behind the cart.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.792}, "power_stats": {"power_gpu_soc_mean_watts": 17.649, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 69.792}, "timestamp": "2026-01-30T14:22:25.590843"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3122.777, "latencies_ms": [3122.777], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A green cart is filled with old suitcases and a cart is parked outside a building.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.52}, "power_stats": {"power_gpu_soc_mean_watts": 23.852, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 76.52}, "timestamp": "2026-01-30T14:22:30.749683"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4554.511, "latencies_ms": [4554.511], "images_per_second": 0.22, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a green trolley with a stack of old suitcases on it, with the suitcases being brown, blue, and green. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.684}, "power_stats": {"power_gpu_soc_mean_watts": 20.138, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 71.684}, "timestamp": "2026-01-30T14:22:37.332785"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3162.196, "latencies_ms": [3162.196], "images_per_second": 0.316, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl in a pink dress is playing a video game on a Wii console.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.159, "power_cpu_cv_mean_watts": 1.031, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 78.385}, "timestamp": "2026-01-30T14:22:42.533007"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6085.375, "latencies_ms": [6085.375], "images_per_second": 0.164, "prompt_tokens": 1113, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. girl: 1\n2. sofa: 1\n3. window blinds: 1\n4. white object: 1\n5. girl's hand: 1\n6. girl's arm: 1\n7. girl's leg: 1\n8. girl's foot: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.098}, "power_stats": {"power_gpu_soc_mean_watts": 18.065, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.098}, "timestamp": "2026-01-30T14:22:50.651906"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4477.885, "latencies_ms": [4477.885], "images_per_second": 0.223, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The girl is standing in the foreground of the image, holding a Wii remote in her right hand. The couch is located in the background, and the window blinds are positioned behind the couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.333, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T14:22:57.170303"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3123.716, "latencies_ms": [3123.716], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young girl is playing a video game on a Wii console in a living room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.08}, "power_stats": {"power_gpu_soc_mean_watts": 23.813, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 75.08}, "timestamp": "2026-01-30T14:23:02.305521"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4341.601, "latencies_ms": [4341.601], "images_per_second": 0.23, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is a photograph with a warm and soft lighting, and the colors are vibrant and bright. The girl is wearing a pink dress with a floral pattern, and the couch is brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.498, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 70.833}, "timestamp": "2026-01-30T14:23:08.697225"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3595.538, "latencies_ms": [3595.538], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A cluttered office desk with a laptop, keyboard, and headphones is surrounded by a trash can, computer tower, and chair.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 22.208, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.157, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-30T14:23:14.321080"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4632.639, "latencies_ms": [4632.639], "images_per_second": 0.216, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " 1. black laptop\n2. black headphones\n3. black keyboard\n4. black mouse\n5. black computer monitor\n6. black computer mouse\n7. black computer keyboard\n8. black computer mouse", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.215, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T14:23:20.989993"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3900.815, "latencies_ms": [3900.815], "images_per_second": 0.256, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The laptop is on the left side of the desk, the chair is on the right side, and the trash can is in the middle of the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.686, "power_cpu_cv_mean_watts": 1.239, "power_sys_5v0_mean_watts": 8.138, "gpu_utilization_percent_mean": 73.031}, "timestamp": "2026-01-30T14:23:26.929514"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3115.811, "latencies_ms": [3115.811], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A cluttered office with a computer on a desk, a chair, and a trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.231}, "power_stats": {"power_gpu_soc_mean_watts": 23.867, "power_cpu_cv_mean_watts": 1.031, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 76.231}, "timestamp": "2026-01-30T14:23:32.085073"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4501.986, "latencies_ms": [4501.986], "images_per_second": 0.222, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the windows, and the walls are painted white. The desk is made of glass and metal, and the chair is upholstered in gray fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.784}, "power_stats": {"power_gpu_soc_mean_watts": 20.615, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 68.784}, "timestamp": "2026-01-30T14:23:38.611287"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3037.025, "latencies_ms": [3037.025], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is eating a pizza with mushrooms, peppers, and cheese on it.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.526, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-30T14:23:43.684482"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5397.917, "latencies_ms": [5397.917], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. plate: 1\n2. pizza: 1\n3. fork: 1\n4. hand: 1\n5. cheese: 1\n6. pepperoni: 1\n7. mushrooms: 1\n8. peppers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.156}, "power_stats": {"power_gpu_soc_mean_watts": 19.016, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 70.156}, "timestamp": "2026-01-30T14:23:51.143105"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5099.202, "latencies_ms": [5099.202], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The pizza is in the foreground, on the left side of the image. The fork is in the right hand of the person, who is in the background. The red and white checkered tablecloth is in the background, covering the entire table.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.977}, "power_stats": {"power_gpu_soc_mean_watts": 19.247, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 69.977}, "timestamp": "2026-01-30T14:23:58.269009"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3038.282, "latencies_ms": [3038.282], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is eating a pizza with mushrooms, peppers, and cheese on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.669, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T14:24:03.321442"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2842.575, "latencies_ms": [2842.575], "images_per_second": 0.352, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The pizza is red and white, and the plate is white.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.304}, "power_stats": {"power_gpu_soc_mean_watts": 24.229, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.233, "gpu_utilization_percent_mean": 82.304}, "timestamp": "2026-01-30T14:24:08.205123"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3933.058, "latencies_ms": [3933.058], "images_per_second": 0.254, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A white and red bus with the words \"Metropolitan Transit System\" on the side is parked on the street.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.781}, "power_stats": {"power_gpu_soc_mean_watts": 25.171, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.56, "gpu_utilization_percent_mean": 75.781}, "timestamp": "2026-01-30T14:24:14.168942"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6054.217, "latencies_ms": [6054.217], "images_per_second": 0.165, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bus: 1\n2. windows: 10\n3. seats: 2\n4. people: 2\n5. trees: 1\n6. building: 1\n7. sign: 1\n8. wheels: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.118}, "power_stats": {"power_gpu_soc_mean_watts": 20.954, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 71.118}, "timestamp": "2026-01-30T14:24:22.272519"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4863.387, "latencies_ms": [4863.387], "images_per_second": 0.206, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bus is parked on the left side of the street, with the sidewalk and trees on the right side. The bus is in the foreground, with the building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.425}, "power_stats": {"power_gpu_soc_mean_watts": 22.963, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.389, "gpu_utilization_percent_mean": 75.425}, "timestamp": "2026-01-30T14:24:29.157114"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4019.695, "latencies_ms": [4019.695], "images_per_second": 0.249, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A white and red bus is parked on the side of the road, with a building and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.394}, "power_stats": {"power_gpu_soc_mean_watts": 25.078, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 8.525, "gpu_utilization_percent_mean": 77.394}, "timestamp": "2026-01-30T14:24:35.199733"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3664.158, "latencies_ms": [3664.158], "images_per_second": 0.273, "prompt_tokens": 1442, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The bus is white and red, and it is parked in a sunny parking lot.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.933}, "power_stats": {"power_gpu_soc_mean_watts": 25.947, "power_cpu_cv_mean_watts": 0.881, "power_sys_5v0_mean_watts": 8.565, "gpu_utilization_percent_mean": 78.933}, "timestamp": "2026-01-30T14:24:40.903780"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3886.013, "latencies_ms": [3886.013], "images_per_second": 0.257, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A baseball glove and a baseball cap are placed on the ground, with the cap resting on the glove.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.375}, "power_stats": {"power_gpu_soc_mean_watts": 24.822, "power_cpu_cv_mean_watts": 0.938, "power_sys_5v0_mean_watts": 8.535, "gpu_utilization_percent_mean": 79.375}, "timestamp": "2026-01-30T14:24:46.820951"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5043.218, "latencies_ms": [5043.218], "images_per_second": 0.198, "prompt_tokens": 1446, "response_tokens_est": 40, "n_tiles": 1, "output_text": " baseball cap: 1, baseball glove: 1, baseball: 1, baseball bat: 0, baseball field: 0, baseball bat: 0, baseball field: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.262}, "power_stats": {"power_gpu_soc_mean_watts": 22.698, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 8.38, "gpu_utilization_percent_mean": 73.262}, "timestamp": "2026-01-30T14:24:53.914919"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5186.65, "latencies_ms": [5186.65], "images_per_second": 0.193, "prompt_tokens": 1450, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The baseball cap is positioned to the left of the baseball glove, which is placed in the center of the image. The glove is located in the foreground of the image, while the cap is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.186}, "power_stats": {"power_gpu_soc_mean_watts": 22.32, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.35, "gpu_utilization_percent_mean": 71.186}, "timestamp": "2026-01-30T14:25:01.149525"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3498.837, "latencies_ms": [3498.837], "images_per_second": 0.286, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A baseball glove and a baseball cap are placed on the ground.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.607}, "power_stats": {"power_gpu_soc_mean_watts": 25.952, "power_cpu_cv_mean_watts": 0.815, "power_sys_5v0_mean_watts": 8.558, "gpu_utilization_percent_mean": 83.607}, "timestamp": "2026-01-30T14:25:06.660856"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4657.651, "latencies_ms": [4657.651], "images_per_second": 0.215, "prompt_tokens": 1442, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image has a blue baseball cap with a white logo on it, and the baseball glove is brown. The baseball cap is placed on top of the baseball glove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.872}, "power_stats": {"power_gpu_soc_mean_watts": 23.243, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.391, "gpu_utilization_percent_mean": 73.872}, "timestamp": "2026-01-30T14:25:13.363177"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3068.556, "latencies_ms": [3068.556], "images_per_second": 0.326, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man wearing a red shirt is riding a surfboard on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.99, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.28, "gpu_utilization_percent_mean": 78.16}, "timestamp": "2026-01-30T14:25:18.497085"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5708.486, "latencies_ms": [5708.486], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Water: 1\n6. Sky: 1\n7. Clouds: 1\n8. Surfboard logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.435, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T14:25:26.239656"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4909.637, "latencies_ms": [4909.637], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The surfer is positioned on the left side of the image, with the wave on the right side. The surfer is in the foreground, with the wave in the background. The surfer is closer to the camera than the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.439}, "power_stats": {"power_gpu_soc_mean_watts": 19.59, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 69.439}, "timestamp": "2026-01-30T14:25:33.173971"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2704.447, "latencies_ms": [2704.447], "images_per_second": 0.37, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is surfing on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.682}, "power_stats": {"power_gpu_soc_mean_watts": 24.623, "power_cpu_cv_mean_watts": 0.782, "power_sys_5v0_mean_watts": 8.295, "gpu_utilization_percent_mean": 78.682}, "timestamp": "2026-01-30T14:25:37.933603"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4630.492, "latencies_ms": [4630.492], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a surfer riding a wave in a vibrant blue ocean, with the surfer wearing a red shirt and a yellow surfboard. The lighting is bright and sunny, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.305, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 70.789}, "timestamp": "2026-01-30T14:25:44.584176"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3311.67, "latencies_ms": [3311.67], "images_per_second": 0.302, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A black and white photo of a bathroom with a toilet, sink, and a mirror above the sink.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.63}, "power_stats": {"power_gpu_soc_mean_watts": 23.118, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.194, "gpu_utilization_percent_mean": 75.63}, "timestamp": "2026-01-30T14:25:49.936893"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4152.041, "latencies_ms": [4152.041], "images_per_second": 0.241, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " toilet: 1, sink: 1, mirror: 1, cup: 1, bottle: 1, cupboard: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.941}, "power_stats": {"power_gpu_soc_mean_watts": 21.126, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 72.941}, "timestamp": "2026-01-30T14:25:56.106538"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4042.337, "latencies_ms": [4042.337], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the sink is on the right side. The sink is positioned closer to the camera than the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.758}, "power_stats": {"power_gpu_soc_mean_watts": 21.329, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.106, "gpu_utilization_percent_mean": 73.758}, "timestamp": "2026-01-30T14:26:02.170994"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2710.418, "latencies_ms": [2710.418], "images_per_second": 0.369, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A bathroom with a toilet, sink, and mirror.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.818}, "power_stats": {"power_gpu_soc_mean_watts": 24.55, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.263, "gpu_utilization_percent_mean": 83.818}, "timestamp": "2026-01-30T14:26:06.905166"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3014.899, "latencies_ms": [3014.899], "images_per_second": 0.332, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The bathroom is black and white, with a granite countertop and a white toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.04}, "power_stats": {"power_gpu_soc_mean_watts": 24.053, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.301, "gpu_utilization_percent_mean": 78.04}, "timestamp": "2026-01-30T14:26:11.948860"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4443.896, "latencies_ms": [4443.896], "images_per_second": 0.225, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a picturesque scene of a white clock tower with a blue dome, standing tall against a backdrop of a clear blue sky, with a white ornate structure adorned with intricate designs in the foreground.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.3, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.189}, "power_stats": {"power_gpu_soc_mean_watts": 20.322, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 69.189}, "timestamp": "2026-01-30T14:26:18.463900"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5719.866, "latencies_ms": [5719.866], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. clock tower: 1\n2. roof tiles: 1\n3. gazebo: 1\n4. clock face: 1\n5. antenna: 1\n6. roof: 1\n7. tree: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.3, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.438}, "power_stats": {"power_gpu_soc_mean_watts": 18.277, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 68.438}, "timestamp": "2026-01-30T14:26:26.208850"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5794.62, "latencies_ms": [5794.62], "images_per_second": 0.173, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The clock tower is positioned in the background, far away from the camera, and is surrounded by a clear blue sky. The ornate white and blue clock face is prominently displayed in the foreground, close to the camera. The white roof tiles are visible in the foreground, while the green trees are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.625}, "power_stats": {"power_gpu_soc_mean_watts": 18.267, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 68.625}, "timestamp": "2026-01-30T14:26:34.037028"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4934.762, "latencies_ms": [4934.762], "images_per_second": 0.203, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a picturesque scene of a clock tower standing tall against the backdrop of a clear blue sky. The tower, painted in pristine white, is adorned with a vibrant green roof and a clock face that stands out against its white facade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.78}, "power_stats": {"power_gpu_soc_mean_watts": 19.473, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 70.78}, "timestamp": "2026-01-30T14:26:41.002115"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4801.174, "latencies_ms": [4801.174], "images_per_second": 0.208, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image features a white clock tower with a blue dome and a red roof, set against a clear blue sky. The tower is adorned with intricate white and gold detailing, and the surrounding area is covered in terracotta tiles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13991.0, "ram_available_mb": 48849.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.1}, "power_stats": {"power_gpu_soc_mean_watts": 19.731, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 70.1}, "timestamp": "2026-01-30T14:26:47.824037"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3934.451, "latencies_ms": [3934.451], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of elephants is seen walking on a dirt path in a forest, with one elephant in the foreground and others in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13991.0, "ram_available_mb": 48849.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13991.0, "ram_available_mb": 48849.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.094}, "power_stats": {"power_gpu_soc_mean_watts": 21.498, "power_cpu_cv_mean_watts": 1.238, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 72.094}, "timestamp": "2026-01-30T14:26:53.783357"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4350.188, "latencies_ms": [4350.188], "images_per_second": 0.23, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.0, "ram_available_mb": 48849.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13990.1, "ram_available_mb": 48850.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.806}, "power_stats": {"power_gpu_soc_mean_watts": 20.776, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 70.806}, "timestamp": "2026-01-30T14:27:00.176892"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4020.818, "latencies_ms": [4020.818], "images_per_second": 0.249, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The main elephant is in the foreground, with the other elephants in the background. The elephants are walking on a dirt path, with trees and bushes on either side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.1, "ram_available_mb": 48850.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13989.4, "ram_available_mb": 48851.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.45, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 71.576}, "timestamp": "2026-01-30T14:27:06.229545"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3608.64, "latencies_ms": [3608.64], "images_per_second": 0.277, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A herd of elephants is walking through a forest, with one elephant in the foreground and the rest of the herd in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13989.4, "ram_available_mb": 48851.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13988.8, "ram_available_mb": 48852.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.2, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.141, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-30T14:27:11.871611"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3008.656, "latencies_ms": [3008.656], "images_per_second": 0.332, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The elephants are gray, the trees are green, and the ground is brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13988.8, "ram_available_mb": 48852.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13988.5, "ram_available_mb": 48852.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.639, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.213, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T14:27:16.908180"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2842.783, "latencies_ms": [2842.783], "images_per_second": 0.352, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " An open refrigerator with a bottle of yellow liquid on the top shelf.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13988.5, "ram_available_mb": 48852.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13988.4, "ram_available_mb": 48852.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.696}, "power_stats": {"power_gpu_soc_mean_watts": 24.632, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.316, "gpu_utilization_percent_mean": 79.696}, "timestamp": "2026-01-30T14:27:21.784631"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6050.389, "latencies_ms": [6050.389], "images_per_second": 0.165, "prompt_tokens": 1114, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. Refrigerator: 1\n2. Egg carton: 1\n3. Bottle: 1\n4. Shelf: 4\n5. Door: 2\n6. Door handle: 1\n7. Refrigerator door: 1\n8. Refrigerator door handle: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13988.4, "ram_available_mb": 48852.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13989.1, "ram_available_mb": 48851.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.039}, "power_stats": {"power_gpu_soc_mean_watts": 17.986, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 69.039}, "timestamp": "2026-01-30T14:27:29.889837"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4978.225, "latencies_ms": [4978.225], "images_per_second": 0.201, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The refrigerator is located in the kitchen, with the left side of the door being closer to the camera than the right side. The bottle of mustard is placed on the top shelf of the refrigerator, which is positioned in the middle of the refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13989.1, "ram_available_mb": 48851.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13988.7, "ram_available_mb": 48852.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.569, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 69.195}, "timestamp": "2026-01-30T14:27:36.887790"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5190.823, "latencies_ms": [5190.823], "images_per_second": 0.193, "prompt_tokens": 1112, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a scene of a kitchen, where an open refrigerator stands, its interior empty and devoid of any food items. The refrigerator, with its white exterior, is situated on a wooden floor, and its door is open, revealing the emptiness of its shelves.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13988.7, "ram_available_mb": 48852.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13988.6, "ram_available_mb": 48852.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.651}, "power_stats": {"power_gpu_soc_mean_watts": 19.053, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.651}, "timestamp": "2026-01-30T14:27:44.100208"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2995.376, "latencies_ms": [2995.376], "images_per_second": 0.334, "prompt_tokens": 1110, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The refrigerator is white and has a light on inside. The floor is brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13988.6, "ram_available_mb": 48852.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13989.1, "ram_available_mb": 48851.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.876, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.244, "gpu_utilization_percent_mean": 74.4}, "timestamp": "2026-01-30T14:27:49.143166"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3356.985, "latencies_ms": [3356.985], "images_per_second": 0.298, "prompt_tokens": 1432, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A bunch of bananas are on a table with a purple background.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13989.1, "ram_available_mb": 48851.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13989.0, "ram_available_mb": 48851.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.259}, "power_stats": {"power_gpu_soc_mean_watts": 26.693, "power_cpu_cv_mean_watts": 0.815, "power_sys_5v0_mean_watts": 8.672, "gpu_utilization_percent_mean": 81.259}, "timestamp": "2026-01-30T14:27:54.535042"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2951.951, "latencies_ms": [2951.951], "images_per_second": 0.339, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " banana: 6", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13989.0, "ram_available_mb": 48851.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 13989.2, "ram_available_mb": 48851.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.75}, "power_stats": {"power_gpu_soc_mean_watts": 26.76, "power_cpu_cv_mean_watts": 0.617, "power_sys_5v0_mean_watts": 8.566, "gpu_utilization_percent_mean": 86.75}, "timestamp": "2026-01-30T14:27:59.529003"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4909.466, "latencies_ms": [4909.466], "images_per_second": 0.204, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The bananas are located in the foreground, with a purple object in the background. The bananas are stacked on top of each other, with the top banana being the closest to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13989.2, "ram_available_mb": 48851.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13989.2, "ram_available_mb": 48851.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.902}, "power_stats": {"power_gpu_soc_mean_watts": 22.94, "power_cpu_cv_mean_watts": 1.318, "power_sys_5v0_mean_watts": 8.382, "gpu_utilization_percent_mean": 72.902}, "timestamp": "2026-01-30T14:28:06.500211"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3440.825, "latencies_ms": [3440.825], "images_per_second": 0.291, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A bunch of bananas are on a table with a purple background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13989.2, "ram_available_mb": 48851.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13989.5, "ram_available_mb": 48851.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.714}, "power_stats": {"power_gpu_soc_mean_watts": 26.58, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.612, "gpu_utilization_percent_mean": 80.714}, "timestamp": "2026-01-30T14:28:11.962809"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3445.076, "latencies_ms": [3445.076], "images_per_second": 0.29, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The bananas are yellow and ripe, and the background is purple.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13989.5, "ram_available_mb": 48851.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13989.0, "ram_available_mb": 48851.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.036}, "power_stats": {"power_gpu_soc_mean_watts": 26.541, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.604, "gpu_utilization_percent_mean": 81.036}, "timestamp": "2026-01-30T14:28:17.441207"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4664.375, "latencies_ms": [4664.375], "images_per_second": 0.214, "prompt_tokens": 1432, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, there are four orange cylindrical bollards with yellow caps, standing in a row on a sidewalk, with a city street and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13989.0, "ram_available_mb": 48851.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13989.2, "ram_available_mb": 48851.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 22.937, "power_cpu_cv_mean_watts": 1.242, "power_sys_5v0_mean_watts": 8.394, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-30T14:28:24.183104"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6321.74, "latencies_ms": [6321.74], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Bollards: 4\n2. Trees: 2\n3. Buildings: 4\n4. Streetlights: 2\n5. Banners: 2\n6. Poles: 2\n7. Windows: 10\n8. Cars: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13989.2, "ram_available_mb": 48851.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13989.1, "ram_available_mb": 48851.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.868}, "power_stats": {"power_gpu_soc_mean_watts": 20.558, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.265, "gpu_utilization_percent_mean": 69.868}, "timestamp": "2026-01-30T14:28:32.516248"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5268.715, "latencies_ms": [5268.715], "images_per_second": 0.19, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The three orange bollards are positioned in the foreground, with the city buildings in the background. The bollards are located on the left side of the image, while the buildings extend across the right side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13989.1, "ram_available_mb": 48851.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13990.3, "ram_available_mb": 48850.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.159}, "power_stats": {"power_gpu_soc_mean_watts": 22.115, "power_cpu_cv_mean_watts": 1.337, "power_sys_5v0_mean_watts": 8.317, "gpu_utilization_percent_mean": 75.159}, "timestamp": "2026-01-30T14:28:39.819867"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4926.528, "latencies_ms": [4926.528], "images_per_second": 0.203, "prompt_tokens": 1444, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image captures a bustling city square with a row of orange bollards standing in the foreground, while a large building with a sign that reads \"WGN\" looms in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.3, "ram_available_mb": 48850.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13990.3, "ram_available_mb": 48850.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.561}, "power_stats": {"power_gpu_soc_mean_watts": 22.931, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.389, "gpu_utilization_percent_mean": 74.561}, "timestamp": "2026-01-30T14:28:46.786132"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4260.227, "latencies_ms": [4260.227], "images_per_second": 0.235, "prompt_tokens": 1442, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a city square with a row of orange bollards, a snow-covered sidewalk, and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13990.3, "ram_available_mb": 48850.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13990.0, "ram_available_mb": 48850.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.371}, "power_stats": {"power_gpu_soc_mean_watts": 24.404, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 8.475, "gpu_utilization_percent_mean": 76.371}, "timestamp": "2026-01-30T14:28:53.075952"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4356.095, "latencies_ms": [4356.095], "images_per_second": 0.23, "prompt_tokens": 1432, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A person wearing a helmet and a yellow shirt is riding a horse in a race, with a sign that says \"Magnum\" in the background.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 13990.0, "ram_available_mb": 48850.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13990.7, "ram_available_mb": 48850.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.278}, "power_stats": {"power_gpu_soc_mean_watts": 24.091, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.504, "gpu_utilization_percent_mean": 75.278}, "timestamp": "2026-01-30T14:28:59.490040"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6223.661, "latencies_ms": [6223.661], "images_per_second": 0.161, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. horse: 1\n3. cart: 1\n4. helmet: 1\n5. number: 1\n6. sign: 1\n7. grass: 1\n8. track: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13990.8, "ram_available_mb": 48850.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.288}, "power_stats": {"power_gpu_soc_mean_watts": 20.435, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 8.211, "gpu_utilization_percent_mean": 70.288}, "timestamp": "2026-01-30T14:29:07.767450"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5122.645, "latencies_ms": [5122.645], "images_per_second": 0.195, "prompt_tokens": 1450, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The horse is in the foreground, pulling the cart, while the rider is in the background. The cart is to the left of the horse, and the rider is to the right of the horse.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13990.8, "ram_available_mb": 48850.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.346, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.327, "gpu_utilization_percent_mean": 72.714}, "timestamp": "2026-01-30T14:29:14.911997"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4641.158, "latencies_ms": [4641.158], "images_per_second": 0.215, "prompt_tokens": 1444, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A young man wearing a helmet and a yellow shirt is riding a horse in a dirt track. The horse is pulling a cart with a number 8 on it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13991.0, "ram_available_mb": 48849.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.947}, "power_stats": {"power_gpu_soc_mean_watts": 23.62, "power_cpu_cv_mean_watts": 1.243, "power_sys_5v0_mean_watts": 8.423, "gpu_utilization_percent_mean": 73.947}, "timestamp": "2026-01-30T14:29:21.571419"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6424.804, "latencies_ms": [6424.804], "images_per_second": 0.156, "prompt_tokens": 1442, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a brown horse pulling a cart with a person wearing a helmet. The horse is running on a dirt track, and the background shows a grassy field with some trees. The lighting is natural, and the colors are vibrant, with the brown of the horse and the green of the grass standing out.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13991.0, "ram_available_mb": 48849.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.345, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 8.238, "gpu_utilization_percent_mean": 71.278}, "timestamp": "2026-01-30T14:29:30.019681"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3267.102, "latencies_ms": [3267.102], "images_per_second": 0.306, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A brown dog is standing on a wooden platform in a backyard with a tree full of oranges behind it.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13990.7, "ram_available_mb": 48850.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.074}, "power_stats": {"power_gpu_soc_mean_watts": 23.178, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 74.074}, "timestamp": "2026-01-30T14:29:35.318937"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5344.108, "latencies_ms": [5344.108], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. dog: 1\n2. fence: 1\n3. tree: 1\n4. grass: 1\n5. house: 1\n6. bench: 1\n7. wall: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13990.7, "ram_available_mb": 48850.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.068}, "power_stats": {"power_gpu_soc_mean_watts": 19.163, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 69.068}, "timestamp": "2026-01-30T14:29:42.682199"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4212.829, "latencies_ms": [4212.829], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The dog is standing on the left side of the image, with the tree and fence in the background. The dog is in the foreground, with the house and garden in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.117, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.158, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T14:29:48.927411"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3130.8, "latencies_ms": [3130.8], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A brown dog is standing on a wooden platform in a backyard with a tree full of oranges.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.778, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.265, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T14:29:54.085065"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3233.343, "latencies_ms": [3233.343], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The dog is brown, the fence is brown, the tree is green, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.804, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T14:29:59.335596"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5358.619, "latencies_ms": [5358.619], "images_per_second": 0.187, "prompt_tokens": 1099, "response_tokens_est": 56, "n_tiles": 1, "output_text": " In the image, a person is standing on a wooden bench with their feet on a sign that reads \"WE'RE HERE TO BE STRONG\". The bench is placed on a brick floor, and the background features a white wall with a blue and red graffiti-like design.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.862, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-30T14:30:06.748708"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3469.055, "latencies_ms": [3469.055], "images_per_second": 0.288, "prompt_tokens": 1113, "response_tokens_est": 24, "n_tiles": 1, "output_text": " bench: 1, person: 1, paper: 1, shoe: 1, brick: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.696, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T14:30:12.278224"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5873.064, "latencies_ms": [5873.064], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The bench is positioned in the foreground, with the person's legs and feet prominently displayed. The sign is placed to the left of the bench, suggesting it is a temporary or makeshift setup. The person's legs are positioned in the center of the image, with the bench serving as a platform for them to stand on.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.633}, "power_stats": {"power_gpu_soc_mean_watts": 18.254, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 68.633}, "timestamp": "2026-01-30T14:30:20.164370"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5457.696, "latencies_ms": [5457.696], "images_per_second": 0.183, "prompt_tokens": 1111, "response_tokens_est": 57, "n_tiles": 1, "output_text": " A person wearing bright orange pants and blue and yellow shoes is standing on a wooden bench. The bench is made of two wooden posts and a wooden plank. There is a piece of paper on the bench with the words \"WE'RE\" and \"WITH\" written on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.304}, "power_stats": {"power_gpu_soc_mean_watts": 18.678, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 69.304}, "timestamp": "2026-01-30T14:30:27.667861"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5758.457, "latencies_ms": [5758.457], "images_per_second": 0.174, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a wooden bench with a person's legs and feet on it, wearing bright orange pants and blue and yellow shoes. The bench is placed on a brick-paved ground, and the background is a plain white wall. The lighting in the image is natural, suggesting it was taken during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.551}, "power_stats": {"power_gpu_soc_mean_watts": 18.384, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 68.551}, "timestamp": "2026-01-30T14:30:35.456649"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4423.87, "latencies_ms": [4423.87], "images_per_second": 0.226, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a red sofa, a dining table set with a white tablecloth and silverware, a television mounted on the wall, and a window with brown curtains.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.865}, "power_stats": {"power_gpu_soc_mean_watts": 20.398, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 69.865}, "timestamp": "2026-01-30T14:30:41.932935"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5539.364, "latencies_ms": [5539.364], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. red sofa: 1\n2. table: 1\n3. lamp: 2\n4. vase: 1\n5. curtains: 2\n6. television: 1\n7. chair: 1\n8. book: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.064}, "power_stats": {"power_gpu_soc_mean_watts": 18.436, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 68.064}, "timestamp": "2026-01-30T14:30:49.519300"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4750.999, "latencies_ms": [4750.999], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The red sofa is located on the left side of the room, with the dining table and chairs situated in the middle. The television is positioned on the right side of the room, with the window and curtains behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.775}, "power_stats": {"power_gpu_soc_mean_watts": 19.77, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 68.775}, "timestamp": "2026-01-30T14:30:56.321528"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4246.974, "latencies_ms": [4246.974], "images_per_second": 0.235, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a red sofa, a dining table set with a white tablecloth and silverware, and a flat screen TV mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.343}, "power_stats": {"power_gpu_soc_mean_watts": 20.786, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 69.343}, "timestamp": "2026-01-30T14:31:02.604710"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4557.676, "latencies_ms": [4557.676], "images_per_second": 0.219, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The room is bathed in warm sunlight, casting a soft glow on the furnishings. The walls are painted a soothing light yellow, and the furniture is made of wood, giving the room a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.38, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 71.184}, "timestamp": "2026-01-30T14:31:09.179606"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3345.527, "latencies_ms": [3345.527], "images_per_second": 0.299, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A black frying pan filled with a mixture of broccoli, carrots, and meat is being stirred with a metal spoon.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.321}, "power_stats": {"power_gpu_soc_mean_watts": 23.224, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.262, "gpu_utilization_percent_mean": 74.321}, "timestamp": "2026-01-30T14:31:14.568741"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5819.251, "latencies_ms": [5819.251], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. broccoli: 12\n2. carrots: 10\n3. meat: 12\n4. potatoes: 10\n5. seasoning: 10\n6. broccoli: 12\n7. carrots: 10\n8. meat: 12", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.082}, "power_stats": {"power_gpu_soc_mean_watts": 18.412, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.082}, "timestamp": "2026-01-30T14:31:22.431205"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4359.606, "latencies_ms": [4359.606], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The broccoli is in the middle of the pan, the carrots are on the right side, and the meat is on the left side. The broccoli is closer to the camera than the carrots.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.917}, "power_stats": {"power_gpu_soc_mean_watts": 20.611, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.917}, "timestamp": "2026-01-30T14:31:28.815812"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3071.781, "latencies_ms": [3071.781], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A black frying pan is on a stove with broccoli, carrots, and meat in it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.16}, "power_stats": {"power_gpu_soc_mean_watts": 24.155, "power_cpu_cv_mean_watts": 1.025, "power_sys_5v0_mean_watts": 8.294, "gpu_utilization_percent_mean": 78.16}, "timestamp": "2026-01-30T14:31:33.912588"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6697.344, "latencies_ms": [6697.344], "images_per_second": 0.149, "prompt_tokens": 1109, "response_tokens_est": 78, "n_tiles": 1, "output_text": " The image features a black frying pan with a variety of vegetables, including broccoli, carrots, and onions, being cooked in a pan on a stove. The vegetables are brightly colored, with the broccoli being a vibrant green, the carrots being orange, and the onions being white. The lighting in the image is bright and even, suggesting that the photo was taken in a well-lit kitchen.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.982}, "power_stats": {"power_gpu_soc_mean_watts": 17.428, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 68.982}, "timestamp": "2026-01-30T14:31:42.659827"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2929.989, "latencies_ms": [2929.989], "images_per_second": 0.341, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three hot dogs with mustard on a plate are on a dark countertop.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.176, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-30T14:31:47.619152"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3536.433, "latencies_ms": [3536.433], "images_per_second": 0.283, "prompt_tokens": 1114, "response_tokens_est": 25, "n_tiles": 1, "output_text": " hot dog: 3, mustard: 3, bun: 3, plate: 1, book: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.483}, "power_stats": {"power_gpu_soc_mean_watts": 22.55, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 73.483}, "timestamp": "2026-01-30T14:31:53.177677"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4803.793, "latencies_ms": [4803.793], "images_per_second": 0.208, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The hot dogs are placed on the plate, which is located in the foreground of the image. The hot dogs are positioned to the left of the plate, and the book is located in the background, to the right of the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.65}, "power_stats": {"power_gpu_soc_mean_watts": 19.95, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.65}, "timestamp": "2026-01-30T14:31:59.996161"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2889.521, "latencies_ms": [2889.521], "images_per_second": 0.346, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three hot dogs with mustard on a plate are on a dark countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.303, "power_cpu_cv_mean_watts": 0.888, "power_sys_5v0_mean_watts": 8.312, "gpu_utilization_percent_mean": 75.652}, "timestamp": "2026-01-30T14:32:04.920284"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4990.16, "latencies_ms": [4990.16], "images_per_second": 0.2, "prompt_tokens": 1110, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features three hot dogs on a dark brown plate, with a yellow mustard sauce drizzled on top. The hot dogs are placed on a dark green countertop, and there is a book titled \"The Hunger Games\" in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.659}, "power_stats": {"power_gpu_soc_mean_watts": 19.71, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 71.659}, "timestamp": "2026-01-30T14:32:11.930904"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4813.225, "latencies_ms": [4813.225], "images_per_second": 0.208, "prompt_tokens": 1432, "response_tokens_est": 36, "n_tiles": 1, "output_text": " In the image, there are four people swimming in the ocean, with a green umbrella and two chairs placed on the beach, and a bird standing on the sand near the water.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.472, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.374, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T14:32:18.776286"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3561.949, "latencies_ms": [3561.949], "images_per_second": 0.281, "prompt_tokens": 1446, "response_tokens_est": 15, "n_tiles": 1, "output_text": " beach umbrella: 1\nchairs: 2\npeople: 4", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.759}, "power_stats": {"power_gpu_soc_mean_watts": 26.179, "power_cpu_cv_mean_watts": 0.883, "power_sys_5v0_mean_watts": 8.587, "gpu_utilization_percent_mean": 77.759}, "timestamp": "2026-01-30T14:32:24.376707"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6323.875, "latencies_ms": [6323.875], "images_per_second": 0.158, "prompt_tokens": 1450, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The green umbrella is positioned to the right of the beach chairs, which are situated in the foreground of the image. The people are swimming in the water, which is located in the middle ground of the image, while the beach chair with a pink cover is placed in the foreground, closer to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.682, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 8.255, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T14:32:32.713862"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3805.022, "latencies_ms": [3805.022], "images_per_second": 0.263, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are swimming in the ocean near a beach with a green umbrella and chairs.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.031}, "power_stats": {"power_gpu_soc_mean_watts": 25.312, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.539, "gpu_utilization_percent_mean": 78.031}, "timestamp": "2026-01-30T14:32:38.539765"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5453.901, "latencies_ms": [5453.901], "images_per_second": 0.183, "prompt_tokens": 1442, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a beach scene with a group of people swimming in the ocean, a green umbrella providing shade, and a beach chair set up on the sand. The lighting suggests it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.326}, "power_stats": {"power_gpu_soc_mean_watts": 21.89, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 8.344, "gpu_utilization_percent_mean": 73.326}, "timestamp": "2026-01-30T14:32:46.034837"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4137.661, "latencies_ms": [4137.661], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a vintage kitchen with green wallpaper, a white sink, a white refrigerator, and a white table with a glass top, surrounded by various kitchen appliances and utensils.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.314}, "power_stats": {"power_gpu_soc_mean_watts": 20.867, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.314}, "timestamp": "2026-01-30T14:32:52.223079"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4375.976, "latencies_ms": [4375.976], "images_per_second": 0.229, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " table: 1, chair: 1, sink: 1, refrigerator: 1, stove: 1, oven: 1, cabinet: 1, counter: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.655, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T14:32:58.628391"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5823.841, "latencies_ms": [5823.841], "images_per_second": 0.172, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The sink is located to the right of the stove, and the refrigerator is positioned to the right of the sink. The table is situated in the center of the room, with the chair placed in front of it. The green wallpaper covers the entire wall, and the floral-patterned carpet is spread across the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.345, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T14:33:06.484003"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4329.51, "latencies_ms": [4329.51], "images_per_second": 0.231, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image depicts a vintage kitchen with green wallpaper and a variety of appliances. The kitchen is equipped with a sink, a stove, and a refrigerator, all of which are in good condition.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.778}, "power_stats": {"power_gpu_soc_mean_watts": 20.633, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 71.778}, "timestamp": "2026-01-30T14:33:12.858413"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3909.185, "latencies_ms": [3909.185], "images_per_second": 0.256, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are covered in green wallpaper. The floor is covered in a green and yellow floral carpet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.094}, "power_stats": {"power_gpu_soc_mean_watts": 21.675, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.155, "gpu_utilization_percent_mean": 73.094}, "timestamp": "2026-01-30T14:33:18.794156"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3239.821, "latencies_ms": [3239.821], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A black and white dog is walking on a dirt path with a brown and white toy in its mouth.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.444}, "power_stats": {"power_gpu_soc_mean_watts": 23.461, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.251, "gpu_utilization_percent_mean": 77.444}, "timestamp": "2026-01-30T14:33:24.085403"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4039.602, "latencies_ms": [4039.602], "images_per_second": 0.248, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " dog: 1, tree: 1, leaves: 1, shadow: 1, ground: 1, bark: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13995.4, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.152}, "power_stats": {"power_gpu_soc_mean_watts": 21.559, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.137, "gpu_utilization_percent_mean": 71.152}, "timestamp": "2026-01-30T14:33:30.139557"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4499.673, "latencies_ms": [4499.673], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The dog is in the foreground, walking towards the right side of the image. The tree is in the background, to the left of the dog. The dog is closer to the camera than the tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.443, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 70.676}, "timestamp": "2026-01-30T14:33:36.676232"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3378.912, "latencies_ms": [3378.912], "images_per_second": 0.296, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A black and white dog is walking on a dirt path in a wooded area, sniffing around a tree.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.736, "power_cpu_cv_mean_watts": 1.044, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 72.286}, "timestamp": "2026-01-30T14:33:42.100566"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3129.862, "latencies_ms": [3129.862], "images_per_second": 0.32, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The dog is black and white, the leaves are brown, and the tree is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.346, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.203, "gpu_utilization_percent_mean": 76.538}, "timestamp": "2026-01-30T14:33:47.263317"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3231.471, "latencies_ms": [3231.471], "images_per_second": 0.309, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill, wearing a white helmet, black jacket, and red backpack.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.926}, "power_stats": {"power_gpu_soc_mean_watts": 23.444, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 74.926}, "timestamp": "2026-01-30T14:33:52.559453"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5615.593, "latencies_ms": [5615.593], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skis: 2\n2. ski poles: 2\n3. backpack: 1\n4. helmet: 1\n5. skier: 1\n6. snow: 1\n7. trees: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.34}, "power_stats": {"power_gpu_soc_mean_watts": 18.412, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 70.34}, "timestamp": "2026-01-30T14:34:00.209804"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4640.852, "latencies_ms": [4640.852], "images_per_second": 0.215, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the ski trail and trees in the background. The skier is moving towards the right side of the image, with the ski trail extending into the distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.371, "power_cpu_cv_mean_watts": 1.486, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 70.974}, "timestamp": "2026-01-30T14:34:06.865149"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2799.1, "latencies_ms": [2799.1], "images_per_second": 0.357, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is skiing down a snowy hill with trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.565}, "power_stats": {"power_gpu_soc_mean_watts": 24.602, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.343, "gpu_utilization_percent_mean": 74.565}, "timestamp": "2026-01-30T14:34:11.680269"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4087.15, "latencies_ms": [4087.15], "images_per_second": 0.245, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a person skiing down a snowy hill, wearing a white helmet and carrying a red backpack. The sky is clear and blue, and the snow is pristine white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.029}, "power_stats": {"power_gpu_soc_mean_watts": 21.376, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 72.029}, "timestamp": "2026-01-30T14:34:17.809827"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3644.068, "latencies_ms": [3644.068], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A large orange and black train with the number 6309 on the front is traveling down a track with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.867}, "power_stats": {"power_gpu_soc_mean_watts": 22.583, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.211, "gpu_utilization_percent_mean": 70.867}, "timestamp": "2026-01-30T14:34:23.478062"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5631.496, "latencies_ms": [5631.496], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. train: 1\n2. trees: 1\n3. sky: 1\n4. gravel: 1\n5. fence: 1\n6. train number: 1\n7. train engine: 1\n8. train caboose: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.495, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 69.638}, "timestamp": "2026-01-30T14:34:31.132225"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4261.772, "latencies_ms": [4261.772], "images_per_second": 0.235, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The main object, the train, is positioned in the foreground, moving from left to right. The background consists of leafless trees and a clear blue sky, indicating a cold season.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.6}, "power_stats": {"power_gpu_soc_mean_watts": 20.936, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 70.6}, "timestamp": "2026-01-30T14:34:37.413626"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2950.899, "latencies_ms": [2950.899], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A large orange and black train is traveling down a track in a rural area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.425, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.306, "gpu_utilization_percent_mean": 80.0}, "timestamp": "2026-01-30T14:34:42.402619"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5302.43, "latencies_ms": [5302.43], "images_per_second": 0.189, "prompt_tokens": 1109, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The locomotive is painted in vibrant shades of orange and black, with the number 6309 prominently displayed on the front. The sky is a clear blue, and the trees in the background are bare, suggesting that the photo was taken in the fall or winter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.886}, "power_stats": {"power_gpu_soc_mean_watts": 18.91, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 70.886}, "timestamp": "2026-01-30T14:34:49.734105"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4007.545, "latencies_ms": [4007.545], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a wooden table with a plate containing a slice of bread topped with guacamole, a bowl of broccoli, and a serving of white dip.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.333, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 70.182}, "timestamp": "2026-01-30T14:34:55.792009"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5347.255, "latencies_ms": [5347.255], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. bread: 2\n3. broccoli: 1\n4. cheese: 1\n5. avocado: 1\n6. bowl: 1\n7. table: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.489}, "power_stats": {"power_gpu_soc_mean_watts": 19.035, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 68.489}, "timestamp": "2026-01-30T14:35:03.162505"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4286.748, "latencies_ms": [4286.748], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The plate is in the foreground, with the bread, avocado, and broccoli in the background. The broccoli is near the plate, while the bread is on the left side of the plate.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.686}, "power_stats": {"power_gpu_soc_mean_watts": 20.994, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 70.686}, "timestamp": "2026-01-30T14:35:09.478275"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3480.771, "latencies_ms": [3480.771], "images_per_second": 0.287, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A plate of food is on a table, including a bowl of broccoli and a slice of bread with avocado on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.823, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.172, "gpu_utilization_percent_mean": 74.143}, "timestamp": "2026-01-30T14:35:14.975519"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4439.127, "latencies_ms": [4439.127], "images_per_second": 0.225, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a wooden table with a plate of food on it, including a bowl of broccoli and a slice of bread with avocado on it. The lighting is natural, and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.297}, "power_stats": {"power_gpu_soc_mean_watts": 20.365, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 69.297}, "timestamp": "2026-01-30T14:35:21.472560"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3044.777, "latencies_ms": [3044.777], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A person is sleeping on a bench with a blanket and a bag on it.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.497, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.225, "gpu_utilization_percent_mean": 75.36}, "timestamp": "2026-01-30T14:35:26.564421"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4431.745, "latencies_ms": [4431.745], "images_per_second": 0.226, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " bench: 1\nbag: 1\npurse: 1\nparking meter: 2\nstreetlamp: 2\ngrass: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.243}, "power_stats": {"power_gpu_soc_mean_watts": 20.28, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 72.243}, "timestamp": "2026-01-30T14:35:33.056686"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4183.797, "latencies_ms": [4183.797], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bench is located in the foreground of the image, with the parking meters and fence in the background. The person is lying on the bench, with the backpack and jacket nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.618}, "power_stats": {"power_gpu_soc_mean_watts": 21.422, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-30T14:35:39.272789"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2657.853, "latencies_ms": [2657.853], "images_per_second": 0.376, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A person is sleeping on a bench in a park.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.909}, "power_stats": {"power_gpu_soc_mean_watts": 25.023, "power_cpu_cv_mean_watts": 0.819, "power_sys_5v0_mean_watts": 8.323, "gpu_utilization_percent_mean": 79.909}, "timestamp": "2026-01-30T14:35:43.953425"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3906.911, "latencies_ms": [3906.911], "images_per_second": 0.256, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The bench is made of wood and is covered with an orange blanket. The scene is bathed in natural light, and the grass is a vibrant green.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.656}, "power_stats": {"power_gpu_soc_mean_watts": 21.695, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 8.108, "gpu_utilization_percent_mean": 69.656}, "timestamp": "2026-01-30T14:35:49.897393"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3474.895, "latencies_ms": [3474.895], "images_per_second": 0.288, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A tall, colorful vase with a mix of dried flowers and plants sits on a white shelf in front of a brown wall.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.586}, "power_stats": {"power_gpu_soc_mean_watts": 22.781, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 74.586}, "timestamp": "2026-01-30T14:35:55.421239"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4342.452, "latencies_ms": [4342.452], "images_per_second": 0.23, "prompt_tokens": 1114, "response_tokens_est": 39, "n_tiles": 1, "output_text": " vase: 1, pot: 1, wall: 1, wall art: 1, plant: 1, potted plant: 1, vase on table: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.821, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.094, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-30T14:36:01.819132"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4257.56, "latencies_ms": [4257.56], "images_per_second": 0.235, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The vase is positioned in the foreground, with the wall and other objects in the background. The vase is placed on a white shelf, which is located to the left of the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.973, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 70.886}, "timestamp": "2026-01-30T14:36:08.105269"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3116.018, "latencies_ms": [3116.018], "images_per_second": 0.321, "prompt_tokens": 1112, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A vase with flowers and other objects is on a white shelf in a room with brown walls.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.72}, "power_stats": {"power_gpu_soc_mean_watts": 23.878, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 78.72}, "timestamp": "2026-01-30T14:36:13.233096"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3999.445, "latencies_ms": [3999.445], "images_per_second": 0.25, "prompt_tokens": 1110, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The vase is made of ceramic and has a variety of colors, including blue, green, and brown. The lighting is bright and natural, coming from the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.758}, "power_stats": {"power_gpu_soc_mean_watts": 21.564, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 71.758}, "timestamp": "2026-01-30T14:36:19.257957"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3358.198, "latencies_ms": [3358.198], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A skateboarder wearing a helmet and knee pads is performing a trick on a ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.964}, "power_stats": {"power_gpu_soc_mean_watts": 22.811, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.174, "gpu_utilization_percent_mean": 73.964}, "timestamp": "2026-01-30T14:36:24.674542"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6153.516, "latencies_ms": [6153.516], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. helmet: 1\n3. knee pads: 1\n4. skateboarder: 1\n5. skateboard wheels: 2\n6. skateboard deck: 1\n7. skateboard trucks: 1\n8. skateboard trucks bolts: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.549}, "power_stats": {"power_gpu_soc_mean_watts": 18.011, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 69.549}, "timestamp": "2026-01-30T14:36:32.841970"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4635.675, "latencies_ms": [4635.675], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The skateboarder is positioned in the foreground of the image, performing a trick on the curved edge of the skatepark. The skatepark is located in the background, with a few spectators visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.213, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 70.5}, "timestamp": "2026-01-30T14:36:39.520337"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3359.693, "latencies_ms": [3359.693], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A skateboarder wearing a helmet and knee pads is performing a trick on a concrete skate park ramp.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.148}, "power_stats": {"power_gpu_soc_mean_watts": 22.854, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.165, "gpu_utilization_percent_mean": 77.148}, "timestamp": "2026-01-30T14:36:44.898958"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3273.166, "latencies_ms": [3273.166], "images_per_second": 0.306, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The skateboarder is wearing a helmet and knee pads, and the skate park is made of concrete.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.778}, "power_stats": {"power_gpu_soc_mean_watts": 23.375, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.227, "gpu_utilization_percent_mean": 75.778}, "timestamp": "2026-01-30T14:36:50.212044"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7060.418, "latencies_ms": [7060.418], "images_per_second": 0.142, "prompt_tokens": 1099, "response_tokens_est": 81, "n_tiles": 1, "output_text": " The image captures a vibrant night scene in a bustling city square, where a majestic clock tower stands tall, adorned with a festive blue and white Christmas tree, and is beautifully illuminated by strings of lights. The square is teeming with people, adding a lively atmosphere to the scene. In the background, a large building with a red and white sign can be seen, adding to the urban charm of the setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.983}, "power_stats": {"power_gpu_soc_mean_watts": 16.865, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 7.873, "gpu_utilization_percent_mean": 67.983}, "timestamp": "2026-01-30T14:36:59.334136"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4126.302, "latencies_ms": [4126.302], "images_per_second": 0.242, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " clock: 1, tower: 1, tree: 1, building: 1, lights: 1, people: 1, street: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.056, "power_cpu_cv_mean_watts": 1.295, "power_sys_5v0_mean_watts": 8.109, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T14:37:05.490891"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5598.114, "latencies_ms": [5598.114], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The clock tower is positioned in the center of the image, with the Christmas tree to its right. The street is in the foreground, with the buildings and shops in the background. The clock tower is the main focal point of the image, with the Christmas tree adding a festive touch to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.426}, "power_stats": {"power_gpu_soc_mean_watts": 18.684, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 70.426}, "timestamp": "2026-01-30T14:37:13.106545"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5789.754, "latencies_ms": [5789.754], "images_per_second": 0.173, "prompt_tokens": 1111, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image captures a vibrant night scene in a bustling city square, where a majestic clock tower stands tall, adorned with twinkling lights that add a magical touch to the urban landscape. The square is alive with people, some walking, others gathered around a large, snow-covered Christmas tree, creating a lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.083}, "power_stats": {"power_gpu_soc_mean_watts": 18.301, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 69.083}, "timestamp": "2026-01-30T14:37:20.910347"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5464.276, "latencies_ms": [5464.276], "images_per_second": 0.183, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a nighttime scene with a prominent clock tower adorned with lights, a snow-covered Christmas tree, and a bustling street lined with shops and pedestrians. The sky is dark, and the street is wet, reflecting the lights and creating a glistening effect on the pavement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.065}, "power_stats": {"power_gpu_soc_mean_watts": 18.644, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.96, "gpu_utilization_percent_mean": 69.065}, "timestamp": "2026-01-30T14:37:28.405627"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3478.17, "latencies_ms": [3478.17], "images_per_second": 0.288, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young man wearing a blue shirt and black shorts is playing tennis on a court with a yellow and black tennis racket.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.793, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T14:37:33.953629"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5723.86, "latencies_ms": [5723.86], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. chain link fence: 1\n5. tennis court: 1\n6. trees: 1\n7. grass: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.792}, "power_stats": {"power_gpu_soc_mean_watts": 18.52, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 68.792}, "timestamp": "2026-01-30T14:37:41.702276"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5728.061, "latencies_ms": [5728.061], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The tennis player is in the foreground of the image, holding a tennis racket and preparing to hit a tennis ball. The tennis ball is in the middle ground, slightly to the right of the player. The tennis court is in the background, with a chain link fence separating the court from the trees.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.361, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T14:37:49.468653"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2945.684, "latencies_ms": [2945.684], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young man is playing tennis on a court with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.042}, "power_stats": {"power_gpu_soc_mean_watts": 24.407, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.306, "gpu_utilization_percent_mean": 76.042}, "timestamp": "2026-01-30T14:37:54.428223"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4421.238, "latencies_ms": [4421.238], "images_per_second": 0.226, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image shows a young man playing tennis on a court with a green fence in the background. The tennis ball is in the air, and the man is holding a yellow and black tennis racket.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.081}, "power_stats": {"power_gpu_soc_mean_watts": 20.399, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 69.081}, "timestamp": "2026-01-30T14:38:00.864196"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3508.609, "latencies_ms": [3508.609], "images_per_second": 0.285, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A well-lit living room with a fireplace, two lamps, a sofa, and a bookshelf filled with books.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.966}, "power_stats": {"power_gpu_soc_mean_watts": 22.645, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 73.966}, "timestamp": "2026-01-30T14:38:06.403064"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5521.03, "latencies_ms": [5521.03], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. sofa: 1\n2. bookshelves: 2\n3. lamp: 2\n4. fireplace: 1\n5. plant: 2\n6. chair: 1\n7. table: 2\n8. picture: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.064}, "power_stats": {"power_gpu_soc_mean_watts": 18.694, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.064}, "timestamp": "2026-01-30T14:38:13.950018"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6278.959, "latencies_ms": [6278.959], "images_per_second": 0.159, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The beige armchair is positioned in the foreground, to the right of the fireplace, with the green plant to its left. The white bookshelves are located behind the armchair, with the fireplace in the center of the room. The beige sofa is situated to the left of the armchair, with the green plant to its right.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.566}, "power_stats": {"power_gpu_soc_mean_watts": 17.716, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 68.566}, "timestamp": "2026-01-30T14:38:22.263838"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2878.333, "latencies_ms": [2878.333], "images_per_second": 0.347, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A cozy living room with a fireplace, two lamps, and a chair.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.833}, "power_stats": {"power_gpu_soc_mean_watts": 24.507, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.323, "gpu_utilization_percent_mean": 76.833}, "timestamp": "2026-01-30T14:38:27.169391"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3058.685, "latencies_ms": [3058.685], "images_per_second": 0.327, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.92}, "power_stats": {"power_gpu_soc_mean_watts": 23.864, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 74.92}, "timestamp": "2026-01-30T14:38:32.255337"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3894.788, "latencies_ms": [3894.788], "images_per_second": 0.257, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there are three zebras standing on a grassy hill, with one of them eating grass, and the other two facing away from the camera.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.182}, "power_stats": {"power_gpu_soc_mean_watts": 21.658, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 73.182}, "timestamp": "2026-01-30T14:38:38.220727"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2206.068, "latencies_ms": [2206.068], "images_per_second": 0.453, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.944}, "power_stats": {"power_gpu_soc_mean_watts": 25.932, "power_cpu_cv_mean_watts": 0.6, "power_sys_5v0_mean_watts": 8.384, "gpu_utilization_percent_mean": 86.944}, "timestamp": "2026-01-30T14:38:42.483251"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5985.242, "latencies_ms": [5985.242], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the one on the left slightly ahead of the other two. The zebras are facing towards the right side of the image, with the one on the left facing the camera. The zebras are standing on a grassy hill, with the dirt path in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.569}, "power_stats": {"power_gpu_soc_mean_watts": 18.003, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 66.569}, "timestamp": "2026-01-30T14:38:50.495128"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3043.913, "latencies_ms": [3043.913], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of zebras are grazing in a grassy field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.738, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 76.88}, "timestamp": "2026-01-30T14:38:55.567117"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4605.672, "latencies_ms": [4605.672], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a group of zebras with black and white stripes, standing in a grassy field under a clear blue sky. The zebras are grazing on the grass, and the image has a natural and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.513}, "power_stats": {"power_gpu_soc_mean_watts": 20.235, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 71.513}, "timestamp": "2026-01-30T14:39:02.207010"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3271.29, "latencies_ms": [3271.29], "images_per_second": 0.306, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, wearing hats and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.313, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 73.37}, "timestamp": "2026-01-30T14:39:07.541243"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5552.107, "latencies_ms": [5552.107], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. chairs: 10\n2. people: 10\n3. table: 1\n4. bottles: 1\n5. napkins: 1\n6. plates: 1\n7. cups: 1\n8. glasses: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.391}, "power_stats": {"power_gpu_soc_mean_watts": 18.705, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 70.391}, "timestamp": "2026-01-30T14:39:15.107846"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4739.58, "latencies_ms": [4739.58], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The group of people is seated around a table in the foreground of the image, with the restaurant's interior and patrons in the background. The table is positioned in the center of the image, with the people seated around it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.385}, "power_stats": {"power_gpu_soc_mean_watts": 20.009, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 71.385}, "timestamp": "2026-01-30T14:39:21.892436"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3165.89, "latencies_ms": [3165.89], "images_per_second": 0.316, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are sitting at a table in a restaurant, wearing hats and smiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.19, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.176, "gpu_utilization_percent_mean": 76.808}, "timestamp": "2026-01-30T14:39:27.088927"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4918.389, "latencies_ms": [4918.389], "images_per_second": 0.203, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere, characterized by the rich brown color of the wooden floor and the warm lighting that illuminates the space. The walls are adorned with brick, adding a rustic charm to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.415}, "power_stats": {"power_gpu_soc_mean_watts": 19.522, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.415}, "timestamp": "2026-01-30T14:39:34.020491"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3330.57, "latencies_ms": [3330.57], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A group of swans are swimming in the water near a marina with boats covered in purple tarps.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.907, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 72.714}, "timestamp": "2026-01-30T14:39:39.425242"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3604.344, "latencies_ms": [3604.344], "images_per_second": 0.277, "prompt_tokens": 1113, "response_tokens_est": 27, "n_tiles": 1, "output_text": " swan: 12, boat: 10, water: 1, dock: 1, purple: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.531, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 73.2}, "timestamp": "2026-01-30T14:39:45.046469"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4633.634, "latencies_ms": [4633.634], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The swans are positioned in the foreground of the image, with the boats in the background. The boats are docked on the left side of the image, while the swans are swimming in the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.051}, "power_stats": {"power_gpu_soc_mean_watts": 19.948, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 71.051}, "timestamp": "2026-01-30T14:39:51.741155"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3194.352, "latencies_ms": [3194.352], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of swans are swimming in a marina with boats docked in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.962}, "power_stats": {"power_gpu_soc_mean_watts": 23.409, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 73.962}, "timestamp": "2026-01-30T14:39:56.963090"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4495.105, "latencies_ms": [4495.105], "images_per_second": 0.222, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a group of swans in a marina with purple-tinted water, reflecting the sunlight. The swans are white, and the water is calm, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.784}, "power_stats": {"power_gpu_soc_mean_watts": 20.42, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 72.784}, "timestamp": "2026-01-30T14:40:03.484360"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3439.392, "latencies_ms": [3439.392], "images_per_second": 0.291, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man and woman are cutting a wedding cake together in a tent with a table covered in a white tablecloth.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.536}, "power_stats": {"power_gpu_soc_mean_watts": 22.649, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.168, "gpu_utilization_percent_mean": 74.536}, "timestamp": "2026-01-30T14:40:08.962210"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5367.468, "latencies_ms": [5367.468], "images_per_second": 0.186, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. woman: 1\n3. table: 1\n4. chair: 1\n5. cake: 1\n6. speaker: 1\n7. person: 1\n8. tent: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.875, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T14:40:16.367541"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5453.218, "latencies_ms": [5453.218], "images_per_second": 0.183, "prompt_tokens": 1118, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The bride and groom are standing close to each other, with the bride on the left and the groom on the right. The cake is placed in the middle of the table, which is located in the foreground. The background of the image shows a stage with musical instruments and a speaker.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.022}, "power_stats": {"power_gpu_soc_mean_watts": 18.882, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 70.022}, "timestamp": "2026-01-30T14:40:23.854154"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3286.503, "latencies_ms": [3286.503], "images_per_second": 0.304, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A newlywed couple is cutting their wedding cake in a tent with a white tablecloth and a wooden floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.481}, "power_stats": {"power_gpu_soc_mean_watts": 23.176, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 74.481}, "timestamp": "2026-01-30T14:40:29.193966"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3530.334, "latencies_ms": [3530.334], "images_per_second": 0.283, "prompt_tokens": 1110, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The wedding reception is well-lit with natural light streaming in from the windows, and the guests are dressed in formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.489, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 72.552}, "timestamp": "2026-01-30T14:40:34.767959"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3151.182, "latencies_ms": [3151.182], "images_per_second": 0.317, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A living room with a blue couch, a red rug, and a lamp on a table.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.769}, "power_stats": {"power_gpu_soc_mean_watts": 23.533, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 76.769}, "timestamp": "2026-01-30T14:40:39.947242"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4254.393, "latencies_ms": [4254.393], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " sofa: 1, coffee table: 1, side table: 1, lamp: 1, plant: 2, rug: 1, painting: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.4, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.114}, "power_stats": {"power_gpu_soc_mean_watts": 20.924, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 73.114}, "timestamp": "2026-01-30T14:40:46.226577"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5411.674, "latencies_ms": [5411.674], "images_per_second": 0.185, "prompt_tokens": 1117, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The sofa is positioned in the center of the room, with the coffee table in front of it. The side table is located to the left of the sofa, while the lamp is situated to the right. The rug is placed on the floor, covering the entire floor space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.4, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.889}, "power_stats": {"power_gpu_soc_mean_watts": 18.882, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 69.889}, "timestamp": "2026-01-30T14:40:53.671093"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3215.251, "latencies_ms": [3215.251], "images_per_second": 0.311, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A living room with a blue couch, a coffee table, and a rug on the floor.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.286, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 71.5}, "timestamp": "2026-01-30T14:40:58.904046"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3179.498, "latencies_ms": [3179.498], "images_per_second": 0.315, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is painted red and has a red carpet. The furniture is made of wood and glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.807, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 76.269}, "timestamp": "2026-01-30T14:41:04.120595"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4584.02, "latencies_ms": [4584.02], "images_per_second": 0.218, "prompt_tokens": 1432, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image features a doll with a clock face on its face, which is positioned in front of a mirror, creating a reflection of the clock and the doll's face.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.605}, "power_stats": {"power_gpu_soc_mean_watts": 23.415, "power_cpu_cv_mean_watts": 1.243, "power_sys_5v0_mean_watts": 8.455, "gpu_utilization_percent_mean": 75.605}, "timestamp": "2026-01-30T14:41:10.742866"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6386.912, "latencies_ms": [6386.912], "images_per_second": 0.157, "prompt_tokens": 1446, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Clock: 1\n2. Doll: 1\n3. Doll hair: 1\n4. Doll face: 1\n5. Doll eyes: 1\n6. Doll mouth: 1\n7. Doll hands: 1\n8. Doll feet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.302}, "power_stats": {"power_gpu_soc_mean_watts": 20.52, "power_cpu_cv_mean_watts": 1.571, "power_sys_5v0_mean_watts": 8.241, "gpu_utilization_percent_mean": 72.302}, "timestamp": "2026-01-30T14:41:19.156833"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4792.02, "latencies_ms": [4792.02], "images_per_second": 0.209, "prompt_tokens": 1450, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The clock is positioned on the left side of the image, while the doll is on the right side. The clock is in the foreground, while the doll is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.725}, "power_stats": {"power_gpu_soc_mean_watts": 23.233, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.418, "gpu_utilization_percent_mean": 73.725}, "timestamp": "2026-01-30T14:41:25.969152"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3523.74, "latencies_ms": [3523.74], "images_per_second": 0.284, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A doll with a clock face on its face is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.793}, "power_stats": {"power_gpu_soc_mean_watts": 26.355, "power_cpu_cv_mean_watts": 0.869, "power_sys_5v0_mean_watts": 8.638, "gpu_utilization_percent_mean": 81.793}, "timestamp": "2026-01-30T14:41:31.521805"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4960.322, "latencies_ms": [4960.322], "images_per_second": 0.202, "prompt_tokens": 1442, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a doll with a clock face on its face, which is a combination of yellow and black. The lighting is dim, and the doll is made of a material that resembles wood.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.2, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.711, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 8.376, "gpu_utilization_percent_mean": 74.286}, "timestamp": "2026-01-30T14:41:38.512228"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2811.566, "latencies_ms": [2811.566], "images_per_second": 0.356, "prompt_tokens": 1100, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A man wearing a helmet and a jacket is sitting on a motorcycle.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.783}, "power_stats": {"power_gpu_soc_mean_watts": 24.895, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.329, "gpu_utilization_percent_mean": 78.783}, "timestamp": "2026-01-30T14:41:43.363294"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5415.054, "latencies_ms": [5415.054], "images_per_second": 0.185, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. helmet: 1\n3. motorcycle: 1\n4. jacket: 1\n5. pants: 1\n6. shoes: 1\n7. seat: 1\n8. seatbelt: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.871, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.043}, "timestamp": "2026-01-30T14:41:50.819000"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4506.099, "latencies_ms": [4506.099], "images_per_second": 0.222, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The man is sitting on the left side of the motorcycle, which is positioned in the foreground of the image. The motorcycle is parked in a parking lot, which is located in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.73}, "power_stats": {"power_gpu_soc_mean_watts": 20.475, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 68.73}, "timestamp": "2026-01-30T14:41:57.359774"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2667.998, "latencies_ms": [2667.998], "images_per_second": 0.375, "prompt_tokens": 1112, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man wearing a helmet is sitting on a motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.371, "power_cpu_cv_mean_watts": 0.819, "power_sys_5v0_mean_watts": 8.267, "gpu_utilization_percent_mean": 81.5}, "timestamp": "2026-01-30T14:42:02.064596"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4043.469, "latencies_ms": [4043.469], "images_per_second": 0.247, "prompt_tokens": 1110, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image has a warm color tone, with the man wearing a beige jacket and black helmet. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13992.2, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.788}, "power_stats": {"power_gpu_soc_mean_watts": 21.317, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 67.788}, "timestamp": "2026-01-30T14:42:08.140760"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2886.438, "latencies_ms": [2886.438], "images_per_second": 0.346, "prompt_tokens": 1100, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is spreading cheese on a pizza that is on a wooden table.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.208}, "power_stats": {"power_gpu_soc_mean_watts": 24.274, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.289, "gpu_utilization_percent_mean": 79.208}, "timestamp": "2026-01-30T14:42:13.076943"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5725.182, "latencies_ms": [5725.182], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Pizza: 1\n2. Cheese: 1\n3. Spice: 1\n4. Meat: 1\n5. Sauce: 1\n6. Bread: 1\n7. Knife: 1\n8. Spatula: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.042}, "power_stats": {"power_gpu_soc_mean_watts": 18.344, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 68.042}, "timestamp": "2026-01-30T14:42:20.825723"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4346.583, "latencies_ms": [4346.583], "images_per_second": 0.23, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The pizza is in the foreground, with the person's hand in the background. The pizza is on the left side of the image, while the person's hand is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.944}, "power_stats": {"power_gpu_soc_mean_watts": 20.475, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 70.944}, "timestamp": "2026-01-30T14:42:27.209769"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2801.577, "latencies_ms": [2801.577], "images_per_second": 0.357, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A person is preparing a pizza on a wooden table in a kitchen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.435}, "power_stats": {"power_gpu_soc_mean_watts": 24.543, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.365, "gpu_utilization_percent_mean": 76.435}, "timestamp": "2026-01-30T14:42:32.030291"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3481.344, "latencies_ms": [3481.344], "images_per_second": 0.287, "prompt_tokens": 1110, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The pizza is golden brown and has a creamy white sauce. The lighting is dim and the pizza is on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.464}, "power_stats": {"power_gpu_soc_mean_watts": 23.049, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.228, "gpu_utilization_percent_mean": 73.464}, "timestamp": "2026-01-30T14:42:37.522863"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3047.535, "latencies_ms": [3047.535], "images_per_second": 0.328, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman in a white dress and white shoes is playing tennis on a grass court.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.797, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 75.56}, "timestamp": "2026-01-30T14:42:42.608720"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5543.471, "latencies_ms": [5543.471], "images_per_second": 0.18, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. woman: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. grass: 1\n5. net: 1\n6. white: 1\n7. white: 1\n8. white: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.457}, "power_stats": {"power_gpu_soc_mean_watts": 18.716, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.457}, "timestamp": "2026-01-30T14:42:50.181373"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4026.152, "latencies_ms": [4026.152], "images_per_second": 0.248, "prompt_tokens": 1118, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the tennis racket held high above her head, and the tennis court stretching out into the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.636}, "power_stats": {"power_gpu_soc_mean_watts": 21.394, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 70.636}, "timestamp": "2026-01-30T14:42:56.230292"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2892.652, "latencies_ms": [2892.652], "images_per_second": 0.346, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A woman in a white dress is playing tennis on a green grass court.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.625}, "power_stats": {"power_gpu_soc_mean_watts": 23.855, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 75.625}, "timestamp": "2026-01-30T14:43:01.156702"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3305.408, "latencies_ms": [3305.408], "images_per_second": 0.303, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The tennis player is wearing a white outfit and white shoes, and the grass on the court is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.407}, "power_stats": {"power_gpu_soc_mean_watts": 23.118, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 71.407}, "timestamp": "2026-01-30T14:43:06.488801"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3494.856, "latencies_ms": [3494.856], "images_per_second": 0.286, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white toilet, a white bathtub, and a white door with a wire shelf inside.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.768, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 73.69}, "timestamp": "2026-01-30T14:43:12.008305"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4338.558, "latencies_ms": [4338.558], "images_per_second": 0.23, "prompt_tokens": 1113, "response_tokens_est": 39, "n_tiles": 1, "output_text": " toilet: 1, towel: 1, closet: 1, shelf: 1, door: 1, bathtub: 1, wall: 1, floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.167}, "power_stats": {"power_gpu_soc_mean_watts": 20.811, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 71.167}, "timestamp": "2026-01-30T14:43:18.386433"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4516.176, "latencies_ms": [4516.176], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the shower curtain is on the right side. The closet is positioned in the background, and the towel is hanging on the wall above the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.388, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 69.974}, "timestamp": "2026-01-30T14:43:24.935623"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3069.278, "latencies_ms": [3069.278], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small bathroom with a white toilet, a shower curtain, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.751, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.232, "gpu_utilization_percent_mean": 74.24}, "timestamp": "2026-01-30T14:43:30.044927"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3172.474, "latencies_ms": [3172.474], "images_per_second": 0.315, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bathroom is painted in a light yellow color, and the floor is covered with brown tiles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.544, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-30T14:43:35.261285"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2711.286, "latencies_ms": [2711.286], "images_per_second": 0.369, "prompt_tokens": 1099, "response_tokens_est": 12, "n_tiles": 1, "output_text": " Two men are holding wine glasses and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.909}, "power_stats": {"power_gpu_soc_mean_watts": 24.987, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 8.337, "gpu_utilization_percent_mean": 81.909}, "timestamp": "2026-01-30T14:43:40.021950"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5369.643, "latencies_ms": [5369.643], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. glasses: 2\n2. people: 3\n3. table: 1\n4. chair: 1\n5. wall: 1\n6. door: 1\n7. window: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.756}, "power_stats": {"power_gpu_soc_mean_watts": 18.988, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 67.756}, "timestamp": "2026-01-30T14:43:47.411094"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5879.728, "latencies_ms": [5879.728], "images_per_second": 0.17, "prompt_tokens": 1117, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The two people are in the foreground, with the man on the right holding a wine glass and the woman on the left holding a wine glass. The man on the right is closer to the camera than the woman on the left. The woman on the left is closer to the camera than the man on the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.082}, "power_stats": {"power_gpu_soc_mean_watts": 18.034, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 70.082}, "timestamp": "2026-01-30T14:43:55.340822"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3444.078, "latencies_ms": [3444.078], "images_per_second": 0.29, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two people are holding wine glasses and smiling at the camera. They are in a room with a table and chairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.464}, "power_stats": {"power_gpu_soc_mean_watts": 22.679, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 74.464}, "timestamp": "2026-01-30T14:44:00.830319"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3498.892, "latencies_ms": [3498.892], "images_per_second": 0.286, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming in from the windows, and the wine glasses are made of clear glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.739, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.18, "gpu_utilization_percent_mean": 72.69}, "timestamp": "2026-01-30T14:44:06.380317"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3425.747, "latencies_ms": [3425.747], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, with a clear blue sky and a beach in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.107}, "power_stats": {"power_gpu_soc_mean_watts": 22.694, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 74.107}, "timestamp": "2026-01-30T14:44:11.848882"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5502.647, "latencies_ms": [5502.647], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. surfer: 1\n2. surfboard: 1\n3. wave: 1\n4. ocean: 1\n5. sky: 1\n6. beach: 1\n7. sand: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 18.739, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T14:44:19.380856"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5843.34, "latencies_ms": [5843.34], "images_per_second": 0.171, "prompt_tokens": 1117, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the middle ground, with the surfer's body and surfboard positioned within it. The background features a sandy beach and a clear sky, providing a serene contrast to the dynamic action of the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.98}, "power_stats": {"power_gpu_soc_mean_watts": 18.345, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 68.98}, "timestamp": "2026-01-30T14:44:27.279247"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3415.265, "latencies_ms": [3415.265], "images_per_second": 0.293, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean, with a beach and clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.521, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 73.893}, "timestamp": "2026-01-30T14:44:32.753927"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4840.176, "latencies_ms": [4840.176], "images_per_second": 0.207, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a surfer riding a wave in a clear blue ocean, with the sun shining brightly in the background. The surfer is wearing a black wetsuit and blue shorts, and the wave is a light blue color.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13992.3, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.85}, "power_stats": {"power_gpu_soc_mean_watts": 19.83, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 70.85}, "timestamp": "2026-01-30T14:44:39.607198"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3233.325, "latencies_ms": [3233.325], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A collection of laptops, tablets, and a red and black backpack are arranged on a wooden table.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13992.3, "ram_available_mb": 48848.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.38, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.194, "gpu_utilization_percent_mean": 75.538}, "timestamp": "2026-01-30T14:44:44.866104"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9872.427, "latencies_ms": [9872.427], "images_per_second": 0.101, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " laptop: 3, laptop: 1, laptop: 1, laptop: 1, laptop: 1, laptop: 1, laptop: 1, laptop: 1, backpack: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: 1, cables: ", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.988}, "power_stats": {"power_gpu_soc_mean_watts": 15.222, "power_cpu_cv_mean_watts": 1.983, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 64.988}, "timestamp": "2026-01-30T14:44:56.782488"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4899.036, "latencies_ms": [4899.036], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The laptop computer is positioned to the left of the backpack, while the tablet is situated to the right of the backpack. The cables are spread out in front of the backpack, with some extending towards the laptop computer and others towards the tablet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.925}, "power_stats": {"power_gpu_soc_mean_watts": 19.921, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 70.925}, "timestamp": "2026-01-30T14:45:03.703647"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3345.825, "latencies_ms": [3345.825], "images_per_second": 0.299, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A collection of laptops and a backpack are placed on the floor, with a computer monitor in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.148}, "power_stats": {"power_gpu_soc_mean_watts": 22.958, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 73.148}, "timestamp": "2026-01-30T14:45:09.068104"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4576.618, "latencies_ms": [4576.618], "images_per_second": 0.219, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is taken in a room with a brown carpet and a white wall. The lighting is dim, and the objects are illuminated by artificial light. The materials of the objects are metal, plastic, and fabric.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.295, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 71.184}, "timestamp": "2026-01-30T14:45:15.693150"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3944.675, "latencies_ms": [3944.675], "images_per_second": 0.254, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A skier in a vibrant orange and green outfit is captured mid-air, performing a jump on a snowy mountain, with a blurred figure in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.632, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 70.562}, "timestamp": "2026-01-30T14:45:21.657007"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5568.277, "latencies_ms": [5568.277], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. skis: 2\n3. poles: 2\n4. helmet: 1\n5. jacket: 1\n6. pants: 1\n7. snowboard: 0\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.128}, "power_stats": {"power_gpu_soc_mean_watts": 18.512, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 70.128}, "timestamp": "2026-01-30T14:45:29.253752"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4677.37, "latencies_ms": [4677.37], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The skier is in the foreground, with the snowboarder in the background. The skier is to the left of the snowboarder. The skier is closer to the camera than the snowboarder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.897}, "power_stats": {"power_gpu_soc_mean_watts": 19.947, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 71.897}, "timestamp": "2026-01-30T14:45:35.972921"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3718.107, "latencies_ms": [3718.107], "images_per_second": 0.269, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A skier in a vibrant orange and green suit is performing a jump in the snow, while another skier stands in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.767}, "power_stats": {"power_gpu_soc_mean_watts": 21.783, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.097, "gpu_utilization_percent_mean": 72.767}, "timestamp": "2026-01-30T14:45:41.717658"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4844.825, "latencies_ms": [4844.825], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The skier is wearing a vibrant orange and green outfit, and the snow is a pristine white. The skier is in mid-air, performing a jump, and the sun is shining brightly, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.78}, "power_stats": {"power_gpu_soc_mean_watts": 19.768, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 70.78}, "timestamp": "2026-01-30T14:45:48.604437"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2948.591, "latencies_ms": [2948.591], "images_per_second": 0.339, "prompt_tokens": 1100, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is perched on a window sill, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.708}, "power_stats": {"power_gpu_soc_mean_watts": 24.303, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 77.708}, "timestamp": "2026-01-30T14:45:53.591386"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5699.776, "latencies_ms": [5699.776], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. window: 1\n2. bird: 1\n3. door: 1\n4. wall: 1\n5. door handle: 1\n6. window frame: 1\n7. window latch: 1\n8. bird's beak: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 18.518, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T14:46:01.319175"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4154.759, "latencies_ms": [4154.759], "images_per_second": 0.241, "prompt_tokens": 1118, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The bird is positioned in the foreground, on the right side of the window, while the water is in the background. The bird is closer to the viewer than the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.114}, "power_stats": {"power_gpu_soc_mean_watts": 20.9, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 70.114}, "timestamp": "2026-01-30T14:46:07.485153"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2881.455, "latencies_ms": [2881.455], "images_per_second": 0.347, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird is perched on a window sill, looking out at the water.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.792}, "power_stats": {"power_gpu_soc_mean_watts": 24.375, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.37, "gpu_utilization_percent_mean": 77.792}, "timestamp": "2026-01-30T14:46:12.396018"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5183.964, "latencies_ms": [5183.964], "images_per_second": 0.193, "prompt_tokens": 1110, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a bird perched on a window sill, with a view of a body of water in the background. The bird is black, and the water is a deep blue. The window is framed in white, and the sill is made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.767}, "power_stats": {"power_gpu_soc_mean_watts": 19.209, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 69.767}, "timestamp": "2026-01-30T14:46:19.594229"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3380.971, "latencies_ms": [3380.971], "images_per_second": 0.296, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Two men are cleaning a bathroom with a bucket and a mop, with a toilet and a trash can nearby.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.143}, "power_stats": {"power_gpu_soc_mean_watts": 22.98, "power_cpu_cv_mean_watts": 1.13, "power_sys_5v0_mean_watts": 8.196, "gpu_utilization_percent_mean": 74.143}, "timestamp": "2026-01-30T14:46:25.043949"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4499.008, "latencies_ms": [4499.008], "images_per_second": 0.222, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " toilet: 1, trash can: 1, trash bag: 1, bucket: 1, person: 2, shelf: 1, bottle: 1, cupboard: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.447}, "power_stats": {"power_gpu_soc_mean_watts": 20.492, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 70.447}, "timestamp": "2026-01-30T14:46:31.576439"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4979.317, "latencies_ms": [4979.317], "images_per_second": 0.201, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The toilet is located in the foreground, with the trash can and the person in the orange hat positioned further back. The person in the orange hat is standing near the toilet, while the person in the white shirt is closer to the trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.214}, "power_stats": {"power_gpu_soc_mean_watts": 19.451, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 69.214}, "timestamp": "2026-01-30T14:46:38.585093"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2797.725, "latencies_ms": [2797.725], "images_per_second": 0.357, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " Two men are cleaning a bathroom with a bucket and a mop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.043}, "power_stats": {"power_gpu_soc_mean_watts": 24.474, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.338, "gpu_utilization_percent_mean": 80.043}, "timestamp": "2026-01-30T14:46:43.423371"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3420.839, "latencies_ms": [3420.839], "images_per_second": 0.292, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a yellowish hue, and the floor is covered in blue paint.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.179}, "power_stats": {"power_gpu_soc_mean_watts": 23.211, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 74.179}, "timestamp": "2026-01-30T14:46:48.879142"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3965.985, "latencies_ms": [3965.985], "images_per_second": 0.252, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " In the image, a person is seen walking down a hallway, holding an umbrella with the word \"opera\" written on it, under a rain shower.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.152}, "power_stats": {"power_gpu_soc_mean_watts": 21.662, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 72.152}, "timestamp": "2026-01-30T14:46:54.882683"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5334.59, "latencies_ms": [5334.59], "images_per_second": 0.187, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 1\n2. umbrella: 1\n3. wall: 2\n4. door: 1\n5. floor: 1\n6. light: 1\n7. picture: 1\n8. text: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.178}, "power_stats": {"power_gpu_soc_mean_watts": 19.076, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 70.178}, "timestamp": "2026-01-30T14:47:02.269349"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4749.475, "latencies_ms": [4749.475], "images_per_second": 0.211, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The person is standing in the middle of the hallway, with the door on the right and the wall on the left. The person is holding the umbrella in front of them, which is blocking the view of the door.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.05}, "power_stats": {"power_gpu_soc_mean_watts": 19.869, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 72.05}, "timestamp": "2026-01-30T14:47:09.057236"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3319.452, "latencies_ms": [3319.452], "images_per_second": 0.301, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is walking down a hallway with a black umbrella that has the word \"opera\" on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.556}, "power_stats": {"power_gpu_soc_mean_watts": 23.34, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 74.556}, "timestamp": "2026-01-30T14:47:14.392139"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5034.743, "latencies_ms": [5034.743], "images_per_second": 0.199, "prompt_tokens": 1110, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image features a person holding a black umbrella with the word \"opera\" written on it, standing in a hallway with red walls and a white door. The lighting is dim, and the rain is falling outside, creating a dramatic atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.929}, "power_stats": {"power_gpu_soc_mean_watts": 19.381, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 67.929}, "timestamp": "2026-01-30T14:47:21.454757"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3995.305, "latencies_ms": [3995.305], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A man wearing a red shirt and a backpack is standing on a path in the woods, while another man in a yellow raincoat is standing on a staircase.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.909}, "power_stats": {"power_gpu_soc_mean_watts": 21.244, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 68.909}, "timestamp": "2026-01-30T14:47:27.473983"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5472.124, "latencies_ms": [5472.124], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. man: 1\n2. backpack: 1\n3. signpost: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.654, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 67.804}, "timestamp": "2026-01-30T14:47:34.962244"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4845.373, "latencies_ms": [4845.373], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man in the red shirt is standing in the foreground, while the man in the yellow jacket is standing on the steps in the background. The man in the red shirt is closer to the camera than the man in the yellow jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.225}, "power_stats": {"power_gpu_soc_mean_watts": 19.752, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.225}, "timestamp": "2026-01-30T14:47:41.839836"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3793.963, "latencies_ms": [3793.963], "images_per_second": 0.264, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man in a red shirt and backpack stands on a rocky path, while another man in a yellow raincoat walks up a set of stairs.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.548}, "power_stats": {"power_gpu_soc_mean_watts": 22.048, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 70.548}, "timestamp": "2026-01-30T14:47:47.682939"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4263.683, "latencies_ms": [4263.683], "images_per_second": 0.235, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a man wearing a red shirt and blue jeans, standing on a rocky path in a lush green forest. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.886}, "power_stats": {"power_gpu_soc_mean_watts": 21.128, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 68.886}, "timestamp": "2026-01-30T14:47:53.979860"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4014.363, "latencies_ms": [4014.363], "images_per_second": 0.249, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " Five men are standing together in a room, with one man wearing a red tie and another wearing a white shirt.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.121}, "power_stats": {"power_gpu_soc_mean_watts": 24.481, "power_cpu_cv_mean_watts": 1.104, "power_sys_5v0_mean_watts": 8.477, "gpu_utilization_percent_mean": 76.121}, "timestamp": "2026-01-30T14:48:00.066518"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6017.616, "latencies_ms": [6017.616], "images_per_second": 0.166, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. chair: 2\n2. man: 5\n3. bottle: 1\n4. man: 1\n5. man: 1\n6. man: 1\n7. man: 1\n8. man: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.46}, "power_stats": {"power_gpu_soc_mean_watts": 21.043, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 8.262, "gpu_utilization_percent_mean": 70.46}, "timestamp": "2026-01-30T14:48:08.100145"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6145.851, "latencies_ms": [6145.851], "images_per_second": 0.163, "prompt_tokens": 1450, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The man on the left is standing closer to the camera than the man on the right. The man in the middle is standing between the two men on the left and the man on the right. The man on the right is standing further away from the camera than the man on the left.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.863}, "power_stats": {"power_gpu_soc_mean_watts": 20.851, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 71.863}, "timestamp": "2026-01-30T14:48:16.289999"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3705.116, "latencies_ms": [3705.116], "images_per_second": 0.27, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Five men are posing for a picture in a room with a bar in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.742}, "power_stats": {"power_gpu_soc_mean_watts": 25.416, "power_cpu_cv_mean_watts": 0.942, "power_sys_5v0_mean_watts": 8.534, "gpu_utilization_percent_mean": 82.742}, "timestamp": "2026-01-30T14:48:22.030892"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5348.773, "latencies_ms": [5348.773], "images_per_second": 0.187, "prompt_tokens": 1442, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the windows. The colors in the image are mostly neutral, with the exception of the red chairs and the red and white banner in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.622}, "power_stats": {"power_gpu_soc_mean_watts": 21.764, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.278, "gpu_utilization_percent_mean": 72.622}, "timestamp": "2026-01-30T14:48:29.413622"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4455.659, "latencies_ms": [4455.659], "images_per_second": 0.224, "prompt_tokens": 1100, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, where a yellow traffic sign stands out against the backdrop of a red traffic light, a black pole, and a white car parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.517, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 70.351}, "timestamp": "2026-01-30T14:48:35.901549"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5836.503, "latencies_ms": [5836.503], "images_per_second": 0.171, "prompt_tokens": 1114, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. pole: 1\n2. traffic light: 1\n3. street sign: 1\n4. traffic light pole: 1\n5. yellow sign: 1\n6. black pole: 1\n7. black box: 1\n8. street: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.163}, "power_stats": {"power_gpu_soc_mean_watts": 18.173, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 68.163}, "timestamp": "2026-01-30T14:48:43.796638"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4784.124, "latencies_ms": [4784.124], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The yellow sign is positioned to the right of the black pole, which is located in the foreground of the image. The sign is situated near the edge of the road, while the pole extends into the background of the image.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.35}, "power_stats": {"power_gpu_soc_mean_watts": 19.69, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.35}, "timestamp": "2026-01-30T14:48:50.594092"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4822.485, "latencies_ms": [4822.485], "images_per_second": 0.207, "prompt_tokens": 1112, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image captures a bustling city street corner, where a yellow traffic sign stands out against the backdrop of a red traffic light and a blue bus. The street is lined with buildings, shops, and cars, creating a lively urban atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.591, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 71.95}, "timestamp": "2026-01-30T14:48:57.435114"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4391.947, "latencies_ms": [4391.947], "images_per_second": 0.228, "prompt_tokens": 1110, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a street corner with a yellow and black traffic sign, a black pole, and a red traffic light. The sky is cloudy, and the street is wet, suggesting recent rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13994.2, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.62, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 71.972}, "timestamp": "2026-01-30T14:49:03.850386"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3202.749, "latencies_ms": [3202.749], "images_per_second": 0.312, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man wearing a white shirt and a white hat is playing tennis on a court at night.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 13994.2, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.538}, "power_stats": {"power_gpu_soc_mean_watts": 23.227, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.199, "gpu_utilization_percent_mean": 76.538}, "timestamp": "2026-01-30T14:49:09.089037"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5541.25, "latencies_ms": [5541.25], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. fence: 1\n5. sign: 1\n6. net: 1\n7. court: 1\n8. player: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.652}, "power_stats": {"power_gpu_soc_mean_watts": 18.821, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 69.652}, "timestamp": "2026-01-30T14:49:16.645048"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4755.086, "latencies_ms": [4755.086], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis racket held in his right hand. The tennis court is located in the middle of the image, with the fence and advertisements in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.025}, "power_stats": {"power_gpu_soc_mean_watts": 19.708, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 70.025}, "timestamp": "2026-01-30T14:49:23.439618"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2668.366, "latencies_ms": [2668.366], "images_per_second": 0.375, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A man is playing tennis on a court at night.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.591}, "power_stats": {"power_gpu_soc_mean_watts": 24.893, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.29, "gpu_utilization_percent_mean": 80.591}, "timestamp": "2026-01-30T14:49:28.143423"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4464.515, "latencies_ms": [4464.515], "images_per_second": 0.224, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a tennis court with a green surface, a red fence, and a player wearing a white shirt and black shorts. The lighting is dim, and the court is illuminated by artificial lights.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.054}, "power_stats": {"power_gpu_soc_mean_watts": 20.29, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 72.054}, "timestamp": "2026-01-30T14:49:34.633736"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4572.963, "latencies_ms": [4572.963], "images_per_second": 0.219, "prompt_tokens": 1432, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A group of people, including a man in a black jacket and a woman in a white helmet, are standing on a snowy slope and talking to each other.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.579}, "power_stats": {"power_gpu_soc_mean_watts": 23.046, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.387, "gpu_utilization_percent_mean": 73.579}, "timestamp": "2026-01-30T14:49:41.267518"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6160.169, "latencies_ms": [6160.169], "images_per_second": 0.162, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 2\n2. helmet: 2\n3. goggles: 2\n4. skis: 2\n5. ski poles: 2\n6. net: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.404}, "power_stats": {"power_gpu_soc_mean_watts": 20.731, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 71.404}, "timestamp": "2026-01-30T14:49:49.468551"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5487.982, "latencies_ms": [5487.982], "images_per_second": 0.182, "prompt_tokens": 1450, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The skier in the foreground is wearing a helmet and goggles, while the skier in the background is wearing a helmet and goggles. The skier in the foreground is standing closer to the camera than the skier in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.587}, "power_stats": {"power_gpu_soc_mean_watts": 21.657, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 8.301, "gpu_utilization_percent_mean": 71.587}, "timestamp": "2026-01-30T14:49:56.983469"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4167.068, "latencies_ms": [4167.068], "images_per_second": 0.24, "prompt_tokens": 1444, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of people are standing on a snowy hill, wearing helmets and goggles, and some of them are holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.829}, "power_stats": {"power_gpu_soc_mean_watts": 24.516, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.476, "gpu_utilization_percent_mean": 74.829}, "timestamp": "2026-01-30T14:50:03.194721"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4917.82, "latencies_ms": [4917.82], "images_per_second": 0.203, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a group of people wearing helmets and goggles, standing on a snowy slope. The sky is clear, and the sun is shining brightly, casting a white glow on the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.9, "ram_available_mb": 48840.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.829}, "power_stats": {"power_gpu_soc_mean_watts": 22.783, "power_cpu_cv_mean_watts": 1.328, "power_sys_5v0_mean_watts": 8.411, "gpu_utilization_percent_mean": 74.829}, "timestamp": "2026-01-30T14:50:10.154650"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3177.762, "latencies_ms": [3177.762], "images_per_second": 0.315, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue truck with a trailer is driving down a wet street with houses and trees on either side.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14000.9, "ram_available_mb": 48840.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14000.9, "ram_available_mb": 48840.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.777, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T14:50:15.361700"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5390.086, "latencies_ms": [5390.086], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. truck: 1\n2. street: 1\n3. road: 1\n4. sidewalk: 1\n5. grass: 1\n6. trees: 1\n7. house: 1\n8. street light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.9, "ram_available_mb": 48840.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.998, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.2}, "timestamp": "2026-01-30T14:50:22.769667"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4016.084, "latencies_ms": [4016.084], "images_per_second": 0.249, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The blue truck is on the left side of the road, while the white car is on the right side. The truck is closer to the camera than the car.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.909}, "power_stats": {"power_gpu_soc_mean_watts": 21.404, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 69.909}, "timestamp": "2026-01-30T14:50:28.824969"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2882.719, "latencies_ms": [2882.719], "images_per_second": 0.347, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A blue truck is driving down a wet street with houses on the side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.042}, "power_stats": {"power_gpu_soc_mean_watts": 24.459, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.302, "gpu_utilization_percent_mean": 79.042}, "timestamp": "2026-01-30T14:50:33.747563"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2803.684, "latencies_ms": [2803.684], "images_per_second": 0.357, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The truck is blue and the road is wet from the rain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.609}, "power_stats": {"power_gpu_soc_mean_watts": 24.439, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 76.609}, "timestamp": "2026-01-30T14:50:38.609520"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3578.108, "latencies_ms": [3578.108], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In the image, a large airplane is seen on a runway, with a mountainous backdrop and a few red lights in the foreground.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.556, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.177, "gpu_utilization_percent_mean": 72.448}, "timestamp": "2026-01-30T14:50:44.221538"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3301.045, "latencies_ms": [3301.045], "images_per_second": 0.303, "prompt_tokens": 1113, "response_tokens_est": 21, "n_tiles": 1, "output_text": " airplane: 1\nrunway: 1\nmountains: 1\nlight: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.704}, "power_stats": {"power_gpu_soc_mean_watts": 23.149, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 72.704}, "timestamp": "2026-01-30T14:50:49.560806"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4944.977, "latencies_ms": [4944.977], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The airplane is positioned in the middle of the runway, with the runway extending towards the foreground and the mountains in the background. The airport lights are located in the foreground, with the airplane in the middle, and the mountains are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.668, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 70.244}, "timestamp": "2026-01-30T14:50:56.535408"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5412.056, "latencies_ms": [5412.056], "images_per_second": 0.185, "prompt_tokens": 1111, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image captures a moment at an airport runway where a large commercial airplane is taxiing on the wet tarmac. In the foreground, a row of red and white lights stands as a silent sentinel, while in the background, a hazy mountain range stretches across the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.356}, "power_stats": {"power_gpu_soc_mean_watts": 18.738, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 68.356}, "timestamp": "2026-01-30T14:51:03.960468"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4158.584, "latencies_ms": [4158.584], "images_per_second": 0.24, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a large airplane on a runway with a hazy sky in the background. The airplane is white with blue accents, and the runway is wet, reflecting the light.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.2}, "power_stats": {"power_gpu_soc_mean_watts": 20.98, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-30T14:51:10.161118"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3910.162, "latencies_ms": [3910.162], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " In the image, a group of people are enjoying a day at the beach, with one person holding a tennis racket and another holding a blue bag.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.848}, "power_stats": {"power_gpu_soc_mean_watts": 21.378, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.106, "gpu_utilization_percent_mean": 71.848}, "timestamp": "2026-01-30T14:51:16.119115"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4195.06, "latencies_ms": [4195.06], "images_per_second": 0.238, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " 1. beach\n2. people\n3. flag\n4. mountain\n5. beach umbrella\n6. beach chair\n7. beach ball\n8. beach umbrella", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.171}, "power_stats": {"power_gpu_soc_mean_watts": 21.018, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 71.171}, "timestamp": "2026-01-30T14:51:22.337334"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6124.462, "latencies_ms": [6124.462], "images_per_second": 0.163, "prompt_tokens": 1117, "response_tokens_est": 68, "n_tiles": 1, "output_text": " The woman in the orange shirt is standing closer to the camera than the woman in the yellow hoodie. The woman in the orange shirt is standing in the foreground, while the woman in the yellow hoodie is standing in the background. The woman in the orange shirt is also standing closer to the camera than the woman in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.231}, "power_stats": {"power_gpu_soc_mean_watts": 17.796, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 69.231}, "timestamp": "2026-01-30T14:51:30.483880"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2927.613, "latencies_ms": [2927.613], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A group of people are on a beach with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.875, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-30T14:51:35.470785"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5603.571, "latencies_ms": [5603.571], "images_per_second": 0.178, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is a vibrant depiction of a sunny day at the beach, with the clear blue sky and the warm sunlight casting a golden glow on the sandy beach. The colors are vivid, with the blue of the sky, the green of the trees, and the orange of the beach umbrellas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.255}, "power_stats": {"power_gpu_soc_mean_watts": 18.622, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 70.255}, "timestamp": "2026-01-30T14:51:43.110831"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3570.183, "latencies_ms": [3570.183], "images_per_second": 0.28, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A tennis player is standing on a blue court with a white logo on it, holding a tennis racket and looking down.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.269, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 74.621}, "timestamp": "2026-01-30T14:51:48.720307"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5713.052, "latencies_ms": [5713.052], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. man: 1\n2. tennis racket: 1\n3. tennis ball: 1\n4. tennis shoes: 2\n5. shorts: 1\n6. shirt: 1\n7. headband: 1\n8. wristband: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.146}, "power_stats": {"power_gpu_soc_mean_watts": 18.475, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 70.146}, "timestamp": "2026-01-30T14:51:56.471105"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4982.012, "latencies_ms": [4982.012], "images_per_second": 0.201, "prompt_tokens": 1118, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the blue tennis court serving as the dominant background. The player's shadow is cast on the court, indicating the direction of the sunlight and the player's position relative to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.098}, "power_stats": {"power_gpu_soc_mean_watts": 19.474, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 69.098}, "timestamp": "2026-01-30T14:52:03.485365"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4117.564, "latencies_ms": [4117.564], "images_per_second": 0.243, "prompt_tokens": 1112, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A tennis player is standing on a blue court with a white logo on it. He is holding a tennis racket and appears to be in a moment of contemplation or reflection.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.856, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 70.5}, "timestamp": "2026-01-30T14:52:09.658622"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4136.951, "latencies_ms": [4136.951], "images_per_second": 0.242, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a tennis player standing on a blue court with a white logo on the ground. The lighting is bright and the player is wearing a blue shirt and white shorts.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.088}, "power_stats": {"power_gpu_soc_mean_watts": 21.161, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 71.088}, "timestamp": "2026-01-30T14:52:15.819306"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3679.513, "latencies_ms": [3679.513], "images_per_second": 0.272, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A woman in a floral shirt and beige shorts is standing in a kitchen with a large black stove and a white cabinet in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.423, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-30T14:52:21.520671"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5414.206, "latencies_ms": [5414.206], "images_per_second": 0.185, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. stove: 1\n3. cupboard: 1\n4. shelf: 1\n5. dish: 1\n6. pot: 1\n7. kettle: 1\n8. cup: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.956}, "power_stats": {"power_gpu_soc_mean_watts": 18.934, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.956}, "timestamp": "2026-01-30T14:52:28.978717"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4601.659, "latencies_ms": [4601.659], "images_per_second": 0.217, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The woman is standing to the left of the stove, which is located in the center of the image. The stove is positioned in the foreground, with the woman's body and the kitchen counter in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.579}, "power_stats": {"power_gpu_soc_mean_watts": 20.02, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 66.579}, "timestamp": "2026-01-30T14:52:35.616095"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3004.374, "latencies_ms": [3004.374], "images_per_second": 0.333, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman is standing in a kitchen with a large black stove and a white cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.044, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 78.75}, "timestamp": "2026-01-30T14:52:40.632803"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5725.251, "latencies_ms": [5725.251], "images_per_second": 0.175, "prompt_tokens": 1110, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image is a black and white photo with a vintage feel, capturing a woman in a kitchen with a large black stove and a white wall. The lighting is soft and diffused, creating a warm atmosphere. The materials used in the photo are wood and metal, giving it a rustic charm.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 18.085, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 7.931, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-30T14:52:48.412721"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3650.157, "latencies_ms": [3650.157], "images_per_second": 0.274, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two giraffes are standing in front of a building, with one of them eating grass.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.4}, "power_stats": {"power_gpu_soc_mean_watts": 25.384, "power_cpu_cv_mean_watts": 0.827, "power_sys_5v0_mean_watts": 8.532, "gpu_utilization_percent_mean": 81.4}, "timestamp": "2026-01-30T14:52:54.096350"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5982.492, "latencies_ms": [5982.492], "images_per_second": 0.167, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. giraffe: 2\n2. giraffe: 2\n3. giraffe: 2\n4. giraffe: 2\n5. giraffe: 2\n6. giraffe: 2\n7. giraffe: 2\n8. giraffe: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.94}, "power_stats": {"power_gpu_soc_mean_watts": 21.199, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.298, "gpu_utilization_percent_mean": 71.94}, "timestamp": "2026-01-30T14:53:02.119095"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4555.133, "latencies_ms": [4555.133], "images_per_second": 0.22, "prompt_tokens": 1450, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The giraffes are positioned in the foreground of the image, with the building in the background. The larger giraffe is standing closer to the camera than the smaller one.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.816}, "power_stats": {"power_gpu_soc_mean_watts": 23.728, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.426, "gpu_utilization_percent_mean": 74.816}, "timestamp": "2026-01-30T14:53:08.732805"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3668.225, "latencies_ms": [3668.225], "images_per_second": 0.273, "prompt_tokens": 1444, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two giraffes are standing in a zoo enclosure, one of them eating from a tree.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.367}, "power_stats": {"power_gpu_soc_mean_watts": 25.944, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 8.573, "gpu_utilization_percent_mean": 81.367}, "timestamp": "2026-01-30T14:53:14.421619"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3429.469, "latencies_ms": [3429.469], "images_per_second": 0.292, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The giraffes are brown and white, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.393}, "power_stats": {"power_gpu_soc_mean_watts": 26.542, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.608, "gpu_utilization_percent_mean": 80.393}, "timestamp": "2026-01-30T14:53:19.877852"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3601.518, "latencies_ms": [3601.518], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young boy wearing a green and yellow baseball uniform is swinging a blue and white baseball bat at a ball in a baseball game.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.261, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-30T14:53:25.543024"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5665.307, "latencies_ms": [5665.307], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. boy: 1\n2. helmet: 1\n3. bat: 1\n4. ball: 1\n5. chain link fence: 1\n6. grass: 1\n7. chain link fence: 1\n8. baseball field: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.588, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 69.596}, "timestamp": "2026-01-30T14:53:33.231079"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4239.081, "latencies_ms": [4239.081], "images_per_second": 0.236, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The baseball player is in the foreground, holding a bat and swinging it towards the ball. The ball is in the middle ground, and the chain link fence is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.4}, "power_stats": {"power_gpu_soc_mean_watts": 20.832, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 71.4}, "timestamp": "2026-01-30T14:53:39.506606"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2966.25, "latencies_ms": [2966.25], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A young boy is playing baseball in a field with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.708}, "power_stats": {"power_gpu_soc_mean_watts": 24.342, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 77.708}, "timestamp": "2026-01-30T14:53:44.492940"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5947.62, "latencies_ms": [5947.62], "images_per_second": 0.168, "prompt_tokens": 1109, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The image features a young boy wearing a green and yellow baseball uniform, swinging a blue and white baseball bat at a white baseball. The boy is standing on a dirt field, and the background includes a chain link fence and some trees. The lighting in the image is bright and sunny, and the colors are vibrant and clear.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.8}, "power_stats": {"power_gpu_soc_mean_watts": 18.05, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 68.8}, "timestamp": "2026-01-30T14:53:52.479681"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4956.201, "latencies_ms": [4956.201], "images_per_second": 0.202, "prompt_tokens": 1099, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image captures a bustling scene at a vintage car show, with a variety of classic vehicles parked on a cobblestone street, including a red bus, a black car, and a motorcycle, all under the watchful eyes of onlookers.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.379, "power_cpu_cv_mean_watts": 1.572, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T14:53:59.477705"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5835.673, "latencies_ms": [5835.673], "images_per_second": 0.171, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. black car: 2\n2. red bus: 1\n3. black motorcycle: 1\n4. green tank: 1\n5. red flag: 1\n6. black car: 1\n7. black motorcycle: 1\n8. red flag: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.6, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.245}, "power_stats": {"power_gpu_soc_mean_watts": 18.301, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 68.245}, "timestamp": "2026-01-30T14:54:07.330706"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5000.183, "latencies_ms": [5000.183], "images_per_second": 0.2, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The motorcycles are positioned in the foreground, with the red bus in the background. The red bus is parked on the right side of the image, while the motorcycles are on the left. The motorcycles are closer to the camera than the red bus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.071}, "power_stats": {"power_gpu_soc_mean_watts": 19.314, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.071}, "timestamp": "2026-01-30T14:54:14.367294"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3198.314, "latencies_ms": [3198.314], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of people are gathered in a parking lot, with vintage cars and motorcycles parked around them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.852}, "power_stats": {"power_gpu_soc_mean_watts": 23.429, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.227, "gpu_utilization_percent_mean": 73.852}, "timestamp": "2026-01-30T14:54:19.619670"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5183.518, "latencies_ms": [5183.518], "images_per_second": 0.193, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a cobblestone street with a variety of vehicles, including vintage cars and motorcycles, parked on the side. The sky is clear and blue, indicating a sunny day. The vehicles are mostly black and white, with some having red and green accents.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.318}, "power_stats": {"power_gpu_soc_mean_watts": 19.155, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 68.318}, "timestamp": "2026-01-30T14:54:26.828798"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4568.704, "latencies_ms": [4568.704], "images_per_second": 0.219, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a close-up view of two parking meters, their backs facing the camera, with the sun setting in the background, casting a warm glow and creating a bokeh effect with the surrounding lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.763}, "power_stats": {"power_gpu_soc_mean_watts": 20.306, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 69.763}, "timestamp": "2026-01-30T14:54:33.425068"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2507.449, "latencies_ms": [2507.449], "images_per_second": 0.399, "prompt_tokens": 1113, "response_tokens_est": 8, "n_tiles": 1, "output_text": " 1. parking meter: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.7, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.95}, "power_stats": {"power_gpu_soc_mean_watts": 25.164, "power_cpu_cv_mean_watts": 0.66, "power_sys_5v0_mean_watts": 8.297, "gpu_utilization_percent_mean": 80.95}, "timestamp": "2026-01-30T14:54:37.951952"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5041.485, "latencies_ms": [5041.485], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The two parking meters are positioned in the foreground, with the sun setting in the background, creating a warm and inviting atmosphere. The parking meters are relatively close to the camera, while the sun is farther away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.14}, "power_stats": {"power_gpu_soc_mean_watts": 19.413, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 70.14}, "timestamp": "2026-01-30T14:54:45.032589"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3784.764, "latencies_ms": [3784.764], "images_per_second": 0.264, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image captures a serene moment at a parking lot during sunset, with two parking meters in the foreground and a blurred cityscape in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.935}, "power_stats": {"power_gpu_soc_mean_watts": 21.931, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.141, "gpu_utilization_percent_mean": 71.935}, "timestamp": "2026-01-30T14:54:50.853656"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5104.514, "latencies_ms": [5104.514], "images_per_second": 0.196, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image features two parking meters with a warm, golden glow from the setting sun in the background. The parking meters are black and have a metallic finish, and the sun is setting behind them, casting a soft light that creates a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.302}, "power_stats": {"power_gpu_soc_mean_watts": 19.228, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 68.302}, "timestamp": "2026-01-30T14:54:57.986852"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5311.869, "latencies_ms": [5311.869], "images_per_second": 0.188, "prompt_tokens": 1099, "response_tokens_est": 55, "n_tiles": 1, "output_text": " In the image, a large brown suitcase adorned with stickers from various countries like China, India, and Bangladesh is prominently displayed on a sidewalk, with a couple of people standing nearby, and a building with a sign that reads \"Fidelity Investments\" in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.837, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-30T14:55:05.324613"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6022.783, "latencies_ms": [6022.783], "images_per_second": 0.166, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. suitcase: 1\n2. man: 1\n3. woman: 1\n4. man's hand: 1\n5. woman's hand: 1\n6. suitcase tag: 4\n7. suitcase handle: 1\n8. suitcase buckle: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.882}, "power_stats": {"power_gpu_soc_mean_watts": 17.933, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 68.882}, "timestamp": "2026-01-30T14:55:13.371104"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4063.255, "latencies_ms": [4063.255], "images_per_second": 0.246, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The suitcase is positioned to the left of the couple, who are standing in the background. The suitcase is in the foreground, while the couple is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.147}, "power_stats": {"power_gpu_soc_mean_watts": 21.502, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.141, "gpu_utilization_percent_mean": 71.147}, "timestamp": "2026-01-30T14:55:19.472731"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4770.286, "latencies_ms": [4770.286], "images_per_second": 0.21, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In the image, a large brown suitcase with stickers from various countries is placed on a sidewalk in front of a building. A couple is standing next to the suitcase, and a man is standing in front of the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.879, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 70.95}, "timestamp": "2026-01-30T14:55:26.281089"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3163.883, "latencies_ms": [3163.883], "images_per_second": 0.316, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The suitcase is brown and white, and the suitcase is in front of a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.731}, "power_stats": {"power_gpu_soc_mean_watts": 23.636, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.265, "gpu_utilization_percent_mean": 76.731}, "timestamp": "2026-01-30T14:55:31.467787"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3662.759, "latencies_ms": [3662.759], "images_per_second": 0.273, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image features a plate of food that includes a variety of mushrooms, broccoli, and a piece of meat, all garnished with parsley.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.486, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.199, "gpu_utilization_percent_mean": 74.1}, "timestamp": "2026-01-30T14:55:37.161678"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2964.263, "latencies_ms": [2964.263], "images_per_second": 0.337, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " mushroom: 10, broccoli: 2, parsley: 10", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.323, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.289, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-30T14:55:42.146857"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4053.367, "latencies_ms": [4053.367], "images_per_second": 0.247, "prompt_tokens": 1117, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The mushrooms are located in the foreground, with the broccoli situated in the background. The parsley is sprinkled on top of the mushrooms and broccoli, creating a visually appealing contrast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.545}, "power_stats": {"power_gpu_soc_mean_watts": 21.547, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 70.545}, "timestamp": "2026-01-30T14:55:48.221769"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4081.261, "latencies_ms": [4081.261], "images_per_second": 0.245, "prompt_tokens": 1111, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In a close-up shot, a plate of food is presented, featuring a variety of ingredients including mushrooms, broccoli, and a piece of meat garnished with parsley.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.765}, "power_stats": {"power_gpu_soc_mean_watts": 21.209, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 69.765}, "timestamp": "2026-01-30T14:55:54.358390"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4438.608, "latencies_ms": [4438.608], "images_per_second": 0.225, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a plate of food with a variety of colors, including green broccoli, brown mushrooms, and white chicken. The lighting is bright and natural, highlighting the textures and colors of the food.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.595}, "power_stats": {"power_gpu_soc_mean_watts": 20.465, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 68.595}, "timestamp": "2026-01-30T14:56:00.812205"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4286.856, "latencies_ms": [4286.856], "images_per_second": 0.233, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce, with a variety of vegetables and fruits neatly arranged on wooden crates and baskets, creating a visually appealing and healthy assortment of food items.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.943}, "power_stats": {"power_gpu_soc_mean_watts": 20.72, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 69.943}, "timestamp": "2026-01-30T14:56:07.144438"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4221.365, "latencies_ms": [4221.365], "images_per_second": 0.237, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " carrot: 12, cabbage: 1, cauliflower: 1, broccoli: 1, lettuce: 1, radish: 1, daisy: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.686}, "power_stats": {"power_gpu_soc_mean_watts": 21.052, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 71.686}, "timestamp": "2026-01-30T14:56:13.411669"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4133.751, "latencies_ms": [4133.751], "images_per_second": 0.242, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The carrots are in the foreground, while the broccoli is in the background. The leafy greens are in the middle ground, with the radishes and fennel in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.588}, "power_stats": {"power_gpu_soc_mean_watts": 21.117, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.097, "gpu_utilization_percent_mean": 71.588}, "timestamp": "2026-01-30T14:56:19.568854"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5217.233, "latencies_ms": [5217.233], "images_per_second": 0.192, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant display of fresh produce at a market stall, with a variety of vegetables and fruits neatly arranged in baskets and crates. The colors and textures of the produce create a visually appealing scene, showcasing the freshness and abundance of the items on display.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.814}, "power_stats": {"power_gpu_soc_mean_watts": 19.118, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.814}, "timestamp": "2026-01-30T14:56:26.822112"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5688.101, "latencies_ms": [5688.101], "images_per_second": 0.176, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a variety of fresh vegetables, including carrots, broccoli, and cauliflower, displayed in a rustic wooden crate. The lighting is natural and soft, highlighting the vibrant colors of the produce. The vegetables are arranged in a way that showcases their textures and colors, creating a visually appealing display.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.234}, "power_stats": {"power_gpu_soc_mean_watts": 18.376, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 68.234}, "timestamp": "2026-01-30T14:56:34.530067"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4576.278, "latencies_ms": [4576.278], "images_per_second": 0.219, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a bustling scene inside a donut shop, where a variety of donuts are being prepared on a conveyor belt, with workers diligently handling the doughnuts, and customers waiting in line to purchase them.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.348, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 68.816}, "timestamp": "2026-01-30T14:56:41.152054"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3011.238, "latencies_ms": [3011.238], "images_per_second": 0.332, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " donut: 10\nmachine: 2\nperson: 3", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.173, "power_cpu_cv_mean_watts": 0.834, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 76.25}, "timestamp": "2026-01-30T14:56:46.206475"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5955.584, "latencies_ms": [5955.584], "images_per_second": 0.168, "prompt_tokens": 1117, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The donut machine is located in the foreground, with the donuts being processed on the left side. The donut machine is positioned in the middle of the image, with the donuts being processed on the right side. The donut machine is located in the foreground, with the donuts being processed on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.32}, "power_stats": {"power_gpu_soc_mean_watts": 18.21, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 68.32}, "timestamp": "2026-01-30T14:56:54.217939"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4848.243, "latencies_ms": [4848.243], "images_per_second": 0.206, "prompt_tokens": 1111, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a bustling scene inside a donut shop, where a variety of donuts are being prepared on a conveyor belt. The shop is well-lit, with customers waiting in line to purchase the freshly made donuts.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.6}, "power_stats": {"power_gpu_soc_mean_watts": 19.569, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 71.6}, "timestamp": "2026-01-30T14:57:01.077536"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4628.562, "latencies_ms": [4628.562], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is taken in a brightly lit bakery with a green wall and a red sign that reads \"HOT\". The bakery is filled with people and various equipment, including a conveyor belt with donuts on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.135, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 66.816}, "timestamp": "2026-01-30T14:57:07.729328"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3398.946, "latencies_ms": [3398.946], "images_per_second": 0.294, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man in a green jacket and white shoes is bending over in a forest, holding an orange frisbee.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.821}, "power_stats": {"power_gpu_soc_mean_watts": 22.906, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.168, "gpu_utilization_percent_mean": 71.821}, "timestamp": "2026-01-30T14:57:13.194051"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5718.459, "latencies_ms": [5718.459], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. person: 1\n2. tree: 2\n3. frisbee: 1\n4. ground: 1\n5. leaves: 1\n6. tree trunk: 1\n7. green jacket: 1\n8. white socks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.208}, "power_stats": {"power_gpu_soc_mean_watts": 18.278, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 66.208}, "timestamp": "2026-01-30T14:57:20.971731"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4337.866, "latencies_ms": [4337.866], "images_per_second": 0.231, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is standing in the middle of the forest, with the trees surrounding him. The orange frisbee is in front of him, and the white frisbee is behind him.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.675, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 72.306}, "timestamp": "2026-01-30T14:57:27.338941"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3132.241, "latencies_ms": [3132.241], "images_per_second": 0.319, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man in a green jacket and white shoes is playing frisbee in a forest.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.962}, "power_stats": {"power_gpu_soc_mean_watts": 23.345, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.215, "gpu_utilization_percent_mean": 71.962}, "timestamp": "2026-01-30T14:57:32.518244"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4523.288, "latencies_ms": [4523.288], "images_per_second": 0.221, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a person in a green jacket and white shoes, standing in a forest with a brown tree trunk and a white frisbee. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.053}, "power_stats": {"power_gpu_soc_mean_watts": 20.367, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 69.053}, "timestamp": "2026-01-30T14:57:39.089809"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3502.319, "latencies_ms": [3502.319], "images_per_second": 0.286, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a white toilet, and a shower curtain with blue and green stripes.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.966}, "power_stats": {"power_gpu_soc_mean_watts": 22.492, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.136, "gpu_utilization_percent_mean": 72.966}, "timestamp": "2026-01-30T14:57:44.630581"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6070.075, "latencies_ms": [6070.075], "images_per_second": 0.165, "prompt_tokens": 1114, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. sink: 1\n2. mirror: 1\n3. toilet: 1\n4. shower curtain: 1\n5. can of Ajax: 1\n6. bottle of blue liquid: 1\n7. bottle of blue liquid: 1\n8. toothbrush holder: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.333}, "power_stats": {"power_gpu_soc_mean_watts": 17.908, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T14:57:52.714610"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4749.782, "latencies_ms": [4749.782], "images_per_second": 0.211, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The sink is located to the left of the mirror, which is above the toilet. The shower curtain is hanging to the right of the toilet. The can of Ajax is placed on the counter in front of the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.959, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T14:57:59.497421"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3015.548, "latencies_ms": [3015.548], "images_per_second": 0.332, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A bathroom with a sink, toilet, and shower curtain is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.88}, "power_stats": {"power_gpu_soc_mean_watts": 23.687, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 76.88}, "timestamp": "2026-01-30T14:58:04.542239"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3588.017, "latencies_ms": [3588.017], "images_per_second": 0.279, "prompt_tokens": 1110, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The bathroom is well-lit with natural light coming from a window, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.49, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 72.448}, "timestamp": "2026-01-30T14:58:10.147878"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3778.098, "latencies_ms": [3778.098], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a modern kitchen with a large island, a sink, and a dining table with chairs, all made of wood and black countertops.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.161}, "power_stats": {"power_gpu_soc_mean_watts": 22.228, "power_cpu_cv_mean_watts": 1.278, "power_sys_5v0_mean_watts": 8.154, "gpu_utilization_percent_mean": 71.161}, "timestamp": "2026-01-30T14:58:15.956406"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4071.284, "latencies_ms": [4071.284], "images_per_second": 0.246, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " sink: 1, countertop: 1, cabinet: 1, window: 1, chair: 1, table: 1, door: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.088}, "power_stats": {"power_gpu_soc_mean_watts": 21.398, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.14, "gpu_utilization_percent_mean": 70.088}, "timestamp": "2026-01-30T14:58:22.081718"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4539.336, "latencies_ms": [4539.336], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sink is located to the left of the stove, and the dining table is situated in the background. The kitchen island is positioned in the foreground, with the sink and stove being the closest objects to the camera.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.472, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 71.816}, "timestamp": "2026-01-30T14:58:28.660385"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2800.333, "latencies_ms": [2800.333], "images_per_second": 0.357, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A kitchen with a large island and a dining table in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.348}, "power_stats": {"power_gpu_soc_mean_watts": 24.977, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.378, "gpu_utilization_percent_mean": 79.348}, "timestamp": "2026-01-30T14:58:33.500734"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3173.705, "latencies_ms": [3173.705], "images_per_second": 0.315, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The kitchen has a black countertop, white walls, and natural light coming in from the windows.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.854, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.304, "gpu_utilization_percent_mean": 77.5}, "timestamp": "2026-01-30T14:58:38.704916"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3213.507, "latencies_ms": [3213.507], "images_per_second": 0.311, "prompt_tokens": 1100, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A person is lying in bed with a blanket that has a pattern of daisies on it.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.692}, "power_stats": {"power_gpu_soc_mean_watts": 23.562, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 74.692}, "timestamp": "2026-01-30T14:58:43.946326"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5519.7, "latencies_ms": [5519.7], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. bed: 1\n3. blanket: 1\n4. pillow: 1\n5. wall: 1\n6. curtain: 1\n7. bedside table: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.555, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 71.043}, "timestamp": "2026-01-30T14:58:51.503190"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4408.294, "latencies_ms": [4408.294], "images_per_second": 0.227, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The person is lying on the bed, which is positioned in the foreground of the image. The bed is located in the middle of the room, with the wall and a window in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.973}, "power_stats": {"power_gpu_soc_mean_watts": 20.333, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.973}, "timestamp": "2026-01-30T14:58:57.972723"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4784.356, "latencies_ms": [4784.356], "images_per_second": 0.209, "prompt_tokens": 1112, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In a dimly lit room, a child lies in bed, covered with a blanket adorned with daisy patterns. The child's face is obscured, and the room is shrouded in darkness, creating an atmosphere of tranquility and solitude.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.551, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 66.95}, "timestamp": "2026-01-30T14:59:04.786952"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5164.995, "latencies_ms": [5164.995], "images_per_second": 0.194, "prompt_tokens": 1110, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image depicts a child sleeping in a bed with a dark blue comforter adorned with white daisy patterns. The room is dimly lit, with only a small amount of light coming from the window, casting a soft glow on the child and the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.256}, "power_stats": {"power_gpu_soc_mean_watts": 19.35, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 69.256}, "timestamp": "2026-01-30T14:59:11.967516"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3840.899, "latencies_ms": [3840.899], "images_per_second": 0.26, "prompt_tokens": 1100, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A person is riding a skateboard on a ramp, wearing shorts and sneakers, with a man sitting on the side of the ramp in the background.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13996.9, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.5}, "power_stats": {"power_gpu_soc_mean_watts": 21.821, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T14:59:17.839966"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5684.014, "latencies_ms": [5684.014], "images_per_second": 0.176, "prompt_tokens": 1114, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. skateboard: 1\n2. person: 1\n3. shorts: 1\n4. socks: 1\n5. shoes: 1\n6. skateboard wheels: 2\n7. skateboard deck: 1\n8. shadow: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.9, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.255}, "power_stats": {"power_gpu_soc_mean_watts": 18.554, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 68.255}, "timestamp": "2026-01-30T14:59:25.544327"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4489.245, "latencies_ms": [4489.245], "images_per_second": 0.223, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The skateboarder's feet are in the foreground, with the skateboard and the ramp in the middle ground. The person sitting on the ramp is in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.214, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 71.892}, "timestamp": "2026-01-30T14:59:32.068313"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3360.618, "latencies_ms": [3360.618], "images_per_second": 0.298, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is riding a skateboard on a ramp, while another person is sitting on the edge of the ramp.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.63}, "power_stats": {"power_gpu_soc_mean_watts": 23.117, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 73.63}, "timestamp": "2026-01-30T14:59:37.463015"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5669.075, "latencies_ms": [5669.075], "images_per_second": 0.176, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image is in black and white, with the skateboarder's legs and shoes being the focal point. The skateboarder is wearing white socks and sneakers with a logo on them. The skateboarder is wearing shorts, and the shadow of the skateboarder is visible on the ground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.723}, "power_stats": {"power_gpu_soc_mean_watts": 18.562, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 69.723}, "timestamp": "2026-01-30T14:59:45.170484"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3428.682, "latencies_ms": [3428.682], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man is lying on the floor with a laptop, a tennis racket, and a book on the floor.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.835, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 74.25}, "timestamp": "2026-01-30T14:59:50.649747"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4588.591, "latencies_ms": [4588.591], "images_per_second": 0.218, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " laptop: 1\ncamera: 1\nphone: 1\nracket: 1\nbottle: 1\nbook: 1\ncamera lens: 1\nbook: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.769}, "power_stats": {"power_gpu_soc_mean_watts": 19.988, "power_cpu_cv_mean_watts": 1.437, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 72.769}, "timestamp": "2026-01-30T14:59:57.259958"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5188.865, "latencies_ms": [5188.865], "images_per_second": 0.193, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The laptop is in the middle of the image, with the tennis racket and camera to its right. The books are in the foreground, with the laptop and camera to its left. The man is lying on the floor, with his head near the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.918, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 69.25}, "timestamp": "2026-01-30T15:00:04.490158"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3204.441, "latencies_ms": [3204.441], "images_per_second": 0.312, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man is lying on the floor with a laptop, a tennis racket, and a book.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.654}, "power_stats": {"power_gpu_soc_mean_watts": 23.758, "power_cpu_cv_mean_watts": 1.062, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 75.654}, "timestamp": "2026-01-30T15:00:09.733134"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4100.826, "latencies_ms": [4100.826], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with natural light coming from the window. The colors in the image are vibrant and the materials are mostly plastic and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.294}, "power_stats": {"power_gpu_soc_mean_watts": 21.078, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 73.294}, "timestamp": "2026-01-30T15:00:15.873257"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3542.514, "latencies_ms": [3542.514], "images_per_second": 0.282, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image shows a kitchen with a black stove top, a black range hood above it, and a marble backsplash.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 22.354, "power_cpu_cv_mean_watts": 1.147, "power_sys_5v0_mean_watts": 8.145, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-30T15:00:21.457018"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5052.547, "latencies_ms": [5052.547], "images_per_second": 0.198, "prompt_tokens": 1113, "response_tokens_est": 47, "n_tiles": 1, "output_text": " 1. black stove top\n2. black range hood\n3. black knife block\n4. black pot\n5. black pot lid\n6. black pot handle\n7. black pot base\n8. black pot ring", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.048}, "power_stats": {"power_gpu_soc_mean_watts": 19.209, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 69.048}, "timestamp": "2026-01-30T15:00:28.533431"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4536.042, "latencies_ms": [4536.042], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The stove is located in the foreground, with the spice rack and hanging towels positioned further back. The spice rack is situated to the left of the stove, while the hanging towels are located to the right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.158}, "power_stats": {"power_gpu_soc_mean_watts": 20.156, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 72.158}, "timestamp": "2026-01-30T15:00:35.109154"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2807.299, "latencies_ms": [2807.299], "images_per_second": 0.356, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A kitchen with a stove and a spice rack on the counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.371, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.254, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T15:00:39.928873"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3240.301, "latencies_ms": [3240.301], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The kitchen has a marble backsplash, a black stove top, and a black range hood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.667}, "power_stats": {"power_gpu_soc_mean_watts": 23.165, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 73.667}, "timestamp": "2026-01-30T15:00:45.204413"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3704.65, "latencies_ms": [3704.65], "images_per_second": 0.27, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A person is sitting at a table with a plate of food, including a donut with chocolate and sprinkles, and a cup of coffee.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.161}, "power_stats": {"power_gpu_soc_mean_watts": 22.18, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 73.161}, "timestamp": "2026-01-30T15:00:50.948423"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5705.041, "latencies_ms": [5705.041], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. cup: 1\n2. plate: 1\n3. donut: 1\n4. donut: 1\n5. donut: 1\n6. donut: 1\n7. donut: 1\n8. donut: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.503, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 69.021}, "timestamp": "2026-01-30T15:00:58.677754"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4554.27, "latencies_ms": [4554.27], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground, with the person in the foreground holding a donut and the plate of food in the middle. The background includes a table with other people and a wall with posters.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.649}, "power_stats": {"power_gpu_soc_mean_watts": 20.549, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 69.649}, "timestamp": "2026-01-30T15:01:05.245465"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3497.729, "latencies_ms": [3497.729], "images_per_second": 0.286, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A young man is sitting at a table in a coffee shop, eating a chocolate donut and drinking a cup of coffee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.034}, "power_stats": {"power_gpu_soc_mean_watts": 22.466, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 74.034}, "timestamp": "2026-01-30T15:01:10.778072"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3770.327, "latencies_ms": [3770.327], "images_per_second": 0.265, "prompt_tokens": 1110, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is taken in a dimly lit cafe with warm lighting, and the food is presented on a tray with a white paper liner.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.097}, "power_stats": {"power_gpu_soc_mean_watts": 22.014, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.125, "gpu_utilization_percent_mean": 72.097}, "timestamp": "2026-01-30T15:01:16.596105"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4110.52, "latencies_ms": [4110.52], "images_per_second": 0.243, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a black and white toilet seat, and a glass countertop, all set against a black and white checkered floor.", "error": null, "sys_before": {"cpu_percent": 17.4, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.853}, "power_stats": {"power_gpu_soc_mean_watts": 21.173, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 71.853}, "timestamp": "2026-01-30T15:01:22.756643"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6072.998, "latencies_ms": [6072.998], "images_per_second": 0.165, "prompt_tokens": 1114, "response_tokens_est": 68, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Sink: 1\n3. Bathtub: 1\n4. Tile: 1\n5. Toilet seat: 1\n6. Bathroom counter: 1\n7. Glass: 1\n8. Tile backsplash: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.216}, "power_stats": {"power_gpu_soc_mean_watts": 18.096, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 70.216}, "timestamp": "2026-01-30T15:01:30.849121"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6171.617, "latencies_ms": [6171.617], "images_per_second": 0.162, "prompt_tokens": 1118, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The sink is located to the left of the toilet, which is situated in the foreground of the image. The toilet lid is black and white, with a pattern resembling a cow's face, and is positioned near the center of the image. The sink is white and has a transparent glass top, and is situated to the right of the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.577}, "power_stats": {"power_gpu_soc_mean_watts": 17.842, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.963, "gpu_utilization_percent_mean": 67.577}, "timestamp": "2026-01-30T15:01:39.076900"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3168.132, "latencies_ms": [3168.132], "images_per_second": 0.316, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A bathroom with a black and white toilet, a sink, and a blue and white tile wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.615}, "power_stats": {"power_gpu_soc_mean_watts": 23.529, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 77.615}, "timestamp": "2026-01-30T15:01:44.261174"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3387.974, "latencies_ms": [3387.974], "images_per_second": 0.295, "prompt_tokens": 1110, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bathroom has a black and white checkered floor, a white sink, and a black and white toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.286}, "power_stats": {"power_gpu_soc_mean_watts": 23.036, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-30T15:01:49.679102"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7142.586, "latencies_ms": [7142.586], "images_per_second": 0.14, "prompt_tokens": 1100, "response_tokens_est": 87, "n_tiles": 1, "output_text": " In the image, there is a memorial for Joseph Panis, who passed away on May 11, 1998, at the age of 41. The memorial is adorned with teddy bears and a sign that reads \"Joseph Panis\" and \"Mysti Mallean.\" The memorial is situated in a garden, surrounded by a fence and various plants, including a large green plant in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.344}, "power_stats": {"power_gpu_soc_mean_watts": 17.0, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 68.344}, "timestamp": "2026-01-30T15:01:58.877587"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4292.149, "latencies_ms": [4292.149], "images_per_second": 0.233, "prompt_tokens": 1114, "response_tokens_est": 38, "n_tiles": 1, "output_text": " teddy bear: 3\ngrass: 1\nstone: 1\nwooden sign: 1\nbrick: 1\ntree: 1\nhouse: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.798, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T15:02:05.199902"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4682.011, "latencies_ms": [4682.011], "images_per_second": 0.214, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The teddy bears are positioned on the right side of the cross, which is located in the middle of the image. The cross is situated in the foreground of the image, with the background featuring a grassy area and a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.41}, "power_stats": {"power_gpu_soc_mean_watts": 20.172, "power_cpu_cv_mean_watts": 1.499, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 71.41}, "timestamp": "2026-01-30T15:02:11.900026"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3559.834, "latencies_ms": [3559.834], "images_per_second": 0.281, "prompt_tokens": 1112, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A teddy bear is placed on a grave with a sign that reads \"Joseph Panis\" and \"Mysti Malain\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.233}, "power_stats": {"power_gpu_soc_mean_watts": 22.113, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 71.233}, "timestamp": "2026-01-30T15:02:17.503937"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3228.252, "latencies_ms": [3228.252], "images_per_second": 0.31, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The teddy bears are white and the grass is green. The sky is blue and the sun is shining.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.575, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 74.37}, "timestamp": "2026-01-30T15:02:22.758398"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4042.131, "latencies_ms": [4042.131], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image captures a bustling restaurant with a large clock on the wall, where people are seated at tables, enjoying their meals and drinks, with a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.706}, "power_stats": {"power_gpu_soc_mean_watts": 21.234, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 70.706}, "timestamp": "2026-01-30T15:02:28.827853"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4246.905, "latencies_ms": [4246.905], "images_per_second": 0.235, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " table: 10, chair: 20, person: 10, clock: 1, light: 1, wall: 1, roof: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.914}, "power_stats": {"power_gpu_soc_mean_watts": 20.957, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.091, "gpu_utilization_percent_mean": 69.914}, "timestamp": "2026-01-30T15:02:35.101702"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4685.117, "latencies_ms": [4685.117], "images_per_second": 0.213, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The clock is positioned in the background, far from the camera, and is surrounded by a dining area with tables and chairs. The dining area is located in the foreground, close to the camera, and is filled with people.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.231}, "power_stats": {"power_gpu_soc_mean_watts": 20.237, "power_cpu_cv_mean_watts": 1.499, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 71.231}, "timestamp": "2026-01-30T15:02:41.799209"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3356.763, "latencies_ms": [3356.763], "images_per_second": 0.298, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image captures a bustling restaurant with a large clock in the background, where people are enjoying their meals and drinks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.857}, "power_stats": {"power_gpu_soc_mean_watts": 23.265, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 72.857}, "timestamp": "2026-01-30T15:02:47.169920"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4881.927, "latencies_ms": [4881.927], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere, characterized by the use of wood and metal in the interior design. The lighting is soft and natural, coming from the large window that allows natural light to flood the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.683}, "power_stats": {"power_gpu_soc_mean_watts": 19.737, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 70.683}, "timestamp": "2026-01-30T15:02:54.074020"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3872.423, "latencies_ms": [3872.423], "images_per_second": 0.258, "prompt_tokens": 1100, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A man and a child are standing on a snow-covered slope, with the man wearing a black jacket and the child wearing a pink snowsuit.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.562}, "power_stats": {"power_gpu_soc_mean_watts": 21.758, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.119, "gpu_utilization_percent_mean": 71.562}, "timestamp": "2026-01-30T15:02:59.981434"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5502.382, "latencies_ms": [5502.382], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. snow: 1\n3. trees: 1\n4. rocks: 1\n5. skis: 1\n6. goggles: 1\n7. snowboard: 1\n8. backpack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.891}, "power_stats": {"power_gpu_soc_mean_watts": 18.758, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 69.891}, "timestamp": "2026-01-30T15:03:07.508954"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5997.936, "latencies_ms": [5997.936], "images_per_second": 0.167, "prompt_tokens": 1118, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The child in the foreground is standing closer to the camera than the person in the black jacket. The child in the foreground is standing on the left side of the image, while the person in the black jacket is standing on the right side. The child in the foreground is closer to the camera than the person in the black jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.922}, "power_stats": {"power_gpu_soc_mean_watts": 17.925, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 67.922}, "timestamp": "2026-01-30T15:03:15.540163"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3079.478, "latencies_ms": [3079.478], "images_per_second": 0.325, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A man and a child are standing on a snowy mountain, with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.845, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 76.4}, "timestamp": "2026-01-30T15:03:20.642559"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4376.659, "latencies_ms": [4376.659], "images_per_second": 0.228, "prompt_tokens": 1110, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a snowy mountain with a child wearing a black jacket and a man wearing a black jacket standing on the snow. The sky is clear and blue, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.41, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 71.351}, "timestamp": "2026-01-30T15:03:27.069261"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4130.49, "latencies_ms": [4130.49], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A pair of feet wearing flip-flops is standing on a wooden floor with three old mobile phones, one of which is a flip phone, and a broken phone battery.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.147}, "power_stats": {"power_gpu_soc_mean_watts": 21.043, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 70.147}, "timestamp": "2026-01-30T15:03:33.256827"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3057.294, "latencies_ms": [3057.294], "images_per_second": 0.327, "prompt_tokens": 1113, "response_tokens_est": 17, "n_tiles": 1, "output_text": " 1. flip phone: 2\n2. person's feet: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.04}, "power_stats": {"power_gpu_soc_mean_watts": 23.765, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 76.04}, "timestamp": "2026-01-30T15:03:38.374100"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5909.0, "latencies_ms": [5909.0], "images_per_second": 0.169, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The two flip phones are positioned in the foreground, with the front of the phones facing the viewer. The person's feet are in the foreground, with the left foot wearing black flip-flops and the right foot wearing white flip-flops. The two flip phones are positioned to the left of the person's feet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.653}, "power_stats": {"power_gpu_soc_mean_watts": 18.246, "power_cpu_cv_mean_watts": 1.658, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 68.653}, "timestamp": "2026-01-30T15:03:46.303976"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3601.622, "latencies_ms": [3601.622], "images_per_second": 0.278, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A pair of feet wearing flip flops are standing on a wooden floor with a broken cell phone and its parts scattered around them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.633}, "power_stats": {"power_gpu_soc_mean_watts": 22.247, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.136, "gpu_utilization_percent_mean": 72.633}, "timestamp": "2026-01-30T15:03:51.937949"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2784.132, "latencies_ms": [2784.132], "images_per_second": 0.359, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The wooden floor is brown and the person's feet are black.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.652}, "power_stats": {"power_gpu_soc_mean_watts": 24.702, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 78.652}, "timestamp": "2026-01-30T15:03:56.744933"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5468.395, "latencies_ms": [5468.395], "images_per_second": 0.183, "prompt_tokens": 1099, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image captures the majestic Palace of Westminster, also known as the Houses of Parliament, bathed in the warm glow of the setting sun, with the iconic Big Ben clock tower standing tall in the background, while a boat with a red and white flag floats on the river in the foreground.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.724, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 71.043}, "timestamp": "2026-01-30T15:04:04.269467"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5462.456, "latencies_ms": [5462.456], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Tower: 1\n2. Boat: 2\n3. Building: 1\n4. Flag: 1\n5. Clock: 1\n6. Boat: 2\n7. Boat: 2\n8. Boat: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.761}, "power_stats": {"power_gpu_soc_mean_watts": 18.585, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 69.761}, "timestamp": "2026-01-30T15:04:11.766513"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5201.21, "latencies_ms": [5201.21], "images_per_second": 0.192, "prompt_tokens": 1117, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The clock tower is located on the left side of the image, while the Palace of Westminster is situated in the background. The foreground features a barge with a red and white striped awning, and the background includes a bridge with a white railing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.512}, "power_stats": {"power_gpu_soc_mean_watts": 19.005, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 68.512}, "timestamp": "2026-01-30T15:04:19.009151"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5952.175, "latencies_ms": [5952.175], "images_per_second": 0.168, "prompt_tokens": 1111, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image captures the iconic Palace of Westminster, also known as the Houses of Parliament, in London, England. The scene is set on a river, with the palace bathed in the warm glow of the setting sun, while boats are visible on the water, adding a sense of movement and life to the tranquil setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.837}, "power_stats": {"power_gpu_soc_mean_watts": 17.995, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 70.837}, "timestamp": "2026-01-30T15:04:26.983048"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4302.022, "latencies_ms": [4302.022], "images_per_second": 0.232, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sky is overcast with a grayish hue, and the buildings are bathed in a warm, golden light. The water is a deep blue, reflecting the city's architectural beauty.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.472}, "power_stats": {"power_gpu_soc_mean_watts": 20.732, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 70.472}, "timestamp": "2026-01-30T15:04:33.346389"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4260.473, "latencies_ms": [4260.473], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a spacious living room with a red carpet, a green sofa, a black leather chair, and a wooden floor, with a ceiling fan and several potted plants.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.057}, "power_stats": {"power_gpu_soc_mean_watts": 20.809, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 70.057}, "timestamp": "2026-01-30T15:04:39.628663"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4605.468, "latencies_ms": [4605.468], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " chair: 1, sofa: 1, television: 1, potted plant: 1, mirror: 1, television stand: 1, sofa: 1, chair: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.763}, "power_stats": {"power_gpu_soc_mean_watts": 20.464, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 72.763}, "timestamp": "2026-01-30T15:04:46.247473"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5904.483, "latencies_ms": [5904.483], "images_per_second": 0.169, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The living room is situated in the center of the image, with the furniture arranged around it. The foreground features a red rug and a coffee table, while the background includes a television and a bookshelf. The left side of the room is dominated by a window, while the right side has a door leading to another room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.306}, "power_stats": {"power_gpu_soc_mean_watts": 18.315, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 68.306}, "timestamp": "2026-01-30T15:04:54.166751"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2880.484, "latencies_ms": [2880.484], "images_per_second": 0.347, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A living room with a red carpet, a couch, and a chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.739}, "power_stats": {"power_gpu_soc_mean_watts": 24.686, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.316, "gpu_utilization_percent_mean": 78.739}, "timestamp": "2026-01-30T15:04:59.060464"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3409.486, "latencies_ms": [3409.486], "images_per_second": 0.293, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The room is well lit with natural light coming in from the windows, and the hardwood floors are polished and clean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.857}, "power_stats": {"power_gpu_soc_mean_watts": 22.834, "power_cpu_cv_mean_watts": 1.044, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 69.857}, "timestamp": "2026-01-30T15:05:04.497138"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3889.51, "latencies_ms": [3889.51], "images_per_second": 0.257, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " Two parking meters are attached to a red pole on a sidewalk, with a building in the background displaying a sign that reads \"40 Years of Saving Lives.\"", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.875}, "power_stats": {"power_gpu_soc_mean_watts": 22.021, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 73.875}, "timestamp": "2026-01-30T15:05:10.420021"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4564.884, "latencies_ms": [4564.884], "images_per_second": 0.219, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. red post\n2. parking meter\n3. red circular holder\n4. parking meter\n5. red post\n6. red circular holder\n7. parking meter\n8. red post", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.632}, "power_stats": {"power_gpu_soc_mean_watts": 20.2, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 68.632}, "timestamp": "2026-01-30T15:05:17.019475"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4782.405, "latencies_ms": [4782.405], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The two parking meters are positioned on the left side of the image, with the red pole in the foreground and the building in the background. The parking meters are closer to the camera than the building, which is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.025}, "power_stats": {"power_gpu_soc_mean_watts": 19.622, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 70.025}, "timestamp": "2026-01-30T15:05:23.840454"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3395.512, "latencies_ms": [3395.512], "images_per_second": 0.295, "prompt_tokens": 1112, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A red pole with two parking meters on top stands on a sidewalk in front of a building with a large window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.107}, "power_stats": {"power_gpu_soc_mean_watts": 22.565, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 73.107}, "timestamp": "2026-01-30T15:05:29.294587"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5794.917, "latencies_ms": [5794.917], "images_per_second": 0.173, "prompt_tokens": 1110, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a red parking meter with two meters on top, standing on a sidewalk. The parking meter is located in front of a building with a large window that has a banner with the text \"40 years of saving lives\". The weather appears to be clear, as the sky is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.875}, "power_stats": {"power_gpu_soc_mean_watts": 18.378, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 67.875}, "timestamp": "2026-01-30T15:05:37.122670"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4318.284, "latencies_ms": [4318.284], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A man and a woman are sitting on a couch in a living room, watching television, with a coffee table in front of them that has a bunch of snacks and a candle on it.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.731, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-30T15:05:43.471781"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5799.786, "latencies_ms": [5799.786], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. sofa: 2\n2. television: 1\n3. coffee table: 1\n4. dining table: 1\n5. dining chairs: 2\n6. dining table: 1\n7. dining table: 1\n8. dining table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.265}, "power_stats": {"power_gpu_soc_mean_watts": 18.279, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 67.265}, "timestamp": "2026-01-30T15:05:51.328647"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4720.644, "latencies_ms": [4720.644], "images_per_second": 0.212, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The television is on the left side of the room, the couch is in the middle, and the coffee table is in the foreground. The person on the couch is closer to the camera than the person on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.3}, "power_stats": {"power_gpu_soc_mean_watts": 19.73, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.3}, "timestamp": "2026-01-30T15:05:58.069310"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3094.309, "latencies_ms": [3094.309], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A young man and woman are sitting on a couch in a living room, watching TV.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.653, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 75.808}, "timestamp": "2026-01-30T15:06:03.207546"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3323.556, "latencies_ms": [3323.556], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is lit by a warm yellow light, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.75}, "power_stats": {"power_gpu_soc_mean_watts": 23.14, "power_cpu_cv_mean_watts": 1.058, "power_sys_5v0_mean_watts": 8.199, "gpu_utilization_percent_mean": 74.75}, "timestamp": "2026-01-30T15:06:08.558048"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3443.521, "latencies_ms": [3443.521], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person is holding a white electrical device with multiple buttons and a red light, which is attached to a white toilet.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.023, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.22, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T15:06:14.028310"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4191.149, "latencies_ms": [4191.149], "images_per_second": 0.239, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " toilet: 1, person: 1, floor: 1, wall: 1, box: 1, floor lamp: 1, electrical outlet: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.866, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.629}, "timestamp": "2026-01-30T15:06:20.243342"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4774.528, "latencies_ms": [4774.528], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The person's hand is positioned to the right of the toilet, with the toilet paper holder being in the foreground. The person is holding the power strip in front of the toilet, which is located in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.4}, "power_stats": {"power_gpu_soc_mean_watts": 19.798, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.4}, "timestamp": "2026-01-30T15:06:27.067030"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2780.426, "latencies_ms": [2780.426], "images_per_second": 0.36, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A person is holding a power strip in front of a toilet.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.545}, "power_stats": {"power_gpu_soc_mean_watts": 25.241, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.328, "gpu_utilization_percent_mean": 81.545}, "timestamp": "2026-01-30T15:06:31.864185"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4030.178, "latencies_ms": [4030.178], "images_per_second": 0.248, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is a photograph of a white toilet with a silver metal stand next to it. The toilet is located in a room with a white wall and a wooden floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.03}, "power_stats": {"power_gpu_soc_mean_watts": 21.523, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 72.03}, "timestamp": "2026-01-30T15:06:37.906869"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3613.739, "latencies_ms": [3613.739], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air above a snow ramp, with a crowd of spectators watching from the side.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.181, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.117, "gpu_utilization_percent_mean": 71.133}, "timestamp": "2026-01-30T15:06:43.591472"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6148.376, "latencies_ms": [6148.376], "images_per_second": 0.163, "prompt_tokens": 1113, "response_tokens_est": 69, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. snowboarder: 1\n3. crowd: 1\n4. snowboarder: 1\n5. snowboarder: 1\n6. snowboarder: 1\n7. snowboarder: 1\n8. snowboarder: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.9, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.255}, "power_stats": {"power_gpu_soc_mean_watts": 18.001, "power_cpu_cv_mean_watts": 1.719, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 68.255}, "timestamp": "2026-01-30T15:06:51.777182"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5263.906, "latencies_ms": [5263.906], "images_per_second": 0.19, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The snowboarder is in the foreground, performing a trick in the air. The crowd is in the background, watching the event. The snow ramp is in the middle ground, with the snowboarder's trick taking place on the right side of the ramp.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.909}, "power_stats": {"power_gpu_soc_mean_watts": 18.847, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 67.909}, "timestamp": "2026-01-30T15:06:59.068234"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3786.856, "latencies_ms": [3786.856], "images_per_second": 0.264, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A snowboarder is performing a trick in the air above a snow ramp. The ramp is surrounded by a crowd of spectators watching the event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.613}, "power_stats": {"power_gpu_soc_mean_watts": 21.996, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 71.613}, "timestamp": "2026-01-30T15:07:04.867527"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4619.574, "latencies_ms": [4619.574], "images_per_second": 0.216, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a snowboarder performing a trick in the air, with a clear blue sky in the background. The snowboarder is wearing a red and white outfit, and the snow is white and pristine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.158}, "power_stats": {"power_gpu_soc_mean_watts": 20.134, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 71.158}, "timestamp": "2026-01-30T15:07:11.503795"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2869.038, "latencies_ms": [2869.038], "images_per_second": 0.349, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A room with a desk, chair, and a plant in it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.783}, "power_stats": {"power_gpu_soc_mean_watts": 24.32, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 74.783}, "timestamp": "2026-01-30T15:07:16.415297"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5659.919, "latencies_ms": [5659.919], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. white chair: 1\n2. desk: 1\n3. computer monitor: 1\n4. keyboard: 1\n5. mouse: 1\n6. lamp: 1\n7. potted plant: 1\n8. bookshelf: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.546, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 68.66}, "timestamp": "2026-01-30T15:07:24.103337"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5720.63, "latencies_ms": [5720.63], "images_per_second": 0.175, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The desk is positioned to the left of the white sofa, with the chair in front of it. The computer monitor is placed on the desk, while the laptop is situated to the right of the monitor. The potted plant is located near the desk, while the bookshelf is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.583}, "power_stats": {"power_gpu_soc_mean_watts": 18.459, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.583}, "timestamp": "2026-01-30T15:07:31.843529"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3085.091, "latencies_ms": [3085.091], "images_per_second": 0.324, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A room with a desk, chair, and computer setup, with a plant nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.32}, "power_stats": {"power_gpu_soc_mean_watts": 23.543, "power_cpu_cv_mean_watts": 0.881, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 76.32}, "timestamp": "2026-01-30T15:07:36.970647"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3041.053, "latencies_ms": [3041.053], "images_per_second": 0.329, "prompt_tokens": 1109, "response_tokens_est": 17, "n_tiles": 1, "output_text": " The room is well-lit with natural light, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.44}, "power_stats": {"power_gpu_soc_mean_watts": 23.845, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 76.44}, "timestamp": "2026-01-30T15:07:42.036665"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3654.791, "latencies_ms": [3654.791], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A person is standing on a dirt road with a motorcycle parked beside them, with a scenic view of mountains and trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.116, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 68.1}, "timestamp": "2026-01-30T15:07:47.718018"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5887.642, "latencies_ms": [5887.642], "images_per_second": 0.17, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Motorcycle: 1\n2. Motorcycle: 1\n3. Motorcycle: 1\n4. Motorcycle: 1\n5. Motorcycle: 1\n6. Motorcycle: 1\n7. Motorcycle: 1\n8. Motorcycle: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.061}, "power_stats": {"power_gpu_soc_mean_watts": 18.164, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 69.061}, "timestamp": "2026-01-30T15:07:55.637548"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4732.185, "latencies_ms": [4732.185], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The motorcycle is positioned on the left side of the image, with the rider standing on the right side. The foreground of the image features the motorcycle and the rider, while the background showcases a scenic view of mountains and trees.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.675}, "power_stats": {"power_gpu_soc_mean_watts": 19.729, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 70.675}, "timestamp": "2026-01-30T15:08:02.396770"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3380.591, "latencies_ms": [3380.591], "images_per_second": 0.296, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A motorcyclist is standing on a dirt road in the mountains, looking out at the scenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.165, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-30T15:08:07.813270"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5740.509, "latencies_ms": [5740.509], "images_per_second": 0.174, "prompt_tokens": 1109, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The image features a dirt road with a motorcyclist and a backpack, set against a backdrop of a clear blue sky with scattered clouds. The motorcyclist is wearing a helmet and a black jacket, while the backpack is black. The road is surrounded by green hills and trees, creating a picturesque scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.5}, "power_stats": {"power_gpu_soc_mean_watts": 18.369, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 68.5}, "timestamp": "2026-01-30T15:08:15.580208"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3769.726, "latencies_ms": [3769.726], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image shows a kitchen with wooden cabinets, a white stove, and a white refrigerator, with a dining table in the center of the room.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.161}, "power_stats": {"power_gpu_soc_mean_watts": 21.764, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.138, "gpu_utilization_percent_mean": 73.161}, "timestamp": "2026-01-30T15:08:21.376798"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5813.183, "latencies_ms": [5813.183], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " table: 1, chair: 1, bananas: 1, oranges: 1, bowl: 1, stove: 1, refrigerator: 1, cabinet: 1, door: 1, light: 1, counter: 1, sink: 1, window: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.286}, "power_stats": {"power_gpu_soc_mean_watts": 18.426, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 69.286}, "timestamp": "2026-01-30T15:08:29.225445"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4799.859, "latencies_ms": [4799.859], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The kitchen is located in the center of the image, with the dining table and chairs placed in the foreground. The refrigerator is positioned to the right of the stove, and the sink is located to the left of the stove.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.538}, "power_stats": {"power_gpu_soc_mean_watts": 19.845, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 70.538}, "timestamp": "2026-01-30T15:08:36.039123"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3545.812, "latencies_ms": [3545.812], "images_per_second": 0.282, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A kitchen with white appliances and wooden cabinets, a dining table with a bowl of oranges on it, and a white refrigerator.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.862}, "power_stats": {"power_gpu_soc_mean_watts": 22.438, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.139, "gpu_utilization_percent_mean": 75.862}, "timestamp": "2026-01-30T15:08:41.634765"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3317.443, "latencies_ms": [3317.443], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The kitchen is well lit with natural light coming in from the windows, and the cabinets are made of wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.444}, "power_stats": {"power_gpu_soc_mean_watts": 23.389, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 76.444}, "timestamp": "2026-01-30T15:08:46.965625"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2944.82, "latencies_ms": [2944.82], "images_per_second": 0.34, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A female tennis player is preparing to serve the ball on a green tennis court.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.437, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T15:08:51.943021"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5676.14, "latencies_ms": [5676.14], "images_per_second": 0.176, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. woman: 1\n2. racket: 1\n3. tennis ball: 1\n4. person: 1\n5. blue wall: 1\n6. white line: 1\n7. green surface: 1\n8. white cap: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.064}, "power_stats": {"power_gpu_soc_mean_watts": 18.717, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.064}, "timestamp": "2026-01-30T15:08:59.630231"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5038.209, "latencies_ms": [5038.209], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the ball slightly above her head, indicating she is in the process of serving. The background features a blue wall with a \"POLO\" logo, suggesting the location of the match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.286}, "power_stats": {"power_gpu_soc_mean_watts": 19.337, "power_cpu_cv_mean_watts": 1.506, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 66.286}, "timestamp": "2026-01-30T15:09:06.729849"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3012.766, "latencies_ms": [3012.766], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A female tennis player is preparing to serve the ball on a green tennis court.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 24.075, "power_cpu_cv_mean_watts": 0.834, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-30T15:09:11.772411"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4070.169, "latencies_ms": [4070.169], "images_per_second": 0.246, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image features a female tennis player in a white outfit, with a green and blue tennis court in the background. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.765}, "power_stats": {"power_gpu_soc_mean_watts": 21.35, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.14, "gpu_utilization_percent_mean": 71.765}, "timestamp": "2026-01-30T15:09:17.876156"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3011.223, "latencies_ms": [3011.223], "images_per_second": 0.332, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red fire hydrant is on the sidewalk, and a man is standing nearby.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.68}, "power_stats": {"power_gpu_soc_mean_watts": 24.073, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.252, "gpu_utilization_percent_mean": 77.68}, "timestamp": "2026-01-30T15:09:22.922003"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4488.172, "latencies_ms": [4488.172], "images_per_second": 0.223, "prompt_tokens": 1114, "response_tokens_est": 42, "n_tiles": 1, "output_text": " 1. red fire hydrant\n2. white manhole cover\n3. yellow pedestrian sign\n4. person standing\n5. person walking\n6. tree\n7. building\n8. sidewalk", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.493, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 68.816}, "timestamp": "2026-01-30T15:09:29.434602"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4142.199, "latencies_ms": [4142.199], "images_per_second": 0.241, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The fire hydrant is located on the left side of the sidewalk, with the pedestrian on the right side. The pedestrian is standing closer to the fire hydrant than the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.353}, "power_stats": {"power_gpu_soc_mean_watts": 21.384, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 71.353}, "timestamp": "2026-01-30T15:09:35.592545"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2999.618, "latencies_ms": [2999.618], "images_per_second": 0.333, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red fire hydrant is on the sidewalk, and a man is standing nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.073, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.311, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T15:09:40.616869"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2943.171, "latencies_ms": [2943.171], "images_per_second": 0.34, "prompt_tokens": 1110, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The fire hydrant is red and white, and the sky is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.208}, "power_stats": {"power_gpu_soc_mean_watts": 24.074, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.248, "gpu_utilization_percent_mean": 77.208}, "timestamp": "2026-01-30T15:09:45.599345"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3466.009, "latencies_ms": [3466.009], "images_per_second": 0.289, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image depicts a small bathroom with a white toilet, a green trash can, and a white paper towel dispenser.", "error": null, "sys_before": {"cpu_percent": 3.2, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.31}, "power_stats": {"power_gpu_soc_mean_watts": 22.478, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 72.31}, "timestamp": "2026-01-30T15:09:51.108868"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4149.506, "latencies_ms": [4149.506], "images_per_second": 0.241, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " toilet: 1, toilet paper: 1, trash can: 1, person: 1, floor: 1, wall: 1, lid: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.647}, "power_stats": {"power_gpu_soc_mean_watts": 21.339, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.113, "gpu_utilization_percent_mean": 69.647}, "timestamp": "2026-01-30T15:09:57.292047"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4751.499, "latencies_ms": [4751.499], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The toilet is positioned in the center of the image, with the person's feet visible in the foreground. The trash can is located to the left of the toilet, while the paper towel dispenser is situated to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.128}, "power_stats": {"power_gpu_soc_mean_watts": 19.886, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 66.128}, "timestamp": "2026-01-30T15:10:04.084844"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3046.735, "latencies_ms": [3046.735], "images_per_second": 0.328, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A person is standing in a small bathroom with a white toilet and a green trash can.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.76}, "power_stats": {"power_gpu_soc_mean_watts": 24.198, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.325, "gpu_utilization_percent_mean": 76.76}, "timestamp": "2026-01-30T15:10:09.158243"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3518.816, "latencies_ms": [3518.816], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The bathroom is small and has white walls and a brown floor. The toilet is white and has a lid that is up.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.034}, "power_stats": {"power_gpu_soc_mean_watts": 22.615, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 74.034}, "timestamp": "2026-01-30T15:10:14.724364"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3474.565, "latencies_ms": [3474.565], "images_per_second": 0.288, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A person wearing a red jacket and black pants is skiing down a snowy mountain with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.069}, "power_stats": {"power_gpu_soc_mean_watts": 22.518, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 69.069}, "timestamp": "2026-01-30T15:10:20.264898"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5439.317, "latencies_ms": [5439.317], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 1\n2. skis: 2\n3. poles: 2\n4. backpack: 1\n5. helmet: 1\n6. jacket: 1\n7. pants: 1\n8. snow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.022}, "power_stats": {"power_gpu_soc_mean_watts": 18.689, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 68.022}, "timestamp": "2026-01-30T15:10:27.731621"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5748.791, "latencies_ms": [5748.791], "images_per_second": 0.174, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the mountain peak in the background. The skier is facing towards the mountain peak, indicating a sense of direction or focus towards the destination. The skier is also positioned to the left of the image, with the mountain peak to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.729}, "power_stats": {"power_gpu_soc_mean_watts": 18.403, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 67.729}, "timestamp": "2026-01-30T15:10:35.500309"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3058.265, "latencies_ms": [3058.265], "images_per_second": 0.327, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is skiing on a snowy mountain with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.719, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 74.56}, "timestamp": "2026-01-30T15:10:40.580329"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4843.237, "latencies_ms": [4843.237], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a person wearing a red jacket and black pants, skiing down a snow-covered mountain under a clear blue sky. The snow is pristine white, and the sunlight reflects off the surface, creating a bright and vibrant atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.3}, "power_stats": {"power_gpu_soc_mean_watts": 19.75, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.3}, "timestamp": "2026-01-30T15:10:47.435870"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3419.046, "latencies_ms": [3419.046], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a bib with the number 30 is skiing down a snowy mountain with trees in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.786}, "power_stats": {"power_gpu_soc_mean_watts": 23.112, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 73.786}, "timestamp": "2026-01-30T15:10:52.885403"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5597.207, "latencies_ms": [5597.207], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. skis: 2\n3. ski poles: 2\n4. bib: 1\n5. backpack: 1\n6. snow: 1\n7. trees: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.638}, "power_stats": {"power_gpu_soc_mean_watts": 18.429, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 68.638}, "timestamp": "2026-01-30T15:11:00.498843"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4255.227, "latencies_ms": [4255.227], "images_per_second": 0.235, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The skier is positioned in the foreground, with the trees and mountains in the background. The skier is closer to the camera than the other skier, who is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.857}, "power_stats": {"power_gpu_soc_mean_watts": 21.211, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.158, "gpu_utilization_percent_mean": 71.857}, "timestamp": "2026-01-30T15:11:06.770096"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3419.345, "latencies_ms": [3419.345], "images_per_second": 0.292, "prompt_tokens": 1112, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing a bib with the number 30 is skiing down a snowy mountain with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.393}, "power_stats": {"power_gpu_soc_mean_watts": 22.712, "power_cpu_cv_mean_watts": 1.13, "power_sys_5v0_mean_watts": 8.203, "gpu_utilization_percent_mean": 75.393}, "timestamp": "2026-01-30T15:11:12.219231"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4744.992, "latencies_ms": [4744.992], "images_per_second": 0.211, "prompt_tokens": 1110, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a man wearing a red and white jacket, black pants, and a black hat, skiing down a snowy mountain with trees in the background. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.103}, "power_stats": {"power_gpu_soc_mean_watts": 19.928, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 71.103}, "timestamp": "2026-01-30T15:11:18.977083"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3985.059, "latencies_ms": [3985.059], "images_per_second": 0.251, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A black and white photo of a computer desk with a keyboard, mouse, and monitor, with the word \"WORKPLACE\" in the top right corner.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.333}, "power_stats": {"power_gpu_soc_mean_watts": 21.208, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 73.333}, "timestamp": "2026-01-30T15:11:24.998025"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5546.1, "latencies_ms": [5546.1], "images_per_second": 0.18, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. monitor: 1\n2. keyboard: 1\n3. mouse: 1\n4. desk: 1\n5. wall: 1\n6. computer: 1\n7. desk chair: 1\n8. desk surface: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.239}, "power_stats": {"power_gpu_soc_mean_watts": 18.551, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 72.239}, "timestamp": "2026-01-30T15:11:32.563076"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4610.409, "latencies_ms": [4610.409], "images_per_second": 0.217, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The keyboard is positioned in the foreground, close to the camera, while the computer monitor is in the background, farther away. The mouse is placed near the keyboard, and the computer monitor is positioned above the keyboard.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.274, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.474}, "timestamp": "2026-01-30T15:11:39.208221"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3027.895, "latencies_ms": [3027.895], "images_per_second": 0.33, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white photo of a computer desk with a keyboard and mouse on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.76}, "power_stats": {"power_gpu_soc_mean_watts": 23.672, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 76.76}, "timestamp": "2026-01-30T15:11:44.279030"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4134.191, "latencies_ms": [4134.191], "images_per_second": 0.242, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is in black and white, with a white desk and a white wall in the background. The lighting is bright and even, and the materials are smooth and shiny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.235}, "power_stats": {"power_gpu_soc_mean_watts": 21.126, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.091, "gpu_utilization_percent_mean": 71.235}, "timestamp": "2026-01-30T15:11:50.446105"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3290.12, "latencies_ms": [3290.12], "images_per_second": 0.304, "prompt_tokens": 1100, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A woman wearing a striped shirt is sitting at a table in a restaurant and smiling while holding a bagel.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.481}, "power_stats": {"power_gpu_soc_mean_watts": 23.46, "power_cpu_cv_mean_watts": 1.112, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 76.481}, "timestamp": "2026-01-30T15:11:55.780186"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5527.808, "latencies_ms": [5527.808], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. bagel: 1\n3. coffee cup: 1\n4. box: 1\n5. sandwich: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.804}, "power_stats": {"power_gpu_soc_mean_watts": 18.656, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.804}, "timestamp": "2026-01-30T15:12:03.345612"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5214.289, "latencies_ms": [5214.289], "images_per_second": 0.192, "prompt_tokens": 1118, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The woman is sitting at a table in the foreground, holding a bagel in her hand. The coffee cup is placed on the table, closer to the camera than the woman. The window is located behind the woman, showing a view of the outside world.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.837}, "power_stats": {"power_gpu_soc_mean_watts": 19.09, "power_cpu_cv_mean_watts": 1.536, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 69.837}, "timestamp": "2026-01-30T15:12:10.593532"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3060.909, "latencies_ms": [3060.909], "images_per_second": 0.327, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman is sitting at a table in a restaurant, holding a bagel and smiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.24}, "power_stats": {"power_gpu_soc_mean_watts": 23.817, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.28, "gpu_utilization_percent_mean": 75.24}, "timestamp": "2026-01-30T15:12:15.688476"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5100.742, "latencies_ms": [5100.742], "images_per_second": 0.196, "prompt_tokens": 1110, "response_tokens_est": 52, "n_tiles": 1, "output_text": " The image has a warm color tone, with the person's shirt being a deep purple and the coffee cup being white. The lighting is natural, coming from the window, and the background is blurred, indicating that the photo was taken while the person was moving.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.381, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 70.07}, "timestamp": "2026-01-30T15:12:22.841571"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3127.204, "latencies_ms": [3127.204], "images_per_second": 0.32, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two zebras with black and white stripes are grazing on green grass in a grassy field.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.308}, "power_stats": {"power_gpu_soc_mean_watts": 23.305, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 74.308}, "timestamp": "2026-01-30T15:12:28.011093"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2211.227, "latencies_ms": [2211.227], "images_per_second": 0.452, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.167}, "power_stats": {"power_gpu_soc_mean_watts": 25.914, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.372, "gpu_utilization_percent_mean": 85.167}, "timestamp": "2026-01-30T15:12:32.279251"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4598.742, "latencies_ms": [4598.742], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with one zebra on the left and the other on the right. The zebras are eating grass in the foreground, with the grass extending into the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.447}, "power_stats": {"power_gpu_soc_mean_watts": 20.315, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 70.447}, "timestamp": "2026-01-30T15:12:38.890955"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3241.952, "latencies_ms": [3241.952], "images_per_second": 0.308, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " Two zebras are grazing on a grassy field, their black and white stripes contrasting with the green grass.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.593}, "power_stats": {"power_gpu_soc_mean_watts": 23.621, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.257, "gpu_utilization_percent_mean": 72.593}, "timestamp": "2026-01-30T15:12:44.151959"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4384.259, "latencies_ms": [4384.259], "images_per_second": 0.228, "prompt_tokens": 1109, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features two zebras with black and white stripes grazing on green grass. The lighting is natural and bright, and the zebras are in a grassy field with a fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.056}, "power_stats": {"power_gpu_soc_mean_watts": 20.656, "power_cpu_cv_mean_watts": 1.346, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 71.056}, "timestamp": "2026-01-30T15:12:50.563943"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3409.031, "latencies_ms": [3409.031], "images_per_second": 0.293, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two young men are riding a green bicycle on a busy street with a Coca Cola store in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.578, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.168, "gpu_utilization_percent_mean": 75.893}, "timestamp": "2026-01-30T15:12:56.006058"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5422.95, "latencies_ms": [5422.95], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bicycle: 2\n2. person: 2\n3. motorcycle: 2\n4. scooter: 1\n5. store: 1\n6. plant: 1\n7. sign: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.733}, "power_stats": {"power_gpu_soc_mean_watts": 18.96, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.733}, "timestamp": "2026-01-30T15:13:03.446629"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4523.643, "latencies_ms": [4523.643], "images_per_second": 0.221, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The two men are positioned in the foreground of the image, with the bicycle in front of them. The motorcycle is parked on the right side of the image, while the storefront is located in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.763}, "power_stats": {"power_gpu_soc_mean_watts": 20.333, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 70.763}, "timestamp": "2026-01-30T15:13:10.004260"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2951.383, "latencies_ms": [2951.383], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two young men are riding a green bicycle down a busy street in Vietnam.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.125}, "power_stats": {"power_gpu_soc_mean_watts": 24.122, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 78.125}, "timestamp": "2026-01-30T15:13:15.014756"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3665.397, "latencies_ms": [3665.397], "images_per_second": 0.273, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image is taken during the day with natural light, and the colors are vibrant with a mix of green, blue, and red.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.933}, "power_stats": {"power_gpu_soc_mean_watts": 22.247, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 71.933}, "timestamp": "2026-01-30T15:13:20.694133"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4492.769, "latencies_ms": [4492.769], "images_per_second": 0.223, "prompt_tokens": 1099, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a tennis match, with two players in white attire actively engaged in a rally on a lush green grass court, while a line judge attentively observes the play from the sidelines.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.216}, "power_stats": {"power_gpu_soc_mean_watts": 20.582, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 68.216}, "timestamp": "2026-01-30T15:13:27.232310"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5944.766, "latencies_ms": [5944.766], "images_per_second": 0.168, "prompt_tokens": 1113, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. Tennis racket: 1\n2. Tennis ball: 1\n3. Player: 2\n4. Chair: 1\n5. Ball boy: 1\n6. Umpire: 1\n7. Spectator: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.918}, "power_stats": {"power_gpu_soc_mean_watts": 18.083, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 68.918}, "timestamp": "2026-01-30T15:13:35.186526"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4159.015, "latencies_ms": [4159.015], "images_per_second": 0.24, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the court, while the ball is located in the center. The audience is seated in the background, far away from the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.324}, "power_stats": {"power_gpu_soc_mean_watts": 21.232, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.125, "gpu_utilization_percent_mean": 70.324}, "timestamp": "2026-01-30T15:13:41.376046"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2999.305, "latencies_ms": [2999.305], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A tennis match is taking place in a large stadium with a crowd of spectators watching.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.12}, "power_stats": {"power_gpu_soc_mean_watts": 24.229, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.333, "gpu_utilization_percent_mean": 77.12}, "timestamp": "2026-01-30T15:13:46.417509"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4877.981, "latencies_ms": [4877.981], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image is taken during a daytime tennis match, with the players dressed in white and the court's green grass contrasting with the spectators' attire. The lighting is natural, coming from the sun, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.452, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T15:13:53.333518"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4268.899, "latencies_ms": [4268.899], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image depicts a cozy living room with a brown couch, a television on a wooden stand, and a variety of plants on shelves and the floor, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.902, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T15:13:59.640107"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5008.065, "latencies_ms": [5008.065], "images_per_second": 0.2, "prompt_tokens": 1113, "response_tokens_est": 48, "n_tiles": 1, "output_text": " television: 1\ncouch: 1\ntelevision stand: 1\ntelevision: 1\ncouch: 1\ntelevision stand: 1\ntelevision: 1\ncouch: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.336, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T15:14:06.682380"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4940.779, "latencies_ms": [4940.779], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The television is located on the left side of the room, with the couch situated on the right side. The plants are placed in the background, near the window, while the rug is positioned in the foreground, in front of the couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.683}, "power_stats": {"power_gpu_soc_mean_watts": 19.503, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 8.062, "gpu_utilization_percent_mean": 70.683}, "timestamp": "2026-01-30T15:14:13.658342"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2967.301, "latencies_ms": [2967.301], "images_per_second": 0.337, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A living room with a brown couch, a TV, and a TV stand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.625}, "power_stats": {"power_gpu_soc_mean_watts": 24.308, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 79.625}, "timestamp": "2026-01-30T15:14:18.648465"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3295.459, "latencies_ms": [3295.459], "images_per_second": 0.303, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.255, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 75.37}, "timestamp": "2026-01-30T15:14:23.971995"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3501.351, "latencies_ms": [3501.351], "images_per_second": 0.286, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A woman in a red dress and white visor is holding a tennis racket and smiling on a red clay tennis court.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.414}, "power_stats": {"power_gpu_soc_mean_watts": 22.586, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.184, "gpu_utilization_percent_mean": 75.414}, "timestamp": "2026-01-30T15:14:29.507399"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5818.598, "latencies_ms": [5818.598], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. woman: 1\n2. tennis racket: 1\n3. visor: 1\n4. shorts: 1\n5. tennis shoes: 1\n6. tennis ball: 1\n7. clay court: 1\n8. green fence: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.653}, "power_stats": {"power_gpu_soc_mean_watts": 18.191, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 68.653}, "timestamp": "2026-01-30T15:14:37.347957"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4900.599, "latencies_ms": [4900.599], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The tennis player is positioned in the foreground of the image, with the green fence and spectators in the background. The player is holding a tennis racket in her right hand, and her body language suggests she is celebrating a successful point.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.9}, "power_stats": {"power_gpu_soc_mean_watts": 19.569, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 69.9}, "timestamp": "2026-01-30T15:14:44.268540"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3764.527, "latencies_ms": [3764.527], "images_per_second": 0.266, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A female tennis player is on a clay court, wearing a red dress and a white visor, holding a tennis racket and celebrating.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.677}, "power_stats": {"power_gpu_soc_mean_watts": 21.934, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 73.677}, "timestamp": "2026-01-30T15:14:50.056762"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4611.685, "latencies_ms": [4611.685], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a woman in a vibrant red dress and white visor, holding a black and red tennis racket, on a clay tennis court. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.18, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 70.474}, "timestamp": "2026-01-30T15:14:56.704902"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7786.664, "latencies_ms": [7786.664], "images_per_second": 0.128, "prompt_tokens": 1099, "response_tokens_est": 95, "n_tiles": 1, "output_text": " The image captures a bustling city street lined with a variety of buildings, including a prominent red brick building with a sign that reads \"OmniFest\" and a green awning with the word \"HOTEL\" on it. The street is filled with cars and people, and there are several signs and advertisements visible, including a large billboard for \"OmniFest\" and a red awning with the word \"HOTEL\" on it.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.877}, "power_stats": {"power_gpu_soc_mean_watts": 16.38, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 7.881, "gpu_utilization_percent_mean": 68.877}, "timestamp": "2026-01-30T15:15:06.517347"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5452.168, "latencies_ms": [5452.168], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. car: 3\n2. building: 10\n3. street: 1\n4. sign: 1\n5. person: 1\n6. airplane: 1\n7. store: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.533}, "power_stats": {"power_gpu_soc_mean_watts": 18.756, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 69.533}, "timestamp": "2026-01-30T15:15:13.988323"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7542.645, "latencies_ms": [7542.645], "images_per_second": 0.133, "prompt_tokens": 1117, "response_tokens_est": 91, "n_tiles": 1, "output_text": " The main objects in the image are positioned in the foreground, with the street and cars in the foreground, and the buildings in the background. The buildings are arranged in a row, with the nearest building being the one with the \"OmniFest\" sign, and the farthest building being the one with the \"For Lease\" sign. The cars are parked along the side of the street, with some in the foreground and others in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.683}, "power_stats": {"power_gpu_soc_mean_watts": 16.606, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 67.683}, "timestamp": "2026-01-30T15:15:23.561205"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4424.875, "latencies_ms": [4424.875], "images_per_second": 0.226, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a bustling city street lined with various shops and restaurants. Cars are parked along the side of the road, and people can be seen walking on the sidewalk, adding to the lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.194}, "power_stats": {"power_gpu_soc_mean_watts": 20.598, "power_cpu_cv_mean_watts": 1.39, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 67.194}, "timestamp": "2026-01-30T15:15:30.011678"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5658.428, "latencies_ms": [5658.428], "images_per_second": 0.177, "prompt_tokens": 1109, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image captures a vibrant city street bathed in the soft glow of daylight, with the sky painted in a light blue hue. The buildings, constructed from brick and wood, stand tall against the overcast sky, their red and green awnings adding a splash of color to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.596}, "power_stats": {"power_gpu_soc_mean_watts": 18.521, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 68.596}, "timestamp": "2026-01-30T15:15:37.699620"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3455.288, "latencies_ms": [3455.288], "images_per_second": 0.289, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A female tennis player in a pink outfit is playing on a blue court with a yellow tennis ball in the air.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.567, "power_cpu_cv_mean_watts": 1.058, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 74.893}, "timestamp": "2026-01-30T15:15:43.197918"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6069.719, "latencies_ms": [6069.719], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. tennis racket: 1\n2. tennis ball: 1\n3. woman: 1\n4. tennis court: 1\n5. white line: 1\n6. blue surface: 1\n7. green surface: 1\n8. white shoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.46}, "power_stats": {"power_gpu_soc_mean_watts": 17.699, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.871, "gpu_utilization_percent_mean": 68.46}, "timestamp": "2026-01-30T15:15:51.281476"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4293.172, "latencies_ms": [4293.172], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball located in the center. The player is in the foreground, while the tennis court extends into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.943}, "power_stats": {"power_gpu_soc_mean_watts": 21.003, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 70.943}, "timestamp": "2026-01-30T15:15:57.588048"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2944.544, "latencies_ms": [2944.544], "images_per_second": 0.34, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A female tennis player is playing on a blue court with a green background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.458}, "power_stats": {"power_gpu_soc_mean_watts": 23.974, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.218, "gpu_utilization_percent_mean": 77.458}, "timestamp": "2026-01-30T15:16:02.573294"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3298.054, "latencies_ms": [3298.054], "images_per_second": 0.303, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The tennis player is wearing a red outfit and white shoes, and the court is blue with white lines.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.133, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 74.333}, "timestamp": "2026-01-30T15:16:07.929797"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3752.517, "latencies_ms": [3752.517], "images_per_second": 0.266, "prompt_tokens": 1432, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A blue and orange train with a white front is traveling on a track through a lush green forest.", "error": null, "sys_before": {"cpu_percent": 7.5, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.032}, "power_stats": {"power_gpu_soc_mean_watts": 25.498, "power_cpu_cv_mean_watts": 0.969, "power_sys_5v0_mean_watts": 8.572, "gpu_utilization_percent_mean": 77.032}, "timestamp": "2026-01-30T15:16:13.719989"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4708.711, "latencies_ms": [4708.711], "images_per_second": 0.212, "prompt_tokens": 1446, "response_tokens_est": 34, "n_tiles": 1, "output_text": " train: 1, tracks: 1, bushes: 1, trees: 1, windows: 1, doors: 1, front: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.173, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 8.39, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T15:16:20.472807"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4726.707, "latencies_ms": [4726.707], "images_per_second": 0.212, "prompt_tokens": 1450, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, moving towards the right. The train is in the foreground, with the tracks and surrounding vegetation in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.974}, "power_stats": {"power_gpu_soc_mean_watts": 23.276, "power_cpu_cv_mean_watts": 1.191, "power_sys_5v0_mean_watts": 8.403, "gpu_utilization_percent_mean": 78.974}, "timestamp": "2026-01-30T15:16:27.231187"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3548.398, "latencies_ms": [3548.398], "images_per_second": 0.282, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A blue and orange train is traveling on a track through a wooded area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.517}, "power_stats": {"power_gpu_soc_mean_watts": 26.278, "power_cpu_cv_mean_watts": 0.828, "power_sys_5v0_mean_watts": 8.593, "gpu_utilization_percent_mean": 82.517}, "timestamp": "2026-01-30T15:16:32.810284"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3429.216, "latencies_ms": [3429.216], "images_per_second": 0.292, "prompt_tokens": 1442, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The train is blue and orange, and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.429}, "power_stats": {"power_gpu_soc_mean_watts": 26.557, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 8.616, "gpu_utilization_percent_mean": 80.429}, "timestamp": "2026-01-30T15:16:38.271014"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2913.112, "latencies_ms": [2913.112], "images_per_second": 0.343, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two cats are sleeping on a pink blanket, with a remote control nearby.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.333}, "power_stats": {"power_gpu_soc_mean_watts": 24.208, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-30T15:16:43.221786"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5397.363, "latencies_ms": [5397.363], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. Cat: 2\n2. Remote control: 2\n3. Fur: 2\n4. Tail: 1\n5. Paw: 1\n6. Fur: 1\n7. Fur: 1\n8. Fur: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.022}, "power_stats": {"power_gpu_soc_mean_watts": 19.014, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 70.022}, "timestamp": "2026-01-30T15:16:50.644807"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5024.565, "latencies_ms": [5024.565], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The two cats are lying on a pink blanket, with the cat on the left being closer to the camera and the cat on the right being farther away. The remote control is placed on the blanket, with the left cat's paw resting on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.762}, "power_stats": {"power_gpu_soc_mean_watts": 19.381, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.762}, "timestamp": "2026-01-30T15:16:57.711292"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2903.365, "latencies_ms": [2903.365], "images_per_second": 0.344, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Two cats are sleeping on a pink blanket, with a remote control nearby.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.2, "ram_available_mb": 48847.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.875}, "power_stats": {"power_gpu_soc_mean_watts": 24.306, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 75.875}, "timestamp": "2026-01-30T15:17:02.643532"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3776.93, "latencies_ms": [3776.93], "images_per_second": 0.265, "prompt_tokens": 1109, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image features two cats sleeping on a pink blanket, with a remote control nearby. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.6, "ram_available_mb": 48847.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.742}, "power_stats": {"power_gpu_soc_mean_watts": 22.202, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.177, "gpu_utilization_percent_mean": 73.742}, "timestamp": "2026-01-30T15:17:08.454496"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4060.154, "latencies_ms": [4060.154], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A man in a black wetsuit is surfing on a river with a blue surfboard, while another person is standing on the riverbank holding a blue surfboard.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.667}, "power_stats": {"power_gpu_soc_mean_watts": 21.356, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T15:17:14.548680"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5578.077, "latencies_ms": [5578.077], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. River: 1\n4. Bridge: 1\n5. Tree: 1\n6. Bench: 1\n7. Wall: 1\n8. Bench: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.043}, "power_stats": {"power_gpu_soc_mean_watts": 18.512, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 68.043}, "timestamp": "2026-01-30T15:17:22.183036"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4224.239, "latencies_ms": [4224.239], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave in the river, while the bridge is located in the background. The surfer is closer to the camera than the bridge.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.514}, "power_stats": {"power_gpu_soc_mean_watts": 20.923, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.106, "gpu_utilization_percent_mean": 71.514}, "timestamp": "2026-01-30T15:17:28.417792"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3663.544, "latencies_ms": [3663.544], "images_per_second": 0.273, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man in a wetsuit is surfing on a river with a blue surfboard. The river is surrounded by trees and a bridge.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.133}, "power_stats": {"power_gpu_soc_mean_watts": 22.382, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 74.133}, "timestamp": "2026-01-30T15:17:34.103549"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5546.409, "latencies_ms": [5546.409], "images_per_second": 0.18, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features a surfer in a black wetsuit riding a wave in a river, with a blue surfboard visible in the background. The scene is bathed in natural light, and the water appears to be a muddy brown color, suggesting it might be a river or a lake.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.085}, "power_stats": {"power_gpu_soc_mean_watts": 18.538, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 70.085}, "timestamp": "2026-01-30T15:17:41.689200"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3790.471, "latencies_ms": [3790.471], "images_per_second": 0.264, "prompt_tokens": 1432, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A woman and a child are flying a colorful kite in a park with trees in the background.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.323}, "power_stats": {"power_gpu_soc_mean_watts": 24.992, "power_cpu_cv_mean_watts": 0.943, "power_sys_5v0_mean_watts": 8.534, "gpu_utilization_percent_mean": 80.323}, "timestamp": "2026-01-30T15:17:47.513179"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6243.202, "latencies_ms": [6243.202], "images_per_second": 0.16, "prompt_tokens": 1446, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. person: 2\n2. child: 1\n3. kite: 1\n4. grass: 1\n5. trees: 1\n6. sky: 1\n7. person's hand: 1\n8. person's leg: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.736}, "power_stats": {"power_gpu_soc_mean_watts": 20.627, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.258, "gpu_utilization_percent_mean": 71.736}, "timestamp": "2026-01-30T15:17:55.783723"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5609.438, "latencies_ms": [5609.438], "images_per_second": 0.178, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The kite is in the foreground, flying high in the sky, while the person is in the background, standing on the grass. The person is holding the kite string, which is in the foreground, and the kite is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.745}, "power_stats": {"power_gpu_soc_mean_watts": 21.411, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 70.745}, "timestamp": "2026-01-30T15:18:03.455085"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3788.11, "latencies_ms": [3788.11], "images_per_second": 0.264, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman and a child are flying a kite in a park with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.29}, "power_stats": {"power_gpu_soc_mean_watts": 25.336, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.505, "gpu_utilization_percent_mean": 82.29}, "timestamp": "2026-01-30T15:18:09.268435"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6793.827, "latencies_ms": [6793.827], "images_per_second": 0.147, "prompt_tokens": 1442, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The image features a vibrant kite with a mix of colors, including pink, blue, and yellow, soaring in the sky. The kite is being flown by a person wearing a black jacket and blue jeans, while a child stands nearby, also dressed in a black shirt and pink pants. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.719}, "power_stats": {"power_gpu_soc_mean_watts": 20.048, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 69.719}, "timestamp": "2026-01-30T15:18:18.121825"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2991.182, "latencies_ms": [2991.182], "images_per_second": 0.334, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young boy is playing tennis on a court with a green fence in the background.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.833}, "power_stats": {"power_gpu_soc_mean_watts": 24.469, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.314, "gpu_utilization_percent_mean": 76.833}, "timestamp": "2026-01-30T15:18:23.132636"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5539.774, "latencies_ms": [5539.774], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. tennis racket: 1\n3. ball: 1\n4. tennis court: 1\n5. banner: 1\n6. fence: 1\n7. net: 1\n8. text: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.13}, "power_stats": {"power_gpu_soc_mean_watts": 18.765, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 71.13}, "timestamp": "2026-01-30T15:18:30.696891"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4496.568, "latencies_ms": [4496.568], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The tennis player is in the foreground, holding a yellow tennis racket and preparing to hit a yellow tennis ball. The green fence is in the background, and the blue court is in the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.541}, "power_stats": {"power_gpu_soc_mean_watts": 20.419, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 72.541}, "timestamp": "2026-01-30T15:18:37.217450"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3059.145, "latencies_ms": [3059.145], "images_per_second": 0.327, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young boy is playing tennis on a court with a green fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.8, "ram_available_mb": 48849.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.68}, "power_stats": {"power_gpu_soc_mean_watts": 23.796, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 75.68}, "timestamp": "2026-01-30T15:18:42.296313"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6051.296, "latencies_ms": [6051.296], "images_per_second": 0.165, "prompt_tokens": 1109, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The image features a young boy playing tennis on a green court with a blue surface. The boy is wearing a white shirt and black shorts, and he is holding a yellow tennis racket. The background of the image is a green curtain, and there is a sign on the left side of the image that reads \"Are you next?\"", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.804}, "power_stats": {"power_gpu_soc_mean_watts": 17.962, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 68.804}, "timestamp": "2026-01-30T15:18:50.383605"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3843.058, "latencies_ms": [3843.058], "images_per_second": 0.26, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a bedroom with a bed covered in a brown blanket, a wooden door, and a chair with a red and black bag on it.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.707, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 69.75}, "timestamp": "2026-01-30T15:18:56.276341"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4066.938, "latencies_ms": [4066.938], "images_per_second": 0.246, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " bed: 1, chair: 1, desk: 1, door: 1, box: 1, blanket: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 13991.6, "ram_available_mb": 48849.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.882}, "power_stats": {"power_gpu_soc_mean_watts": 21.185, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.156, "gpu_utilization_percent_mean": 70.882}, "timestamp": "2026-01-30T15:19:02.362343"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4510.172, "latencies_ms": [4510.172], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the desk and chair situated on the right side. The desk is positioned in the foreground, while the chair is located further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.541}, "power_stats": {"power_gpu_soc_mean_watts": 20.593, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 67.541}, "timestamp": "2026-01-30T15:19:08.895003"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2880.698, "latencies_ms": [2880.698], "images_per_second": 0.347, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A messy bedroom with a bed, a chair, and a desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.826}, "power_stats": {"power_gpu_soc_mean_watts": 24.455, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.299, "gpu_utilization_percent_mean": 77.826}, "timestamp": "2026-01-30T15:19:13.815440"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3184.816, "latencies_ms": [3184.816], "images_per_second": 0.314, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is lit by a single lightbulb, and the walls are made of brick.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.39, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T15:19:19.022584"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3606.02, "latencies_ms": [3606.02], "images_per_second": 0.277, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A woman in a red and green outfit is riding a brown horse over a jump obstacle in a field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.533}, "power_stats": {"power_gpu_soc_mean_watts": 22.247, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 75.533}, "timestamp": "2026-01-30T15:19:24.685730"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4516.86, "latencies_ms": [4516.86], "images_per_second": 0.221, "prompt_tokens": 1113, "response_tokens_est": 42, "n_tiles": 1, "output_text": " horse: 1, rider: 1, saddle: 1, bridle: 1, leg protection: 2, leg band: 1, helmet: 1, number: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.57, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 69.676}, "timestamp": "2026-01-30T15:19:31.238436"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5160.336, "latencies_ms": [5160.336], "images_per_second": 0.194, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The horse is in the foreground, jumping over the obstacle, while the rider is in the background, wearing a helmet and a colorful jacket. The obstacle is positioned to the left of the horse, and the rider is positioned to the right of the horse.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.985, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T15:19:38.418828"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3348.398, "latencies_ms": [3348.398], "images_per_second": 0.299, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman in a red and green outfit is riding a brown horse over a jump obstacle in a field.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.407}, "power_stats": {"power_gpu_soc_mean_watts": 22.942, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 75.407}, "timestamp": "2026-01-30T15:19:43.784527"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5873.244, "latencies_ms": [5873.244], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a horse and rider in a dynamic pose, with the horse's coat a rich brown and the rider's attire a vibrant mix of red, green, and white. The scene is bathed in natural light, casting soft shadows and highlighting the textures of the horse's coat and the rider's gear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.98}, "power_stats": {"power_gpu_soc_mean_watts": 18.019, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 70.98}, "timestamp": "2026-01-30T15:19:51.695298"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3360.769, "latencies_ms": [3360.769], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Three men are sitting under a large umbrella on a sidewalk, with a car and a bicycle parked behind them.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.893}, "power_stats": {"power_gpu_soc_mean_watts": 22.82, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 71.893}, "timestamp": "2026-01-30T15:19:57.093311"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5416.67, "latencies_ms": [5416.67], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 3\n2. umbrella: 2\n3. chair: 1\n4. car: 2\n5. bicycle: 1\n6. table: 1\n7. sign: 1\n8. person: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.261}, "power_stats": {"power_gpu_soc_mean_watts": 18.715, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 71.261}, "timestamp": "2026-01-30T15:20:04.524294"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5286.512, "latencies_ms": [5286.512], "images_per_second": 0.189, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The man sitting under the umbrella is positioned to the left of the man sitting on the ground, with the man on the ground being closer to the camera. The man sitting under the umbrella is in the foreground, while the man sitting on the ground is in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.0, "ram_available_mb": 48848.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.568}, "power_stats": {"power_gpu_soc_mean_watts": 18.947, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 68.568}, "timestamp": "2026-01-30T15:20:11.841520"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3816.97, "latencies_ms": [3816.97], "images_per_second": 0.262, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A man sits under a large umbrella on a sidewalk, while two other men sit on the ground next to a cart with various items on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.281}, "power_stats": {"power_gpu_soc_mean_watts": 21.547, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 70.281}, "timestamp": "2026-01-30T15:20:17.690432"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3509.018, "latencies_ms": [3509.018], "images_per_second": 0.285, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is in black and white, with the exception of the man's white shirt, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.241}, "power_stats": {"power_gpu_soc_mean_watts": 22.711, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 73.241}, "timestamp": "2026-01-30T15:20:23.229886"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3558.523, "latencies_ms": [3558.523], "images_per_second": 0.281, "prompt_tokens": 1100, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image depicts a kitchen with white cabinets, a stove, and a refrigerator, and a ceiling fan with lights hanging from it.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.697, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.203, "gpu_utilization_percent_mean": 74.172}, "timestamp": "2026-01-30T15:20:28.830091"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4448.167, "latencies_ms": [4448.167], "images_per_second": 0.225, "prompt_tokens": 1114, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. white cabinets\n2. white stove\n3. white refrigerator\n4. white oven\n5. white sink\n6. white dishwasher\n7. white microwave\n8. white toaster", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.541}, "power_stats": {"power_gpu_soc_mean_watts": 20.667, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 69.541}, "timestamp": "2026-01-30T15:20:35.291932"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4542.515, "latencies_ms": [4542.515], "images_per_second": 0.22, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The stove is located to the left of the sink, and the refrigerator is positioned to the right of the sink. The ceiling fan is located above the sink, and the window is located above the sink.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.177, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 70.026}, "timestamp": "2026-01-30T15:20:41.867281"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3614.225, "latencies_ms": [3614.225], "images_per_second": 0.277, "prompt_tokens": 1112, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image captures a quaint, well-lit kitchen with white cabinets and a white stove, where a ceiling fan hangs above the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.633}, "power_stats": {"power_gpu_soc_mean_watts": 22.114, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 73.633}, "timestamp": "2026-01-30T15:20:47.522934"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3248.983, "latencies_ms": [3248.983], "images_per_second": 0.308, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light coming through the windows, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.519}, "power_stats": {"power_gpu_soc_mean_watts": 23.532, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.235, "gpu_utilization_percent_mean": 75.519}, "timestamp": "2026-01-30T15:20:52.793890"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4164.376, "latencies_ms": [4164.376], "images_per_second": 0.24, "prompt_tokens": 1100, "response_tokens_est": 35, "n_tiles": 1, "output_text": " A child is lying in bed with a pillow under their head, wearing a white tank top and blue pajama pants with a pattern of daisies and other shapes.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.382}, "power_stats": {"power_gpu_soc_mean_watts": 20.929, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 72.382}, "timestamp": "2026-01-30T15:20:58.987807"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5417.772, "latencies_ms": [5417.772], "images_per_second": 0.185, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. child: 1\n2. pillow: 1\n3. blanket: 1\n4. bed: 1\n5. wall: 1\n6. nightstand: 1\n7. lamp: 1\n8. curtain: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.867}, "power_stats": {"power_gpu_soc_mean_watts": 18.936, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 70.867}, "timestamp": "2026-01-30T15:21:06.424539"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4432.17, "latencies_ms": [4432.17], "images_per_second": 0.226, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The child is lying on the bed, which is positioned in the foreground of the image. The bed is located in the middle of the room, with the wall and a lamp in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.611}, "power_stats": {"power_gpu_soc_mean_watts": 20.512, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 67.611}, "timestamp": "2026-01-30T15:21:12.887586"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2845.064, "latencies_ms": [2845.064], "images_per_second": 0.351, "prompt_tokens": 1112, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A child is sleeping in a room with a lamp on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.391}, "power_stats": {"power_gpu_soc_mean_watts": 24.212, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.29, "gpu_utilization_percent_mean": 78.391}, "timestamp": "2026-01-30T15:21:17.771522"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5600.874, "latencies_ms": [5600.874], "images_per_second": 0.179, "prompt_tokens": 1110, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image is a nighttime photograph of a child in a bedroom, with the room dimly lit by a lamp. The child is lying on a bed with a blue and white checkered blanket, wearing a white tank top and blue pajama pants with a pattern of white daisies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.851}, "power_stats": {"power_gpu_soc_mean_watts": 18.557, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.851}, "timestamp": "2026-01-30T15:21:25.391793"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4393.177, "latencies_ms": [4393.177], "images_per_second": 0.228, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image features a green highway sign with the text \"EAST Interstate 78 Queens Bronx\" and a \"NO TRUCKS\" sign above it, indicating a restricted area for trucks.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.056}, "power_stats": {"power_gpu_soc_mean_watts": 20.519, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 71.056}, "timestamp": "2026-01-30T15:21:31.826521"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5557.135, "latencies_ms": [5557.135], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sign: 1\n2. graffiti: 1\n3. road sign: 1\n4. metal structure: 1\n5. highway: 1\n6. bridge: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.239}, "power_stats": {"power_gpu_soc_mean_watts": 18.541, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 69.239}, "timestamp": "2026-01-30T15:21:39.416259"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4154.091, "latencies_ms": [4154.091], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The green highway sign is positioned in the foreground, slightly to the left of the center of the image. The metal truss structure is located in the background, behind the sign.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.471}, "power_stats": {"power_gpu_soc_mean_watts": 21.315, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.088, "gpu_utilization_percent_mean": 72.471}, "timestamp": "2026-01-30T15:21:45.603697"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5041.303, "latencies_ms": [5041.303], "images_per_second": 0.198, "prompt_tokens": 1111, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a green highway sign with the words \"Queens Bronx\" written on it, indicating a route for travelers. The sign is situated on a metal structure, possibly part of a highway or bridge, and is surrounded by a clear sky.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.524}, "power_stats": {"power_gpu_soc_mean_watts": 19.286, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 67.524}, "timestamp": "2026-01-30T15:21:52.660226"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4047.762, "latencies_ms": [4047.762], "images_per_second": 0.247, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The sign is green with white lettering, and it is attached to a metal frame. The sky is overcast, and the sign is illuminated by artificial lighting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.545}, "power_stats": {"power_gpu_soc_mean_watts": 21.378, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 71.545}, "timestamp": "2026-01-30T15:21:58.719599"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3236.89, "latencies_ms": [3236.89], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A red vintage Chevrolet pickup truck is parked in a lot with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.374, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.238, "gpu_utilization_percent_mean": 76.815}, "timestamp": "2026-01-30T15:22:04.014638"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5581.962, "latencies_ms": [5581.962], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. truck: 1\n2. wheels: 2\n3. tires: 2\n4. tail lights: 2\n5. headlights: 2\n6. license plate: 1\n7. body: 1\n8. roof: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.391}, "power_stats": {"power_gpu_soc_mean_watts": 18.618, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 68.391}, "timestamp": "2026-01-30T15:22:11.610966"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4777.234, "latencies_ms": [4777.234], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The red pickup truck is positioned in the foreground, with the blue tent and street lamp in the background. The truck is facing towards the left side of the image, while the tent and lamp are located towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.3}, "power_stats": {"power_gpu_soc_mean_watts": 19.659, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 70.3}, "timestamp": "2026-01-30T15:22:18.422845"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3066.884, "latencies_ms": [3066.884], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A red vintage truck is parked in a lot with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.765, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 75.4}, "timestamp": "2026-01-30T15:22:23.503830"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3331.353, "latencies_ms": [3331.353], "images_per_second": 0.3, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The truck is red with chrome wheels and a shiny finish. The sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.407}, "power_stats": {"power_gpu_soc_mean_watts": 23.029, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.179, "gpu_utilization_percent_mean": 73.407}, "timestamp": "2026-01-30T15:22:28.868747"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3054.724, "latencies_ms": [3054.724], "images_per_second": 0.327, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A group of cows are standing behind a barbed wire fence, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.814, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.241, "gpu_utilization_percent_mean": 72.16}, "timestamp": "2026-01-30T15:22:33.980937"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5466.351, "latencies_ms": [5466.351], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. barbed wire: 1\n2. cows: 4\n3. grass: 1\n4. trees: 1\n5. fence: 1\n6. sky: 1\n7. clouds: 1\n8. fence post: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.391}, "power_stats": {"power_gpu_soc_mean_watts": 18.878, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 69.391}, "timestamp": "2026-01-30T15:22:41.478469"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3623.818, "latencies_ms": [3623.818], "images_per_second": 0.276, "prompt_tokens": 1117, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The cows are positioned in the foreground, with the barbed wire fence in the middle ground, and the field and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.267}, "power_stats": {"power_gpu_soc_mean_watts": 22.475, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.195, "gpu_utilization_percent_mean": 74.267}, "timestamp": "2026-01-30T15:22:47.140543"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4916.872, "latencies_ms": [4916.872], "images_per_second": 0.203, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " In this black and white photo, we see a group of cows standing behind a barbed wire fence, looking directly at the camera. The cows are of different colors, with one having a white face and the others having various shades of brown.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.073}, "power_stats": {"power_gpu_soc_mean_watts": 19.541, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 71.073}, "timestamp": "2026-01-30T15:22:54.083357"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3803.406, "latencies_ms": [3803.406], "images_per_second": 0.263, "prompt_tokens": 1109, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image is in black and white, with a barbed wire fence in the foreground, and the cows are standing in a field with tall grass.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.452}, "power_stats": {"power_gpu_soc_mean_watts": 21.749, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 69.452}, "timestamp": "2026-01-30T15:22:59.913866"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4806.775, "latencies_ms": [4806.775], "images_per_second": 0.208, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image depicts a cozy bedroom with a large bed, a comfortable chair, a fireplace, and a television mounted on the wall, all set against a warm and inviting backdrop of wooden furniture and a ceiling with a glowing light strip.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.049}, "power_stats": {"power_gpu_soc_mean_watts": 19.541, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 69.049}, "timestamp": "2026-01-30T15:23:06.790231"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5571.966, "latencies_ms": [5571.966], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bed: 1\n2. clock: 1\n3. television: 1\n4. chair: 2\n5. lamp: 1\n6. window blinds: 1\n7. fireplace: 1\n8. rug: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.511}, "power_stats": {"power_gpu_soc_mean_watts": 18.477, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.934, "gpu_utilization_percent_mean": 68.511}, "timestamp": "2026-01-30T15:23:14.378897"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5381.494, "latencies_ms": [5381.494], "images_per_second": 0.186, "prompt_tokens": 1117, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The bed is located on the left side of the room, with the clock on the wall above it. The fireplace is situated on the right side of the room, with the television above it. The chair is placed in the middle of the room, with the window behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.867}, "power_stats": {"power_gpu_soc_mean_watts": 18.852, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 69.867}, "timestamp": "2026-01-30T15:23:21.788807"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2990.908, "latencies_ms": [2990.908], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The room is a cozy bedroom with a bed, chairs, and a fireplace.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.272, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.276, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T15:23:26.796300"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3348.789, "latencies_ms": [3348.789], "images_per_second": 0.299, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The room is illuminated by a warm yellow light, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.037}, "power_stats": {"power_gpu_soc_mean_watts": 23.191, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.228, "gpu_utilization_percent_mean": 74.037}, "timestamp": "2026-01-30T15:23:32.166965"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4055.009, "latencies_ms": [4055.009], "images_per_second": 0.247, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, a group of four birds with black feathers and blue accents are seen walking on a dry, grassy field, with a bush and trees in the background.", "error": null, "sys_before": {"cpu_percent": 12.1, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.758}, "power_stats": {"power_gpu_soc_mean_watts": 21.341, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.097, "gpu_utilization_percent_mean": 69.758}, "timestamp": "2026-01-30T15:23:38.267012"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5471.538, "latencies_ms": [5471.538], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 4\n2. grass: 1\n3. bush: 1\n4. tree: 1\n5. sky: 1\n6. ground: 1\n7. dirt: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.756}, "power_stats": {"power_gpu_soc_mean_watts": 18.597, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 66.756}, "timestamp": "2026-01-30T15:23:45.777896"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5225.609, "latencies_ms": [5225.609], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the two larger birds in the center and the smaller bird to the right. The larger birds are positioned closer to the camera than the smaller bird, which is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.395}, "power_stats": {"power_gpu_soc_mean_watts": 18.624, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 7.941, "gpu_utilization_percent_mean": 68.395}, "timestamp": "2026-01-30T15:23:53.044070"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3198.593, "latencies_ms": [3198.593], "images_per_second": 0.313, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of four birds with black feathers and blue accents are walking on a dry grassy field.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.423}, "power_stats": {"power_gpu_soc_mean_watts": 23.377, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 75.423}, "timestamp": "2026-01-30T15:23:58.290431"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3604.433, "latencies_ms": [3604.433], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a group of four birds with black feathers and blue accents, walking on a dry, grassy field under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.867}, "power_stats": {"power_gpu_soc_mean_watts": 22.514, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 73.867}, "timestamp": "2026-01-30T15:24:03.925814"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3478.72, "latencies_ms": [3478.72], "images_per_second": 0.287, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Three people are standing in the snow, wearing winter clothing and holding ski poles, with a forested area in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.448}, "power_stats": {"power_gpu_soc_mean_watts": 22.463, "power_cpu_cv_mean_watts": 1.118, "power_sys_5v0_mean_watts": 8.146, "gpu_utilization_percent_mean": 70.448}, "timestamp": "2026-01-30T15:24:09.445986"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5538.899, "latencies_ms": [5538.899], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skis: 3\n2. snow: 1\n3. trees: 1\n4. people: 3\n5. skis poles: 3\n6. backpack: 1\n7. hat: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.978}, "power_stats": {"power_gpu_soc_mean_watts": 18.817, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 68.978}, "timestamp": "2026-01-30T15:24:17.008380"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6497.827, "latencies_ms": [6497.827], "images_per_second": 0.154, "prompt_tokens": 1117, "response_tokens_est": 75, "n_tiles": 1, "output_text": " The person on the left is standing closer to the camera than the person in the middle, who is standing slightly farther away. The person on the right is standing in the background, with the person in the middle being the closest to the camera. The person on the left is also standing closer to the camera than the person in the middle, who is standing slightly farther away.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.218}, "power_stats": {"power_gpu_soc_mean_watts": 17.515, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 69.218}, "timestamp": "2026-01-30T15:24:25.563157"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2910.836, "latencies_ms": [2910.836], "images_per_second": 0.344, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three people are standing in the snow wearing winter clothing and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.958}, "power_stats": {"power_gpu_soc_mean_watts": 24.189, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 77.958}, "timestamp": "2026-01-30T15:24:30.525243"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4483.617, "latencies_ms": [4483.617], "images_per_second": 0.223, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features three people standing in a snowy landscape, wearing winter clothing and holding ski poles. The sky is overcast, and the snow is pristine white, covering the ground and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.297}, "power_stats": {"power_gpu_soc_mean_watts": 20.429, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 69.297}, "timestamp": "2026-01-30T15:24:37.022473"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4465.54, "latencies_ms": [4465.54], "images_per_second": 0.224, "prompt_tokens": 1432, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A white and blue bus with the number 61 and the word \"Crosstown\" on the front is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.757}, "power_stats": {"power_gpu_soc_mean_watts": 23.622, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.431, "gpu_utilization_percent_mean": 76.757}, "timestamp": "2026-01-30T15:24:43.521327"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6579.935, "latencies_ms": [6579.935], "images_per_second": 0.152, "prompt_tokens": 1446, "response_tokens_est": 65, "n_tiles": 1, "output_text": " 1. Bus: 1\n2. License plate: 1\n3. Bike rack: 1\n4. Side mirror: 1\n5. Headlights: 2\n6. Windshield: 1\n7. Side mirrors: 2\n8. License plate holder: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.732}, "power_stats": {"power_gpu_soc_mean_watts": 20.129, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 72.732}, "timestamp": "2026-01-30T15:24:52.153444"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5228.257, "latencies_ms": [5228.257], "images_per_second": 0.191, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The bus is positioned on the left side of the image, with the driver's side facing the camera. The background features a brick building and a clear blue sky, while the foreground shows a sidewalk and a street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.614}, "power_stats": {"power_gpu_soc_mean_watts": 22.331, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.356, "gpu_utilization_percent_mean": 74.614}, "timestamp": "2026-01-30T15:24:59.405820"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4424.216, "latencies_ms": [4424.216], "images_per_second": 0.226, "prompt_tokens": 1444, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A white and blue bus is parked on the side of the road, with a sign on the front that says \"51 CROSSTOWN\".", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.973}, "power_stats": {"power_gpu_soc_mean_watts": 24.057, "power_cpu_cv_mean_watts": 1.19, "power_sys_5v0_mean_watts": 8.457, "gpu_utilization_percent_mean": 75.973}, "timestamp": "2026-01-30T15:25:05.872289"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3780.511, "latencies_ms": [3780.511], "images_per_second": 0.265, "prompt_tokens": 1442, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The bus is white with blue and green graphics, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.484}, "power_stats": {"power_gpu_soc_mean_watts": 25.704, "power_cpu_cv_mean_watts": 0.891, "power_sys_5v0_mean_watts": 8.56, "gpu_utilization_percent_mean": 78.484}, "timestamp": "2026-01-30T15:25:11.668038"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3890.416, "latencies_ms": [3890.416], "images_per_second": 0.257, "prompt_tokens": 768, "response_tokens_est": 41, "n_tiles": 1, "output_text": " A man is dressed in a school uniform, consisting of a blue blazer, a white shirt, a red and blue striped tie, a gray pleated skirt, black tights, and black shoes.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.562}, "power_stats": {"power_gpu_soc_mean_watts": 17.73, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 7.674, "gpu_utilization_percent_mean": 64.562}, "timestamp": "2026-01-30T15:25:17.597973"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5004.053, "latencies_ms": [5004.053], "images_per_second": 0.2, "prompt_tokens": 782, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 1\n2. wall: 1\n3. handbag: 1\n4. tie: 1\n5. shirt: 1\n6. tie clip: 1\n7. tie: 1\n8. tie clip: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.619}, "power_stats": {"power_gpu_soc_mean_watts": 16.35, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 7.686, "gpu_utilization_percent_mean": 65.619}, "timestamp": "2026-01-30T15:25:24.637875"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3989.498, "latencies_ms": [3989.498], "images_per_second": 0.251, "prompt_tokens": 786, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The man is standing in the foreground of the image, with the red carpet and white wall in the background. The black bag is held in his left hand, while his right hand is resting on his hip.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.242}, "power_stats": {"power_gpu_soc_mean_watts": 17.763, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.715, "gpu_utilization_percent_mean": 65.242}, "timestamp": "2026-01-30T15:25:30.662880"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2498.638, "latencies_ms": [2498.638], "images_per_second": 0.4, "prompt_tokens": 780, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man dressed in a school uniform stands in front of a red and white wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.95}, "power_stats": {"power_gpu_soc_mean_watts": 21.361, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 7.782, "gpu_utilization_percent_mean": 71.95}, "timestamp": "2026-01-30T15:25:35.189141"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2973.858, "latencies_ms": [2973.858], "images_per_second": 0.336, "prompt_tokens": 778, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image is a photograph with a white background and a red carpet. The lighting is natural, and the colors are vibrant.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.137, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 66.667}, "timestamp": "2026-01-30T15:25:40.197614"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4398.352, "latencies_ms": [4398.352], "images_per_second": 0.227, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image depicts a series of metal structures, possibly part of a railway or industrial facility, with numerous cables and wires crisscrossing above them, set against a hazy, yellowish backdrop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.027}, "power_stats": {"power_gpu_soc_mean_watts": 20.246, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.027}, "timestamp": "2026-01-30T15:25:46.655597"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5426.322, "latencies_ms": [5426.322], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. train: 1\n2. train: 1\n3. train: 1\n4. train: 1\n5. train: 1\n6. train: 1\n7. train: 1\n8. train: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.533}, "power_stats": {"power_gpu_soc_mean_watts": 18.81, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 68.533}, "timestamp": "2026-01-30T15:25:54.114798"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6079.585, "latencies_ms": [6079.585], "images_per_second": 0.164, "prompt_tokens": 1117, "response_tokens_est": 67, "n_tiles": 1, "output_text": " The main objects in the image are the train tracks, which are located in the foreground and are parallel to each other. The poles and wires are positioned above the tracks, with some poles closer to the camera and others farther away. The background of the image features a hazy sky and trees, which are located behind the train tracks.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.647}, "power_stats": {"power_gpu_soc_mean_watts": 17.876, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 7.954, "gpu_utilization_percent_mean": 66.647}, "timestamp": "2026-01-30T15:26:02.208627"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5283.343, "latencies_ms": [5283.343], "images_per_second": 0.189, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a serene scene of a railway track, lined with numerous train cars, all of which are covered in a layer of water. The track is surrounded by a dense forest, and the sky above is hazy, suggesting a foggy or misty day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.023}, "power_stats": {"power_gpu_soc_mean_watts": 19.036, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 68.023}, "timestamp": "2026-01-30T15:26:09.552910"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4845.087, "latencies_ms": [4845.087], "images_per_second": 0.206, "prompt_tokens": 1109, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a series of metal structures with wires attached to them, set against a hazy sky. The colors are muted, with the metal structures appearing in shades of silver and gray, while the sky is a pale blue.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.65}, "power_stats": {"power_gpu_soc_mean_watts": 19.76, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 69.65}, "timestamp": "2026-01-30T15:26:16.435821"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3843.694, "latencies_ms": [3843.694], "images_per_second": 0.26, "prompt_tokens": 1100, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white toilet, a green stool with a plant on it, and a pile of clothes and shoes on the floor.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.677}, "power_stats": {"power_gpu_soc_mean_watts": 22.007, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.141, "gpu_utilization_percent_mean": 70.677}, "timestamp": "2026-01-30T15:26:22.305640"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4119.864, "latencies_ms": [4119.864], "images_per_second": 0.243, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " toilet: 1, shoes: 10, socks: 1, bag: 1, boots: 1, jacket: 1, towel: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.243, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.101, "gpu_utilization_percent_mean": 71.382}, "timestamp": "2026-01-30T15:26:28.451653"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5345.941, "latencies_ms": [5345.941], "images_per_second": 0.187, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The toilet is located on the left side of the image, while the shoes are scattered throughout the room, with some near the left side and others closer to the right side. The clothes are primarily located near the center of the image, with a few scattered around the edges.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.067}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 70.067}, "timestamp": "2026-01-30T15:26:35.811866"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3298.649, "latencies_ms": [3298.649], "images_per_second": 0.303, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A messy bathroom with a toilet, a stool with a plant, and a bunch of clothes on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.161, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.232, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-30T15:26:41.150380"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3166.465, "latencies_ms": [3166.465], "images_per_second": 0.316, "prompt_tokens": 1110, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is lit by natural light coming from a window, and the walls are painted white.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.543, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.21, "gpu_utilization_percent_mean": 73.808}, "timestamp": "2026-01-30T15:26:46.379985"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3044.099, "latencies_ms": [3044.099], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A polar bear is playing with two green and yellow balls in a pool of water.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.56}, "power_stats": {"power_gpu_soc_mean_watts": 23.718, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.24, "gpu_utilization_percent_mean": 72.56}, "timestamp": "2026-01-30T15:26:51.454771"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5622.469, "latencies_ms": [5622.469], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. polar bear: 1\n2. green ball: 2\n3. yellow ball: 1\n4. water: 1\n5. rock: 1\n6. concrete: 1\n7. sand: 1\n8. concrete wall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.234}, "power_stats": {"power_gpu_soc_mean_watts": 18.527, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 68.234}, "timestamp": "2026-01-30T15:26:59.091716"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4464.133, "latencies_ms": [4464.133], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The polar bear is in the foreground of the image, with the green and yellow balls in the water in the middle ground. The bear is reaching towards the balls with its mouth, indicating a playful interaction.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.57, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 71.676}, "timestamp": "2026-01-30T15:27:05.609017"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3369.587, "latencies_ms": [3369.587], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " In a zoo enclosure, a polar bear is playing with two green and yellow balls in a pool of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.963}, "power_stats": {"power_gpu_soc_mean_watts": 23.147, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.18, "gpu_utilization_percent_mean": 75.963}, "timestamp": "2026-01-30T15:27:10.988885"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4202.95, "latencies_ms": [4202.95], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The polar bear is in a pool of water, with a green and yellow ball in its mouth. The lighting is natural, and the bear's fur is wet and matted.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.843, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 70.8}, "timestamp": "2026-01-30T15:27:17.221867"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5223.935, "latencies_ms": [5223.935], "images_per_second": 0.191, "prompt_tokens": 1432, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image is a split-screen photo showing a person sitting on a chair with their legs crossed, wearing blue socks and jeans, and holding a flip phone, with the phone's screen displaying the time and date.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.86}, "power_stats": {"power_gpu_soc_mean_watts": 21.967, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.329, "gpu_utilization_percent_mean": 72.86}, "timestamp": "2026-01-30T15:27:24.476325"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4765.268, "latencies_ms": [4765.268], "images_per_second": 0.21, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " chair: 1, person: 1, cell phone: 1, window: 1, floor: 1, legs: 1, socks: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.45}, "power_stats": {"power_gpu_soc_mean_watts": 23.012, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.43, "gpu_utilization_percent_mean": 75.45}, "timestamp": "2026-01-30T15:27:31.272649"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5708.559, "latencies_ms": [5708.559], "images_per_second": 0.175, "prompt_tokens": 1450, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The left image shows a person's legs and feet resting on a chair, with the chair positioned on the left side of the image. The right image shows a hand holding a cell phone, with the cell phone positioned on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.521, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 8.301, "gpu_utilization_percent_mean": 70.125}, "timestamp": "2026-01-30T15:27:39.021411"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4091.723, "latencies_ms": [4091.723], "images_per_second": 0.244, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A person is sitting on a chair with their feet up on the floor, and they are holding a cell phone.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.059}, "power_stats": {"power_gpu_soc_mean_watts": 24.671, "power_cpu_cv_mean_watts": 1.059, "power_sys_5v0_mean_watts": 8.466, "gpu_utilization_percent_mean": 79.059}, "timestamp": "2026-01-30T15:27:45.140447"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4810.002, "latencies_ms": [4810.002], "images_per_second": 0.208, "prompt_tokens": 1442, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a wooden floor with a blue towel on it, and a person is holding a cell phone. The lighting is natural, coming from a window with a white frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.825}, "power_stats": {"power_gpu_soc_mean_watts": 23.121, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 8.382, "gpu_utilization_percent_mean": 72.825}, "timestamp": "2026-01-30T15:27:52.002790"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3610.667, "latencies_ms": [3610.667], "images_per_second": 0.277, "prompt_tokens": 1432, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A yellow train is traveling down a snowy track surrounded by trees and power lines.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.867}, "power_stats": {"power_gpu_soc_mean_watts": 25.381, "power_cpu_cv_mean_watts": 0.894, "power_sys_5v0_mean_watts": 8.542, "gpu_utilization_percent_mean": 78.867}, "timestamp": "2026-01-30T15:27:57.651879"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4751.983, "latencies_ms": [4751.983], "images_per_second": 0.21, "prompt_tokens": 1446, "response_tokens_est": 35, "n_tiles": 1, "output_text": " train: 1, trees: 10, snow: 1, sky: 1, birds: 1, signal: 1, wires: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.513}, "power_stats": {"power_gpu_soc_mean_watts": 23.356, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 8.41, "gpu_utilization_percent_mean": 72.513}, "timestamp": "2026-01-30T15:28:04.436457"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5533.801, "latencies_ms": [5533.801], "images_per_second": 0.181, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The train is moving from the left to the right side of the image, with the tracks running parallel to the viewer's perspective. The trees and power lines are located in the background, while the snow-covered ground is in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.457}, "power_stats": {"power_gpu_soc_mean_watts": 21.872, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 8.307, "gpu_utilization_percent_mean": 72.457}, "timestamp": "2026-01-30T15:28:11.993169"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3751.982, "latencies_ms": [3751.982], "images_per_second": 0.267, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A yellow train is traveling down a snowy track, surrounded by trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.935}, "power_stats": {"power_gpu_soc_mean_watts": 25.481, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 8.567, "gpu_utilization_percent_mean": 75.935}, "timestamp": "2026-01-30T15:28:17.766687"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4231.153, "latencies_ms": [4231.153], "images_per_second": 0.236, "prompt_tokens": 1442, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The image features a yellow train traveling down a snowy track, with a gray sky overhead and trees lining the sides of the track.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.6}, "power_stats": {"power_gpu_soc_mean_watts": 24.284, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 8.464, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T15:28:24.030111"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4250.136, "latencies_ms": [4250.136], "images_per_second": 0.235, "prompt_tokens": 1099, "response_tokens_est": 37, "n_tiles": 1, "output_text": " In the image, a pile of snow has accumulated on the side of a road, with a few people walking in the background, and a black pipe is partially buried in the snow.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.899, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-30T15:28:30.304948"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5700.151, "latencies_ms": [5700.151], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. snow: 3\n2. people: 4\n3. snowbank: 1\n4. pole: 1\n5. building: 1\n6. road: 1\n7. snowplow: 1\n8. snowdrift: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.723}, "power_stats": {"power_gpu_soc_mean_watts": 18.47, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 69.723}, "timestamp": "2026-01-30T15:28:38.023339"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5190.984, "latencies_ms": [5190.984], "images_per_second": 0.193, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The main objects are located in the foreground of the image, with the snow-covered ground and the two metal poles being the closest to the viewer. The people are in the background, walking away from the camera, and the wooden building is further in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.545}, "power_stats": {"power_gpu_soc_mean_watts": 19.164, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.545}, "timestamp": "2026-01-30T15:28:45.269926"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3604.038, "latencies_ms": [3604.038], "images_per_second": 0.277, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In a snowy urban setting, a pile of snow has accumulated on the side of a road, with several people walking past it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.517}, "power_stats": {"power_gpu_soc_mean_watts": 22.6, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 71.517}, "timestamp": "2026-01-30T15:28:50.889969"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4385.509, "latencies_ms": [4385.509], "images_per_second": 0.228, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a snowy scene with a pile of snow in the foreground, and people walking in the background. The snow is white and fluffy, and the lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.432}, "power_stats": {"power_gpu_soc_mean_watts": 20.614, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 71.432}, "timestamp": "2026-01-30T15:28:57.308071"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2808.311, "latencies_ms": [2808.311], "images_per_second": 0.356, "prompt_tokens": 1099, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A no parking sign is on a pole in a wooded area.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.391}, "power_stats": {"power_gpu_soc_mean_watts": 24.439, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 75.391}, "timestamp": "2026-01-30T15:29:02.159764"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5482.658, "latencies_ms": [5482.658], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sign: 1\n2. tree: 2\n3. pole: 1\n4. building: 1\n5. street light: 1\n6. fence: 1\n7. tree branch: 1\n8. leaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.725, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 70.021}, "timestamp": "2026-01-30T15:29:09.686150"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3643.788, "latencies_ms": [3643.788], "images_per_second": 0.274, "prompt_tokens": 1117, "response_tokens_est": 26, "n_tiles": 1, "output_text": " The sign is located on the right side of the street, near a tree, and in the background, there is a building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.06, "power_cpu_cv_mean_watts": 1.174, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 73.8}, "timestamp": "2026-01-30T15:29:15.358470"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2765.173, "latencies_ms": [2765.173], "images_per_second": 0.362, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A no parking sign is on a pole in a wooded area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.857, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.321, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T15:29:20.145476"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3540.887, "latencies_ms": [3540.887], "images_per_second": 0.282, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The image features a street scene with a no parking sign, a yellow and black umbrella, and a tree with green leaves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.207}, "power_stats": {"power_gpu_soc_mean_watts": 22.57, "power_cpu_cv_mean_watts": 1.132, "power_sys_5v0_mean_watts": 8.162, "gpu_utilization_percent_mean": 71.207}, "timestamp": "2026-01-30T15:29:25.712633"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3752.516, "latencies_ms": [3752.516], "images_per_second": 0.266, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A teddy bear wearing glasses and headphones is sitting on a red desk with a keyboard, a microphone, and a tape recorder in front of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.323}, "power_stats": {"power_gpu_soc_mean_watts": 22.033, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 73.323}, "timestamp": "2026-01-30T15:29:31.508838"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4260.711, "latencies_ms": [4260.711], "images_per_second": 0.235, "prompt_tokens": 1114, "response_tokens_est": 38, "n_tiles": 1, "output_text": " teddy bear: 1\nglasses: 1\nkeyboard: 1\ncamera: 1\nmic: 1\nremote: 1\ncomputer mouse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13998.2, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.571}, "power_stats": {"power_gpu_soc_mean_watts": 21.161, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 70.571}, "timestamp": "2026-01-30T15:29:37.779924"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4622.92, "latencies_ms": [4622.92], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The teddy bear is positioned in the foreground, with the keyboard and microphone placed in front of it. The teddy bear is situated to the left of the keyboard, while the microphone is located to the right of the keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.474}, "power_stats": {"power_gpu_soc_mean_watts": 20.441, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 70.474}, "timestamp": "2026-01-30T15:29:44.434777"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3177.599, "latencies_ms": [3177.599], "images_per_second": 0.315, "prompt_tokens": 1112, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A teddy bear wearing glasses and headphones is sitting on a desk with a keyboard in front of it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.154}, "power_stats": {"power_gpu_soc_mean_watts": 23.497, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.292, "gpu_utilization_percent_mean": 77.154}, "timestamp": "2026-01-30T15:29:49.629889"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3056.757, "latencies_ms": [3056.757], "images_per_second": 0.327, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The teddy bear is beige, the keyboard is black, and the background is blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.231, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.305, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T15:29:54.712691"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4575.595, "latencies_ms": [4575.595], "images_per_second": 0.219, "prompt_tokens": 1432, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image captures a skier in mid-air, performing a backflip on a snowy mountain, with a clear blue sky and a rocky mountain in the background.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.711}, "power_stats": {"power_gpu_soc_mean_watts": 23.348, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.435, "gpu_utilization_percent_mean": 75.711}, "timestamp": "2026-01-30T15:30:01.353462"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6068.828, "latencies_ms": [6068.828], "images_per_second": 0.165, "prompt_tokens": 1446, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. skis: 2\n2. person: 1\n3. mountain: 1\n4. snow: 1\n5. trees: 1\n6. sky: 1\n7. text: 1\n8. logo: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.804}, "power_stats": {"power_gpu_soc_mean_watts": 20.921, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.282, "gpu_utilization_percent_mean": 71.804}, "timestamp": "2026-01-30T15:30:09.455158"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4927.895, "latencies_ms": [4927.895], "images_per_second": 0.203, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The skier is in the foreground, with the mountain and trees in the background. The skier is to the left of the mountain, and the skis are to the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.976}, "power_stats": {"power_gpu_soc_mean_watts": 22.653, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.348, "gpu_utilization_percent_mean": 73.976}, "timestamp": "2026-01-30T15:30:16.395599"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3726.795, "latencies_ms": [3726.795], "images_per_second": 0.268, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A skier is performing a trick in the snow, wearing a white and orange outfit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.129}, "power_stats": {"power_gpu_soc_mean_watts": 25.661, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 8.557, "gpu_utilization_percent_mean": 79.129}, "timestamp": "2026-01-30T15:30:22.142649"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6131.35, "latencies_ms": [6131.35], "images_per_second": 0.163, "prompt_tokens": 1442, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a skier in an orange and white outfit, with skis in the air, against a backdrop of a snowy mountain and clear blue sky. The lighting is bright and natural, suggesting daytime, and the snow appears to be freshly fallen, giving it a pristine white appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.788}, "power_stats": {"power_gpu_soc_mean_watts": 20.697, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.272, "gpu_utilization_percent_mean": 71.788}, "timestamp": "2026-01-30T15:30:30.302270"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4967.751, "latencies_ms": [4967.751], "images_per_second": 0.201, "prompt_tokens": 1432, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In the image, two surfers are riding the waves on their surfboards, with one surfer positioned closer to the camera and the other further away, both enjoying the thrill of the ocean waves.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.48, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.401, "gpu_utilization_percent_mean": 74.667}, "timestamp": "2026-01-30T15:30:37.313879"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6124.127, "latencies_ms": [6124.127], "images_per_second": 0.163, "prompt_tokens": 1446, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. surfboard: 2\n2. surfer: 2\n3. wave: 2\n4. ocean: 2\n5. sky: 1\n6. sun: 1\n7. water: 2\n8. sand: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.481}, "power_stats": {"power_gpu_soc_mean_watts": 20.866, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 72.481}, "timestamp": "2026-01-30T15:30:45.456904"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6361.536, "latencies_ms": [6361.536], "images_per_second": 0.157, "prompt_tokens": 1450, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The surfer on the left is closer to the camera than the surfer on the right. The surfer on the left is in the foreground, while the surfer on the right is in the background. The surfer on the left is closer to the camera than the surfer on the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.796}, "power_stats": {"power_gpu_soc_mean_watts": 20.413, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 8.249, "gpu_utilization_percent_mean": 70.796}, "timestamp": "2026-01-30T15:30:53.876693"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3858.196, "latencies_ms": [3858.196], "images_per_second": 0.259, "prompt_tokens": 1444, "response_tokens_est": 19, "n_tiles": 1, "output_text": " Two surfers are riding the waves on the ocean, with the sun setting in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.375}, "power_stats": {"power_gpu_soc_mean_watts": 25.26, "power_cpu_cv_mean_watts": 0.988, "power_sys_5v0_mean_watts": 8.504, "gpu_utilization_percent_mean": 80.375}, "timestamp": "2026-01-30T15:30:59.759217"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5888.169, "latencies_ms": [5888.169], "images_per_second": 0.17, "prompt_tokens": 1442, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures the dynamic interaction between the surfer and the ocean, with the surfer riding a wave and the ocean's surface reflecting the sunlight. The colors are predominantly blue and white, with the surfer's dark silhouette contrasting against the lighter hues of the water.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.36}, "power_stats": {"power_gpu_soc_mean_watts": 21.106, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.299, "gpu_utilization_percent_mean": 72.36}, "timestamp": "2026-01-30T15:31:07.678417"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4378.002, "latencies_ms": [4378.002], "images_per_second": 0.228, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A pizza with a variety of toppings is placed on a metal tray, accompanied by a jar of pepperoni and a bottle of sauce, all set on a table with a blue tablecloth.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.343, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 69.324}, "timestamp": "2026-01-30T15:31:14.099514"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4141.489, "latencies_ms": [4141.489], "images_per_second": 0.241, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " pizza: 1, plate: 1, pepperoni: 1, cheese: 1, sauce: 1, crust: 1, table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.9, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T15:31:20.280807"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4868.472, "latencies_ms": [4868.472], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The pizza is located in the foreground, with the pepperoni pizza in the middle and the salt shaker in the background. The pizza is placed on the left side of the table, while the salt shaker is on the right side.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.195}, "power_stats": {"power_gpu_soc_mean_watts": 19.764, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 71.195}, "timestamp": "2026-01-30T15:31:27.190514"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5226.369, "latencies_ms": [5226.369], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " In a dimly lit restaurant, a delicious pizza sits on a metal tray, accompanied by a jar of pepperoni sauce and a napkin. The pizza boasts a golden crust, topped with melted cheese, and a variety of toppings that add to its appeal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.837}, "power_stats": {"power_gpu_soc_mean_watts": 19.108, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.837}, "timestamp": "2026-01-30T15:31:34.448142"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3425.632, "latencies_ms": [3425.632], "images_per_second": 0.292, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The pizza is on a metal tray with a blue tablecloth, and the table is lit by a red light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.779, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.179, "gpu_utilization_percent_mean": 74.286}, "timestamp": "2026-01-30T15:31:39.903651"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3113.562, "latencies_ms": [3113.562], "images_per_second": 0.321, "prompt_tokens": 1100, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A clock with Roman numerals is on a pole, and the street is covered in snow.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.64}, "power_stats": {"power_gpu_soc_mean_watts": 23.686, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.228, "gpu_utilization_percent_mean": 72.64}, "timestamp": "2026-01-30T15:31:45.064552"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5723.221, "latencies_ms": [5723.221], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. clock: 1\n2. street: 1\n3. snow: 1\n4. building: 1\n5. pole: 1\n6. sidewalk: 1\n7. streetlamp: 1\n8. tree: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.812}, "power_stats": {"power_gpu_soc_mean_watts": 17.792, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.899, "gpu_utilization_percent_mean": 66.812}, "timestamp": "2026-01-30T15:31:52.813873"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4446.869, "latencies_ms": [4446.869], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The clock is positioned on the left side of the image, with the street and buildings extending into the background. The clock is in the foreground, with the street and buildings receding into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.376, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 67.676}, "timestamp": "2026-01-30T15:31:59.275336"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5363.587, "latencies_ms": [5363.587], "images_per_second": 0.186, "prompt_tokens": 1112, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a serene winter scene on a street corner, where a black clock tower stands tall against the backdrop of a clear blue sky. The clock, adorned with a gold face and black numbers, silently marks the passage of time amidst the quietude of the snow-covered sidewalk.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14000.9, "ram_available_mb": 48840.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.156}, "power_stats": {"power_gpu_soc_mean_watts": 18.952, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.156}, "timestamp": "2026-01-30T15:32:06.676681"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3302.569, "latencies_ms": [3302.569], "images_per_second": 0.303, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The clock is black with white numbers and hands, and the sky is blue with a hint of orange.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14000.9, "ram_available_mb": 48840.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.259}, "power_stats": {"power_gpu_soc_mean_watts": 23.045, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.217, "gpu_utilization_percent_mean": 72.259}, "timestamp": "2026-01-30T15:32:12.020463"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3461.505, "latencies_ms": [3461.505], "images_per_second": 0.289, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A baseball player wearing a blue helmet and white uniform is swinging a bat at a baseball that is in mid-air.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.879, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.194, "gpu_utilization_percent_mean": 72.357}, "timestamp": "2026-01-30T15:32:17.517485"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6410.589, "latencies_ms": [6410.589], "images_per_second": 0.156, "prompt_tokens": 1113, "response_tokens_est": 74, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball: 1\n3. catcher's mitt: 1\n4. baseball player: 1\n5. baseball player's uniform: 1\n6. baseball player's helmet: 1\n7. baseball player's glove: 1\n8. baseball player's pants: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.185}, "power_stats": {"power_gpu_soc_mean_watts": 17.723, "power_cpu_cv_mean_watts": 1.757, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 69.185}, "timestamp": "2026-01-30T15:32:25.948799"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4976.478, "latencies_ms": [4976.478], "images_per_second": 0.201, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The batter is in the foreground, the catcher is in the background, and the ball is in the middle ground. The batter is closer to the camera than the catcher, and the ball is closer to the batter than the catcher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.459, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.976}, "timestamp": "2026-01-30T15:32:32.970136"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4322.248, "latencies_ms": [4322.248], "images_per_second": 0.231, "prompt_tokens": 1111, "response_tokens_est": 38, "n_tiles": 1, "output_text": " A baseball player wearing a blue helmet and white uniform is swinging a bat at a baseball. A catcher in a red uniform is crouched behind him, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.854, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 70.657}, "timestamp": "2026-01-30T15:32:39.310965"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6196.169, "latencies_ms": [6196.169], "images_per_second": 0.161, "prompt_tokens": 1109, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter in full swing, the catcher poised to catch the ball, and the field bathed in the warm glow of sunlight. The colors are vibrant, with the blue of the batter's uniform standing out against the green of the field and the red of the catcher's uniform.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.962}, "power_stats": {"power_gpu_soc_mean_watts": 17.919, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 69.962}, "timestamp": "2026-01-30T15:32:47.531885"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3173.894, "latencies_ms": [3173.894], "images_per_second": 0.315, "prompt_tokens": 1100, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A brown teddy bear with a red bow tie is sitting on a chair with a red cushion.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.346}, "power_stats": {"power_gpu_soc_mean_watts": 23.593, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.254, "gpu_utilization_percent_mean": 74.346}, "timestamp": "2026-01-30T15:32:52.744476"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3538.095, "latencies_ms": [3538.095], "images_per_second": 0.283, "prompt_tokens": 1114, "response_tokens_est": 25, "n_tiles": 1, "output_text": " chair: 1, teddy bear: 1, cushion: 1, curtain: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.172}, "power_stats": {"power_gpu_soc_mean_watts": 22.478, "power_cpu_cv_mean_watts": 1.118, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 73.172}, "timestamp": "2026-01-30T15:32:58.316509"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4354.909, "latencies_ms": [4354.909], "images_per_second": 0.23, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The teddy bear is positioned on the left side of the chair, which is located in the middle of the image. The chair is situated in the foreground, with the background featuring a striped curtain.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.083}, "power_stats": {"power_gpu_soc_mean_watts": 20.744, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 70.083}, "timestamp": "2026-01-30T15:33:04.712289"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2762.518, "latencies_ms": [2762.518], "images_per_second": 0.362, "prompt_tokens": 1112, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A teddy bear is sitting on a chair with a red cushion.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.957}, "power_stats": {"power_gpu_soc_mean_watts": 24.475, "power_cpu_cv_mean_watts": 0.87, "power_sys_5v0_mean_watts": 8.321, "gpu_utilization_percent_mean": 78.957}, "timestamp": "2026-01-30T15:33:09.493901"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3676.509, "latencies_ms": [3676.509], "images_per_second": 0.272, "prompt_tokens": 1110, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The teddy bear is brown and has a red bow around its neck. The chair is made of wood and has a red cushion on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.433}, "power_stats": {"power_gpu_soc_mean_watts": 22.367, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 72.433}, "timestamp": "2026-01-30T15:33:15.188220"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3036.279, "latencies_ms": [3036.279], "images_per_second": 0.329, "prompt_tokens": 1100, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain with a bright sun shining in the background.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.6}, "power_stats": {"power_gpu_soc_mean_watts": 23.912, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 74.6}, "timestamp": "2026-01-30T15:33:20.248742"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5446.033, "latencies_ms": [5446.033], "images_per_second": 0.184, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. person: 2\n3. helmet: 1\n4. goggles: 1\n5. sun: 1\n6. rock: 1\n7. snow: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.911}, "power_stats": {"power_gpu_soc_mean_watts": 18.809, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 66.911}, "timestamp": "2026-01-30T15:33:27.720812"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5867.375, "latencies_ms": [5867.375], "images_per_second": 0.17, "prompt_tokens": 1118, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The person on the left is standing closer to the camera than the person on the right. The person on the right is standing in the background, while the person on the left is standing in the foreground. The person on the right is holding a snowboard, while the person on the left is holding a snowboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.918}, "power_stats": {"power_gpu_soc_mean_watts": 18.237, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 70.918}, "timestamp": "2026-01-30T15:33:35.628325"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3644.246, "latencies_ms": [3644.246], "images_per_second": 0.274, "prompt_tokens": 1112, "response_tokens_est": 28, "n_tiles": 1, "output_text": " Two snowboarders stand on a snowy mountain, one holding a snowboard and the other a helmet, ready to ride down the slope.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.289, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 72.1}, "timestamp": "2026-01-30T15:33:41.325984"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4194.784, "latencies_ms": [4194.784], "images_per_second": 0.238, "prompt_tokens": 1110, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features two individuals standing on a snow-covered mountain, with the sun shining brightly in the background. The sky is clear and blue, and the snow is pristine white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.888, "power_cpu_cv_mean_watts": 1.315, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 69.8}, "timestamp": "2026-01-30T15:33:47.547263"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4271.034, "latencies_ms": [4271.034], "images_per_second": 0.234, "prompt_tokens": 1099, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image captures a serene scene of a tree laden with ripe red apples, set against a backdrop of a warm, autumnal forest, with the tree trunk prominently featured in the foreground.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.229}, "power_stats": {"power_gpu_soc_mean_watts": 21.083, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.098, "gpu_utilization_percent_mean": 69.229}, "timestamp": "2026-01-30T15:33:53.861600"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4145.703, "latencies_ms": [4145.703], "images_per_second": 0.241, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " apple: 6, tree: 1, leaf: 1, branch: 1, hole: 1, tree trunk: 1, background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.343}, "power_stats": {"power_gpu_soc_mean_watts": 21.003, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 71.343}, "timestamp": "2026-01-30T15:34:00.023254"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4571.814, "latencies_ms": [4571.814], "images_per_second": 0.219, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The apples are located in the foreground of the image, with the tree trunk positioned in the middle ground. The background is filled with a blurred forest scene, providing a sense of depth and context to the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.053}, "power_stats": {"power_gpu_soc_mean_watts": 20.239, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 67.053}, "timestamp": "2026-01-30T15:34:06.618698"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4398.98, "latencies_ms": [4398.98], "images_per_second": 0.227, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image captures a serene autumn scene in a forest where a tree stands tall with its branches laden with ripe red apples. The warm sunlight filters through the leaves, casting a soft glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.592, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 69.676}, "timestamp": "2026-01-30T15:34:13.043515"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4549.481, "latencies_ms": [4549.481], "images_per_second": 0.22, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image features a tree with a hole in its trunk, surrounded by red apples. The lighting is warm and soft, creating a serene atmosphere. The apples are ripe and appear to be in good condition.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.316}, "power_stats": {"power_gpu_soc_mean_watts": 20.136, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 72.316}, "timestamp": "2026-01-30T15:34:19.638501"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3333.425, "latencies_ms": [3333.425], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two men in white shirts are working in a kitchen, one of them is preparing food in a frying pan.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.267, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.224, "gpu_utilization_percent_mean": 74.333}, "timestamp": "2026-01-30T15:34:24.995345"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4499.677, "latencies_ms": [4499.677], "images_per_second": 0.222, "prompt_tokens": 1113, "response_tokens_est": 41, "n_tiles": 1, "output_text": " 1. Kitchen counter\n2. Food containers\n3. Pots\n4. Pans\n5. Utensils\n6. Food trays\n7. Kitchen equipment\n8. Shelves", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.105}, "power_stats": {"power_gpu_soc_mean_watts": 20.188, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.105}, "timestamp": "2026-01-30T15:34:31.530303"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5654.166, "latencies_ms": [5654.166], "images_per_second": 0.177, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The man in the foreground is closer to the camera than the man in the background. The man in the foreground is on the left side of the image, while the man in the background is on the right side. The man in the foreground is closer to the camera than the man in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.447}, "power_stats": {"power_gpu_soc_mean_watts": 18.443, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.447}, "timestamp": "2026-01-30T15:34:39.217382"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3624.33, "latencies_ms": [3624.33], "images_per_second": 0.276, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two men are working in a kitchen, one is cooking food in a fryer and the other is preparing food in a pan.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.733}, "power_stats": {"power_gpu_soc_mean_watts": 22.074, "power_cpu_cv_mean_watts": 1.147, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 70.733}, "timestamp": "2026-01-30T15:34:44.864126"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3320.91, "latencies_ms": [3320.91], "images_per_second": 0.301, "prompt_tokens": 1109, "response_tokens_est": 22, "n_tiles": 1, "output_text": " The kitchen is well-lit with fluorescent lights, and the stainless steel appliances gleam under the bright lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.963}, "power_stats": {"power_gpu_soc_mean_watts": 23.429, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.239, "gpu_utilization_percent_mean": 76.963}, "timestamp": "2026-01-30T15:34:50.227330"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2690.485, "latencies_ms": [2690.485], "images_per_second": 0.372, "prompt_tokens": 766, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of motorcyclists are gathered on a roadside overlooking the ocean, with a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5179.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.818}, "power_stats": {"power_gpu_soc_mean_watts": 20.562, "power_cpu_cv_mean_watts": 1.092, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 69.818}, "timestamp": "2026-01-30T15:34:54.983918"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2432.908, "latencies_ms": [2432.908], "images_per_second": 0.411, "prompt_tokens": 780, "response_tokens_est": 16, "n_tiles": 1, "output_text": " motorcycle: 10\nperson: 10\nroad: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.5, "power_cpu_cv_mean_watts": 0.941, "power_sys_5v0_mean_watts": 7.822, "gpu_utilization_percent_mean": 72.75}, "timestamp": "2026-01-30T15:34:59.461949"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4226.454, "latencies_ms": [4226.454], "images_per_second": 0.237, "prompt_tokens": 784, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The motorcycles are positioned on the left side of the road, with the nearest motorcycle being closest to the camera. The group of people is standing on the right side of the road, with the furthest person being farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.486}, "power_stats": {"power_gpu_soc_mean_watts": 17.605, "power_cpu_cv_mean_watts": 1.613, "power_sys_5v0_mean_watts": 7.778, "gpu_utilization_percent_mean": 65.486}, "timestamp": "2026-01-30T15:35:05.730133"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2692.792, "latencies_ms": [2692.792], "images_per_second": 0.371, "prompt_tokens": 778, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A group of motorcyclists are gathered on a roadside overlooking the ocean, with a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.364}, "power_stats": {"power_gpu_soc_mean_watts": 21.165, "power_cpu_cv_mean_watts": 1.165, "power_sys_5v0_mean_watts": 7.871, "gpu_utilization_percent_mean": 73.364}, "timestamp": "2026-01-30T15:35:10.459844"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5018.818, "latencies_ms": [5018.818], "images_per_second": 0.199, "prompt_tokens": 776, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The image features a group of motorcyclists gathered on a roadside, with their motorcycles parked in a line. The sky is filled with clouds, and the lighting suggests it is either early morning or late afternoon. The colors of the motorcycles vary, with some being predominantly red, blue, and black.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.738}, "power_stats": {"power_gpu_soc_mean_watts": 16.395, "power_cpu_cv_mean_watts": 1.734, "power_sys_5v0_mean_watts": 7.661, "gpu_utilization_percent_mean": 64.738}, "timestamp": "2026-01-30T15:35:17.498260"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3807.545, "latencies_ms": [3807.545], "images_per_second": 0.263, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A small airplane with the letters \"G-VWZ\" on the tail flies through the sky, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.812}, "power_stats": {"power_gpu_soc_mean_watts": 21.533, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.101, "gpu_utilization_percent_mean": 70.812}, "timestamp": "2026-01-30T15:35:23.359702"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5406.725, "latencies_ms": [5406.725], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. smoke: 1\n3. clouds: 2\n4. sky: 1\n5. tail: 1\n6. propeller: 1\n7. wing: 1\n8. fuselage: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.289}, "power_stats": {"power_gpu_soc_mean_watts": 18.809, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 68.289}, "timestamp": "2026-01-30T15:35:30.777818"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3822.308, "latencies_ms": [3822.308], "images_per_second": 0.262, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The airplane is in the foreground, flying from left to right, while the clouds are in the background. The airplane is flying higher than the clouds.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.312}, "power_stats": {"power_gpu_soc_mean_watts": 21.758, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 73.312}, "timestamp": "2026-01-30T15:35:36.612257"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3000.618, "latencies_ms": [3000.618], "images_per_second": 0.333, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A small airplane is flying in the sky, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.88}, "power_stats": {"power_gpu_soc_mean_watts": 24.117, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.285, "gpu_utilization_percent_mean": 77.88}, "timestamp": "2026-01-30T15:35:41.643361"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4201.125, "latencies_ms": [4201.125], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the dark clouds and the lighter sky. The airplane is flying through the air, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.96, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T15:35:47.875718"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3439.284, "latencies_ms": [3439.284], "images_per_second": 0.291, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " In the image, a group of sheep are standing on a grassy hill, with a lake and mountains in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.836, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.192, "gpu_utilization_percent_mean": 72.357}, "timestamp": "2026-01-30T15:35:53.364772"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5454.936, "latencies_ms": [5454.936], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. sheep: 4\n2. grass: 1\n3. rocks: 1\n4. water: 1\n5. mountains: 2\n6. sky: 1\n7. clouds: 1\n8. lake: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.391}, "power_stats": {"power_gpu_soc_mean_watts": 18.551, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 69.391}, "timestamp": "2026-01-30T15:36:00.876257"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4357.737, "latencies_ms": [4357.737], "images_per_second": 0.229, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sheep are positioned in the foreground of the image, with the mountains in the background. The sheep are standing on a grassy hill, with the lake visible to the right of the image.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.667}, "power_stats": {"power_gpu_soc_mean_watts": 20.521, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 68.667}, "timestamp": "2026-01-30T15:36:07.253444"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3690.435, "latencies_ms": [3690.435], "images_per_second": 0.271, "prompt_tokens": 1111, "response_tokens_est": 27, "n_tiles": 1, "output_text": " In this picturesque landscape, a group of sheep are grazing on a grassy hillside, with a serene lake and majestic mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.733}, "power_stats": {"power_gpu_soc_mean_watts": 22.142, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 74.733}, "timestamp": "2026-01-30T15:36:12.966321"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4137.546, "latencies_ms": [4137.546], "images_per_second": 0.242, "prompt_tokens": 1109, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image features a group of sheep standing on a grassy hill, with the mountains in the background. The sky is clear and blue, and the sheep are white with black faces.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.471}, "power_stats": {"power_gpu_soc_mean_watts": 21.349, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 70.471}, "timestamp": "2026-01-30T15:36:19.125905"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3049.468, "latencies_ms": [3049.468], "images_per_second": 0.328, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A woman in a wheelchair is holding a tennis racket and looking at the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.92}, "power_stats": {"power_gpu_soc_mean_watts": 23.75, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 72.92}, "timestamp": "2026-01-30T15:36:24.214410"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6054.359, "latencies_ms": [6054.359], "images_per_second": 0.165, "prompt_tokens": 1113, "response_tokens_est": 67, "n_tiles": 1, "output_text": " 1. woman: 1\n2. wheelchair: 1\n3. racket: 1\n4. woman's hand: 1\n5. woman's arm: 1\n6. woman's leg: 1\n7. woman's foot: 1\n8. woman's knee: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.2, "ram_available_mb": 48843.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.98}, "power_stats": {"power_gpu_soc_mean_watts": 17.916, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 7.953, "gpu_utilization_percent_mean": 67.98}, "timestamp": "2026-01-30T15:36:32.294136"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3828.852, "latencies_ms": [3828.852], "images_per_second": 0.261, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The woman in the wheelchair is in the foreground, holding a tennis racket. The other woman is in the background, sitting in a wheelchair.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.156}, "power_stats": {"power_gpu_soc_mean_watts": 21.533, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 70.156}, "timestamp": "2026-01-30T15:36:38.164716"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3813.326, "latencies_ms": [3813.326], "images_per_second": 0.262, "prompt_tokens": 1111, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A woman in a wheelchair is holding a tennis racket and looking at the camera. There are other people in the background, also in wheelchairs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.656}, "power_stats": {"power_gpu_soc_mean_watts": 21.845, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 70.656}, "timestamp": "2026-01-30T15:36:43.990079"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4075.136, "latencies_ms": [4075.136], "images_per_second": 0.245, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a gymnasium with a white wall in the background. The lighting is natural, coming from the windows on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.294}, "power_stats": {"power_gpu_soc_mean_watts": 21.149, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 68.294}, "timestamp": "2026-01-30T15:36:50.097872"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4126.825, "latencies_ms": [4126.825], "images_per_second": 0.242, "prompt_tokens": 1432, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A young child wearing a black helmet and a pink plaid shirt is sitting on a brown leather saddle with a purple blanket underneath.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.147}, "power_stats": {"power_gpu_soc_mean_watts": 24.609, "power_cpu_cv_mean_watts": 1.13, "power_sys_5v0_mean_watts": 8.523, "gpu_utilization_percent_mean": 76.147}, "timestamp": "2026-01-30T15:36:56.267926"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6272.552, "latencies_ms": [6272.552], "images_per_second": 0.159, "prompt_tokens": 1446, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. child: 1\n2. helmet: 1\n3. plaid shirt: 1\n4. jeans: 1\n5. brown saddle: 1\n6. purple blanket: 1\n7. tree: 1\n8. horse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.962}, "power_stats": {"power_gpu_soc_mean_watts": 20.569, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 8.246, "gpu_utilization_percent_mean": 71.962}, "timestamp": "2026-01-30T15:37:04.583885"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5995.938, "latencies_ms": [5995.938], "images_per_second": 0.167, "prompt_tokens": 1450, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The child is sitting on the saddle, which is placed on the purple blanket. The saddle is positioned in the foreground, while the child is in the background. The child is sitting to the left of the saddle, and the saddle is to the right of the child.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.02}, "power_stats": {"power_gpu_soc_mean_watts": 20.725, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 71.02}, "timestamp": "2026-01-30T15:37:12.609752"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4333.993, "latencies_ms": [4333.993], "images_per_second": 0.231, "prompt_tokens": 1444, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A young girl wearing a black helmet and a pink plaid shirt is sitting on a brown saddle in a field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.0, "ram_available_mb": 48844.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.083}, "power_stats": {"power_gpu_soc_mean_watts": 24.21, "power_cpu_cv_mean_watts": 1.156, "power_sys_5v0_mean_watts": 8.449, "gpu_utilization_percent_mean": 75.083}, "timestamp": "2026-01-30T15:37:18.990226"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4952.129, "latencies_ms": [4952.129], "images_per_second": 0.202, "prompt_tokens": 1442, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a young girl wearing a black helmet and a pink plaid shirt, sitting on a brown leather saddle. The background is filled with lush green trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.171}, "power_stats": {"power_gpu_soc_mean_watts": 23.018, "power_cpu_cv_mean_watts": 1.318, "power_sys_5v0_mean_watts": 8.378, "gpu_utilization_percent_mean": 73.171}, "timestamp": "2026-01-30T15:37:25.974299"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4082.254, "latencies_ms": [4082.254], "images_per_second": 0.245, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " In the image, two surfers are riding the waves on their surfboards, with one of them being a woman, and the location is Raglan, New Zealand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.088}, "power_stats": {"power_gpu_soc_mean_watts": 21.032, "power_cpu_cv_mean_watts": 1.283, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 71.088}, "timestamp": "2026-01-30T15:37:32.098549"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5706.183, "latencies_ms": [5706.183], "images_per_second": 0.175, "prompt_tokens": 1113, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Surfer: 2\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Bird: 1\n6. Photographer: 1\n7. Photograph: 1\n8. Frame: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.915}, "power_stats": {"power_gpu_soc_mean_watts": 18.427, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 68.915}, "timestamp": "2026-01-30T15:37:39.822240"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6334.846, "latencies_ms": [6334.846], "images_per_second": 0.158, "prompt_tokens": 1117, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The surfer on the left is closer to the camera than the surfer on the right. The surfer on the left is in the foreground, while the surfer on the right is in the background. The surfer on the left is riding a wave that is closer to the camera than the wave that the surfer on the right is riding.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.623}, "power_stats": {"power_gpu_soc_mean_watts": 17.564, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 68.623}, "timestamp": "2026-01-30T15:37:48.190909"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3483.256, "latencies_ms": [3483.256], "images_per_second": 0.287, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " Two surfers are riding the waves in the ocean, one is closer to the camera and the other is farther away.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.5, "ram_available_mb": 48843.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.589, "power_cpu_cv_mean_watts": 1.091, "power_sys_5v0_mean_watts": 8.162, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T15:37:53.724960"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5080.075, "latencies_ms": [5080.075], "images_per_second": 0.197, "prompt_tokens": 1109, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a dynamic scene of two surfers riding a wave in the ocean, with the water appearing deep blue and the sky not visible in the frame. The surfers are wearing wetsuits, and the image is framed with a black border.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.442}, "power_stats": {"power_gpu_soc_mean_watts": 19.321, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 68.442}, "timestamp": "2026-01-30T15:38:00.820307"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3869.831, "latencies_ms": [3869.831], "images_per_second": 0.258, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image depicts a cozy kitchen with a window that has frosted glass, a wooden cabinet, and a small table with a potted plant on it.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.771, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 73.031}, "timestamp": "2026-01-30T15:38:06.746575"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5417.206, "latencies_ms": [5417.206], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. window: 1\n2. shelf: 2\n3. cabinet: 1\n4. stove: 1\n5. pot: 1\n6. plant: 1\n7. shelf: 1\n8. cupboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.63}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 70.63}, "timestamp": "2026-01-30T15:38:14.178157"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4793.723, "latencies_ms": [4793.723], "images_per_second": 0.209, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The window is located in the center of the image, with the wooden cabinet to the right and the stove to the left. The plants are placed in front of the window, while the books are on the shelf above the cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.025}, "power_stats": {"power_gpu_soc_mean_watts": 19.859, "power_cpu_cv_mean_watts": 1.481, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 69.025}, "timestamp": "2026-01-30T15:38:20.988346"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6352.213, "latencies_ms": [6352.213], "images_per_second": 0.157, "prompt_tokens": 1111, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image captures a cozy kitchen scene, bathed in soft light filtering through a window adorned with a colorful paper decoration. The room is filled with an array of objects, each telling a story of its own. Shelves brimming with jars and containers, a stove waiting for its next culinary adventure, and a wooden cabinet that seems to hold secrets of its own.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.352}, "power_stats": {"power_gpu_soc_mean_watts": 17.705, "power_cpu_cv_mean_watts": 1.757, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 69.352}, "timestamp": "2026-01-30T15:38:29.366763"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3223.261, "latencies_ms": [3223.261], "images_per_second": 0.31, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The room is dimly lit with a warm yellow light, and the window is covered with frost.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.0, "ram_available_mb": 48842.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13999.2, "ram_available_mb": 48841.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.385}, "power_stats": {"power_gpu_soc_mean_watts": 23.467, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 74.385}, "timestamp": "2026-01-30T15:38:34.601212"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4735.152, "latencies_ms": [4735.152], "images_per_second": 0.211, "prompt_tokens": 1099, "response_tokens_est": 46, "n_tiles": 1, "output_text": " In the image, a vibrant red background serves as a backdrop for a collection of objects, including a large pineapple, a potted plant, a plate of oranges, and a red cup, all arranged in a visually appealing manner.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13998.5, "ram_available_mb": 48842.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.45}, "power_stats": {"power_gpu_soc_mean_watts": 19.927, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 70.45}, "timestamp": "2026-01-30T15:38:41.376628"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3949.598, "latencies_ms": [3949.598], "images_per_second": 0.253, "prompt_tokens": 1113, "response_tokens_est": 32, "n_tiles": 1, "output_text": " pineapple: 1, red cups: 5, oranges: 4, red pot: 1, incense: 1, red plate: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.487, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 70.273}, "timestamp": "2026-01-30T15:38:47.345437"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4864.936, "latencies_ms": [4864.936], "images_per_second": 0.206, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The pineapple is positioned to the left of the incense holder, with the oranges placed on the right side of the incense holder. The red cups are arranged in a row in the foreground, with the incense holder and oranges positioned in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.804, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 69.244}, "timestamp": "2026-01-30T15:38:54.253723"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4449.188, "latencies_ms": [4449.188], "images_per_second": 0.225, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In this image, we can see a table with some objects like a pineapple, a plate with oranges, some cups and a pot. In the background, we can see a wall with some text.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.216}, "power_stats": {"power_gpu_soc_mean_watts": 20.409, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 70.216}, "timestamp": "2026-01-30T15:39:00.735381"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6655.842, "latencies_ms": [6655.842], "images_per_second": 0.15, "prompt_tokens": 1109, "response_tokens_est": 76, "n_tiles": 1, "output_text": " The image features a vibrant display of red and orange fruits, with a pineapple and a plate of oranges prominently displayed. The lighting is warm and inviting, casting a soft glow on the objects. The materials used in the image are a mix of natural and man-made elements, with the fruits and pineapples being organic, and the red and white ceramic cups being man-made.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.732}, "power_stats": {"power_gpu_soc_mean_watts": 17.231, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 7.925, "gpu_utilization_percent_mean": 69.732}, "timestamp": "2026-01-30T15:39:09.415609"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3279.994, "latencies_ms": [3279.994], "images_per_second": 0.305, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man with a beard and glasses is eating a large piece of fried food with fries and dipping sauce.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 13998.2, "ram_available_mb": 48842.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.281, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 75.37}, "timestamp": "2026-01-30T15:39:14.742962"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5567.921, "latencies_ms": [5567.921], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. plate: 1\n2. fries: 1\n3. sandwich: 1\n4. cup: 1\n5. man: 1\n6. clock: 1\n7. wall: 1\n8. table: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.021}, "power_stats": {"power_gpu_soc_mean_watts": 18.297, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 67.021}, "timestamp": "2026-01-30T15:39:22.351736"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3915.679, "latencies_ms": [3915.679], "images_per_second": 0.255, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The man is in the foreground, holding a plate of food. The fries are in the middle ground, and the background shows a restaurant with other people.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13996.6, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.657, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.114, "gpu_utilization_percent_mean": 68.125}, "timestamp": "2026-01-30T15:39:28.320409"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3692.968, "latencies_ms": [3692.968], "images_per_second": 0.271, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A man is eating a large piece of fried food with fries and dipping sauce. He is in a restaurant with other people in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13996.6, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.223, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 70.8}, "timestamp": "2026-01-30T15:39:34.028737"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4200.715, "latencies_ms": [4200.715], "images_per_second": 0.238, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere. The lighting is bright and natural, illuminating the scene and highlighting the colors of the food and the man's attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.914}, "power_stats": {"power_gpu_soc_mean_watts": 21.163, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 70.914}, "timestamp": "2026-01-30T15:39:40.273486"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3938.354, "latencies_ms": [3938.354], "images_per_second": 0.254, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image captures a rainy day scene from inside a building, where a person is seen walking with an umbrella, and a bike rack is filled with bicycles outside.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.438}, "power_stats": {"power_gpu_soc_mean_watts": 21.62, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 70.438}, "timestamp": "2026-01-30T15:39:46.242931"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5890.902, "latencies_ms": [5890.902], "images_per_second": 0.17, "prompt_tokens": 1114, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. Bike: 5\n2. Bike: 2\n3. Bike: 1\n4. Bike: 1\n5. Bike: 1\n6. Bike: 1\n7. Bike: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.98}, "power_stats": {"power_gpu_soc_mean_watts": 18.173, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.963, "gpu_utilization_percent_mean": 69.98}, "timestamp": "2026-01-30T15:39:54.147733"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4219.118, "latencies_ms": [4219.118], "images_per_second": 0.237, "prompt_tokens": 1118, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The bicycle is positioned in the foreground, while the person is in the background. The person is walking on the sidewalk, and the bicycle is parked on the side of the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.657}, "power_stats": {"power_gpu_soc_mean_watts": 20.818, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 70.657}, "timestamp": "2026-01-30T15:40:00.394857"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3596.648, "latencies_ms": [3596.648], "images_per_second": 0.278, "prompt_tokens": 1112, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image captures a rainy day at a modern building complex, where people are seen walking with umbrellas and bicycles are parked outside.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.931}, "power_stats": {"power_gpu_soc_mean_watts": 22.504, "power_cpu_cv_mean_watts": 1.16, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 73.931}, "timestamp": "2026-01-30T15:40:06.000461"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5343.105, "latencies_ms": [5343.105], "images_per_second": 0.187, "prompt_tokens": 1110, "response_tokens_est": 56, "n_tiles": 1, "output_text": " The image is taken from inside a building, looking out at a rainy day. The sky is overcast, and the ground is wet, reflecting the gray and white tones of the scene. The buildings are made of glass and metal, with a mix of gray and white colors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.467}, "power_stats": {"power_gpu_soc_mean_watts": 19.023, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 69.467}, "timestamp": "2026-01-30T15:40:13.376197"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4728.074, "latencies_ms": [4728.074], "images_per_second": 0.212, "prompt_tokens": 1099, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image features a close-up view of a plate with a creamy, yellow-colored substance, possibly cheese, spread over a piece of bread, with a fork placed on the plate, and a knife in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.282}, "power_stats": {"power_gpu_soc_mean_watts": 19.864, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 67.282}, "timestamp": "2026-01-30T15:40:20.133889"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2293.214, "latencies_ms": [2293.214], "images_per_second": 0.436, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " fork: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.611}, "power_stats": {"power_gpu_soc_mean_watts": 24.996, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.221, "gpu_utilization_percent_mean": 81.611}, "timestamp": "2026-01-30T15:40:24.438744"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3847.371, "latencies_ms": [3847.371], "images_per_second": 0.26, "prompt_tokens": 1117, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The fork is located in the background, behind the plate of food. The plate is in the foreground, and the food is on top of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.125}, "power_stats": {"power_gpu_soc_mean_watts": 21.606, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 69.125}, "timestamp": "2026-01-30T15:40:30.299102"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3011.666, "latencies_ms": [3011.666], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A close up of a plate of food with a fork and knife on the side.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.6}, "power_stats": {"power_gpu_soc_mean_watts": 24.15, "power_cpu_cv_mean_watts": 1.009, "power_sys_5v0_mean_watts": 8.269, "gpu_utilization_percent_mean": 75.6}, "timestamp": "2026-01-30T15:40:35.342916"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3897.29, "latencies_ms": [3897.29], "images_per_second": 0.257, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image features a close-up of a plate of food with a creamy yellow sauce, a fork and knife on the side, and a dark background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.781}, "power_stats": {"power_gpu_soc_mean_watts": 21.645, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.148, "gpu_utilization_percent_mean": 68.781}, "timestamp": "2026-01-30T15:40:41.294011"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3449.132, "latencies_ms": [3449.132], "images_per_second": 0.29, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A silver laptop sits open on a desk with a green leaf wallpaper, a black computer mouse, and a black keyboard.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.571}, "power_stats": {"power_gpu_soc_mean_watts": 22.891, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.2, "gpu_utilization_percent_mean": 71.571}, "timestamp": "2026-01-30T15:40:46.796931"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2317.228, "latencies_ms": [2317.228], "images_per_second": 0.432, "prompt_tokens": 1113, "response_tokens_est": 5, "n_tiles": 1, "output_text": " computer monitor: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.579}, "power_stats": {"power_gpu_soc_mean_watts": 25.386, "power_cpu_cv_mean_watts": 0.611, "power_sys_5v0_mean_watts": 8.319, "gpu_utilization_percent_mean": 83.579}, "timestamp": "2026-01-30T15:40:51.150877"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4634.133, "latencies_ms": [4634.133], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The laptop is in the foreground, to the right of the mouse, and in front of the computer monitor. The mouse is to the right of the laptop, and the computer monitor is to the left of the laptop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.323, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 70.026}, "timestamp": "2026-01-30T15:40:57.807650"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2863.161, "latencies_ms": [2863.161], "images_per_second": 0.349, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A silver laptop sits on a desk with a computer monitor and keyboard.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.405, "power_cpu_cv_mean_watts": 0.835, "power_sys_5v0_mean_watts": 8.308, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T15:41:02.701367"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3432.204, "latencies_ms": [3432.204], "images_per_second": 0.291, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The laptop is silver and the mouse is black. The room is well lit and the laptop is on a white desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.071}, "power_stats": {"power_gpu_soc_mean_watts": 23.178, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 71.071}, "timestamp": "2026-01-30T15:41:08.158913"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4061.784, "latencies_ms": [4061.784], "images_per_second": 0.246, "prompt_tokens": 1099, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A young girl in a green shirt is sitting on a bed in a room with orange walls, a lamp on a table, and a box of toys on the floor.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.647}, "power_stats": {"power_gpu_soc_mean_watts": 21.114, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 71.647}, "timestamp": "2026-01-30T15:41:14.280721"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5352.262, "latencies_ms": [5352.262], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 1\n2. girl: 1\n3. lamp: 1\n4. books: 1\n5. table: 1\n6. floor: 1\n7. wall: 1\n8. curtain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.444}, "power_stats": {"power_gpu_soc_mean_watts": 18.898, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 70.444}, "timestamp": "2026-01-30T15:41:21.667131"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4681.202, "latencies_ms": [4681.202], "images_per_second": 0.214, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The bed is positioned to the left of the room, with the girl sitting on it. The lamp is placed on the right side of the bed, and the books are scattered on the floor in front of the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.487}, "power_stats": {"power_gpu_soc_mean_watts": 19.926, "power_cpu_cv_mean_watts": 1.499, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 69.487}, "timestamp": "2026-01-30T15:41:28.382629"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3363.167, "latencies_ms": [3363.167], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A young girl is sitting on a bed in a bedroom. The room has orange walls and a wooden headboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.12, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.225, "gpu_utilization_percent_mean": 75.5}, "timestamp": "2026-01-30T15:41:33.784893"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3161.879, "latencies_ms": [3161.879], "images_per_second": 0.316, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The room is painted in a warm orange color, and the floor is made of stone tiles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14001.3, "ram_available_mb": 48839.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.769}, "power_stats": {"power_gpu_soc_mean_watts": 23.594, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 74.769}, "timestamp": "2026-01-30T15:41:38.973367"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4879.658, "latencies_ms": [4879.658], "images_per_second": 0.205, "prompt_tokens": 1099, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter in the midst of a powerful swing, the catcher poised in anticipation behind him, and the umpire attentively observing the play from his position behind the catcher.", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 14001.3, "ram_available_mb": 48839.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.293}, "power_stats": {"power_gpu_soc_mean_watts": 19.638, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.293}, "timestamp": "2026-01-30T15:41:45.889870"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5571.322, "latencies_ms": [5571.322], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. batter: 1\n2. catcher: 1\n3. umpire: 1\n4. pitcher: 1\n5. baseball: 1\n6. baseball field: 1\n7. grass: 1\n8. dirt: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14001.8, "ram_available_mb": 48839.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.681}, "power_stats": {"power_gpu_soc_mean_watts": 18.714, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.681}, "timestamp": "2026-01-30T15:41:53.509424"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4128.749, "latencies_ms": [4128.749], "images_per_second": 0.242, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire in the background. The batter is closer to the camera than the catcher and umpire.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14001.8, "ram_available_mb": 48839.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.6}, "power_stats": {"power_gpu_soc_mean_watts": 21.276, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.138, "gpu_utilization_percent_mean": 72.6}, "timestamp": "2026-01-30T15:41:59.663231"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5793.29, "latencies_ms": [5793.29], "images_per_second": 0.173, "prompt_tokens": 1111, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image captures a dynamic moment in a baseball game, with the batter poised to swing at the incoming pitch, the catcher crouched behind him, and the umpire attentively observing the play. The lush green field stretches out behind them, providing a stark contrast to the brown dirt of the infield.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.714}, "power_stats": {"power_gpu_soc_mean_watts": 18.326, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 69.714}, "timestamp": "2026-01-30T15:42:07.515345"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4763.058, "latencies_ms": [4763.058], "images_per_second": 0.21, "prompt_tokens": 1109, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the lush green grass contrasting against the brown dirt of the field. The sun casts a warm glow on the scene, illuminating the players and their actions with a soft light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.275}, "power_stats": {"power_gpu_soc_mean_watts": 19.815, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-30T15:42:14.298291"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2635.893, "latencies_ms": [2635.893], "images_per_second": 0.379, "prompt_tokens": 1099, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A cat is eating a bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.455}, "power_stats": {"power_gpu_soc_mean_watts": 25.146, "power_cpu_cv_mean_watts": 0.837, "power_sys_5v0_mean_watts": 8.364, "gpu_utilization_percent_mean": 78.455}, "timestamp": "2026-01-30T15:42:18.985183"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4618.838, "latencies_ms": [4618.838], "images_per_second": 0.217, "prompt_tokens": 1113, "response_tokens_est": 44, "n_tiles": 1, "output_text": " cat: 1, bird: 1, bird's head: 1, bird's body: 1, bird's legs: 1, bird's feet: 1, bird's beak: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.205}, "power_stats": {"power_gpu_soc_mean_watts": 20.152, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 71.205}, "timestamp": "2026-01-30T15:42:25.637770"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4554.754, "latencies_ms": [4554.754], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The bird is in the foreground, with the cat's head in the middle ground. The cat's body is partially obscured by the bird, and the bird is positioned to the left of the cat's head.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.22, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 69.237}, "timestamp": "2026-01-30T15:42:32.229753"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2669.577, "latencies_ms": [2669.577], "images_per_second": 0.375, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A cat is eating a bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.682}, "power_stats": {"power_gpu_soc_mean_watts": 24.857, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 8.3, "gpu_utilization_percent_mean": 76.682}, "timestamp": "2026-01-30T15:42:36.958658"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4923.922, "latencies_ms": [4923.922], "images_per_second": 0.203, "prompt_tokens": 1109, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a close-up of a cat with a bird in its mouth, with the cat's fur being white and brown, and the bird being red and black. The lighting is natural, and the cat is on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.214}, "power_stats": {"power_gpu_soc_mean_watts": 19.564, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-30T15:42:43.921596"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3633.671, "latencies_ms": [3633.671], "images_per_second": 0.275, "prompt_tokens": 1432, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a sandwich with lettuce, tomato, and cheese in their hand.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.8}, "power_stats": {"power_gpu_soc_mean_watts": 25.476, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 8.607, "gpu_utilization_percent_mean": 81.8}, "timestamp": "2026-01-30T15:42:49.576098"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5995.113, "latencies_ms": [5995.113], "images_per_second": 0.167, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. hand: 1\n2. sandwich: 1\n3. bread: 1\n4. tomato: 1\n5. lettuce: 1\n6. cheese: 1\n7. sauce: 1\n8. stove: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.8}, "power_stats": {"power_gpu_soc_mean_watts": 21.066, "power_cpu_cv_mean_watts": 1.521, "power_sys_5v0_mean_watts": 8.284, "gpu_utilization_percent_mean": 69.8}, "timestamp": "2026-01-30T15:42:57.599901"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4606.017, "latencies_ms": [4606.017], "images_per_second": 0.217, "prompt_tokens": 1450, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The sandwich is held in the left hand, with the right hand holding the plate. The sandwich is in the foreground, while the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.316}, "power_stats": {"power_gpu_soc_mean_watts": 23.367, "power_cpu_cv_mean_watts": 1.211, "power_sys_5v0_mean_watts": 8.395, "gpu_utilization_percent_mean": 76.316}, "timestamp": "2026-01-30T15:43:04.241180"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3914.173, "latencies_ms": [3914.173], "images_per_second": 0.255, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A person is holding a sandwich with lettuce and tomato on it. The sandwich is on a white plate.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.719}, "power_stats": {"power_gpu_soc_mean_watts": 25.371, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.526, "gpu_utilization_percent_mean": 77.719}, "timestamp": "2026-01-30T15:43:10.195706"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3617.3, "latencies_ms": [3617.3], "images_per_second": 0.276, "prompt_tokens": 1442, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The sandwich is on a white plate and the background is a white countertop.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.233}, "power_stats": {"power_gpu_soc_mean_watts": 26.01, "power_cpu_cv_mean_watts": 0.88, "power_sys_5v0_mean_watts": 8.566, "gpu_utilization_percent_mean": 77.233}, "timestamp": "2026-01-30T15:43:15.844299"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3594.796, "latencies_ms": [3594.796], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " Two girls are sitting on the back of a boat, one of them is wearing a hat and they are looking at the water.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.208, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.146, "gpu_utilization_percent_mean": 74.1}, "timestamp": "2026-01-30T15:43:21.478104"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5365.068, "latencies_ms": [5365.068], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. girl: 2\n2. hat: 1\n3. girl: 2\n4. girl: 1\n5. girl: 1\n6. girl: 1\n7. girl: 1\n8. girl: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.622}, "power_stats": {"power_gpu_soc_mean_watts": 18.97, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 69.622}, "timestamp": "2026-01-30T15:43:28.864852"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5028.534, "latencies_ms": [5028.534], "images_per_second": 0.199, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The girl in the white shirt is sitting on the left side of the boat, while the girl in the pink shirt is sitting on the right side. The girl in the white shirt is closer to the camera than the girl in the pink shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14001.8, "ram_available_mb": 48839.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.762}, "power_stats": {"power_gpu_soc_mean_watts": 19.228, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 70.762}, "timestamp": "2026-01-30T15:43:35.910196"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3092.633, "latencies_ms": [3092.633], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Two girls are sitting on the back of a boat, looking out at the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.8, "ram_available_mb": 48839.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14001.6, "ram_available_mb": 48839.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.6}, "power_stats": {"power_gpu_soc_mean_watts": 23.636, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 76.6}, "timestamp": "2026-01-30T15:43:41.027738"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3902.749, "latencies_ms": [3902.749], "images_per_second": 0.256, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image features a boat with a blue ocean in the background, and the sky is clear. The boat is white and has a gray cushion on it.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14001.6, "ram_available_mb": 48839.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14001.6, "ram_available_mb": 48839.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.625}, "power_stats": {"power_gpu_soc_mean_watts": 21.657, "power_cpu_cv_mean_watts": 1.226, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 72.625}, "timestamp": "2026-01-30T15:43:46.945969"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3065.49, "latencies_ms": [3065.49], "images_per_second": 0.326, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A sheep with white wool stands in a grassy field with a stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 14001.6, "ram_available_mb": 48839.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.96}, "power_stats": {"power_gpu_soc_mean_watts": 24.052, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.252, "gpu_utilization_percent_mean": 75.96}, "timestamp": "2026-01-30T15:43:52.072805"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2286.398, "latencies_ms": [2286.398], "images_per_second": 0.437, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " sheep: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 14002.0, "ram_available_mb": 48838.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.632}, "power_stats": {"power_gpu_soc_mean_watts": 24.945, "power_cpu_cv_mean_watts": 0.611, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 84.632}, "timestamp": "2026-01-30T15:43:56.409264"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3855.416, "latencies_ms": [3855.416], "images_per_second": 0.259, "prompt_tokens": 1117, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The sheep is located in the foreground of the image, standing on a patch of grass. The stone wall is situated in the background, behind the sheep.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.9, "ram_available_mb": 48839.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.375}, "power_stats": {"power_gpu_soc_mean_watts": 21.929, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.149, "gpu_utilization_percent_mean": 70.375}, "timestamp": "2026-01-30T15:44:02.281961"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2923.024, "latencies_ms": [2923.024], "images_per_second": 0.342, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A sheep stands in a grassy field with a stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.1, "ram_available_mb": 48839.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.375}, "power_stats": {"power_gpu_soc_mean_watts": 24.204, "power_cpu_cv_mean_watts": 0.9, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 76.375}, "timestamp": "2026-01-30T15:44:07.251202"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3019.741, "latencies_ms": [3019.741], "images_per_second": 0.331, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The sheep is white, the grass is green, and the wall is gray.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.36}, "power_stats": {"power_gpu_soc_mean_watts": 23.621, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.193, "gpu_utilization_percent_mean": 74.36}, "timestamp": "2026-01-30T15:44:12.295807"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3970.439, "latencies_ms": [3970.439], "images_per_second": 0.252, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A man in a white shirt and plaid shorts is standing on the side of a truck, looking at a large cylindrical object that is being transported on the truck.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.03}, "power_stats": {"power_gpu_soc_mean_watts": 21.595, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.121, "gpu_utilization_percent_mean": 70.03}, "timestamp": "2026-01-30T15:44:18.329988"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5924.598, "latencies_ms": [5924.598], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. truck: 1\n2. man: 2\n3. man on truck: 1\n4. man on ground: 1\n5. container: 1\n6. pipe: 1\n7. container on truck: 1\n8. container on ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.429}, "power_stats": {"power_gpu_soc_mean_watts": 18.075, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.959, "gpu_utilization_percent_mean": 70.429}, "timestamp": "2026-01-30T15:44:26.269065"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4876.698, "latencies_ms": [4876.698], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The man in the white shirt is standing in the foreground, while the man in the blue shirt is standing on the truck in the background. The man in the white shirt is closer to the camera than the man in the blue shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.493, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 70.244}, "timestamp": "2026-01-30T15:44:33.191321"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4445.086, "latencies_ms": [4445.086], "images_per_second": 0.225, "prompt_tokens": 1111, "response_tokens_est": 40, "n_tiles": 1, "output_text": " A man in a white shirt and plaid shorts is standing next to a truck with a large cylindrical object on it. The truck is parked in a parking lot, surrounded by trees and other buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.973}, "power_stats": {"power_gpu_soc_mean_watts": 20.377, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.973}, "timestamp": "2026-01-30T15:44:39.673142"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4283.1, "latencies_ms": [4283.1], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image is taken in a cloudy day with a blue sky and trees in the background. The truck is black and yellow, and the man is wearing a white shirt and blue shorts.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.934, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 67.8}, "timestamp": "2026-01-30T15:44:45.975227"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3421.396, "latencies_ms": [3421.396], "images_per_second": 0.292, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of giraffes is walking in a line across a dirt path, with a pond and trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.806, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.164, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-30T15:44:51.430376"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5419.414, "latencies_ms": [5419.414], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. giraffe: 4\n2. giraffe: 4\n3. giraffe: 4\n4. giraffe: 4\n5. giraffe: 4\n6. giraffe: 4\n7. giraffe: 4\n8. giraffe: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.6}, "power_stats": {"power_gpu_soc_mean_watts": 18.781, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 67.6}, "timestamp": "2026-01-30T15:44:58.875030"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4270.981, "latencies_ms": [4270.981], "images_per_second": 0.234, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The giraffes are positioned in the foreground of the image, with the pond and trees in the background. The giraffes are walking towards the pond, which is located to the left of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.029}, "power_stats": {"power_gpu_soc_mean_watts": 21.093, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.103, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T15:45:05.165199"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3554.74, "latencies_ms": [3554.74], "images_per_second": 0.281, "prompt_tokens": 1111, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A group of giraffes are walking in a line through a dirt path near a pond, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.435, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.154, "gpu_utilization_percent_mean": 72.552}, "timestamp": "2026-01-30T15:45:10.748168"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3121.483, "latencies_ms": [3121.483], "images_per_second": 0.32, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The giraffes are brown and white, the trees are green, and the sky is cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.439, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 75.885}, "timestamp": "2026-01-30T15:45:15.906071"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3356.769, "latencies_ms": [3356.769], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A pizza with various toppings is on a plate, with a glass of beer and a glass of water nearby.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13996.9, "ram_available_mb": 48844.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.963}, "power_stats": {"power_gpu_soc_mean_watts": 23.384, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.238, "gpu_utilization_percent_mean": 73.963}, "timestamp": "2026-01-30T15:45:21.288867"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3824.359, "latencies_ms": [3824.359], "images_per_second": 0.261, "prompt_tokens": 1113, "response_tokens_est": 30, "n_tiles": 1, "output_text": " pizza: 1, glass: 2, wine: 1, tablecloth: 1, chair: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.2, "ram_available_mb": 48844.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.219}, "power_stats": {"power_gpu_soc_mean_watts": 21.67, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.12, "gpu_utilization_percent_mean": 71.219}, "timestamp": "2026-01-30T15:45:27.155204"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4217.126, "latencies_ms": [4217.126], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The pizza is positioned in the foreground, with the glasses of beer placed behind it. The glasses of beer are located in the middle ground, with the table and chairs in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.114}, "power_stats": {"power_gpu_soc_mean_watts": 21.128, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.123, "gpu_utilization_percent_mean": 71.114}, "timestamp": "2026-01-30T15:45:33.422590"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3579.684, "latencies_ms": [3579.684], "images_per_second": 0.279, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " In a cozy restaurant, a delicious pizza with various toppings is served on a white plate, accompanied by two glasses of beer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.598, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 72.552}, "timestamp": "2026-01-30T15:45:39.024186"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6431.486, "latencies_ms": [6431.486], "images_per_second": 0.155, "prompt_tokens": 1109, "response_tokens_est": 73, "n_tiles": 1, "output_text": " The image features a pizza with a variety of toppings, including mushrooms, pineapple, and ham, placed on a white plate. The pizza is placed on a table covered with a blue tablecloth, and there are two glasses of beer in the background. The lighting in the room is warm, and the overall atmosphere appears to be a cozy and inviting dining experience.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.352}, "power_stats": {"power_gpu_soc_mean_watts": 17.528, "power_cpu_cv_mean_watts": 1.727, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 67.352}, "timestamp": "2026-01-30T15:45:47.495753"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3020.872, "latencies_ms": [3020.872], "images_per_second": 0.331, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white cat is drinking water from a faucet in a bathroom sink.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.042}, "power_stats": {"power_gpu_soc_mean_watts": 23.754, "power_cpu_cv_mean_watts": 0.834, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 75.042}, "timestamp": "2026-01-30T15:45:52.549324"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5770.823, "latencies_ms": [5770.823], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. black cat: 1\n2. sink: 1\n3. faucet: 1\n4. soap bottle: 1\n5. water: 1\n6. white plate: 1\n7. white wall: 1\n8. white baseboard: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.837}, "power_stats": {"power_gpu_soc_mean_watts": 18.148, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 68.837}, "timestamp": "2026-01-30T15:46:00.355736"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5076.988, "latencies_ms": [5076.988], "images_per_second": 0.197, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The cat is positioned to the right of the faucet, with its head bent down towards the water. The sink is located in the foreground of the image, while the bottle of soap is situated in the background, slightly to the left of the cat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.738}, "power_stats": {"power_gpu_soc_mean_watts": 19.208, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 68.738}, "timestamp": "2026-01-30T15:46:07.467833"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2995.705, "latencies_ms": [2995.705], "images_per_second": 0.334, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A black and white cat is drinking water from a faucet in a bathroom sink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.125}, "power_stats": {"power_gpu_soc_mean_watts": 24.009, "power_cpu_cv_mean_watts": 0.868, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 73.125}, "timestamp": "2026-01-30T15:46:12.475492"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5413.095, "latencies_ms": [5413.095], "images_per_second": 0.185, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image features a black and white cat drinking water from a faucet in a bathroom. The cat is positioned in front of a white sink, with a bottle of soap and a white soap dish nearby. The lighting in the bathroom is bright, and the overall atmosphere is calm and domestic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.733}, "power_stats": {"power_gpu_soc_mean_watts": 18.978, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 70.733}, "timestamp": "2026-01-30T15:46:19.908270"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5336.105, "latencies_ms": [5336.105], "images_per_second": 0.187, "prompt_tokens": 1432, "response_tokens_est": 45, "n_tiles": 1, "output_text": " In the image, a man wearing a hat and a woman wearing a hat are riding in a horse-drawn carriage, with the horse walking in a muddy field, and the carriage is reflected in a puddle of water.", "error": null, "sys_before": {"cpu_percent": 9.4, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.711}, "power_stats": {"power_gpu_soc_mean_watts": 21.559, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 8.337, "gpu_utilization_percent_mean": 71.711}, "timestamp": "2026-01-30T15:46:27.280117"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6608.59, "latencies_ms": [6608.59], "images_per_second": 0.151, "prompt_tokens": 1446, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. horse: 1\n2. man: 1\n3. carriage: 1\n4. man's hat: 1\n5. man's shirt: 1\n6. man's pants: 1\n7. man's boots: 1\n8. man's belt: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.278, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T15:46:35.947615"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5901.152, "latencies_ms": [5901.152], "images_per_second": 0.169, "prompt_tokens": 1450, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The horse is positioned in the foreground, pulling the carriage, while the man is seated in the carriage, holding the reins. The reflection of the carriage and horse can be seen in the puddle of water, which is located in the middle ground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.367}, "power_stats": {"power_gpu_soc_mean_watts": 21.059, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.253, "gpu_utilization_percent_mean": 72.367}, "timestamp": "2026-01-30T15:46:43.890291"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4353.326, "latencies_ms": [4353.326], "images_per_second": 0.23, "prompt_tokens": 1444, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man and woman are riding in a horse-drawn carriage, with a large puddle reflecting the sky and trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.25}, "power_stats": {"power_gpu_soc_mean_watts": 23.644, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.383, "gpu_utilization_percent_mean": 74.25}, "timestamp": "2026-01-30T15:46:50.269624"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6156.104, "latencies_ms": [6156.104], "images_per_second": 0.162, "prompt_tokens": 1442, "response_tokens_est": 58, "n_tiles": 1, "output_text": " The image features a horse-drawn carriage with two people riding in it, with a brown horse pulling the carriage. The carriage is made of wood and has large spoked wheels. The sky is clear and blue, and the ground is wet, reflecting the carriage and the people on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.49}, "power_stats": {"power_gpu_soc_mean_watts": 20.748, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 8.251, "gpu_utilization_percent_mean": 70.49}, "timestamp": "2026-01-30T15:46:58.438555"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3321.037, "latencies_ms": [3321.037], "images_per_second": 0.301, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man and woman are standing together in a grassy area, with the man holding an umbrella over them.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.704}, "power_stats": {"power_gpu_soc_mean_watts": 23.028, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.152, "gpu_utilization_percent_mean": 73.704}, "timestamp": "2026-01-30T15:47:03.807509"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5409.277, "latencies_ms": [5409.277], "images_per_second": 0.185, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. umbrella: 1\n2. bride: 1\n3. groom: 1\n4. woman: 1\n5. man: 1\n6. house: 1\n7. grass: 1\n8. flowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.356}, "power_stats": {"power_gpu_soc_mean_watts": 18.817, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 69.356}, "timestamp": "2026-01-30T15:47:11.230874"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4346.312, "latencies_ms": [4346.312], "images_per_second": 0.23, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The bride is standing to the left of the groom, with the umbrella held by the groom. The bride is in the foreground, while the groom and the other guests are in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.222}, "power_stats": {"power_gpu_soc_mean_watts": 20.676, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 73.222}, "timestamp": "2026-01-30T15:47:17.606400"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4077.194, "latencies_ms": [4077.194], "images_per_second": 0.245, "prompt_tokens": 1112, "response_tokens_est": 34, "n_tiles": 1, "output_text": " A newlywed couple is standing in a grassy area with a house in the background. The bride is holding a bouquet of flowers and the groom is holding an umbrella.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.05, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 68.242}, "timestamp": "2026-01-30T15:47:23.713436"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5052.84, "latencies_ms": [5052.84], "images_per_second": 0.198, "prompt_tokens": 1110, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The image features a couple dressed in formal attire, with the woman wearing a white wedding dress and the man holding a black and white umbrella. The weather appears to be rainy, as evidenced by the wet grass and the couple's attire.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.524}, "power_stats": {"power_gpu_soc_mean_watts": 18.704, "power_cpu_cv_mean_watts": 1.506, "power_sys_5v0_mean_watts": 7.9, "gpu_utilization_percent_mean": 67.524}, "timestamp": "2026-01-30T15:47:30.781402"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3692.042, "latencies_ms": [3692.042], "images_per_second": 0.271, "prompt_tokens": 1099, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A group of people are on a beach, with one person lying down and another person sitting up, and a kite flying in the air.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.967}, "power_stats": {"power_gpu_soc_mean_watts": 22.326, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 8.153, "gpu_utilization_percent_mean": 72.967}, "timestamp": "2026-01-30T15:47:36.497558"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5431.801, "latencies_ms": [5431.801], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. sand: 3\n2. legs: 4\n3. shorts: 2\n4. kite: 1\n5. kite string: 1\n6. person: 2\n7. beach: 1\n8. ocean: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.667}, "power_stats": {"power_gpu_soc_mean_watts": 18.889, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T15:47:43.941618"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4581.433, "latencies_ms": [4581.433], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The kite is in the foreground, with the people lying on the beach in the background. The kite is positioned to the right of the people, and the people are lying on the left side of the beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.083, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 70.184}, "timestamp": "2026-01-30T15:47:50.555248"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3035.967, "latencies_ms": [3035.967], "images_per_second": 0.329, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A group of people are on a beach, with one person flying a kite.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.792}, "power_stats": {"power_gpu_soc_mean_watts": 23.826, "power_cpu_cv_mean_watts": 0.918, "power_sys_5v0_mean_watts": 8.244, "gpu_utilization_percent_mean": 73.792}, "timestamp": "2026-01-30T15:47:55.603493"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4607.48, "latencies_ms": [4607.48], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a sunny day at the beach with clear blue skies and the ocean in the background. The sand is light brown and the kite flying in the air is colorful with red, blue, and green stripes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.658}, "power_stats": {"power_gpu_soc_mean_watts": 20.166, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 71.658}, "timestamp": "2026-01-30T15:48:02.239376"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3354.867, "latencies_ms": [3354.867], "images_per_second": 0.298, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A living room with a brown couch, a red chair, a black table, a lamp, and a TV.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.714}, "power_stats": {"power_gpu_soc_mean_watts": 23.107, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 74.714}, "timestamp": "2026-01-30T15:48:07.640840"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5985.095, "latencies_ms": [5985.095], "images_per_second": 0.167, "prompt_tokens": 1113, "response_tokens_est": 66, "n_tiles": 1, "output_text": " 1. brown sofa: 1\n2. black chair: 1\n3. black stool: 1\n4. black table: 1\n5. black TV stand: 1\n6. black TV: 1\n7. black lamp: 1\n8. yellow lamp: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.64}, "power_stats": {"power_gpu_soc_mean_watts": 18.091, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 69.64}, "timestamp": "2026-01-30T15:48:15.653776"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4870.096, "latencies_ms": [4870.096], "images_per_second": 0.205, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The brown couch is located on the left side of the room, while the red chair is situated on the right side. The coffee table is positioned in the center of the room, with the television set placed against the wall in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.25}, "power_stats": {"power_gpu_soc_mean_watts": 19.888, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 70.25}, "timestamp": "2026-01-30T15:48:22.539602"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3235.687, "latencies_ms": [3235.687], "images_per_second": 0.309, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A living room with a brown couch, a red chair, a black table, and a lamp.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.519}, "power_stats": {"power_gpu_soc_mean_watts": 23.132, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.194, "gpu_utilization_percent_mean": 73.519}, "timestamp": "2026-01-30T15:48:27.821607"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3518.662, "latencies_ms": [3518.662], "images_per_second": 0.284, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The room is well lit with natural light coming through the windows, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.724}, "power_stats": {"power_gpu_soc_mean_watts": 22.546, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T15:48:33.386545"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3639.528, "latencies_ms": [3639.528], "images_per_second": 0.275, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bald man wearing glasses is eating a slice of cake with a spoon in his hand.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 13994.6, "ram_available_mb": 48846.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.567}, "power_stats": {"power_gpu_soc_mean_watts": 25.746, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 8.596, "gpu_utilization_percent_mean": 82.567}, "timestamp": "2026-01-30T15:48:39.081926"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6036.683, "latencies_ms": [6036.683], "images_per_second": 0.166, "prompt_tokens": 1446, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. plate: 1\n3. spoon: 1\n4. cake: 1\n5. grass: 1\n6. tree: 1\n7. sky: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.18}, "power_stats": {"power_gpu_soc_mean_watts": 20.94, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 8.252, "gpu_utilization_percent_mean": 73.18}, "timestamp": "2026-01-30T15:48:47.148271"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5295.85, "latencies_ms": [5295.85], "images_per_second": 0.189, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The man is in the foreground, holding a plate of cake in his hand. The cake is in the middle of the image, and the man is eating it. The background is a park with trees and grass.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.75}, "power_stats": {"power_gpu_soc_mean_watts": 21.903, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.339, "gpu_utilization_percent_mean": 73.75}, "timestamp": "2026-01-30T15:48:54.489841"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4088.895, "latencies_ms": [4088.895], "images_per_second": 0.245, "prompt_tokens": 1444, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A man wearing glasses and a blue shirt is eating a slice of cake in a park with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.147}, "power_stats": {"power_gpu_soc_mean_watts": 24.295, "power_cpu_cv_mean_watts": 1.083, "power_sys_5v0_mean_watts": 8.442, "gpu_utilization_percent_mean": 81.147}, "timestamp": "2026-01-30T15:49:00.608907"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4134.038, "latencies_ms": [4134.038], "images_per_second": 0.242, "prompt_tokens": 1442, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The man is wearing a blue shirt and has a bald head. The sun is shining brightly, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.441}, "power_stats": {"power_gpu_soc_mean_watts": 24.721, "power_cpu_cv_mean_watts": 1.095, "power_sys_5v0_mean_watts": 8.481, "gpu_utilization_percent_mean": 77.441}, "timestamp": "2026-01-30T15:49:06.771129"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3584.854, "latencies_ms": [3584.854], "images_per_second": 0.279, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man wearing a purple vest and jeans is walking next to a brown horse that is carrying a large load of luggage on its back.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13991.3, "ram_available_mb": 48849.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.69}, "power_stats": {"power_gpu_soc_mean_watts": 22.834, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.203, "gpu_utilization_percent_mean": 73.69}, "timestamp": "2026-01-30T15:49:12.379758"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5346.502, "latencies_ms": [5346.502], "images_per_second": 0.187, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. horse: 1\n3. luggage: 2\n4. backpack: 1\n5. blanket: 1\n6. rope: 1\n7. tree: 1\n8. ground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.3, "ram_available_mb": 48849.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.422}, "power_stats": {"power_gpu_soc_mean_watts": 18.997, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.422}, "timestamp": "2026-01-30T15:49:19.765423"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4748.199, "latencies_ms": [4748.199], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The man is standing to the left of the donkey, which is positioned in the foreground of the image. The man is closer to the camera than the donkey, which is also closer to the camera than the trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.282}, "power_stats": {"power_gpu_soc_mean_watts": 20.164, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.062, "gpu_utilization_percent_mean": 70.282}, "timestamp": "2026-01-30T15:49:26.529625"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3550.977, "latencies_ms": [3550.977], "images_per_second": 0.282, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man is walking with a donkey that is carrying a large load of luggage. The man is wearing a purple jacket and jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.6, "ram_available_mb": 48848.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.569, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.188, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-30T15:49:32.125548"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4407.463, "latencies_ms": [4407.463], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a man and a donkey with colorful luggage on its back. The man is wearing a purple jacket and the donkey is brown. The lighting is natural and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.622}, "power_stats": {"power_gpu_soc_mean_watts": 20.451, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 70.622}, "timestamp": "2026-01-30T15:49:38.571443"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4596.493, "latencies_ms": [4596.493], "images_per_second": 0.218, "prompt_tokens": 766, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge adorned with blue lights, standing majestically over a river, with a boat docked on the river's edge, and people strolling along the riverbank, all under a dark sky speckled with stars.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5179.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.744}, "power_stats": {"power_gpu_soc_mean_watts": 16.715, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.685, "gpu_utilization_percent_mean": 65.744}, "timestamp": "2026-01-30T15:49:45.211858"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4786.34, "latencies_ms": [4786.34], "images_per_second": 0.209, "prompt_tokens": 780, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bridge: 1\n2. lights: 1\n3. people: 1\n4. boat: 1\n5. water: 1\n6. street: 1\n7. sky: 1\n8. clouds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.375}, "power_stats": {"power_gpu_soc_mean_watts": 16.794, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 7.723, "gpu_utilization_percent_mean": 65.375}, "timestamp": "2026-01-30T15:49:52.042772"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3206.828, "latencies_ms": [3206.828], "images_per_second": 0.312, "prompt_tokens": 784, "response_tokens_est": 30, "n_tiles": 1, "output_text": " The bridge is located in the background, with the river in the foreground. The people are standing on the sidewalk, which is adjacent to the river.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.923}, "power_stats": {"power_gpu_soc_mean_watts": 19.696, "power_cpu_cv_mean_watts": 1.355, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 65.923}, "timestamp": "2026-01-30T15:49:57.276105"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5622.617, "latencies_ms": [5622.617], "images_per_second": 0.178, "prompt_tokens": 778, "response_tokens_est": 70, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge illuminated with blue lights, spanning across a river. The bridge is adorned with a series of lights that create a striking pattern against the dark sky. In the foreground, a boat is docked, adding to the lively atmosphere. The city lights in the background suggest that this is a bustling urban area.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 62.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.955, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 62.0}, "timestamp": "2026-01-30T15:50:04.955425"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4607.411, "latencies_ms": [4607.411], "images_per_second": 0.217, "prompt_tokens": 776, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image captures a vibrant night scene of a bridge adorned with blue and white lights, reflecting off the calm waters of the river below. The sky is a dark canvas, punctuated by the glow of streetlights and distant buildings, creating a serene yet lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.615}, "power_stats": {"power_gpu_soc_mean_watts": 16.755, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.689, "gpu_utilization_percent_mean": 66.615}, "timestamp": "2026-01-30T15:50:11.606112"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2938.614, "latencies_ms": [2938.614], "images_per_second": 0.34, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is wearing blue jeans and pink shoes with a bow on them.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13993.4, "ram_available_mb": 48847.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.25}, "power_stats": {"power_gpu_soc_mean_watts": 24.219, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 77.25}, "timestamp": "2026-01-30T15:50:16.596109"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5821.946, "latencies_ms": [5821.946], "images_per_second": 0.172, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. pink shoe: 1\n2. blue jeans: 1\n3. wooden floor: 1\n4. pink bow: 1\n5. blue paint: 1\n6. green paint: 1\n7. black paint: 1\n8. white paint: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.653}, "power_stats": {"power_gpu_soc_mean_watts": 18.448, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 68.653}, "timestamp": "2026-01-30T15:50:24.438247"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4468.949, "latencies_ms": [4468.949], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The pink shoe is positioned on the left side of the image, with the person's leg extending towards the right side. The shoe is in the foreground, while the wooden bench is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.351}, "power_stats": {"power_gpu_soc_mean_watts": 20.266, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 65.351}, "timestamp": "2026-01-30T15:50:30.946853"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2727.597, "latencies_ms": [2727.597], "images_per_second": 0.367, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A person is wearing a pink shoe and blue jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.7, "ram_available_mb": 48848.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.401, "power_cpu_cv_mean_watts": 0.764, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T15:50:35.693941"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6009.435, "latencies_ms": [6009.435], "images_per_second": 0.166, "prompt_tokens": 1109, "response_tokens_est": 66, "n_tiles": 1, "output_text": " The image features a person wearing a pair of pink shoes and blue jeans, with the shoes being the focal point of the image. The shoes are placed on a wooden surface that has a blue and green color scheme, and the lighting in the image is bright and clear, highlighting the details of the shoes and the person's attire.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.66}, "power_stats": {"power_gpu_soc_mean_watts": 18.048, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 66.66}, "timestamp": "2026-01-30T15:50:43.721795"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3432.122, "latencies_ms": [3432.122], "images_per_second": 0.291, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A woman and a boy are standing in a room with a red wall, and the woman is holding a knife.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.179}, "power_stats": {"power_gpu_soc_mean_watts": 22.849, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.176, "gpu_utilization_percent_mean": 76.179}, "timestamp": "2026-01-30T15:50:49.202697"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4092.735, "latencies_ms": [4092.735], "images_per_second": 0.244, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " woman: 1, man: 1, cup: 1, plate: 1, knife: 1, red: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13990.7, "ram_available_mb": 48850.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.559}, "power_stats": {"power_gpu_soc_mean_watts": 21.101, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 72.559}, "timestamp": "2026-01-30T15:50:55.355245"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3845.801, "latencies_ms": [3845.801], "images_per_second": 0.26, "prompt_tokens": 1117, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The woman is standing to the left of the boy, with the table between them. The boy is standing closer to the camera than the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.7, "ram_available_mb": 48850.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.781}, "power_stats": {"power_gpu_soc_mean_watts": 21.544, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 70.781}, "timestamp": "2026-01-30T15:51:01.223177"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3722.569, "latencies_ms": [3722.569], "images_per_second": 0.269, "prompt_tokens": 1111, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A woman and a boy are standing in a room with a red wall. The woman is holding a knife and the boy is holding a cup.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.419}, "power_stats": {"power_gpu_soc_mean_watts": 22.267, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 72.419}, "timestamp": "2026-01-30T15:51:06.981520"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3240.93, "latencies_ms": [3240.93], "images_per_second": 0.309, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image has a warm color palette with red and brown tones, and the lighting is natural and soft.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.556}, "power_stats": {"power_gpu_soc_mean_watts": 23.4, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 74.556}, "timestamp": "2026-01-30T15:51:12.258550"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7915.365, "latencies_ms": [7915.365], "images_per_second": 0.126, "prompt_tokens": 1099, "response_tokens_est": 99, "n_tiles": 1, "output_text": " In the center of an indoor arena, two elephants are engaged in a performance, their trunks intertwined in a display of strength and coordination. The arena is adorned with a vibrant red and yellow striped border, adding a splash of color to the scene. In the background, a solitary figure can be seen, perhaps an audience member or a performer, observing the spectacle. The image captures a moment of harmony and spectacle, as the elephants and their human handlers come together in a display of skill and coordination.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.03}, "power_stats": {"power_gpu_soc_mean_watts": 16.601, "power_cpu_cv_mean_watts": 1.876, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 67.03}, "timestamp": "2026-01-30T15:51:22.225294"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 9701.481, "latencies_ms": [9701.481], "images_per_second": 0.103, "prompt_tokens": 1113, "response_tokens_est": 128, "n_tiles": 1, "output_text": " elephant: 3, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: 1, elephant: ", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13991.1, "ram_available_mb": 48849.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 13991.3, "ram_available_mb": 48849.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.53}, "power_stats": {"power_gpu_soc_mean_watts": 15.514, "power_cpu_cv_mean_watts": 1.953, "power_sys_5v0_mean_watts": 7.844, "gpu_utilization_percent_mean": 66.53}, "timestamp": "2026-01-30T15:51:33.947052"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4462.79, "latencies_ms": [4462.79], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The elephants are positioned in the foreground of the image, with the camera and the audience in the background. The elephants are standing on a circular platform, which is surrounded by a red and yellow border.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.3, "ram_available_mb": 48849.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.919}, "power_stats": {"power_gpu_soc_mean_watts": 20.42, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 68.919}, "timestamp": "2026-01-30T15:51:40.427699"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4629.418, "latencies_ms": [4629.418], "images_per_second": 0.216, "prompt_tokens": 1111, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the center of an indoor arena, two elephants are standing on a dirt floor, surrounded by a ring of red and yellow. A person is standing on the elephant's back, while another elephant is positioned nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.184}, "power_stats": {"power_gpu_soc_mean_watts": 20.102, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.184}, "timestamp": "2026-01-30T15:51:47.081344"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3770.795, "latencies_ms": [3770.795], "images_per_second": 0.265, "prompt_tokens": 1109, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The elephants are brown and gray, and the circus ring is red and yellow. The lighting is bright and the elephants are well-lit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13990.8, "ram_available_mb": 48850.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.516}, "power_stats": {"power_gpu_soc_mean_watts": 21.721, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 73.516}, "timestamp": "2026-01-30T15:51:52.873793"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5115.045, "latencies_ms": [5115.045], "images_per_second": 0.196, "prompt_tokens": 1099, "response_tokens_est": 51, "n_tiles": 1, "output_text": " In the sepia-toned photograph, a group of jockeys is seen riding horses along a beach, with the horses' legs and hooves creating a blurred effect due to the motion, and the background featuring a cloudy sky and the ocean.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13990.8, "ram_available_mb": 48850.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13991.3, "ram_available_mb": 48849.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.07}, "power_stats": {"power_gpu_soc_mean_watts": 19.069, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 70.07}, "timestamp": "2026-01-30T15:52:00.041258"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5465.552, "latencies_ms": [5465.552], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. horse: 2\n2. rider: 2\n3. horse: 1\n4. rider: 1\n5. horse: 1\n6. rider: 1\n7. horse: 1\n8. rider: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.3, "ram_available_mb": 48849.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.222}, "power_stats": {"power_gpu_soc_mean_watts": 18.612, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 70.222}, "timestamp": "2026-01-30T15:52:07.519194"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4455.103, "latencies_ms": [4455.103], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The horses are positioned on the left side of the image, with the riders appearing to be in the middle of the frame. The background of the image is the beach, with the sky above it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.9, "ram_available_mb": 48850.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.243}, "power_stats": {"power_gpu_soc_mean_watts": 20.321, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 70.243}, "timestamp": "2026-01-30T15:52:14.036082"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3167.347, "latencies_ms": [3167.347], "images_per_second": 0.316, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A group of people are riding horses on a beach, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.143, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.184, "gpu_utilization_percent_mean": 77.846}, "timestamp": "2026-01-30T15:52:19.258659"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3451.659, "latencies_ms": [3451.659], "images_per_second": 0.29, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is in black and white, with a sepia tone, and the horses are running on a wet beach.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.5}, "power_stats": {"power_gpu_soc_mean_watts": 23.006, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-30T15:52:24.743873"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3470.257, "latencies_ms": [3470.257], "images_per_second": 0.288, "prompt_tokens": 1100, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A young man wearing a black jacket and a black helmet with blue goggles is talking on a cell phone in the snow.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13990.6, "ram_available_mb": 48850.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13991.2, "ram_available_mb": 48849.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.552}, "power_stats": {"power_gpu_soc_mean_watts": 22.461, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.143, "gpu_utilization_percent_mean": 73.552}, "timestamp": "2026-01-30T15:52:30.264336"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5514.81, "latencies_ms": [5514.81], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. goggles: 1\n3. jacket: 1\n4. phone: 1\n5. tree: 1\n6. snow: 1\n7. tree trunk: 1\n8. snowboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.5, "ram_available_mb": 48850.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13990.1, "ram_available_mb": 48850.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.761}, "power_stats": {"power_gpu_soc_mean_watts": 18.643, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 67.761}, "timestamp": "2026-01-30T15:52:37.841120"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4452.124, "latencies_ms": [4452.124], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, wearing a black jacket and a black helmet with blue goggles. The background of the image shows a snowy landscape with trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13990.1, "ram_available_mb": 48850.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13989.6, "ram_available_mb": 48851.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.419, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 70.324}, "timestamp": "2026-01-30T15:52:44.324131"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3283.942, "latencies_ms": [3283.942], "images_per_second": 0.305, "prompt_tokens": 1112, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A young man wearing a black jacket and a black helmet is talking on a cell phone in the snow.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13989.6, "ram_available_mb": 48851.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13989.2, "ram_available_mb": 48851.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.889}, "power_stats": {"power_gpu_soc_mean_watts": 22.821, "power_cpu_cv_mean_watts": 1.127, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 71.889}, "timestamp": "2026-01-30T15:52:49.621536"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3280.928, "latencies_ms": [3280.928], "images_per_second": 0.305, "prompt_tokens": 1110, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The person is wearing a black jacket and a blue and black helmet, and the sun is shining brightly.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13989.2, "ram_available_mb": 48851.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13984.0, "ram_available_mb": 48856.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.074}, "power_stats": {"power_gpu_soc_mean_watts": 23.293, "power_cpu_cv_mean_watts": 1.097, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 74.074}, "timestamp": "2026-01-30T15:52:54.944460"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3152.308, "latencies_ms": [3152.308], "images_per_second": 0.317, "prompt_tokens": 1099, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A green tent and a white motorcycle are parked in a field with a sunset in the background.", "error": null, "sys_before": {"cpu_percent": 13.8, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13984.7, "ram_available_mb": 48856.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.527, "power_cpu_cv_mean_watts": 1.062, "power_sys_5v0_mean_watts": 8.234, "gpu_utilization_percent_mean": 74.846}, "timestamp": "2026-01-30T15:53:00.167877"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5771.974, "latencies_ms": [5771.974], "images_per_second": 0.173, "prompt_tokens": 1113, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. green tent: 1\n2. motorcycle: 1\n3. backpack: 1\n4. saddlebags: 1\n5. tent poles: 2\n6. tent fabric: 1\n7. motorcycle seat: 1\n8. motorcycle handlebars: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13984.7, "ram_available_mb": 48856.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13985.4, "ram_available_mb": 48855.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.25}, "power_stats": {"power_gpu_soc_mean_watts": 18.525, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 69.25}, "timestamp": "2026-01-30T15:53:07.959789"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4506.662, "latencies_ms": [4506.662], "images_per_second": 0.222, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The motorcycle is positioned to the right of the tent, with the motorcycle's front wheel slightly closer to the camera than the tent. The motorcycle is in the foreground, with the tent situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13985.4, "ram_available_mb": 48855.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13979.4, "ram_available_mb": 48861.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.676}, "power_stats": {"power_gpu_soc_mean_watts": 20.428, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 71.676}, "timestamp": "2026-01-30T15:53:14.494708"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3979.135, "latencies_ms": [3979.135], "images_per_second": 0.251, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A green tent and a white motorcycle are parked in a field of dry grass. The sun is setting in the background, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13979.4, "ram_available_mb": 48861.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13979.7, "ram_available_mb": 48861.2, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.758}, "power_stats": {"power_gpu_soc_mean_watts": 21.365, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 67.758}, "timestamp": "2026-01-30T15:53:20.490425"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4334.03, "latencies_ms": [4334.03], "images_per_second": 0.231, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a green tent and a white motorcycle parked in a field with dry grass. The sky is filled with clouds and the sun is setting, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13979.7, "ram_available_mb": 48861.2, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.606, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T15:53:26.852628"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4365.968, "latencies_ms": [4365.968], "images_per_second": 0.229, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A black and white photo shows a steam locomotive with the number 67371 on the front, pulling a train of passenger cars, with people standing on the platform next to it.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.5}, "power_stats": {"power_gpu_soc_mean_watts": 20.632, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 68.5}, "timestamp": "2026-01-30T15:53:33.261474"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5424.294, "latencies_ms": [5424.294], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. train: 1\n2. people: 4\n3. platform: 1\n4. sign: 1\n5. chimney: 1\n6. smoke: 1\n7. train car: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13980.0, "ram_available_mb": 48860.9, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13980.2, "ram_available_mb": 48860.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.543}, "power_stats": {"power_gpu_soc_mean_watts": 18.853, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.543}, "timestamp": "2026-01-30T15:53:40.709171"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4626.915, "latencies_ms": [4626.915], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The train is on the left side of the image, with the platform on the right. The people are standing on the platform, near the train. The buildings are in the background, far away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.2, "ram_available_mb": 48860.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13980.2, "ram_available_mb": 48860.7, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.974}, "power_stats": {"power_gpu_soc_mean_watts": 20.068, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 69.974}, "timestamp": "2026-01-30T15:53:47.365690"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3291.214, "latencies_ms": [3291.214], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A black and white photo of a train station with a steam locomotive and people waiting for the train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.2, "ram_available_mb": 48860.7, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13980.4, "ram_available_mb": 48860.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.91, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 75.185}, "timestamp": "2026-01-30T15:53:52.669944"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3442.974, "latencies_ms": [3442.974], "images_per_second": 0.29, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The image is in black and white, with the train and people in the foreground and the background showing a clear sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13980.4, "ram_available_mb": 48860.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13980.4, "ram_available_mb": 48860.5, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.929}, "power_stats": {"power_gpu_soc_mean_watts": 23.02, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 72.929}, "timestamp": "2026-01-30T15:53:58.148383"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3905.278, "latencies_ms": [3905.278], "images_per_second": 0.256, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image captures a bustling street scene in a densely populated urban area, with numerous signs and advertisements hanging from the buildings, creating a vibrant and colorful atmosphere.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13980.4, "ram_available_mb": 48860.5, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.062}, "power_stats": {"power_gpu_soc_mean_watts": 21.695, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.127, "gpu_utilization_percent_mean": 71.062}, "timestamp": "2026-01-30T15:54:04.083933"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5663.55, "latencies_ms": [5663.55], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. sign: 10\n2. building: 1\n3. window: 1\n4. air conditioner: 1\n5. power line: 1\n6. street sign: 1\n7. pole: 1\n8. wire: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13981.1, "ram_available_mb": 48859.8, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.702}, "power_stats": {"power_gpu_soc_mean_watts": 18.511, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.944, "gpu_utilization_percent_mean": 68.702}, "timestamp": "2026-01-30T15:54:11.779041"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4393.443, "latencies_ms": [4393.443], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The main objects are the street signs and the buildings. The street signs are in the foreground, while the buildings are in the background. The street signs are closer to the viewer than the buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13980.9, "ram_available_mb": 48860.0, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.306}, "power_stats": {"power_gpu_soc_mean_watts": 20.697, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 69.306}, "timestamp": "2026-01-30T15:54:18.200124"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3264.052, "latencies_ms": [3264.052], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " This is a black and white photo of a street in Hong Kong with lots of signs and buildings.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13981.3, "ram_available_mb": 48859.6, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.296}, "power_stats": {"power_gpu_soc_mean_watts": 23.057, "power_cpu_cv_mean_watts": 1.052, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 74.296}, "timestamp": "2026-01-30T15:54:23.484524"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4285.691, "latencies_ms": [4285.691], "images_per_second": 0.233, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image is in black and white, with a high contrast between the dark and light areas. The buildings are covered in signs and advertisements, with some of the signs being in Chinese characters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13981.6, "ram_available_mb": 48859.3, "ram_percent": 22.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.785, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 71.972}, "timestamp": "2026-01-30T15:54:29.809722"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4039.178, "latencies_ms": [4039.178], "images_per_second": 0.248, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A man is lying on a concrete ledge by a body of water, while a sign reading \"OPEN\" is placed on the ground in front of him.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.254, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.576}, "timestamp": "2026-01-30T15:54:35.893235"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5587.899, "latencies_ms": [5587.899], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. man: 1\n2. grass: 1\n3. lake: 1\n4. sign: 1\n5. wood: 1\n6. water: 1\n7. man's legs: 1\n8. man's feet: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.936}, "power_stats": {"power_gpu_soc_mean_watts": 18.74, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 69.936}, "timestamp": "2026-01-30T15:54:43.511390"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4632.792, "latencies_ms": [4632.792], "images_per_second": 0.216, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The sign is in the foreground, close to the camera, and the man is in the background, far away from the camera. The man is sitting on the grass, and the sign is lying on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.251, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.816}, "timestamp": "2026-01-30T15:54:50.168267"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4634.129, "latencies_ms": [4634.129], "images_per_second": 0.216, "prompt_tokens": 1112, "response_tokens_est": 41, "n_tiles": 1, "output_text": " A man is sunbathing on a concrete ledge overlooking a body of water. In the foreground, there is a sign that reads \"OPEN\" and \"CLOSED\" in red letters.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.974}, "power_stats": {"power_gpu_soc_mean_watts": 19.525, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 69.974}, "timestamp": "2026-01-30T15:54:56.827868"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4676.447, "latencies_ms": [4676.447], "images_per_second": 0.214, "prompt_tokens": 1110, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The image features a man lounging on a concrete ledge by a body of water, with a sign reading \"OPEN\" in red letters. The sky is clear and blue, and the grass is green.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.05, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T15:55:03.529161"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3954.538, "latencies_ms": [3954.538], "images_per_second": 0.253, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, there is a brown horse standing in a field of tall grass, and a white dog with a pink tongue is sitting in front of it.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13982.3, "ram_available_mb": 48858.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.939}, "power_stats": {"power_gpu_soc_mean_watts": 21.353, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.088, "gpu_utilization_percent_mean": 68.939}, "timestamp": "2026-01-30T15:55:09.540931"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4620.205, "latencies_ms": [4620.205], "images_per_second": 0.216, "prompt_tokens": 1114, "response_tokens_est": 43, "n_tiles": 1, "output_text": " horse: 1, dog: 1, grass: 1, horse's tail: 1, horse's mane: 1, horse's ear: 1, horse's eye: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.436}, "power_stats": {"power_gpu_soc_mean_watts": 19.979, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 69.436}, "timestamp": "2026-01-30T15:55:16.220945"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4859.089, "latencies_ms": [4859.089], "images_per_second": 0.206, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The brown horse is positioned to the left of the white dog, with the dog being in the foreground and the horse in the background. The dog is closer to the camera than the horse, and the horse is positioned behind the dog.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.268}, "power_stats": {"power_gpu_soc_mean_watts": 19.512, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 71.268}, "timestamp": "2026-01-30T15:55:23.114158"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4408.595, "latencies_ms": [4408.595], "images_per_second": 0.227, "prompt_tokens": 1112, "response_tokens_est": 40, "n_tiles": 1, "output_text": " In a serene field, a brown horse and a golden retriever are enjoying a sunny day. The horse stands tall, while the dog sits comfortably in the grass, both looking content and happy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.838}, "power_stats": {"power_gpu_soc_mean_watts": 20.247, "power_cpu_cv_mean_watts": 1.439, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 68.838}, "timestamp": "2026-01-30T15:55:29.553357"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4914.966, "latencies_ms": [4914.966], "images_per_second": 0.203, "prompt_tokens": 1110, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a brown horse and a white dog in a field of tall grass. The horse is wearing a bridle, while the dog is panting with its tongue out. The lighting is natural and bright, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.476}, "power_stats": {"power_gpu_soc_mean_watts": 19.436, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 69.476}, "timestamp": "2026-01-30T15:55:36.517179"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4141.469, "latencies_ms": [4141.469], "images_per_second": 0.241, "prompt_tokens": 1099, "response_tokens_est": 35, "n_tiles": 1, "output_text": " In the indoor volleyball court, a group of people are playing volleyball, with one person in the foreground wearing a blue shirt and the other in the background wearing a green shirt.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.8}, "power_stats": {"power_gpu_soc_mean_watts": 20.991, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 70.8}, "timestamp": "2026-01-30T15:55:42.698595"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5090.692, "latencies_ms": [5090.692], "images_per_second": 0.196, "prompt_tokens": 1113, "response_tokens_est": 51, "n_tiles": 1, "output_text": " volleyball: 1\nvolleyball: 1\ncourt: 1\nmen: 1\nmen's: 1\nmen's volleyball: 1\nmen's volleyball court: 1\nmen's volleyball court floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13982.4, "ram_available_mb": 48858.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.571}, "power_stats": {"power_gpu_soc_mean_watts": 19.285, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 67.571}, "timestamp": "2026-01-30T15:55:49.821037"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6191.676, "latencies_ms": [6191.676], "images_per_second": 0.162, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The main objects in the image are positioned in the foreground, with the volleyball court taking up a significant portion of the space. The players are arranged in a line, with the person in the foreground holding the volleyball and the others standing behind them. The court is surrounded by walls and windows, with the ceiling being the highest point in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.4, "ram_available_mb": 48858.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.231}, "power_stats": {"power_gpu_soc_mean_watts": 17.879, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.943, "gpu_utilization_percent_mean": 67.231}, "timestamp": "2026-01-30T15:55:58.048184"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6333.137, "latencies_ms": [6333.137], "images_per_second": 0.158, "prompt_tokens": 1111, "response_tokens_est": 71, "n_tiles": 1, "output_text": " The image captures a lively volleyball game in an indoor gymnasium. The players, clad in blue uniforms, are actively engaged in the game, their movements and interactions highlighting the dynamic nature of the sport. The gymnasium itself is well-equipped with a high ceiling, large windows, and a wooden floor, providing an ideal environment for the game.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.736}, "power_stats": {"power_gpu_soc_mean_watts": 17.648, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.945, "gpu_utilization_percent_mean": 66.736}, "timestamp": "2026-01-30T15:56:06.392990"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3124.203, "latencies_ms": [3124.203], "images_per_second": 0.32, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The indoor volleyball court is blue with white lines, and the players are wearing blue uniforms.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.685, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T15:56:11.542116"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4608.792, "latencies_ms": [4608.792], "images_per_second": 0.217, "prompt_tokens": 1099, "response_tokens_est": 43, "n_tiles": 1, "output_text": " In the image, a herd of zebras and wildebeests are grazing in a grassy field, with a flock of pink flamingos standing in the water behind them, and a mountain range in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13982.7, "ram_available_mb": 48858.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.897}, "power_stats": {"power_gpu_soc_mean_watts": 20.029, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 67.897}, "timestamp": "2026-01-30T15:56:18.185870"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4070.757, "latencies_ms": [4070.757], "images_per_second": 0.246, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " zebra: 10\nflamingo: 100\ngrass: 100\nwater: 100\nmountain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.382}, "power_stats": {"power_gpu_soc_mean_watts": 21.195, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 71.382}, "timestamp": "2026-01-30T15:56:24.289835"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4925.801, "latencies_ms": [4925.801], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground, with the flamingos in the background. The zebras are standing in a line, with the flamingos scattered across the water. The zebras are closer to the camera than the flamingos.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.048}, "power_stats": {"power_gpu_soc_mean_watts": 19.447, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 70.048}, "timestamp": "2026-01-30T15:56:31.251482"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5242.683, "latencies_ms": [5242.683], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 53, "n_tiles": 1, "output_text": " In the vast savannah, a herd of zebras and wildebeests graze peacefully, while a flock of pink flamingos wades in the nearby lake. The tranquil scene is set against the backdrop of a distant mountain range, under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.659}, "power_stats": {"power_gpu_soc_mean_watts": 18.909, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 69.659}, "timestamp": "2026-01-30T15:56:38.519244"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5233.498, "latencies_ms": [5233.498], "images_per_second": 0.191, "prompt_tokens": 1109, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a vibrant scene with a mix of green grass, brown and black animals, and pink flamingos. The lighting is natural and bright, suggesting a sunny day, while the materials are organic and natural, with the animals and grass being the main subjects.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.6, "ram_available_mb": 48858.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13982.9, "ram_available_mb": 48858.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.273}, "power_stats": {"power_gpu_soc_mean_watts": 18.99, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 68.273}, "timestamp": "2026-01-30T15:56:45.768049"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3296.244, "latencies_ms": [3296.244], "images_per_second": 0.303, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A ginger and white cat is sitting on a wooden deck and looking at its reflection in a window.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13982.9, "ram_available_mb": 48858.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.778}, "power_stats": {"power_gpu_soc_mean_watts": 22.834, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.152, "gpu_utilization_percent_mean": 76.778}, "timestamp": "2026-01-30T15:56:51.095919"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4230.261, "latencies_ms": [4230.261], "images_per_second": 0.236, "prompt_tokens": 1113, "response_tokens_est": 37, "n_tiles": 1, "output_text": " cat: 1, wooden floor: 1, glass: 1, mirror: 1, wall: 1, window: 1, cat's tail: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.1, "ram_available_mb": 48857.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.029}, "power_stats": {"power_gpu_soc_mean_watts": 21.071, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T15:56:57.358911"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3600.086, "latencies_ms": [3600.086], "images_per_second": 0.278, "prompt_tokens": 1117, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The cat is in the foreground, sitting on a wooden deck. The glass window is in the background, reflecting the cat's image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.667}, "power_stats": {"power_gpu_soc_mean_watts": 22.553, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 72.667}, "timestamp": "2026-01-30T15:57:03.008918"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3226.447, "latencies_ms": [3226.447], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A ginger and white cat is sitting on a wooden deck, looking at its reflection in a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.4, "ram_available_mb": 48857.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13982.9, "ram_available_mb": 48858.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.962}, "power_stats": {"power_gpu_soc_mean_watts": 23.558, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 73.962}, "timestamp": "2026-01-30T15:57:08.261626"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3501.676, "latencies_ms": [3501.676], "images_per_second": 0.286, "prompt_tokens": 1109, "response_tokens_est": 25, "n_tiles": 1, "output_text": " The cat is orange and white, and the wooden floor is green. The cat is looking at its reflection in the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.9, "ram_available_mb": 48858.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13982.2, "ram_available_mb": 48858.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.862}, "power_stats": {"power_gpu_soc_mean_watts": 22.681, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 72.862}, "timestamp": "2026-01-30T15:57:13.778319"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4315.882, "latencies_ms": [4315.882], "images_per_second": 0.232, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures a serene lakeside scene with boats docked at a pier, a street lamp standing tall, and a distant view of buildings nestled among trees, all under a hazy sky.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13982.2, "ram_available_mb": 48858.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.74, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 69.972}, "timestamp": "2026-01-30T15:57:20.128237"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5405.235, "latencies_ms": [5405.235], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. Boat: 4\n2. Boat: 1\n3. Boat: 1\n4. Boat: 1\n5. Boat: 1\n6. Boat: 1\n7. Boat: 1\n8. Boat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.5, "ram_available_mb": 48858.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.244}, "power_stats": {"power_gpu_soc_mean_watts": 18.791, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 69.244}, "timestamp": "2026-01-30T15:57:27.576076"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4385.96, "latencies_ms": [4385.96], "images_per_second": 0.228, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The boats are located in the foreground of the image, with the shoreline and buildings in the background. The skyline of mountains is visible in the far background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13982.1, "ram_available_mb": 48858.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.333}, "power_stats": {"power_gpu_soc_mean_watts": 20.854, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 71.333}, "timestamp": "2026-01-30T15:57:33.985916"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4933.424, "latencies_ms": [4933.424], "images_per_second": 0.203, "prompt_tokens": 1111, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image captures a serene lakeside scene with boats docked at a pier, a building with a red roof in the background, and a mountainous landscape in the distance. The sky is overcast, casting a soft light over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13982.1, "ram_available_mb": 48858.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13983.0, "ram_available_mb": 48857.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.341}, "power_stats": {"power_gpu_soc_mean_watts": 19.492, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 67.341}, "timestamp": "2026-01-30T15:57:40.954014"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3205.672, "latencies_ms": [3205.672], "images_per_second": 0.312, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The sky is overcast, the water is a deep blue, and the boats are white.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13983.0, "ram_available_mb": 48857.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.359, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.195, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T15:57:46.214773"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3675.255, "latencies_ms": [3675.255], "images_per_second": 0.272, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " A man is standing next to a bicycle in a street with a sign that says \"\u6c34\u997a\" on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13982.8, "ram_available_mb": 48858.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13983.5, "ram_available_mb": 48857.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.8}, "power_stats": {"power_gpu_soc_mean_watts": 22.14, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 74.8}, "timestamp": "2026-01-30T15:57:51.909774"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5369.933, "latencies_ms": [5369.933], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. bicycle: 1\n3. umbrella: 1\n4. building: 1\n5. sign: 2\n6. pole: 1\n7. street: 1\n8. wires: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13983.5, "ram_available_mb": 48857.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13983.5, "ram_available_mb": 48857.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.932}, "power_stats": {"power_gpu_soc_mean_watts": 19.09, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 68.932}, "timestamp": "2026-01-30T15:57:59.291182"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5771.928, "latencies_ms": [5771.928], "images_per_second": 0.173, "prompt_tokens": 1117, "response_tokens_est": 62, "n_tiles": 1, "output_text": " The man is standing next to a bicycle, which is in the foreground of the image. The bicycle is positioned to the left of the man, and the man is standing on the right side of the bicycle. The man is also standing in front of a building, which is in the background of the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13983.5, "ram_available_mb": 48857.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.833}, "power_stats": {"power_gpu_soc_mean_watts": 18.399, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 69.833}, "timestamp": "2026-01-30T15:58:07.119535"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3097.866, "latencies_ms": [3097.866], "images_per_second": 0.323, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man is riding a bicycle down a street with a woman walking in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13984.2, "ram_available_mb": 48856.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13984.7, "ram_available_mb": 48856.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.428, "power_cpu_cv_mean_watts": 0.913, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-30T15:58:12.259162"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3970.05, "latencies_ms": [3970.05], "images_per_second": 0.252, "prompt_tokens": 1109, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The image is in black and white, with a street scene featuring a man on a bicycle, a woman with an umbrella, and a building with Chinese characters.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13984.7, "ram_available_mb": 48856.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13984.9, "ram_available_mb": 48856.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.364}, "power_stats": {"power_gpu_soc_mean_watts": 21.318, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 71.364}, "timestamp": "2026-01-30T15:58:18.289061"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4076.597, "latencies_ms": [4076.597], "images_per_second": 0.245, "prompt_tokens": 1432, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A bunch of bananas are hanging from the ceiling of a store, and there is a black shirt hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13984.9, "ram_available_mb": 48856.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13985.6, "ram_available_mb": 48855.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.294}, "power_stats": {"power_gpu_soc_mean_watts": 24.177, "power_cpu_cv_mean_watts": 1.083, "power_sys_5v0_mean_watts": 8.473, "gpu_utilization_percent_mean": 79.294}, "timestamp": "2026-01-30T15:58:24.408620"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5356.419, "latencies_ms": [5356.419], "images_per_second": 0.187, "prompt_tokens": 1446, "response_tokens_est": 45, "n_tiles": 1, "output_text": " banana: 100, bunches: 100, bananas: 100, black cloth: 1, blue door: 1, white wall: 1, wooden stick: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13985.6, "ram_available_mb": 48855.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13986.1, "ram_available_mb": 48854.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.156}, "power_stats": {"power_gpu_soc_mean_watts": 22.046, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.305, "gpu_utilization_percent_mean": 72.156}, "timestamp": "2026-01-30T15:58:31.808226"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5138.447, "latencies_ms": [5138.447], "images_per_second": 0.195, "prompt_tokens": 1450, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The bananas are hanging from the ceiling, with the clothes hanging below them. The bananas are in the foreground, while the clothes are in the background. The bananas are closer to the viewer than the clothes.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13986.1, "ram_available_mb": 48854.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13986.5, "ram_available_mb": 48854.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.721}, "power_stats": {"power_gpu_soc_mean_watts": 22.427, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 8.32, "gpu_utilization_percent_mean": 73.721}, "timestamp": "2026-01-30T15:58:38.994459"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3451.725, "latencies_ms": [3451.725], "images_per_second": 0.29, "prompt_tokens": 1444, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A bunch of bananas are hanging from the ceiling of a store.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13986.5, "ram_available_mb": 48854.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13986.5, "ram_available_mb": 48854.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.607}, "power_stats": {"power_gpu_soc_mean_watts": 26.649, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.601, "gpu_utilization_percent_mean": 80.607}, "timestamp": "2026-01-30T15:58:44.470439"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4003.2, "latencies_ms": [4003.2], "images_per_second": 0.25, "prompt_tokens": 1442, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The bananas are yellow and hanging from the ceiling, the lighting is bright and natural, and the weather is sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13986.5, "ram_available_mb": 48854.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13986.5, "ram_available_mb": 48854.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.697}, "power_stats": {"power_gpu_soc_mean_watts": 25.075, "power_cpu_cv_mean_watts": 1.055, "power_sys_5v0_mean_watts": 8.521, "gpu_utilization_percent_mean": 78.697}, "timestamp": "2026-01-30T15:58:50.506249"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3553.57, "latencies_ms": [3553.57], "images_per_second": 0.281, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A green and white electric train with red and green cargo cars is traveling on a track through a green field with a mountainous backdrop.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13986.5, "ram_available_mb": 48854.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13987.2, "ram_available_mb": 48853.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.777, "power_cpu_cv_mean_watts": 1.187, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T15:58:56.086228"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5587.732, "latencies_ms": [5587.732], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. train: 1\n2. train cars: 3\n3. train tracks: 1\n4. power lines: 1\n5. mountains: 1\n6. grass: 1\n7. trees: 1\n8. houses: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13987.2, "ram_available_mb": 48853.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13987.5, "ram_available_mb": 48853.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.489}, "power_stats": {"power_gpu_soc_mean_watts": 18.467, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 68.489}, "timestamp": "2026-01-30T15:59:03.717619"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5046.527, "latencies_ms": [5046.527], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The train is positioned on the left side of the image, moving from left to right. The background features a mountain range, while the foreground shows a grassy field. The train is relatively close to the camera, while the mountains are farther away.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13987.5, "ram_available_mb": 48853.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13986.4, "ram_available_mb": 48854.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.738}, "power_stats": {"power_gpu_soc_mean_watts": 19.188, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 69.738}, "timestamp": "2026-01-30T15:59:10.808572"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3111.367, "latencies_ms": [3111.367], "images_per_second": 0.321, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A green and white train is traveling through a green field with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13986.4, "ram_available_mb": 48854.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13990.5, "ram_available_mb": 48850.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.4}, "power_stats": {"power_gpu_soc_mean_watts": 23.51, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.201, "gpu_utilization_percent_mean": 78.4}, "timestamp": "2026-01-30T15:59:15.950436"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2963.926, "latencies_ms": [2963.926], "images_per_second": 0.337, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The train is green and white, and the sky is blue with white clouds.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13990.5, "ram_available_mb": 48850.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13990.5, "ram_available_mb": 48850.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.167}, "power_stats": {"power_gpu_soc_mean_watts": 24.271, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 79.167}, "timestamp": "2026-01-30T15:59:20.947463"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3835.879, "latencies_ms": [3835.879], "images_per_second": 0.261, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A man wearing a hat and shorts is standing on the beach with his arms up, and there is a green chair and a kite in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13990.5, "ram_available_mb": 48850.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.656}, "power_stats": {"power_gpu_soc_mean_watts": 21.521, "power_cpu_cv_mean_watts": 1.238, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 71.656}, "timestamp": "2026-01-30T15:59:26.819521"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5388.847, "latencies_ms": [5388.847], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. man: 1\n2. hat: 1\n3. shorts: 1\n4. sand: 1\n5. chair: 1\n6. kite: 1\n7. ocean: 1\n8. sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13991.5, "ram_available_mb": 48849.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13991.2, "ram_available_mb": 48849.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.6}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.6}, "timestamp": "2026-01-30T15:59:34.239942"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4199.611, "latencies_ms": [4199.611], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The man is standing on the left side of the image, with the ocean waves on the right side. The green chair is in the foreground, while the kite is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13991.2, "ram_available_mb": 48849.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13991.2, "ram_available_mb": 48849.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.343}, "power_stats": {"power_gpu_soc_mean_watts": 21.139, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.112, "gpu_utilization_percent_mean": 70.343}, "timestamp": "2026-01-30T15:59:40.463992"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3625.08, "latencies_ms": [3625.08], "images_per_second": 0.276, "prompt_tokens": 1111, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A man is standing on a beach with his arms up, holding a cell phone, and a kite is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13991.2, "ram_available_mb": 48849.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.1}, "power_stats": {"power_gpu_soc_mean_watts": 22.047, "power_cpu_cv_mean_watts": 1.134, "power_sys_5v0_mean_watts": 8.13, "gpu_utilization_percent_mean": 70.1}, "timestamp": "2026-01-30T15:59:46.110097"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3246.455, "latencies_ms": [3246.455], "images_per_second": 0.308, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The sky is blue and cloudy, and the man is wearing a black shirt and khaki shorts.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.963}, "power_stats": {"power_gpu_soc_mean_watts": 23.056, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.205, "gpu_utilization_percent_mean": 73.963}, "timestamp": "2026-01-30T15:59:51.398836"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3233.089, "latencies_ms": [3233.089], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image shows a garden with several potted plants, including broccoli and cabbage, planted in the soil.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.501, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T15:59:56.685205"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3193.454, "latencies_ms": [3193.454], "images_per_second": 0.313, "prompt_tokens": 1113, "response_tokens_est": 19, "n_tiles": 1, "output_text": " broccoli: 2, pot: 2, dirt: 1, plant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.923}, "power_stats": {"power_gpu_soc_mean_watts": 23.435, "power_cpu_cv_mean_watts": 0.939, "power_sys_5v0_mean_watts": 8.183, "gpu_utilization_percent_mean": 73.923}, "timestamp": "2026-01-30T16:00:01.920496"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4206.612, "latencies_ms": [4206.612], "images_per_second": 0.238, "prompt_tokens": 1117, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The broccoli plants are in the foreground, with the dirt and the pink animal in the background. The broccoli plants are near the orange pots, and the dirt is near the broccoli plants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.4, "ram_available_mb": 48849.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.229}, "power_stats": {"power_gpu_soc_mean_watts": 21.105, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 71.229}, "timestamp": "2026-01-30T16:00:08.148078"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7123.457, "latencies_ms": [7123.457], "images_per_second": 0.14, "prompt_tokens": 1111, "response_tokens_est": 85, "n_tiles": 1, "output_text": " The image captures a serene garden scene where two large potted plants, each with a vibrant green hue, are thriving in their terracotta pots. The plants, exhibiting a healthy green color, are the main focus of the image, with one plant positioned slightly to the left and the other to the right. The background, though blurred, reveals a glimpse of a sandy ground, suggesting a well-maintained garden space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.733}, "power_stats": {"power_gpu_soc_mean_watts": 17.049, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 66.733}, "timestamp": "2026-01-30T16:00:17.314711"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4039.239, "latencies_ms": [4039.239], "images_per_second": 0.248, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image shows a garden with green plants in pots, with a pinkish-brown ground. The plants are in pots, and the ground is covered with dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13991.9, "ram_available_mb": 48849.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.455}, "power_stats": {"power_gpu_soc_mean_watts": 21.242, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 68.455}, "timestamp": "2026-01-30T16:00:23.397131"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3621.795, "latencies_ms": [3621.795], "images_per_second": 0.276, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " An elderly man is walking a small brown and white pony with a red bridle, while a young boy sits on the pony.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.033}, "power_stats": {"power_gpu_soc_mean_watts": 22.127, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 8.155, "gpu_utilization_percent_mean": 70.033}, "timestamp": "2026-01-30T16:00:29.051803"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5400.776, "latencies_ms": [5400.776], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. person: 2\n2. child: 1\n3. horse: 1\n4. pony: 1\n5. man: 1\n6. woman: 1\n7. chair: 1\n8. building: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.044}, "power_stats": {"power_gpu_soc_mean_watts": 18.817, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 70.044}, "timestamp": "2026-01-30T16:00:36.494010"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4729.061, "latencies_ms": [4729.061], "images_per_second": 0.211, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The man is holding the pony's reins, which are in front of him, and the pony is in front of the man. The pony is in the foreground, while the man and the boy are in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.923}, "power_stats": {"power_gpu_soc_mean_watts": 19.793, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 70.923}, "timestamp": "2026-01-30T16:00:43.258704"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4108.172, "latencies_ms": [4108.172], "images_per_second": 0.243, "prompt_tokens": 1111, "response_tokens_est": 35, "n_tiles": 1, "output_text": " An elderly man and a young boy are walking down a sidewalk with a small brown horse. The man is holding the horse's reins and the boy is sitting on the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.1, "ram_available_mb": 48848.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.088}, "power_stats": {"power_gpu_soc_mean_watts": 21.218, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.131, "gpu_utilization_percent_mean": 70.088}, "timestamp": "2026-01-30T16:00:49.379971"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4617.458, "latencies_ms": [4617.458], "images_per_second": 0.217, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a young boy riding a small brown and white pony, with the pony wearing a red bridle. The setting appears to be a sunny day with clear skies, and the ground is paved with bricks.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.553}, "power_stats": {"power_gpu_soc_mean_watts": 20.219, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.553}, "timestamp": "2026-01-30T16:00:56.023083"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4002.755, "latencies_ms": [4002.755], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A young boy with blonde hair and blue jeans is walking down a dirt path in a field of blue flowers, carrying a brown teddy bear on his back.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.697}, "power_stats": {"power_gpu_soc_mean_watts": 21.183, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 70.697}, "timestamp": "2026-01-30T16:01:02.094039"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5930.847, "latencies_ms": [5930.847], "images_per_second": 0.169, "prompt_tokens": 1113, "response_tokens_est": 64, "n_tiles": 1, "output_text": " 1. child: 1\n2. blue shirt: 1\n3. blue jeans: 1\n4. brown shoes: 1\n5. brown teddy bear: 1\n6. blue flowers: 1\n7. dirt path: 1\n8. green leaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.22}, "power_stats": {"power_gpu_soc_mean_watts": 18.017, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 70.22}, "timestamp": "2026-01-30T16:01:10.073587"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4212.887, "latencies_ms": [4212.887], "images_per_second": 0.237, "prompt_tokens": 1117, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The child is standing on the left side of the image, with the path leading to the right. The child is positioned in the foreground, with the flowers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.629}, "power_stats": {"power_gpu_soc_mean_watts": 20.75, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 72.629}, "timestamp": "2026-01-30T16:01:16.335245"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3186.153, "latencies_ms": [3186.153], "images_per_second": 0.314, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A young boy with blonde hair is walking down a dirt path in a field of blue flowers.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.962}, "power_stats": {"power_gpu_soc_mean_watts": 23.76, "power_cpu_cv_mean_watts": 1.062, "power_sys_5v0_mean_watts": 8.288, "gpu_utilization_percent_mean": 76.962}, "timestamp": "2026-01-30T16:01:21.538155"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5340.469, "latencies_ms": [5340.469], "images_per_second": 0.187, "prompt_tokens": 1109, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image features a young boy with blonde hair, wearing a blue and white striped shirt and blue jeans, walking on a dirt path surrounded by a field of blue flowers. The lighting is natural and soft, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.622}, "power_stats": {"power_gpu_soc_mean_watts": 18.887, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.984, "gpu_utilization_percent_mean": 68.622}, "timestamp": "2026-01-30T16:01:28.898227"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3262.331, "latencies_ms": [3262.331], "images_per_second": 0.307, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " An orange sits on the ground in a parking lot, with a line of cars in the background.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.185}, "power_stats": {"power_gpu_soc_mean_watts": 22.982, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 76.185}, "timestamp": "2026-01-30T16:01:34.208605"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2284.167, "latencies_ms": [2284.167], "images_per_second": 0.438, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " orange: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.974, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.226, "gpu_utilization_percent_mean": 81.0}, "timestamp": "2026-01-30T16:01:38.511845"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4760.958, "latencies_ms": [4760.958], "images_per_second": 0.21, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The orange is positioned in the foreground, with the parking lot and cars in the background. The orange is located to the left of the white line on the asphalt, and the parking lot extends to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.1}, "power_stats": {"power_gpu_soc_mean_watts": 19.948, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 70.1}, "timestamp": "2026-01-30T16:01:45.326248"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3171.235, "latencies_ms": [3171.235], "images_per_second": 0.315, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A single orange sits on the ground in a parking lot, surrounded by cars and trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.615}, "power_stats": {"power_gpu_soc_mean_watts": 23.267, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.191, "gpu_utilization_percent_mean": 76.615}, "timestamp": "2026-01-30T16:01:50.549283"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3602.601, "latencies_ms": [3602.601], "images_per_second": 0.278, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The orange is a vibrant orange color, and the asphalt is black. The sky is cloudy, and there are trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.433}, "power_stats": {"power_gpu_soc_mean_watts": 22.606, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.177, "gpu_utilization_percent_mean": 73.433}, "timestamp": "2026-01-30T16:01:56.200111"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3839.02, "latencies_ms": [3839.02], "images_per_second": 0.26, "prompt_tokens": 1432, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit is sitting at a table with a bowl of food and several empty beer bottles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.5}, "power_stats": {"power_gpu_soc_mean_watts": 25.121, "power_cpu_cv_mean_watts": 1.051, "power_sys_5v0_mean_watts": 8.541, "gpu_utilization_percent_mean": 78.5}, "timestamp": "2026-01-30T16:02:02.075351"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4268.44, "latencies_ms": [4268.44], "images_per_second": 0.234, "prompt_tokens": 1446, "response_tokens_est": 27, "n_tiles": 1, "output_text": " man:1, bowl:1, bottle:4, keys:1, remote:1, table:1, wall:1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.056}, "power_stats": {"power_gpu_soc_mean_watts": 24.276, "power_cpu_cv_mean_watts": 1.179, "power_sys_5v0_mean_watts": 8.466, "gpu_utilization_percent_mean": 76.056}, "timestamp": "2026-01-30T16:02:08.384410"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6543.625, "latencies_ms": [6543.625], "images_per_second": 0.153, "prompt_tokens": 1450, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The man is seated at a table with a bowl of food in front of him, which is positioned to his left. The bottles of beer are arranged to his right, with one bottle closer to the camera than the others. The keys are placed on the table in front of the man, near the bowl of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.786}, "power_stats": {"power_gpu_soc_mean_watts": 20.128, "power_cpu_cv_mean_watts": 1.594, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 70.786}, "timestamp": "2026-01-30T16:02:16.951362"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3911.928, "latencies_ms": [3911.928], "images_per_second": 0.256, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a suit is sitting at a table with a bowl of food and several bottles of beer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.497, "power_cpu_cv_mean_watts": 1.026, "power_sys_5v0_mean_watts": 8.535, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-30T16:02:22.875587"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3740.338, "latencies_ms": [3740.338], "images_per_second": 0.267, "prompt_tokens": 1442, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The man is wearing a grey suit and white shirt. The table is made of wood.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.29}, "power_stats": {"power_gpu_soc_mean_watts": 25.713, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.547, "gpu_utilization_percent_mean": 77.29}, "timestamp": "2026-01-30T16:02:28.670887"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3595.429, "latencies_ms": [3595.429], "images_per_second": 0.278, "prompt_tokens": 1099, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image shows a hotel room with a large bed, a desk with a chair, and a window with a view of the outside.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.2}, "power_stats": {"power_gpu_soc_mean_watts": 22.499, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.197, "gpu_utilization_percent_mean": 74.2}, "timestamp": "2026-01-30T16:02:34.335943"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5362.406, "latencies_ms": [5362.406], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bed: 2\n2. pillows: 4\n3. chair: 1\n4. desk: 1\n5. lamp: 1\n6. window: 1\n7. carpet: 1\n8. wall: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.978}, "power_stats": {"power_gpu_soc_mean_watts": 18.851, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.978}, "timestamp": "2026-01-30T16:02:41.715836"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4405.199, "latencies_ms": [4405.199], "images_per_second": 0.227, "prompt_tokens": 1117, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The bed is positioned to the left of the desk, with the desk located in the foreground of the image. The window is situated to the right of the bed, providing natural light to the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.3, "ram_available_mb": 48844.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.595}, "power_stats": {"power_gpu_soc_mean_watts": 20.503, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 71.595}, "timestamp": "2026-01-30T16:02:48.162277"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3065.343, "latencies_ms": [3065.343], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A hotel room with a large bed, a desk, and a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.72}, "power_stats": {"power_gpu_soc_mean_watts": 23.363, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.15, "gpu_utilization_percent_mean": 76.72}, "timestamp": "2026-01-30T16:02:53.264393"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3843.07, "latencies_ms": [3843.07], "images_per_second": 0.26, "prompt_tokens": 1109, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window. The walls are painted in a light color, and the carpet is a neutral shade.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.834, "power_cpu_cv_mean_watts": 1.301, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T16:02:59.152062"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3896.633, "latencies_ms": [3896.633], "images_per_second": 0.257, "prompt_tokens": 1100, "response_tokens_est": 32, "n_tiles": 1, "output_text": " Three stuffed animals, including a bear, a snowman, and a bear wearing a hat, are sitting on a blue surface with a red and orange background.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.693, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 71.242}, "timestamp": "2026-01-30T16:03:05.101055"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4489.737, "latencies_ms": [4489.737], "images_per_second": 0.223, "prompt_tokens": 1114, "response_tokens_est": 41, "n_tiles": 1, "output_text": " teddy bear: 1, hat: 1, scarf: 1, shirt: 1, shirt: 1, shirt: 1, shirt: 1, shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.649}, "power_stats": {"power_gpu_soc_mean_watts": 20.495, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 70.649}, "timestamp": "2026-01-30T16:03:11.623579"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5704.67, "latencies_ms": [5704.67], "images_per_second": 0.175, "prompt_tokens": 1118, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The teddy bear wearing the green hat is positioned to the left of the teddy bear with the red scarf, which is in front of the teddy bear with the black hat. The teddy bear with the red scarf is in the foreground, while the teddy bear with the black hat is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.401, "power_cpu_cv_mean_watts": 1.643, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 67.0}, "timestamp": "2026-01-30T16:03:19.340409"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2902.072, "latencies_ms": [2902.072], "images_per_second": 0.345, "prompt_tokens": 1112, "response_tokens_est": 15, "n_tiles": 1, "output_text": " Three stuffed animals are sitting on a table with a red and orange background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.875}, "power_stats": {"power_gpu_soc_mean_watts": 24.088, "power_cpu_cv_mean_watts": 0.917, "power_sys_5v0_mean_watts": 8.298, "gpu_utilization_percent_mean": 75.875}, "timestamp": "2026-01-30T16:03:24.285724"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3764.627, "latencies_ms": [3764.627], "images_per_second": 0.266, "prompt_tokens": 1110, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The teddy bears are in a room with a red and orange background. The teddy bears are made of plush material and are in different colors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.4, "ram_available_mb": 48843.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.031}, "power_stats": {"power_gpu_soc_mean_watts": 21.832, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 69.031}, "timestamp": "2026-01-30T16:03:30.072110"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3265.236, "latencies_ms": [3265.236], "images_per_second": 0.306, "prompt_tokens": 1432, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A glass bowl filled with oranges sits on a table.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 83.815}, "power_stats": {"power_gpu_soc_mean_watts": 26.288, "power_cpu_cv_mean_watts": 0.771, "power_sys_5v0_mean_watts": 8.635, "gpu_utilization_percent_mean": 83.815}, "timestamp": "2026-01-30T16:03:35.375412"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3341.39, "latencies_ms": [3341.39], "images_per_second": 0.299, "prompt_tokens": 1446, "response_tokens_est": 11, "n_tiles": 1, "output_text": " bowl: 1\noranges: 12", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.0, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 85.821}, "power_stats": {"power_gpu_soc_mean_watts": 26.24, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.565, "gpu_utilization_percent_mean": 85.821}, "timestamp": "2026-01-30T16:03:40.774481"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4008.375, "latencies_ms": [4008.375], "images_per_second": 0.249, "prompt_tokens": 1450, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The oranges are in the foreground, on a tablecloth, and the bowl is in the middle of the table.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13998.9, "ram_available_mb": 48842.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.853}, "power_stats": {"power_gpu_soc_mean_watts": 24.987, "power_cpu_cv_mean_watts": 1.071, "power_sys_5v0_mean_watts": 8.51, "gpu_utilization_percent_mean": 77.853}, "timestamp": "2026-01-30T16:03:46.828238"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3211.482, "latencies_ms": [3211.482], "images_per_second": 0.311, "prompt_tokens": 1444, "response_tokens_est": 10, "n_tiles": 1, "output_text": " A bowl of oranges is sitting on a table.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.8, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.778}, "power_stats": {"power_gpu_soc_mean_watts": 27.032, "power_cpu_cv_mean_watts": 0.771, "power_sys_5v0_mean_watts": 8.647, "gpu_utilization_percent_mean": 84.778}, "timestamp": "2026-01-30T16:03:52.080017"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3347.979, "latencies_ms": [3347.979], "images_per_second": 0.299, "prompt_tokens": 1442, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The oranges are bright orange and the bowl is clear glass.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13999.7, "ram_available_mb": 48841.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.429}, "power_stats": {"power_gpu_soc_mean_watts": 26.609, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.626, "gpu_utilization_percent_mean": 81.429}, "timestamp": "2026-01-30T16:03:57.476237"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2656.888, "latencies_ms": [2656.888], "images_per_second": 0.376, "prompt_tokens": 766, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A surfer is riding a large wave in the ocean, with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5179.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.136}, "power_stats": {"power_gpu_soc_mean_watts": 20.4, "power_cpu_cv_mean_watts": 1.11, "power_sys_5v0_mean_watts": 7.737, "gpu_utilization_percent_mean": 70.136}, "timestamp": "2026-01-30T16:04:02.163788"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5135.564, "latencies_ms": [5135.564], "images_per_second": 0.195, "prompt_tokens": 780, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Wave: 1\n4. Ocean: 1\n5. Sky: 1\n6. Clouds: 1\n7. Water: 1\n8. Surfboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 64.273}, "power_stats": {"power_gpu_soc_mean_watts": 16.17, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 7.663, "gpu_utilization_percent_mean": 64.273}, "timestamp": "2026-01-30T16:04:09.332105"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3735.208, "latencies_ms": [3735.208], "images_per_second": 0.268, "prompt_tokens": 784, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, riding a wave that dominates the majority of the image. The wave is in the background, with the sky occupying the upper portion of the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.387}, "power_stats": {"power_gpu_soc_mean_watts": 18.194, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.712, "gpu_utilization_percent_mean": 65.387}, "timestamp": "2026-01-30T16:04:15.107559"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3228.269, "latencies_ms": [3228.269], "images_per_second": 0.31, "prompt_tokens": 778, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A surfer is riding a large wave in the ocean. The surfer is wearing a black wetsuit and is standing on a surfboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.694, "power_cpu_cv_mean_watts": 1.324, "power_sys_5v0_mean_watts": 7.795, "gpu_utilization_percent_mean": 68.0}, "timestamp": "2026-01-30T16:04:20.349920"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4086.94, "latencies_ms": [4086.94], "images_per_second": 0.245, "prompt_tokens": 776, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The image captures a surfer riding a large wave in the ocean, with the surfer wearing a black wetsuit and a white surfboard. The sky is overcast, and the water is a deep blue color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5180.1, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 65.471}, "power_stats": {"power_gpu_soc_mean_watts": 17.626, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.74, "gpu_utilization_percent_mean": 65.471}, "timestamp": "2026-01-30T16:04:26.491564"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2842.552, "latencies_ms": [2842.552], "images_per_second": 0.352, "prompt_tokens": 1099, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is sitting on a laptop computer and looking at the screen.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.957}, "power_stats": {"power_gpu_soc_mean_watts": 24.455, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.289, "gpu_utilization_percent_mean": 77.957}, "timestamp": "2026-01-30T16:04:31.372064"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5581.081, "latencies_ms": [5581.081], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. cat: 1\n2. laptop: 1\n3. keyboard: 1\n4. screen: 1\n5. mouse: 1\n6. mousepad: 1\n7. cat collar: 1\n8. cat's fur: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.848}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 69.848}, "timestamp": "2026-01-30T16:04:38.962862"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4637.091, "latencies_ms": [4637.091], "images_per_second": 0.216, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The cat is in the foreground, sitting on the left side of the laptop, and the laptop is on the right side of the image. The cat is near the laptop, and the laptop is near the couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.744}, "power_stats": {"power_gpu_soc_mean_watts": 19.977, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 67.744}, "timestamp": "2026-01-30T16:04:45.626973"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2828.501, "latencies_ms": [2828.501], "images_per_second": 0.354, "prompt_tokens": 1111, "response_tokens_est": 14, "n_tiles": 1, "output_text": " A cat is sitting on a laptop computer, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.565}, "power_stats": {"power_gpu_soc_mean_watts": 24.751, "power_cpu_cv_mean_watts": 0.853, "power_sys_5v0_mean_watts": 8.316, "gpu_utilization_percent_mean": 79.565}, "timestamp": "2026-01-30T16:04:50.476227"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2776.606, "latencies_ms": [2776.606], "images_per_second": 0.36, "prompt_tokens": 1109, "response_tokens_est": 13, "n_tiles": 1, "output_text": " The cat is white and brown, and the laptop is black.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 81.591}, "power_stats": {"power_gpu_soc_mean_watts": 24.858, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 8.332, "gpu_utilization_percent_mean": 81.591}, "timestamp": "2026-01-30T16:04:55.265325"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3774.036, "latencies_ms": [3774.036], "images_per_second": 0.265, "prompt_tokens": 1099, "response_tokens_est": 30, "n_tiles": 1, "output_text": " In the image, a group of horses, including a brown one, are gathered around a hay feeder, with a house and trees in the background.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13997.9, "ram_available_mb": 48843.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.355}, "power_stats": {"power_gpu_soc_mean_watts": 22.227, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.154, "gpu_utilization_percent_mean": 72.355}, "timestamp": "2026-01-30T16:05:01.087943"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4106.39, "latencies_ms": [4106.39], "images_per_second": 0.244, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " horse: 4, hay: 1, fence: 1, trees: 1, house: 1, power lines: 1, grass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.618}, "power_stats": {"power_gpu_soc_mean_watts": 21.278, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 69.618}, "timestamp": "2026-01-30T16:05:07.209478"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4552.931, "latencies_ms": [4552.931], "images_per_second": 0.22, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The brown horse is in the foreground, eating hay from a feeder. The brown horse is in the background, eating hay from a feeder. The brown horse is in the foreground, eating hay from a feeder.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.8, "ram_available_mb": 48843.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.053}, "power_stats": {"power_gpu_soc_mean_watts": 20.219, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 69.053}, "timestamp": "2026-01-30T16:05:13.776747"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4968.308, "latencies_ms": [4968.308], "images_per_second": 0.201, "prompt_tokens": 1111, "response_tokens_est": 49, "n_tiles": 1, "output_text": " In a rural setting, a group of horses, including a brown foal, are gathered around a hay feeder, enjoying their meal. The scene is set in a field with a fence in the background, and power lines can be seen above.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.171}, "power_stats": {"power_gpu_soc_mean_watts": 19.58, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 71.171}, "timestamp": "2026-01-30T16:05:20.767174"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4897.362, "latencies_ms": [4897.362], "images_per_second": 0.204, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a group of horses in a field with a mix of brown and black coats, with the brown horses being the most prominent. The lighting is natural and bright, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.366}, "power_stats": {"power_gpu_soc_mean_watts": 19.649, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 69.366}, "timestamp": "2026-01-30T16:05:27.715172"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3335.232, "latencies_ms": [3335.232], "images_per_second": 0.3, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A man in a black wetsuit is riding a yellow surfboard on a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.815}, "power_stats": {"power_gpu_soc_mean_watts": 22.838, "power_cpu_cv_mean_watts": 1.008, "power_sys_5v0_mean_watts": 8.145, "gpu_utilization_percent_mean": 78.815}, "timestamp": "2026-01-30T16:05:33.097037"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5747.916, "latencies_ms": [5747.916], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Water: 1\n5. Sky: 1\n6. Clouds: 1\n7. Land: 1\n8. Surfboard sticker: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.875}, "power_stats": {"power_gpu_soc_mean_watts": 18.393, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 69.875}, "timestamp": "2026-01-30T16:05:40.871053"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4607.26, "latencies_ms": [4607.26], "images_per_second": 0.217, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground, with the ocean and coastline in the background. The surfer is crouched low on the board, with the wave forming a near-perfect arc around him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.237}, "power_stats": {"power_gpu_soc_mean_watts": 20.03, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 70.237}, "timestamp": "2026-01-30T16:05:47.521111"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3151.76, "latencies_ms": [3151.76], "images_per_second": 0.317, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A man in a wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.529, "power_cpu_cv_mean_watts": 1.032, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 76.269}, "timestamp": "2026-01-30T16:05:52.703253"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4073.117, "latencies_ms": [4073.117], "images_per_second": 0.246, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The surfer is wearing a black wetsuit and is riding a yellow surfboard. The water is a greenish-blue color, and the sky is partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.765}, "power_stats": {"power_gpu_soc_mean_watts": 21.126, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.074, "gpu_utilization_percent_mean": 68.765}, "timestamp": "2026-01-30T16:05:58.800022"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5159.592, "latencies_ms": [5159.592], "images_per_second": 0.194, "prompt_tokens": 1099, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a collection of pumpkins, including a large one with a face carved into it, a smaller one with a skull design, and a third pumpkin with a carved face, all arranged on a table with a vase of pink and white flowers in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.116}, "power_stats": {"power_gpu_soc_mean_watts": 19.34, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 71.116}, "timestamp": "2026-01-30T16:06:06.014818"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2292.266, "latencies_ms": [2292.266], "images_per_second": 0.436, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " pumpkin: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.556}, "power_stats": {"power_gpu_soc_mean_watts": 25.198, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.237, "gpu_utilization_percent_mean": 84.556}, "timestamp": "2026-01-30T16:06:10.331180"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4191.56, "latencies_ms": [4191.56], "images_per_second": 0.239, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The pumpkin with the face is positioned in the foreground, while the other pumpkins are in the background. The pumpkin with the face is also closer to the camera than the other pumpkins.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.257}, "power_stats": {"power_gpu_soc_mean_watts": 20.98, "power_cpu_cv_mean_watts": 1.372, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 73.257}, "timestamp": "2026-01-30T16:06:16.556299"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2937.54, "latencies_ms": [2937.54], "images_per_second": 0.34, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A collection of pumpkins with faces carved into them are displayed on a table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.958}, "power_stats": {"power_gpu_soc_mean_watts": 24.222, "power_cpu_cv_mean_watts": 0.834, "power_sys_5v0_mean_watts": 8.255, "gpu_utilization_percent_mean": 77.958}, "timestamp": "2026-01-30T16:06:21.524484"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3101.444, "latencies_ms": [3101.444], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The pumpkins are orange, the flowers are pink and white, and the lighting is natural.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.64}, "power_stats": {"power_gpu_soc_mean_watts": 24.01, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 76.64}, "timestamp": "2026-01-30T16:06:26.638390"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3705.635, "latencies_ms": [3705.635], "images_per_second": 0.27, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " The image depicts a bathroom with a white sink, a mirror, and a door, all of which are in a state of disrepair.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.954, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 8.101, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T16:06:32.372764"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4105.855, "latencies_ms": [4105.855], "images_per_second": 0.244, "prompt_tokens": 1114, "response_tokens_est": 35, "n_tiles": 1, "output_text": " sink: 1, mirror: 1, door: 1, trash bag: 1, toilet: 1, shelf: 1, wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.206}, "power_stats": {"power_gpu_soc_mean_watts": 21.255, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 8.108, "gpu_utilization_percent_mean": 72.206}, "timestamp": "2026-01-30T16:06:38.508408"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4641.431, "latencies_ms": [4641.431], "images_per_second": 0.215, "prompt_tokens": 1118, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The sink is located to the left of the door, and the trash bag is positioned in the foreground, closer to the camera. The mirror is above the sink, and the door is to the right of the sink.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.289}, "power_stats": {"power_gpu_soc_mean_watts": 20.356, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 69.289}, "timestamp": "2026-01-30T16:06:45.162319"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2682.236, "latencies_ms": [2682.236], "images_per_second": 0.373, "prompt_tokens": 1112, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A bathroom with a white sink, mirror, and door.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.6, "ram_available_mb": 48840.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.136}, "power_stats": {"power_gpu_soc_mean_watts": 24.878, "power_cpu_cv_mean_watts": 0.728, "power_sys_5v0_mean_watts": 8.322, "gpu_utilization_percent_mean": 80.136}, "timestamp": "2026-01-30T16:06:49.859109"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2903.271, "latencies_ms": [2903.271], "images_per_second": 0.344, "prompt_tokens": 1110, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The room is lit by a yellowish light, and the walls are white.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.917}, "power_stats": {"power_gpu_soc_mean_watts": 24.342, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 76.917}, "timestamp": "2026-01-30T16:06:54.794198"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3236.733, "latencies_ms": [3236.733], "images_per_second": 0.309, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A young child sits on a bed with a laptop in front of them, looking at the screen.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 14000.0, "ram_available_mb": 48840.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.269}, "power_stats": {"power_gpu_soc_mean_watts": 23.283, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.197, "gpu_utilization_percent_mean": 73.269}, "timestamp": "2026-01-30T16:07:00.059135"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5524.151, "latencies_ms": [5524.151], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. laptop: 1\n2. child: 1\n3. bed: 1\n4. wall: 1\n5. screen: 1\n6. keyboard: 1\n7. laptop screen: 1\n8. laptop body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.674}, "power_stats": {"power_gpu_soc_mean_watts": 18.548, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 69.674}, "timestamp": "2026-01-30T16:07:07.615076"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3921.462, "latencies_ms": [3921.462], "images_per_second": 0.255, "prompt_tokens": 1117, "response_tokens_est": 32, "n_tiles": 1, "output_text": " The laptop is on the left side of the bed, and the child is on the right side. The child is sitting closer to the laptop than the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.438}, "power_stats": {"power_gpu_soc_mean_watts": 21.771, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.129, "gpu_utilization_percent_mean": 71.438}, "timestamp": "2026-01-30T16:07:13.577667"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3014.448, "latencies_ms": [3014.448], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A little girl is sitting on a bed with a laptop in front of her.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.68}, "power_stats": {"power_gpu_soc_mean_watts": 23.56, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 76.68}, "timestamp": "2026-01-30T16:07:18.616902"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3297.493, "latencies_ms": [3297.493], "images_per_second": 0.303, "prompt_tokens": 1109, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image is in black and white, with a white background and a white laptop on a white bed.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.148}, "power_stats": {"power_gpu_soc_mean_watts": 23.032, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.182, "gpu_utilization_percent_mean": 73.148}, "timestamp": "2026-01-30T16:07:23.960890"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3379.002, "latencies_ms": [3379.002], "images_per_second": 0.296, "prompt_tokens": 1099, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A skier wearing a brown jacket, blue helmet, and goggles is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13999.1, "ram_available_mb": 48841.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.393}, "power_stats": {"power_gpu_soc_mean_watts": 23.019, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.181, "gpu_utilization_percent_mean": 74.393}, "timestamp": "2026-01-30T16:07:29.375122"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5608.823, "latencies_ms": [5608.823], "images_per_second": 0.178, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skier: 1\n2. ski poles: 2\n3. skis: 2\n4. snow: 1\n5. trees: 1\n6. jacket: 1\n7. helmet: 1\n8. goggles: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.0, "ram_available_mb": 48841.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.468}, "power_stats": {"power_gpu_soc_mean_watts": 18.511, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 70.468}, "timestamp": "2026-01-30T16:07:37.034911"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4593.851, "latencies_ms": [4593.851], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The skier is positioned in the foreground of the image, with the trees in the background. The skier is moving towards the right side of the image, while the trees are located on the left side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.789}, "power_stats": {"power_gpu_soc_mean_watts": 20.24, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 68.789}, "timestamp": "2026-01-30T16:07:43.651423"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2871.832, "latencies_ms": [2871.832], "images_per_second": 0.348, "prompt_tokens": 1111, "response_tokens_est": 13, "n_tiles": 1, "output_text": " A skier is skiing down a snowy slope surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.304}, "power_stats": {"power_gpu_soc_mean_watts": 24.125, "power_cpu_cv_mean_watts": 0.818, "power_sys_5v0_mean_watts": 8.229, "gpu_utilization_percent_mean": 79.304}, "timestamp": "2026-01-30T16:07:48.541759"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3273.469, "latencies_ms": [3273.469], "images_per_second": 0.305, "prompt_tokens": 1109, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The skier is wearing a brown jacket and blue helmet, and the snow is white and fluffy.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.259}, "power_stats": {"power_gpu_soc_mean_watts": 23.013, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.16, "gpu_utilization_percent_mean": 76.259}, "timestamp": "2026-01-30T16:07:53.840367"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4139.196, "latencies_ms": [4139.196], "images_per_second": 0.242, "prompt_tokens": 1099, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The image depicts a spacious hotel room with a large bed, a blue armchair, and a nightstand with a lamp, all set against a backdrop of a window with curtains.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.206}, "power_stats": {"power_gpu_soc_mean_watts": 21.278, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.128, "gpu_utilization_percent_mean": 71.206}, "timestamp": "2026-01-30T16:08:00.024018"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5528.457, "latencies_ms": [5528.457], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. bed: 1\n2. lamps: 2\n3. chair: 1\n4. suitcase: 1\n5. ottoman: 1\n6. window: 1\n7. wall: 1\n8. carpet: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.304}, "power_stats": {"power_gpu_soc_mean_watts": 18.828, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 68.304}, "timestamp": "2026-01-30T16:08:07.584557"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4819.62, "latencies_ms": [4819.62], "images_per_second": 0.207, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The bed is positioned in the center of the room, with the armchair to its left and the lamp to its right. The window is located behind the bed, and the suitcase is placed to the left of the bed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.7, "ram_available_mb": 48840.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 14000.9, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.825}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.825}, "timestamp": "2026-01-30T16:08:14.432964"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2949.22, "latencies_ms": [2949.22], "images_per_second": 0.339, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A hotel room with a large bed, a blue chair, and a lamp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.9, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.542}, "power_stats": {"power_gpu_soc_mean_watts": 24.321, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.281, "gpu_utilization_percent_mean": 76.542}, "timestamp": "2026-01-30T16:08:19.426629"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3434.981, "latencies_ms": [3434.981], "images_per_second": 0.291, "prompt_tokens": 1109, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The room is well-lit with natural light coming through the window, and the walls are painted in a neutral color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.143}, "power_stats": {"power_gpu_soc_mean_watts": 23.006, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 73.143}, "timestamp": "2026-01-30T16:08:24.894899"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4500.009, "latencies_ms": [4500.009], "images_per_second": 0.222, "prompt_tokens": 1099, "response_tokens_est": 41, "n_tiles": 1, "output_text": " In the image, a skier is performing a jump on a red rail on a snowy mountain, with other skiers and snowboarders in the background, and a ski lift visible in the distance.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 14001.2, "ram_available_mb": 48839.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.27}, "power_stats": {"power_gpu_soc_mean_watts": 20.202, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 70.27}, "timestamp": "2026-01-30T16:08:31.424506"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6188.03, "latencies_ms": [6188.03], "images_per_second": 0.162, "prompt_tokens": 1113, "response_tokens_est": 70, "n_tiles": 1, "output_text": " 1. snowboard: 1\n2. skier: 1\n3. snowboarder: 1\n4. ski lift: 1\n5. ski pole: 1\n6. ski pole holder: 1\n7. ski pole tip: 1\n8. snowboarder's foot: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.5}, "power_stats": {"power_gpu_soc_mean_watts": 17.985, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 67.5}, "timestamp": "2026-01-30T16:08:39.669790"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5985.322, "latencies_ms": [5985.322], "images_per_second": 0.167, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main object, a snowboarder, is in the foreground, performing a trick on a red rail. The background features a ski lift and other skiers, indicating a bustling ski resort. The snowboarder is positioned to the left of the red rail, and the ski lift is located further back in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.9}, "power_stats": {"power_gpu_soc_mean_watts": 18.001, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 67.9}, "timestamp": "2026-01-30T16:08:47.701175"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3223.526, "latencies_ms": [3223.526], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 19, "n_tiles": 1, "output_text": " A group of people are skiing down a snowy hill, with a red structure in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.231}, "power_stats": {"power_gpu_soc_mean_watts": 23.205, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.155, "gpu_utilization_percent_mean": 76.231}, "timestamp": "2026-01-30T16:08:52.944998"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4400.705, "latencies_ms": [4400.705], "images_per_second": 0.227, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image features a vibrant scene of a snow-covered mountain with a clear blue sky, and the snow is a bright white color. The lighting is natural and bright, indicating that it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.778}, "power_stats": {"power_gpu_soc_mean_watts": 20.641, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.096, "gpu_utilization_percent_mean": 71.778}, "timestamp": "2026-01-30T16:08:59.369577"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5344.536, "latencies_ms": [5344.536], "images_per_second": 0.187, "prompt_tokens": 1100, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The image captures a vibrant scene of urban artistry, where a graffiti-covered wall serves as a canvas for a multitude of colorful tags and designs, with a prominent sign reading \"THE ONE N' ONLY\" and a parking meter standing as a silent observer amidst the creative chaos.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.956}, "power_stats": {"power_gpu_soc_mean_watts": 18.738, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 68.956}, "timestamp": "2026-01-30T16:09:06.757274"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5106.226, "latencies_ms": [5106.226], "images_per_second": 0.196, "prompt_tokens": 1114, "response_tokens_est": 51, "n_tiles": 1, "output_text": " 1. Graffiti wall\n2. Graffiti art\n3. Graffiti lettering\n4. Graffiti design\n5. Graffiti lettering\n6. Graffiti design\n7. Graffiti lettering\n8. Graffiti design", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.605}, "power_stats": {"power_gpu_soc_mean_watts": 19.2, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 68.605}, "timestamp": "2026-01-30T16:09:13.883967"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4437.326, "latencies_ms": [4437.326], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The graffiti is located on the side of a building, with the parking meter situated in the foreground. The parking meter is positioned near the entrance of the building, with the graffiti extending further into the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.703}, "power_stats": {"power_gpu_soc_mean_watts": 20.701, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 70.703}, "timestamp": "2026-01-30T16:09:20.377501"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4983.532, "latencies_ms": [4983.532], "images_per_second": 0.201, "prompt_tokens": 1112, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a vibrant scene of urban artistry, where a graffiti-covered wall serves as a canvas for various tags and designs. The wall, adorned with a mix of colors and patterns, stands as a testament to the creative energy of the city.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.39}, "power_stats": {"power_gpu_soc_mean_watts": 19.531, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 67.39}, "timestamp": "2026-01-30T16:09:27.396432"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5715.905, "latencies_ms": [5715.905], "images_per_second": 0.175, "prompt_tokens": 1110, "response_tokens_est": 61, "n_tiles": 1, "output_text": " The image features a vibrant and colorful graffiti-covered wall with a mix of black, white, blue, and red colors. The lighting is natural, likely from the sun, casting shadows and highlights on the wall. The materials used for the graffiti are spray paint, which gives the artwork a textured appearance.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13999.6, "ram_available_mb": 48841.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.458}, "power_stats": {"power_gpu_soc_mean_watts": 18.351, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 67.458}, "timestamp": "2026-01-30T16:09:35.134749"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2904.571, "latencies_ms": [2904.571], "images_per_second": 0.344, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A surfer is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 14000.1, "ram_available_mb": 48840.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14005.5, "ram_available_mb": 48835.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.958}, "power_stats": {"power_gpu_soc_mean_watts": 24.24, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 78.958}, "timestamp": "2026-01-30T16:09:40.083267"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5555.501, "latencies_ms": [5555.501], "images_per_second": 0.18, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. Surfer: 1\n2. Surfboard: 1\n3. Ocean: 1\n4. Wave: 1\n5. Water: 1\n6. Sky: 1\n7. Clouds: 1\n8. Sunlight: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14006.0, "ram_available_mb": 48834.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14005.1, "ram_available_mb": 48835.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.681}, "power_stats": {"power_gpu_soc_mean_watts": 18.793, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 70.681}, "timestamp": "2026-01-30T16:09:47.688603"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4953.6, "latencies_ms": [4953.6], "images_per_second": 0.202, "prompt_tokens": 1117, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, riding a wave that is moving towards the right side of the frame. The wave is the main focus of the image, with the surfer positioned on the left side of the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.1, "ram_available_mb": 48835.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 14005.3, "ram_available_mb": 48835.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.095}, "power_stats": {"power_gpu_soc_mean_watts": 19.439, "power_cpu_cv_mean_watts": 1.544, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 70.095}, "timestamp": "2026-01-30T16:09:54.660239"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2632.267, "latencies_ms": [2632.267], "images_per_second": 0.38, "prompt_tokens": 1111, "response_tokens_est": 11, "n_tiles": 1, "output_text": " A surfer is riding a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14005.3, "ram_available_mb": 48835.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.1, "ram_used_mb": 14005.2, "ram_available_mb": 48835.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.091}, "power_stats": {"power_gpu_soc_mean_watts": 25.167, "power_cpu_cv_mean_watts": 0.837, "power_sys_5v0_mean_watts": 8.341, "gpu_utilization_percent_mean": 79.091}, "timestamp": "2026-01-30T16:09:59.329641"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5465.856, "latencies_ms": [5465.856], "images_per_second": 0.183, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image captures a surfer riding a wave in the ocean, with the surfer wearing a black wetsuit and the wave displaying a deep blue color. The lighting in the image suggests it is either early morning or late afternoon, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14005.2, "ram_available_mb": 48835.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14005.5, "ram_available_mb": 48835.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.304}, "power_stats": {"power_gpu_soc_mean_watts": 18.645, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 70.304}, "timestamp": "2026-01-30T16:10:06.826876"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4223.645, "latencies_ms": [4223.645], "images_per_second": 0.237, "prompt_tokens": 1100, "response_tokens_est": 37, "n_tiles": 1, "output_text": " A double-decker bus with the number 11 and the destination \"Lytham St Annes\" is parked at a bus stop, with a few people waiting nearby.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 14005.5, "ram_available_mb": 48835.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14005.7, "ram_available_mb": 48835.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.371}, "power_stats": {"power_gpu_soc_mean_watts": 20.912, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 70.371}, "timestamp": "2026-01-30T16:10:13.113577"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5468.258, "latencies_ms": [5468.258], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. bus: 1\n2. people: 2\n3. flowers: 1\n4. bus stop: 1\n5. building: 1\n6. street: 1\n7. sky: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14005.7, "ram_available_mb": 48835.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14005.7, "ram_available_mb": 48835.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.622}, "power_stats": {"power_gpu_soc_mean_watts": 18.898, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 68.622}, "timestamp": "2026-01-30T16:10:20.608826"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4793.804, "latencies_ms": [4793.804], "images_per_second": 0.209, "prompt_tokens": 1118, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The bus is on the left side of the image, with the people standing on the right side. The bus is in the foreground, while the people are in the background. The bus is closer to the camera than the people.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14005.7, "ram_available_mb": 48835.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 14005.1, "ram_available_mb": 48835.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.81, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 68.95}, "timestamp": "2026-01-30T16:10:27.464249"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3065.05, "latencies_ms": [3065.05], "images_per_second": 0.326, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A double-decker bus is parked at a bus stop on a city street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14005.1, "ram_available_mb": 48835.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14004.3, "ram_available_mb": 48836.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.96}, "power_stats": {"power_gpu_soc_mean_watts": 23.334, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 77.96}, "timestamp": "2026-01-30T16:10:32.562774"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4538.129, "latencies_ms": [4538.129], "images_per_second": 0.22, "prompt_tokens": 1110, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The image features a yellow double-decker bus with a black front, parked on a street with a red brick sidewalk. The sky is overcast, and the lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14004.3, "ram_available_mb": 48836.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.737}, "power_stats": {"power_gpu_soc_mean_watts": 20.256, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 70.737}, "timestamp": "2026-01-30T16:10:39.129066"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3347.83, "latencies_ms": [3347.83], "images_per_second": 0.299, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A yellow and red biplane with the registration number SP-AWE is flying in the cloudy sky.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 14000.8, "ram_available_mb": 48840.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.259}, "power_stats": {"power_gpu_soc_mean_watts": 22.88, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 76.259}, "timestamp": "2026-01-30T16:10:44.513877"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5651.041, "latencies_ms": [5651.041], "images_per_second": 0.177, "prompt_tokens": 1113, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. airplane: 1\n2. tail: 1\n3. wing: 2\n4. propeller: 1\n5. propeller blade: 1\n6. engine: 1\n7. landing gear: 1\n8. wing strut: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 14001.5, "ram_available_mb": 48839.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.298}, "power_stats": {"power_gpu_soc_mean_watts": 18.47, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 71.298}, "timestamp": "2026-01-30T16:10:52.195146"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3800.831, "latencies_ms": [3800.831], "images_per_second": 0.263, "prompt_tokens": 1117, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The yellow and red biplane is positioned in the foreground, flying from left to right, while the cloudy sky is in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14001.5, "ram_available_mb": 48839.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 14001.5, "ram_available_mb": 48839.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.484}, "power_stats": {"power_gpu_soc_mean_watts": 21.893, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.086, "gpu_utilization_percent_mean": 71.484}, "timestamp": "2026-01-30T16:10:58.012363"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2758.35, "latencies_ms": [2758.35], "images_per_second": 0.363, "prompt_tokens": 1111, "response_tokens_est": 12, "n_tiles": 1, "output_text": " A yellow and red biplane is flying in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.5, "ram_available_mb": 48839.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.64, "power_cpu_cv_mean_watts": 0.764, "power_sys_5v0_mean_watts": 8.291, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-30T16:11:02.804316"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3972.362, "latencies_ms": [3972.362], "images_per_second": 0.252, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The airplane is painted in vibrant yellow and red, with a blue propeller and a red tail. The sky is overcast, with gray clouds covering the entire background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 14001.7, "ram_available_mb": 48839.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14002.2, "ram_available_mb": 48838.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.03}, "power_stats": {"power_gpu_soc_mean_watts": 21.595, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 72.03}, "timestamp": "2026-01-30T16:11:08.823716"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4435.84, "latencies_ms": [4435.84], "images_per_second": 0.225, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The image captures an aerial view of a bustling airport, with a large parking lot brimming with cars, a building with a distinctive red roof, and a prominent airplane wing visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14001.5, "ram_available_mb": 48839.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14001.4, "ram_available_mb": 48839.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.806}, "power_stats": {"power_gpu_soc_mean_watts": 20.429, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.806}, "timestamp": "2026-01-30T16:11:15.296887"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4202.501, "latencies_ms": [4202.501], "images_per_second": 0.238, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " airplane wing: 1, car: 100, building: 1, parking lot: 100, trees: 10, sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14001.4, "ram_available_mb": 48839.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 14001.4, "ram_available_mb": 48839.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.143}, "power_stats": {"power_gpu_soc_mean_watts": 20.877, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 73.143}, "timestamp": "2026-01-30T16:11:21.534630"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4303.251, "latencies_ms": [4303.251], "images_per_second": 0.232, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The airplane wing is on the left side of the image, while the parking lot is on the right side. The parking lot is in the foreground, with the cityscape in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14001.4, "ram_available_mb": 48839.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.972}, "power_stats": {"power_gpu_soc_mean_watts": 20.72, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 71.972}, "timestamp": "2026-01-30T16:11:27.879329"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5114.575, "latencies_ms": [5114.575], "images_per_second": 0.196, "prompt_tokens": 1111, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The image captures a bustling airport scene from the perspective of an airplane wing. The airport is nestled amidst a sprawling cityscape, with numerous buildings and roads visible in the distance. The parking lot is teeming with cars, indicating a busy day at the airport.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14001.0, "ram_available_mb": 48839.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.349}, "power_stats": {"power_gpu_soc_mean_watts": 19.209, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 69.349}, "timestamp": "2026-01-30T16:11:35.032780"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5472.128, "latencies_ms": [5472.128], "images_per_second": 0.183, "prompt_tokens": 1109, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image is a high-angle aerial view of a large parking lot, with a clear blue sky and white clouds in the background. The parking lot is filled with numerous cars of various colors, and there are several buildings in the vicinity, including a large one with a red roof.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.652}, "power_stats": {"power_gpu_soc_mean_watts": 18.757, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 69.652}, "timestamp": "2026-01-30T16:11:42.543692"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3013.229, "latencies_ms": [3013.229], "images_per_second": 0.332, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A person is holding a pink flip phone with a picture of a girl on it.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 14000.4, "ram_available_mb": 48840.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.08}, "power_stats": {"power_gpu_soc_mean_watts": 24.02, "power_cpu_cv_mean_watts": 0.993, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 78.08}, "timestamp": "2026-01-30T16:11:47.606352"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5444.72, "latencies_ms": [5444.72], "images_per_second": 0.184, "prompt_tokens": 1113, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. person: 2\n2. cell phone: 1\n3. cup: 1\n4. book: 1\n5. bag: 1\n6. person: 1\n7. person: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.356}, "power_stats": {"power_gpu_soc_mean_watts": 18.845, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 68.356}, "timestamp": "2026-01-30T16:11:55.075708"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5592.672, "latencies_ms": [5592.672], "images_per_second": 0.179, "prompt_tokens": 1117, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The pink flip phone is held in the foreground by a person's hand, with the person's legs and another person's legs in the background. The pink flip phone is positioned to the left of the person's legs, and the person's legs are positioned to the right of the pink flip phone.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 13998.4, "ram_available_mb": 48842.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.362}, "power_stats": {"power_gpu_soc_mean_watts": 18.711, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 68.362}, "timestamp": "2026-01-30T16:12:02.685190"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3928.834, "latencies_ms": [3928.834], "images_per_second": 0.255, "prompt_tokens": 1111, "response_tokens_est": 32, "n_tiles": 1, "output_text": " A person is holding a pink flip phone with a picture of a girl on it. The person is sitting on a couch with a book in front of them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.242}, "power_stats": {"power_gpu_soc_mean_watts": 21.535, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.115, "gpu_utilization_percent_mean": 72.242}, "timestamp": "2026-01-30T16:12:08.667783"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4051.489, "latencies_ms": [4051.489], "images_per_second": 0.247, "prompt_tokens": 1109, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a dimly lit room with a pink flip phone in the foreground. The phone is held by a person wearing blue jeans and white sneakers.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.576}, "power_stats": {"power_gpu_soc_mean_watts": 21.405, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 73.576}, "timestamp": "2026-01-30T16:12:14.745785"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3473.694, "latencies_ms": [3473.694], "images_per_second": 0.288, "prompt_tokens": 1099, "response_tokens_est": 25, "n_tiles": 1, "output_text": " Two zebras are standing in a dry grass field, with one zebra looking directly at the camera and the other looking away.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.857}, "power_stats": {"power_gpu_soc_mean_watts": 23.065, "power_cpu_cv_mean_watts": 1.115, "power_sys_5v0_mean_watts": 8.206, "gpu_utilization_percent_mean": 73.857}, "timestamp": "2026-01-30T16:12:20.241930"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2249.934, "latencies_ms": [2249.934], "images_per_second": 0.444, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " zebra: 2", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13998.3, "ram_available_mb": 48842.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.3, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.444}, "power_stats": {"power_gpu_soc_mean_watts": 25.447, "power_cpu_cv_mean_watts": 0.556, "power_sys_5v0_mean_watts": 8.254, "gpu_utilization_percent_mean": 87.444}, "timestamp": "2026-01-30T16:12:24.534354"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5172.669, "latencies_ms": [5172.669], "images_per_second": 0.193, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the one on the left slightly closer to the camera than the one on the right. The background of the image features a grassy field with trees and bushes, providing a natural habitat for the zebras.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.6, "ram_available_mb": 48843.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.295}, "power_stats": {"power_gpu_soc_mean_watts": 19.273, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.295}, "timestamp": "2026-01-30T16:12:31.748876"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3124.21, "latencies_ms": [3124.21], "images_per_second": 0.32, "prompt_tokens": 1111, "response_tokens_est": 18, "n_tiles": 1, "output_text": " Two zebras are standing in a tall, dry grass field, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.7, "ram_available_mb": 48843.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.561, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 72.462}, "timestamp": "2026-01-30T16:12:36.902858"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4544.231, "latencies_ms": [4544.231], "images_per_second": 0.22, "prompt_tokens": 1109, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The zebras are black and white with a pattern of stripes, and the grass is a golden brown color. The lighting is bright and sunny, and the zebras are standing in a field of tall grass.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.947}, "power_stats": {"power_gpu_soc_mean_watts": 20.188, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 70.947}, "timestamp": "2026-01-30T16:12:43.511186"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3036.403, "latencies_ms": [3036.403], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A man is walking on the beach with a yellow surfboard in his hand.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13998.1, "ram_available_mb": 48842.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.84}, "power_stats": {"power_gpu_soc_mean_watts": 23.511, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.208, "gpu_utilization_percent_mean": 77.84}, "timestamp": "2026-01-30T16:12:48.590212"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5575.408, "latencies_ms": [5575.408], "images_per_second": 0.179, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. Surfboard: 1\n2. Man: 1\n3. Ocean: 2\n4. Waves: 2\n5. Sunlight: 1\n6. Sky: 1\n7. Water: 1\n8. Sand: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13998.6, "ram_available_mb": 48842.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.702}, "power_stats": {"power_gpu_soc_mean_watts": 18.571, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 68.702}, "timestamp": "2026-01-30T16:12:56.196144"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4431.442, "latencies_ms": [4431.442], "images_per_second": 0.226, "prompt_tokens": 1117, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The man is standing in the foreground of the image, with the ocean waves in the background. The yellow surfboard is held in front of the man, and the waves are crashing behind him.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.081}, "power_stats": {"power_gpu_soc_mean_watts": 20.18, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 66.081}, "timestamp": "2026-01-30T16:13:02.649870"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3423.546, "latencies_ms": [3423.546], "images_per_second": 0.292, "prompt_tokens": 1111, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A young man is walking into the ocean with a yellow surfboard. The ocean is blue and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.286}, "power_stats": {"power_gpu_soc_mean_watts": 23.061, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.221, "gpu_utilization_percent_mean": 76.286}, "timestamp": "2026-01-30T16:13:08.097542"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4263.053, "latencies_ms": [4263.053], "images_per_second": 0.235, "prompt_tokens": 1109, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image features a man in the ocean, holding a yellow surfboard. The sky is clear and blue, and the water is a deep blue with white waves crashing onto the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.621, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 72.278}, "timestamp": "2026-01-30T16:13:14.399773"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3039.35, "latencies_ms": [3039.35], "images_per_second": 0.329, "prompt_tokens": 1099, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A black and white cow is standing on a beach with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.04}, "power_stats": {"power_gpu_soc_mean_watts": 23.783, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 78.04}, "timestamp": "2026-01-30T16:13:19.486083"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2264.105, "latencies_ms": [2264.105], "images_per_second": 0.442, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " cow: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 84.556}, "power_stats": {"power_gpu_soc_mean_watts": 25.287, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.299, "gpu_utilization_percent_mean": 84.556}, "timestamp": "2026-01-30T16:13:23.793800"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4290.354, "latencies_ms": [4290.354], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The cow is standing in the foreground, with the water in the background. The cow is positioned to the left of the water, and the water extends to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.167}, "power_stats": {"power_gpu_soc_mean_watts": 20.787, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 71.167}, "timestamp": "2026-01-30T16:13:30.138533"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2892.483, "latencies_ms": [2892.483], "images_per_second": 0.346, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A black and white cow stands on a beach, looking at the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.75}, "power_stats": {"power_gpu_soc_mean_watts": 24.49, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.293, "gpu_utilization_percent_mean": 77.75}, "timestamp": "2026-01-30T16:13:35.050548"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3113.419, "latencies_ms": [3113.419], "images_per_second": 0.321, "prompt_tokens": 1109, "response_tokens_est": 19, "n_tiles": 1, "output_text": " The cow is black and white, standing on a sandy beach with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.346}, "power_stats": {"power_gpu_soc_mean_watts": 23.823, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 8.268, "gpu_utilization_percent_mean": 75.346}, "timestamp": "2026-01-30T16:13:40.187429"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3710.063, "latencies_ms": [3710.063], "images_per_second": 0.27, "prompt_tokens": 1100, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A woman in a white blouse and black pants is standing on skis in the snow, holding ski poles and wearing a scarf.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.355}, "power_stats": {"power_gpu_soc_mean_watts": 21.93, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.124, "gpu_utilization_percent_mean": 68.355}, "timestamp": "2026-01-30T16:13:45.967568"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5616.878, "latencies_ms": [5616.878], "images_per_second": 0.178, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. woman: 1\n2. ski poles: 2\n3. skis: 2\n4. backpack: 1\n5. trees: 2\n6. clouds: 1\n7. snow: 1\n8. woman's hair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.149}, "power_stats": {"power_gpu_soc_mean_watts": 18.665, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 69.149}, "timestamp": "2026-01-30T16:13:53.598308"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4288.042, "latencies_ms": [4288.042], "images_per_second": 0.233, "prompt_tokens": 1118, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The woman is standing in the foreground, with the ski poles and trees in the background. The woman is holding the ski poles in her right hand, and the trees are behind her.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.114}, "power_stats": {"power_gpu_soc_mean_watts": 20.731, "power_cpu_cv_mean_watts": 1.361, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 72.114}, "timestamp": "2026-01-30T16:13:59.911488"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3464.064, "latencies_ms": [3464.064], "images_per_second": 0.289, "prompt_tokens": 1112, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A woman in a white blouse and black pants is standing on a snowy hill, holding ski poles and wearing skis.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.7, "ram_available_mb": 48844.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.276}, "power_stats": {"power_gpu_soc_mean_watts": 22.573, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 8.185, "gpu_utilization_percent_mean": 75.276}, "timestamp": "2026-01-30T16:14:05.418582"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4510.334, "latencies_ms": [4510.334], "images_per_second": 0.222, "prompt_tokens": 1110, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image is in black and white, with a clear contrast between the subject and the background. The subject is wearing a white blouse and black pants, and the background features a snowy landscape with trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.892}, "power_stats": {"power_gpu_soc_mean_watts": 20.28, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 70.892}, "timestamp": "2026-01-30T16:14:11.954794"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4006.96, "latencies_ms": [4006.96], "images_per_second": 0.25, "prompt_tokens": 1099, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A dog with a black and white coat is holding a yellow frisbee in its mouth on a sandy beach with the ocean and a small island in the background.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.152}, "power_stats": {"power_gpu_soc_mean_watts": 21.257, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.081, "gpu_utilization_percent_mean": 69.152}, "timestamp": "2026-01-30T16:14:18.020545"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4200.852, "latencies_ms": [4200.852], "images_per_second": 0.238, "prompt_tokens": 1113, "response_tokens_est": 36, "n_tiles": 1, "output_text": " dog: 1, frisbee: 1, beach: 1, ocean: 1, island: 1, sand: 1, sky: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.457}, "power_stats": {"power_gpu_soc_mean_watts": 20.82, "power_cpu_cv_mean_watts": 1.315, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 71.457}, "timestamp": "2026-01-30T16:14:24.261683"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5102.352, "latencies_ms": [5102.352], "images_per_second": 0.196, "prompt_tokens": 1117, "response_tokens_est": 51, "n_tiles": 1, "output_text": " The dog is in the foreground, holding a yellow frisbee in its mouth. The beach is in the background, with the ocean and a small island visible. The dog is looking towards the camera, which is positioned to the left of the dog.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.19}, "power_stats": {"power_gpu_soc_mean_watts": 19.344, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 69.19}, "timestamp": "2026-01-30T16:14:31.398955"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3766.852, "latencies_ms": [3766.852], "images_per_second": 0.265, "prompt_tokens": 1111, "response_tokens_est": 28, "n_tiles": 1, "output_text": " A dog is playing on the beach with a frisbee. The beach is sandy and there is a body of water in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.129}, "power_stats": {"power_gpu_soc_mean_watts": 21.723, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.107, "gpu_utilization_percent_mean": 72.129}, "timestamp": "2026-01-30T16:14:37.221221"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4443.132, "latencies_ms": [4443.132], "images_per_second": 0.225, "prompt_tokens": 1109, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The dog is black and white with a yellow frisbee in its mouth, standing on a sandy beach with the ocean in the background. The sky is cloudy and the water is a light blue.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.324}, "power_stats": {"power_gpu_soc_mean_watts": 20.389, "power_cpu_cv_mean_watts": 1.363, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 72.324}, "timestamp": "2026-01-30T16:14:43.689075"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4415.153, "latencies_ms": [4415.153], "images_per_second": 0.226, "prompt_tokens": 1099, "response_tokens_est": 39, "n_tiles": 1, "output_text": " In a kitchen, a group of women, including a woman in a camouflage uniform, are gathered around a table with a large pot of food, while a woman in a white shirt stands nearby.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.833}, "power_stats": {"power_gpu_soc_mean_watts": 20.422, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 68.833}, "timestamp": "2026-01-30T16:14:50.148613"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5413.335, "latencies_ms": [5413.335], "images_per_second": 0.185, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. woman: 2\n2. woman: 2\n3. woman: 2\n4. woman: 2\n5. woman: 2\n6. woman: 2\n7. woman: 2\n8. woman: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.1, "ram_available_mb": 48843.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.711}, "power_stats": {"power_gpu_soc_mean_watts": 18.836, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 68.711}, "timestamp": "2026-01-30T16:14:57.587555"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5926.409, "latencies_ms": [5926.409], "images_per_second": 0.169, "prompt_tokens": 1117, "response_tokens_est": 65, "n_tiles": 1, "output_text": " The main objects are positioned in the foreground of the image, with the kitchen appliances and countertop in the background. The woman in the camouflage uniform is standing near the countertop, while the woman in the striped shirt is standing near the refrigerator. The woman in the floral shirt is standing near the woman in the camouflage uniform.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.44}, "power_stats": {"power_gpu_soc_mean_watts": 18.209, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 68.44}, "timestamp": "2026-01-30T16:15:05.560553"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3470.748, "latencies_ms": [3470.748], "images_per_second": 0.288, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A group of women in military uniforms are standing in a kitchen, with a large pot of food on the counter.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13997.3, "ram_available_mb": 48843.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.714}, "power_stats": {"power_gpu_soc_mean_watts": 22.664, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.146, "gpu_utilization_percent_mean": 74.714}, "timestamp": "2026-01-30T16:15:11.054043"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3103.822, "latencies_ms": [3103.822], "images_per_second": 0.322, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The kitchen is well-lit with natural light, and the walls are made of concrete.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13996.4, "ram_available_mb": 48844.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.48}, "power_stats": {"power_gpu_soc_mean_watts": 23.816, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.228, "gpu_utilization_percent_mean": 75.48}, "timestamp": "2026-01-30T16:15:16.188506"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3294.22, "latencies_ms": [3294.22], "images_per_second": 0.304, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The image shows a bathroom with a toilet, a shelf with various toiletries, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.926}, "power_stats": {"power_gpu_soc_mean_watts": 23.074, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.187, "gpu_utilization_percent_mean": 76.926}, "timestamp": "2026-01-30T16:15:21.527281"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5456.002, "latencies_ms": [5456.002], "images_per_second": 0.183, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. toilet: 1\n2. shelf: 3\n3. bottles: 4\n4. towel: 2\n5. toilet paper: 1\n6. phone: 1\n7. mirror: 1\n8. wall: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.6, "ram_available_mb": 48844.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.156}, "power_stats": {"power_gpu_soc_mean_watts": 18.783, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 69.156}, "timestamp": "2026-01-30T16:15:29.016662"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4700.568, "latencies_ms": [4700.568], "images_per_second": 0.213, "prompt_tokens": 1118, "response_tokens_est": 45, "n_tiles": 1, "output_text": " The toilet is located in the foreground of the image, with the shelf above it in the middle ground. The wall-mounted phone is positioned to the left of the toilet, while the towel rack is situated to the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.113, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T16:15:35.765880"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2961.615, "latencies_ms": [2961.615], "images_per_second": 0.338, "prompt_tokens": 1112, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bathroom with a toilet, sink, and shower is shown in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.8, "ram_available_mb": 48844.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.25}, "power_stats": {"power_gpu_soc_mean_watts": 23.97, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 8.26, "gpu_utilization_percent_mean": 80.25}, "timestamp": "2026-01-30T16:15:40.751107"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3451.92, "latencies_ms": [3451.92], "images_per_second": 0.29, "prompt_tokens": 1110, "response_tokens_est": 24, "n_tiles": 1, "output_text": " The bathroom is well-lit with a warm yellow light, and the walls are painted in a light beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13997.0, "ram_available_mb": 48843.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.5, "ram_available_mb": 48844.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.286}, "power_stats": {"power_gpu_soc_mean_watts": 23.033, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.214, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-30T16:15:46.215735"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3290.448, "latencies_ms": [3290.448], "images_per_second": 0.304, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A dog wearing a green hat is sitting in the back seat of a car, looking out the window.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 13995.9, "ram_available_mb": 48845.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.815}, "power_stats": {"power_gpu_soc_mean_watts": 23.117, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.171, "gpu_utilization_percent_mean": 71.815}, "timestamp": "2026-01-30T16:15:51.571278"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4131.045, "latencies_ms": [4131.045], "images_per_second": 0.242, "prompt_tokens": 1113, "response_tokens_est": 35, "n_tiles": 1, "output_text": " dog: 1, hat: 1, car: 1, window: 1, light: 1, shamrock: 1, person: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.412}, "power_stats": {"power_gpu_soc_mean_watts": 21.209, "power_cpu_cv_mean_watts": 1.33, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 70.412}, "timestamp": "2026-01-30T16:15:57.720263"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4920.122, "latencies_ms": [4920.122], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The dog is in the driver's seat, which is on the left side of the vehicle. The person is in the passenger seat, which is on the right side of the vehicle. The dog is closer to the camera than the person.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.561}, "power_stats": {"power_gpu_soc_mean_watts": 19.638, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.561}, "timestamp": "2026-01-30T16:16:04.661877"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3289.562, "latencies_ms": [3289.562], "images_per_second": 0.304, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A dog wearing a green hat is sitting in the back seat of a car, looking out the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.252, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 74.333}, "timestamp": "2026-01-30T16:16:09.977938"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4878.217, "latencies_ms": [4878.217], "images_per_second": 0.205, "prompt_tokens": 1109, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The image features a dog wearing a green hat and a green shamrock on the side of a vehicle, with a person in the driver's seat. The vehicle is decorated with green and orange balloons, and the lighting suggests it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.976}, "power_stats": {"power_gpu_soc_mean_watts": 19.756, "power_cpu_cv_mean_watts": 1.504, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 68.976}, "timestamp": "2026-01-30T16:16:16.883512"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3984.83, "latencies_ms": [3984.83], "images_per_second": 0.251, "prompt_tokens": 1099, "response_tokens_est": 32, "n_tiles": 1, "output_text": " In the image, a large elephant is standing in a shallow pool of water, with a large log lying nearby, and a fence and trees in the background.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.273}, "power_stats": {"power_gpu_soc_mean_watts": 21.231, "power_cpu_cv_mean_watts": 1.286, "power_sys_5v0_mean_watts": 8.091, "gpu_utilization_percent_mean": 69.273}, "timestamp": "2026-01-30T16:16:22.921914"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3928.538, "latencies_ms": [3928.538], "images_per_second": 0.255, "prompt_tokens": 1113, "response_tokens_est": 31, "n_tiles": 1, "output_text": " elephant: 1\nwater: 1\nrocks: 3\ntree: 1\nfence: 1\npeople: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.531}, "power_stats": {"power_gpu_soc_mean_watts": 21.621, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.105, "gpu_utilization_percent_mean": 68.531}, "timestamp": "2026-01-30T16:16:28.876495"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5353.701, "latencies_ms": [5353.701], "images_per_second": 0.187, "prompt_tokens": 1117, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The elephant is positioned in the foreground, with the water body and rocks in the middle ground, and the people and fence in the background. The elephant is facing the water body, with its trunk extended towards it, and the rocks are positioned to the left of the elephant.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.822}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 70.822}, "timestamp": "2026-01-30T16:16:36.268715"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3368.224, "latencies_ms": [3368.224], "images_per_second": 0.297, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " In a zoo enclosure, a large elephant is drinking water from a pool, with a log and rocks nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.85, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T16:16:41.682385"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2960.996, "latencies_ms": [2960.996], "images_per_second": 0.338, "prompt_tokens": 1109, "response_tokens_est": 16, "n_tiles": 1, "output_text": " The elephant is gray, the water is blue, and the ground is brown.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.358, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.264, "gpu_utilization_percent_mean": 78.5}, "timestamp": "2026-01-30T16:16:46.675338"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3831.649, "latencies_ms": [3831.649], "images_per_second": 0.261, "prompt_tokens": 1099, "response_tokens_est": 31, "n_tiles": 1, "output_text": " Four people are standing on a snowy mountain, wearing ski gear and holding ski poles, with a clear blue sky and snow-covered mountains in the background.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 13993.8, "ram_available_mb": 48847.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.25}, "power_stats": {"power_gpu_soc_mean_watts": 21.945, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.142, "gpu_utilization_percent_mean": 71.25}, "timestamp": "2026-01-30T16:16:52.540724"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5531.385, "latencies_ms": [5531.385], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. skis: 4\n2. ski poles: 4\n3. skiers: 4\n4. jackets: 4\n5. hats: 4\n6. goggles: 4\n7. gloves: 4\n8. snow: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.319}, "power_stats": {"power_gpu_soc_mean_watts": 18.673, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.319}, "timestamp": "2026-01-30T16:17:00.118733"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5241.933, "latencies_ms": [5241.933], "images_per_second": 0.191, "prompt_tokens": 1117, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The skiers are positioned in the foreground of the image, with the mountains in the background. The skier on the left is slightly closer to the camera than the skier in the middle, while the skier on the right is positioned farthest from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.909}, "power_stats": {"power_gpu_soc_mean_watts": 19.0, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.909}, "timestamp": "2026-01-30T16:17:07.401301"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3070.978, "latencies_ms": [3070.978], "images_per_second": 0.326, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " Four people are standing on a snowy mountain, wearing ski gear and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.64}, "power_stats": {"power_gpu_soc_mean_watts": 23.686, "power_cpu_cv_mean_watts": 0.912, "power_sys_5v0_mean_watts": 8.216, "gpu_utilization_percent_mean": 74.64}, "timestamp": "2026-01-30T16:17:12.496079"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5779.966, "latencies_ms": [5779.966], "images_per_second": 0.173, "prompt_tokens": 1109, "response_tokens_est": 63, "n_tiles": 1, "output_text": " The image features a group of four people standing on a snowy mountain, wearing ski gear and holding ski poles. The sky is clear and blue, and the sun is shining brightly, casting shadows on the snow. The snow is pristine white, and the mountain is covered in snow, with trees visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.9, "ram_available_mb": 48848.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.688}, "power_stats": {"power_gpu_soc_mean_watts": 18.502, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 70.688}, "timestamp": "2026-01-30T16:17:20.295124"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4418.646, "latencies_ms": [4418.646], "images_per_second": 0.226, "prompt_tokens": 1100, "response_tokens_est": 39, "n_tiles": 1, "output_text": " A person is holding a black smartphone in their hand, and the screen displays a photo of a tree with the time \"9:45\" and the date \"Mon, 11\".", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.409, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 67.444}, "timestamp": "2026-01-30T16:17:26.757562"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5349.692, "latencies_ms": [5349.692], "images_per_second": 0.187, "prompt_tokens": 1114, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. hand: 1\n2. smartphone: 1\n3. keyboard: 1\n4. screen: 1\n5. finger: 1\n6. wrist: 1\n7. table: 1\n8. light: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13991.7, "ram_available_mb": 48849.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.644}, "power_stats": {"power_gpu_soc_mean_watts": 19.005, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 68.644}, "timestamp": "2026-01-30T16:17:34.130360"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4444.441, "latencies_ms": [4444.441], "images_per_second": 0.225, "prompt_tokens": 1118, "response_tokens_est": 39, "n_tiles": 1, "output_text": " The smartphone is held in a person's hand, which is positioned in the foreground of the image. The smartphone is in front of a keyboard, which is located in the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.419, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.278}, "timestamp": "2026-01-30T16:17:40.585717"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3283.952, "latencies_ms": [3283.952], "images_per_second": 0.305, "prompt_tokens": 1112, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A person is holding a black smartphone in their hand, and the screen is displaying a picture of a tree.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.63}, "power_stats": {"power_gpu_soc_mean_watts": 23.132, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.238, "gpu_utilization_percent_mean": 74.63}, "timestamp": "2026-01-30T16:17:45.918335"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2771.219, "latencies_ms": [2771.219], "images_per_second": 0.361, "prompt_tokens": 1110, "response_tokens_est": 12, "n_tiles": 1, "output_text": " The phone is black and the screen is reflecting a tree.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.522}, "power_stats": {"power_gpu_soc_mean_watts": 24.143, "power_cpu_cv_mean_watts": 0.783, "power_sys_5v0_mean_watts": 8.219, "gpu_utilization_percent_mean": 76.522}, "timestamp": "2026-01-30T16:17:50.736944"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5211.313, "latencies_ms": [5211.313], "images_per_second": 0.192, "prompt_tokens": 1432, "response_tokens_est": 44, "n_tiles": 1, "output_text": " A red and blue parking meter is on the sidewalk, with a sign that says \"DENVER'S ROAD HOME\" and another sign that says \"CAMPAIGN TO END HOMELESSNESS.\"", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.744}, "power_stats": {"power_gpu_soc_mean_watts": 22.236, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 8.369, "gpu_utilization_percent_mean": 73.744}, "timestamp": "2026-01-30T16:17:57.998926"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4653.264, "latencies_ms": [4653.264], "images_per_second": 0.215, "prompt_tokens": 1446, "response_tokens_est": 33, "n_tiles": 1, "output_text": " 1. parking meter\n2. sign\n3. fence\n4. bushes\n5. flowers\n6. trees\n7. sidewalk\n8. grass", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.462}, "power_stats": {"power_gpu_soc_mean_watts": 23.397, "power_cpu_cv_mean_watts": 1.242, "power_sys_5v0_mean_watts": 8.375, "gpu_utilization_percent_mean": 74.462}, "timestamp": "2026-01-30T16:18:04.691164"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4876.359, "latencies_ms": [4876.359], "images_per_second": 0.205, "prompt_tokens": 1450, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The parking meter is located on the right side of the image, with a sign on the left side. The parking meter is in the foreground, while the sign is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.0, "ram_available_mb": 48847.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.512}, "power_stats": {"power_gpu_soc_mean_watts": 22.89, "power_cpu_cv_mean_watts": 1.298, "power_sys_5v0_mean_watts": 8.385, "gpu_utilization_percent_mean": 72.512}, "timestamp": "2026-01-30T16:18:11.611082"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4450.959, "latencies_ms": [4450.959], "images_per_second": 0.225, "prompt_tokens": 1444, "response_tokens_est": 30, "n_tiles": 1, "output_text": " A red and blue parking meter is on the side of the road, with a sign that says \"DENVER'S ROAD HOME\".", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.0, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.297}, "power_stats": {"power_gpu_soc_mean_watts": 23.806, "power_cpu_cv_mean_watts": 1.179, "power_sys_5v0_mean_watts": 8.41, "gpu_utilization_percent_mean": 74.297}, "timestamp": "2026-01-30T16:18:18.110980"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3896.564, "latencies_ms": [3896.564], "images_per_second": 0.257, "prompt_tokens": 1442, "response_tokens_est": 21, "n_tiles": 1, "output_text": " The parking meter is red and white, and it is located on a sidewalk next to a green wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.2, "ram_available_mb": 48848.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.656}, "power_stats": {"power_gpu_soc_mean_watts": 25.449, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.532, "gpu_utilization_percent_mean": 78.656}, "timestamp": "2026-01-30T16:18:24.043509"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3755.499, "latencies_ms": [3755.499], "images_per_second": 0.266, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " In the image, a group of zebras are grazing in a grassy field, their black and white stripes contrasting with the green and brown vegetation.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 13992.5, "ram_available_mb": 48848.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.982, "power_cpu_cv_mean_watts": 1.265, "power_sys_5v0_mean_watts": 8.146, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T16:18:29.858808"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2894.036, "latencies_ms": [2894.036], "images_per_second": 0.346, "prompt_tokens": 1113, "response_tokens_est": 14, "n_tiles": 1, "output_text": " zebra: 3\ngrass: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13992.4, "ram_available_mb": 48848.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.208}, "power_stats": {"power_gpu_soc_mean_watts": 24.057, "power_cpu_cv_mean_watts": 0.851, "power_sys_5v0_mean_watts": 8.209, "gpu_utilization_percent_mean": 77.208}, "timestamp": "2026-01-30T16:18:34.775839"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5060.622, "latencies_ms": [5060.622], "images_per_second": 0.198, "prompt_tokens": 1117, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The zebras are positioned in the foreground of the image, with the background featuring a mix of green and brown vegetation. The zebras are facing different directions, with some grazing and others standing, creating a sense of depth and movement in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.167}, "power_stats": {"power_gpu_soc_mean_watts": 19.361, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 68.167}, "timestamp": "2026-01-30T16:18:41.860195"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3267.336, "latencies_ms": [3267.336], "images_per_second": 0.306, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A group of zebras are grazing in a grassy field, with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13993.7, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.6, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.852}, "power_stats": {"power_gpu_soc_mean_watts": 23.073, "power_cpu_cv_mean_watts": 1.038, "power_sys_5v0_mean_watts": 8.19, "gpu_utilization_percent_mean": 74.852}, "timestamp": "2026-01-30T16:18:47.157682"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4569.858, "latencies_ms": [4569.858], "images_per_second": 0.219, "prompt_tokens": 1109, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image features a group of zebras grazing in a grassy field, with the sun shining brightly overhead. The zebras' black and white stripes contrast sharply with the green grass and the brown trees in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13993.6, "ram_available_mb": 48847.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.763}, "power_stats": {"power_gpu_soc_mean_watts": 20.347, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 8.102, "gpu_utilization_percent_mean": 69.763}, "timestamp": "2026-01-30T16:18:53.752436"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3213.661, "latencies_ms": [3213.661], "images_per_second": 0.311, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man in a black wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.333}, "power_stats": {"power_gpu_soc_mean_watts": 23.206, "power_cpu_cv_mean_watts": 1.053, "power_sys_5v0_mean_watts": 8.201, "gpu_utilization_percent_mean": 74.333}, "timestamp": "2026-01-30T16:18:59.013665"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5479.906, "latencies_ms": [5479.906], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. surfboard: 1\n3. wave: 1\n4. water: 1\n5. sky: 0\n6. surfboard: 1\n7. person: 1\n8. water: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.37}, "power_stats": {"power_gpu_soc_mean_watts": 18.748, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 68.37}, "timestamp": "2026-01-30T16:19:06.508333"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4923.405, "latencies_ms": [4923.405], "images_per_second": 0.203, "prompt_tokens": 1117, "response_tokens_est": 44, "n_tiles": 1, "output_text": " The surfer is positioned in the foreground of the image, with the wave in the background. The surfer is riding the wave from left to right, with the wave's crest to the right of the surfer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.927}, "power_stats": {"power_gpu_soc_mean_watts": 18.592, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 7.89, "gpu_utilization_percent_mean": 70.927}, "timestamp": "2026-01-30T16:19:13.484683"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3330.993, "latencies_ms": [3330.993], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A surfer in a black wetsuit is riding a wave on a surfboard in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.286}, "power_stats": {"power_gpu_soc_mean_watts": 22.834, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.189, "gpu_utilization_percent_mean": 76.286}, "timestamp": "2026-01-30T16:19:18.847274"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4093.652, "latencies_ms": [4093.652], "images_per_second": 0.244, "prompt_tokens": 1109, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The surfer is wearing a black wetsuit and is riding a wave on a white surfboard. The ocean is a deep blue color, and the sky is clear.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13993.5, "ram_available_mb": 48847.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.941}, "power_stats": {"power_gpu_soc_mean_watts": 21.339, "power_cpu_cv_mean_watts": 1.331, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 71.941}, "timestamp": "2026-01-30T16:19:24.969433"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3195.108, "latencies_ms": [3195.108], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain, one of them is holding a pair of skis.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.699, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.244, "gpu_utilization_percent_mean": 76.0}, "timestamp": "2026-01-30T16:19:30.195272"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5516.622, "latencies_ms": [5516.622], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 59, "n_tiles": 1, "output_text": " 1. person: 2\n2. backpack: 1\n3. ski: 1\n4. snowboard: 1\n5. pole: 1\n6. snowboarder: 1\n7. mountain: 1\n8. sun: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.565}, "power_stats": {"power_gpu_soc_mean_watts": 18.802, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 68.565}, "timestamp": "2026-01-30T16:19:37.765461"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6232.828, "latencies_ms": [6232.828], "images_per_second": 0.16, "prompt_tokens": 1117, "response_tokens_est": 69, "n_tiles": 1, "output_text": " The skier on the left is positioned closer to the camera, while the skier on the right is farther away. The skier on the left is also closer to the foreground, while the skier on the right is in the background. The skier on the left is also positioned to the left of the skier on the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.491}, "power_stats": {"power_gpu_soc_mean_watts": 17.641, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 7.916, "gpu_utilization_percent_mean": 68.491}, "timestamp": "2026-01-30T16:19:46.027470"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3337.743, "latencies_ms": [3337.743], "images_per_second": 0.3, "prompt_tokens": 1111, "response_tokens_est": 22, "n_tiles": 1, "output_text": " Two people are standing on a snowy mountain at sunset, one of them is holding a pair of skis.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.25}, "power_stats": {"power_gpu_soc_mean_watts": 22.879, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 8.188, "gpu_utilization_percent_mean": 74.25}, "timestamp": "2026-01-30T16:19:51.413419"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5524.61, "latencies_ms": [5524.61], "images_per_second": 0.181, "prompt_tokens": 1109, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The image features two individuals dressed in white snow gear, with one of them holding a pair of skis. The sun is setting in the background, casting a warm glow on the scene. The sky is a clear blue, and the snow is pristine white, creating a serene and picturesque atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.1, "ram_available_mb": 48846.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13993.9, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.149}, "power_stats": {"power_gpu_soc_mean_watts": 18.65, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.149}, "timestamp": "2026-01-30T16:19:58.978008"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3227.144, "latencies_ms": [3227.144], "images_per_second": 0.31, "prompt_tokens": 1099, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A baseball player in a red shirt and white pants is swinging a bat at a ball in a game.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13993.9, "ram_available_mb": 48846.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.148}, "power_stats": {"power_gpu_soc_mean_watts": 23.535, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 73.148}, "timestamp": "2026-01-30T16:20:04.278763"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5744.417, "latencies_ms": [5744.417], "images_per_second": 0.174, "prompt_tokens": 1113, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. baseball bat: 1\n2. baseball glove: 1\n3. baseball: 1\n4. baseball player: 1\n5. catcher: 1\n6. umpire: 1\n7. fence: 1\n8. spectators: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.542}, "power_stats": {"power_gpu_soc_mean_watts": 18.377, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 67.542}, "timestamp": "2026-01-30T16:20:12.047946"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4890.713, "latencies_ms": [4890.713], "images_per_second": 0.204, "prompt_tokens": 1117, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The batter is positioned in the foreground, with the catcher and umpire behind him. The ball is in the air, and the batter is ready to swing. The fence is in the background, separating the field from the spectators.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.244}, "power_stats": {"power_gpu_soc_mean_watts": 19.63, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 70.244}, "timestamp": "2026-01-30T16:20:18.971488"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4166.688, "latencies_ms": [4166.688], "images_per_second": 0.24, "prompt_tokens": 1111, "response_tokens_est": 36, "n_tiles": 1, "output_text": " A baseball game is taking place on a sunny day in a park. The batter is swinging at the ball, while the catcher and umpire are ready to catch it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.147}, "power_stats": {"power_gpu_soc_mean_watts": 21.305, "power_cpu_cv_mean_watts": 1.354, "power_sys_5v0_mean_watts": 8.099, "gpu_utilization_percent_mean": 72.147}, "timestamp": "2026-01-30T16:20:25.151495"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4507.611, "latencies_ms": [4507.611], "images_per_second": 0.222, "prompt_tokens": 1109, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The image captures a vibrant scene of a baseball game, with the players dressed in crisp white and red uniforms, the sun casting a warm glow on the field, and the lush green trees in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13992.8, "ram_available_mb": 48848.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.459}, "power_stats": {"power_gpu_soc_mean_watts": 20.342, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.459}, "timestamp": "2026-01-30T16:20:31.687577"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3939.79, "latencies_ms": [3939.79], "images_per_second": 0.254, "prompt_tokens": 1432, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A large glass milkshake with whipped cream and a straw sits on a table next to a slice of cake.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13993.1, "ram_available_mb": 48847.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.438}, "power_stats": {"power_gpu_soc_mean_watts": 25.072, "power_cpu_cv_mean_watts": 1.026, "power_sys_5v0_mean_watts": 8.551, "gpu_utilization_percent_mean": 78.438}, "timestamp": "2026-01-30T16:20:37.656466"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6335.787, "latencies_ms": [6335.787], "images_per_second": 0.158, "prompt_tokens": 1446, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. glass of milkshake: 1\n2. cake: 1\n3. fork: 2\n4. knife: 1\n5. napkin: 1\n6. table: 1\n7. chair: 1\n8. person: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.302}, "power_stats": {"power_gpu_soc_mean_watts": 20.469, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.221, "gpu_utilization_percent_mean": 73.302}, "timestamp": "2026-01-30T16:20:46.036878"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4263.659, "latencies_ms": [4263.659], "images_per_second": 0.235, "prompt_tokens": 1450, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The milkshake is to the left of the cake, the cake is in the foreground, and the table is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.914}, "power_stats": {"power_gpu_soc_mean_watts": 24.456, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 8.466, "gpu_utilization_percent_mean": 75.914}, "timestamp": "2026-01-30T16:20:52.322606"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3904.338, "latencies_ms": [3904.338], "images_per_second": 0.256, "prompt_tokens": 1444, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A woman is sitting at a table in a restaurant with a milkshake and a slice of cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.062}, "power_stats": {"power_gpu_soc_mean_watts": 25.421, "power_cpu_cv_mean_watts": 1.026, "power_sys_5v0_mean_watts": 8.532, "gpu_utilization_percent_mean": 78.062}, "timestamp": "2026-01-30T16:20:58.268450"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6117.372, "latencies_ms": [6117.372], "images_per_second": 0.163, "prompt_tokens": 1442, "response_tokens_est": 57, "n_tiles": 1, "output_text": " The image is taken in a restaurant with a warm and inviting atmosphere. The lighting is soft and natural, coming from the windows in the background. The colors in the image are vibrant and inviting, with the brown of the table and the white of the cake and napkins standing out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.3, "ram_available_mb": 48847.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.098}, "power_stats": {"power_gpu_soc_mean_watts": 20.754, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 73.098}, "timestamp": "2026-01-30T16:21:06.435707"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3990.491, "latencies_ms": [3990.491], "images_per_second": 0.251, "prompt_tokens": 1100, "response_tokens_est": 33, "n_tiles": 1, "output_text": " A large, multi-tiered wedding cake with blue and white decorations sits on a table in a room with a chandelier and other tables in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.545}, "power_stats": {"power_gpu_soc_mean_watts": 21.486, "power_cpu_cv_mean_watts": 1.31, "power_sys_5v0_mean_watts": 8.125, "gpu_utilization_percent_mean": 69.545}, "timestamp": "2026-01-30T16:21:12.454758"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5574.061, "latencies_ms": [5574.061], "images_per_second": 0.179, "prompt_tokens": 1114, "response_tokens_est": 60, "n_tiles": 1, "output_text": " 1. cake: 1\n2. tablecloth: 1\n3. flowers: 1\n4. table: 1\n5. chairs: 1\n6. chandelier: 1\n7. windows: 1\n8. tablecloth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.468}, "power_stats": {"power_gpu_soc_mean_watts": 18.68, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.468}, "timestamp": "2026-01-30T16:21:20.073624"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5357.112, "latencies_ms": [5357.112], "images_per_second": 0.187, "prompt_tokens": 1118, "response_tokens_est": 55, "n_tiles": 1, "output_text": " The cake is positioned in the foreground, with the tablecloth covering the bottom tier. The tablecloth is draped over the cake, which is placed on a table. The table is situated in the middle of the room, with the chandelier hanging above it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.2}, "power_stats": {"power_gpu_soc_mean_watts": 18.826, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 68.2}, "timestamp": "2026-01-30T16:21:27.486773"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3898.264, "latencies_ms": [3898.264], "images_per_second": 0.257, "prompt_tokens": 1112, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A large, multi-tiered wedding cake sits on a table in a room with tables and chairs, and a chandelier hanging from the ceiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.938}, "power_stats": {"power_gpu_soc_mean_watts": 21.357, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 71.938}, "timestamp": "2026-01-30T16:21:33.409117"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3179.942, "latencies_ms": [3179.942], "images_per_second": 0.314, "prompt_tokens": 1110, "response_tokens_est": 20, "n_tiles": 1, "output_text": " The cake is white and blue, with gold accents, and is lit by a chandelier.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.615}, "power_stats": {"power_gpu_soc_mean_watts": 23.881, "power_cpu_cv_mean_watts": 1.031, "power_sys_5v0_mean_watts": 8.277, "gpu_utilization_percent_mean": 76.615}, "timestamp": "2026-01-30T16:21:38.608945"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3773.259, "latencies_ms": [3773.259], "images_per_second": 0.265, "prompt_tokens": 1100, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A woman wearing a blue sweater with red and white patterns is standing in a kitchen and holding a plate with a piece of food on it.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.226}, "power_stats": {"power_gpu_soc_mean_watts": 21.928, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.116, "gpu_utilization_percent_mean": 71.226}, "timestamp": "2026-01-30T16:21:44.418957"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5483.34, "latencies_ms": [5483.34], "images_per_second": 0.182, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. plate: 1\n3. pot: 1\n4. stove: 1\n5. wall: 1\n6. poster: 1\n7. wall shelf: 1\n8. spice rack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.935}, "power_stats": {"power_gpu_soc_mean_watts": 18.798, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 69.935}, "timestamp": "2026-01-30T16:21:51.938196"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4688.752, "latencies_ms": [4688.752], "images_per_second": 0.213, "prompt_tokens": 1118, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The person is standing in the foreground of the image, with the stove and pot in the middle ground. The wall decorations are in the background, and the person is holding the plate with the food in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.564}, "power_stats": {"power_gpu_soc_mean_watts": 19.864, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 71.564}, "timestamp": "2026-01-30T16:21:58.660570"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3129.488, "latencies_ms": [3129.488], "images_per_second": 0.32, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman wearing a sweater is standing in a kitchen and holding a plate of food.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.8}, "power_stats": {"power_gpu_soc_mean_watts": 23.364, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 76.8}, "timestamp": "2026-01-30T16:22:03.818791"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4153.02, "latencies_ms": [4153.02], "images_per_second": 0.241, "prompt_tokens": 1110, "response_tokens_est": 35, "n_tiles": 1, "output_text": " The image is taken in a kitchen with a warm and cozy atmosphere. The lighting is natural, coming from the window in the background, and the colors are vibrant and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.686}, "power_stats": {"power_gpu_soc_mean_watts": 20.923, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 72.686}, "timestamp": "2026-01-30T16:22:10.006075"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3423.957, "latencies_ms": [3423.957], "images_per_second": 0.292, "prompt_tokens": 1100, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A woman in a pink shirt and black pants is walking a horse in a dirt area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.357}, "power_stats": {"power_gpu_soc_mean_watts": 22.793, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.167, "gpu_utilization_percent_mean": 72.357}, "timestamp": "2026-01-30T16:22:15.480604"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5434.918, "latencies_ms": [5434.918], "images_per_second": 0.184, "prompt_tokens": 1114, "response_tokens_est": 57, "n_tiles": 1, "output_text": " 1. woman: 1\n2. horse: 1\n3. rope: 1\n4. fence: 1\n5. boots: 1\n6. shirt: 1\n7. pants: 1\n8. leash: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.267}, "power_stats": {"power_gpu_soc_mean_watts": 18.835, "power_cpu_cv_mean_watts": 1.592, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 69.267}, "timestamp": "2026-01-30T16:22:22.932060"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4293.93, "latencies_ms": [4293.93], "images_per_second": 0.233, "prompt_tokens": 1118, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The woman is standing in the foreground of the image, with the horse in the background. The horse is positioned to the left of the woman, and the fence is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.444}, "power_stats": {"power_gpu_soc_mean_watts": 20.819, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.111, "gpu_utilization_percent_mean": 71.444}, "timestamp": "2026-01-30T16:22:29.269758"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3091.47, "latencies_ms": [3091.47], "images_per_second": 0.323, "prompt_tokens": 1112, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A woman in a pink shirt and black pants is walking a horse in a dirt field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.32}, "power_stats": {"power_gpu_soc_mean_watts": 23.573, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 77.32}, "timestamp": "2026-01-30T16:22:34.381893"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4996.596, "latencies_ms": [4996.596], "images_per_second": 0.2, "prompt_tokens": 1110, "response_tokens_est": 49, "n_tiles": 1, "output_text": " The image features a woman in a pink shirt and black pants, with a white horse in the background. The lighting is natural and bright, suggesting it is daytime. The woman is holding a rope, which is likely used for controlling the horse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.071}, "power_stats": {"power_gpu_soc_mean_watts": 19.266, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 72.071}, "timestamp": "2026-01-30T16:22:41.415462"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5044.893, "latencies_ms": [5044.893], "images_per_second": 0.198, "prompt_tokens": 1100, "response_tokens_est": 50, "n_tiles": 1, "output_text": " The image captures a bustling city street with a mix of vehicles and pedestrians, including a prominent yellow traffic sign with a camera icon, a sign indicating a 7AM-7PM parking restriction, and a street sign with a blue and white design.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.905}, "power_stats": {"power_gpu_soc_mean_watts": 19.39, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 68.905}, "timestamp": "2026-01-30T16:22:48.517746"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5537.51, "latencies_ms": [5537.51], "images_per_second": 0.181, "prompt_tokens": 1114, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sign: 2\n2. traffic light: 1\n3. street sign: 1\n4. car: 2\n5. building: 1\n6. tree: 1\n7. person: 1\n8. road: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13995.3, "ram_available_mb": 48845.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.217}, "power_stats": {"power_gpu_soc_mean_watts": 18.565, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.217}, "timestamp": "2026-01-30T16:22:56.093742"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5664.409, "latencies_ms": [5664.409], "images_per_second": 0.177, "prompt_tokens": 1118, "response_tokens_est": 60, "n_tiles": 1, "output_text": " The main objects are positioned in a way that the street sign is on the left side of the image, the traffic light is on the right side, and the yellow sign is in the middle. The street sign is closer to the camera than the traffic light, and the yellow sign is farther away.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.312}, "power_stats": {"power_gpu_soc_mean_watts": 18.359, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 69.312}, "timestamp": "2026-01-30T16:23:03.793833"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4227.522, "latencies_ms": [4227.522], "images_per_second": 0.237, "prompt_tokens": 1112, "response_tokens_est": 37, "n_tiles": 1, "output_text": " The image captures a bustling city street during the day, with cars and pedestrians going about their daily routines. The skyline of tall buildings looms in the background, suggesting a metropolitan area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.886}, "power_stats": {"power_gpu_soc_mean_watts": 20.74, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 68.886}, "timestamp": "2026-01-30T16:23:10.046067"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3651.003, "latencies_ms": [3651.003], "images_per_second": 0.274, "prompt_tokens": 1110, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The image features a city street with a mix of modern and older buildings, and the sky is overcast with a grayish hue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.9}, "power_stats": {"power_gpu_soc_mean_watts": 22.287, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.147, "gpu_utilization_percent_mean": 72.9}, "timestamp": "2026-01-30T16:23:15.726681"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3064.129, "latencies_ms": [3064.129], "images_per_second": 0.326, "prompt_tokens": 1099, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A person is standing in a bathroom with a stainless steel toilet and a blue toilet brush.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.52}, "power_stats": {"power_gpu_soc_mean_watts": 24.164, "power_cpu_cv_mean_watts": 0.977, "power_sys_5v0_mean_watts": 8.296, "gpu_utilization_percent_mean": 79.52}, "timestamp": "2026-01-30T16:23:20.825030"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3013.006, "latencies_ms": [3013.006], "images_per_second": 0.332, "prompt_tokens": 1113, "response_tokens_est": 16, "n_tiles": 1, "output_text": " toilet: 1\ntoilet brush: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.16}, "power_stats": {"power_gpu_soc_mean_watts": 23.748, "power_cpu_cv_mean_watts": 0.88, "power_sys_5v0_mean_watts": 8.212, "gpu_utilization_percent_mean": 74.16}, "timestamp": "2026-01-30T16:23:25.867008"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4579.292, "latencies_ms": [4579.292], "images_per_second": 0.218, "prompt_tokens": 1117, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The toilet is located in the center of the image, with the person's feet visible in the foreground. The blue brush is placed to the left of the toilet, while the metal bars are located to the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.816}, "power_stats": {"power_gpu_soc_mean_watts": 20.427, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.816}, "timestamp": "2026-01-30T16:23:32.460136"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2913.332, "latencies_ms": [2913.332], "images_per_second": 0.343, "prompt_tokens": 1111, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A person is standing in a bathroom with a toilet and a blue brush.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.958}, "power_stats": {"power_gpu_soc_mean_watts": 24.221, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 8.273, "gpu_utilization_percent_mean": 76.958}, "timestamp": "2026-01-30T16:23:37.389821"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3120.032, "latencies_ms": [3120.032], "images_per_second": 0.321, "prompt_tokens": 1109, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The bathroom is well-lit with natural light, and the floor is made of tiles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.808}, "power_stats": {"power_gpu_soc_mean_watts": 23.529, "power_cpu_cv_mean_watts": 0.97, "power_sys_5v0_mean_watts": 8.207, "gpu_utilization_percent_mean": 73.808}, "timestamp": "2026-01-30T16:23:42.552305"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3236.782, "latencies_ms": [3236.782], "images_per_second": 0.309, "prompt_tokens": 1100, "response_tokens_est": 21, "n_tiles": 1, "output_text": " A pink bicycle is parked in a store with other bicycles, and a woman is walking in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.37}, "power_stats": {"power_gpu_soc_mean_watts": 23.47, "power_cpu_cv_mean_watts": 1.067, "power_sys_5v0_mean_watts": 8.238, "gpu_utilization_percent_mean": 75.37}, "timestamp": "2026-01-30T16:23:47.831964"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5708.876, "latencies_ms": [5708.876], "images_per_second": 0.175, "prompt_tokens": 1114, "response_tokens_est": 62, "n_tiles": 1, "output_text": " 1. Bicycle: 1\n2. Wall: 1\n3. Floor: 1\n4. Bike: 1\n5. Bike: 1\n6. Bike: 1\n7. Bike: 1\n8. Bike: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.75}, "power_stats": {"power_gpu_soc_mean_watts": 18.526, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 68.75}, "timestamp": "2026-01-30T16:23:55.601265"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4589.983, "latencies_ms": [4589.983], "images_per_second": 0.218, "prompt_tokens": 1118, "response_tokens_est": 42, "n_tiles": 1, "output_text": " The pink bicycle is positioned in the foreground, with the other bicycles in the background. The pink bicycle is to the left of the other bicycles, and the other bicycles are to the right of the pink bicycle.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.026}, "power_stats": {"power_gpu_soc_mean_watts": 20.135, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 72.026}, "timestamp": "2026-01-30T16:24:02.233289"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5193.335, "latencies_ms": [5193.335], "images_per_second": 0.193, "prompt_tokens": 1112, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a quaint bicycle shop with a variety of bicycles on display. The shop is adorned with a pink bicycle, which stands out against the backdrop of other bicycles. The shop's interior is visible through the open door, revealing a glimpse of the bustling street outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.674}, "power_stats": {"power_gpu_soc_mean_watts": 19.228, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 69.674}, "timestamp": "2026-01-30T16:24:09.465635"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5177.406, "latencies_ms": [5177.406], "images_per_second": 0.193, "prompt_tokens": 1110, "response_tokens_est": 53, "n_tiles": 1, "output_text": " The image features a collection of bicycles, with a prominent pink bicycle in the foreground, and a variety of colors and materials, including wood and metal. The lighting is bright and natural, coming from the window in the background, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.93}, "power_stats": {"power_gpu_soc_mean_watts": 19.367, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 67.93}, "timestamp": "2026-01-30T16:24:16.678136"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2962.299, "latencies_ms": [2962.299], "images_per_second": 0.338, "prompt_tokens": 1099, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A giraffe stands in a dry savanna with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.167}, "power_stats": {"power_gpu_soc_mean_watts": 24.087, "power_cpu_cv_mean_watts": 0.867, "power_sys_5v0_mean_watts": 8.238, "gpu_utilization_percent_mean": 76.167}, "timestamp": "2026-01-30T16:24:21.701037"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2273.159, "latencies_ms": [2273.159], "images_per_second": 0.44, "prompt_tokens": 1113, "response_tokens_est": 4, "n_tiles": 1, "output_text": " giraffe: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.4, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 87.5}, "power_stats": {"power_gpu_soc_mean_watts": 25.197, "power_cpu_cv_mean_watts": 0.578, "power_sys_5v0_mean_watts": 8.248, "gpu_utilization_percent_mean": 87.5}, "timestamp": "2026-01-30T16:24:25.989397"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4811.841, "latencies_ms": [4811.841], "images_per_second": 0.208, "prompt_tokens": 1117, "response_tokens_est": 46, "n_tiles": 1, "output_text": " The giraffe is positioned in the foreground of the image, with the background consisting of a grassy field and trees. The giraffe is facing towards the right side of the image, with its body oriented towards the left side of the frame.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.95}, "power_stats": {"power_gpu_soc_mean_watts": 19.707, "power_cpu_cv_mean_watts": 1.501, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.95}, "timestamp": "2026-01-30T16:24:32.820053"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3916.811, "latencies_ms": [3916.811], "images_per_second": 0.255, "prompt_tokens": 1111, "response_tokens_est": 31, "n_tiles": 1, "output_text": " A giraffe stands in a dry savanna, surrounded by trees and bushes. The giraffe is tall and has a long neck, with a brown and white coat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.719}, "power_stats": {"power_gpu_soc_mean_watts": 21.667, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.126, "gpu_utilization_percent_mean": 73.719}, "timestamp": "2026-01-30T16:24:38.773703"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3422.078, "latencies_ms": [3422.078], "images_per_second": 0.292, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The giraffe is brown and white with a long neck and legs. The sky is cloudy and the grass is dry.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.849, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 8.174, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T16:24:44.231081"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3734.607, "latencies_ms": [3734.607], "images_per_second": 0.268, "prompt_tokens": 1099, "response_tokens_est": 29, "n_tiles": 1, "output_text": " A young girl with red hair and a little girl with blonde hair are sitting on a luggage cart filled with suitcases in a parking lot.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13995.5, "ram_available_mb": 48845.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.097}, "power_stats": {"power_gpu_soc_mean_watts": 22.158, "power_cpu_cv_mean_watts": 1.226, "power_sys_5v0_mean_watts": 8.161, "gpu_utilization_percent_mean": 73.097}, "timestamp": "2026-01-30T16:24:50.024612"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5490.345, "latencies_ms": [5490.345], "images_per_second": 0.182, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. car: 2\n2. luggage: 3\n3. suitcase: 1\n4. child: 2\n5. woman: 1\n6. sign: 1\n7. license plate: 1\n8. mirror: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.7, "ram_available_mb": 48845.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.753, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T16:24:57.548364"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4473.481, "latencies_ms": [4473.481], "images_per_second": 0.224, "prompt_tokens": 1117, "response_tokens_est": 41, "n_tiles": 1, "output_text": " The luggage is positioned in the foreground, with the children sitting on it. The luggage is located to the left of the children, and the children are sitting on the luggage in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.243}, "power_stats": {"power_gpu_soc_mean_watts": 20.546, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 71.243}, "timestamp": "2026-01-30T16:25:04.075306"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3076.774, "latencies_ms": [3076.774], "images_per_second": 0.325, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A young girl with red hair is sitting on a luggage cart in a parking lot.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.04}, "power_stats": {"power_gpu_soc_mean_watts": 23.972, "power_cpu_cv_mean_watts": 0.929, "power_sys_5v0_mean_watts": 8.24, "gpu_utilization_percent_mean": 76.04}, "timestamp": "2026-01-30T16:25:09.176479"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3986.102, "latencies_ms": [3986.102], "images_per_second": 0.251, "prompt_tokens": 1109, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The image is taken on a rainy day, with the wet pavement reflecting the blue sky. The car's exterior is black, and the luggage is black and red.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13994.2, "ram_available_mb": 48846.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.061}, "power_stats": {"power_gpu_soc_mean_watts": 21.499, "power_cpu_cv_mean_watts": 1.334, "power_sys_5v0_mean_watts": 8.114, "gpu_utilization_percent_mean": 71.061}, "timestamp": "2026-01-30T16:25:15.181443"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3194.749, "latencies_ms": [3194.749], "images_per_second": 0.313, "prompt_tokens": 1099, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A yellow and blue bus is driving down a street in a town with a mountain in the background.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.692}, "power_stats": {"power_gpu_soc_mean_watts": 23.651, "power_cpu_cv_mean_watts": 1.062, "power_sys_5v0_mean_watts": 8.242, "gpu_utilization_percent_mean": 76.692}, "timestamp": "2026-01-30T16:25:20.422580"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5524.994, "latencies_ms": [5524.994], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. bus: 1\n2. street lamp: 1\n3. building: 1\n4. car: 1\n5. tree: 1\n6. flower bed: 1\n7. bench: 1\n8. mountain: 1", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.609}, "power_stats": {"power_gpu_soc_mean_watts": 18.61, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 68.609}, "timestamp": "2026-01-30T16:25:27.988239"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5605.942, "latencies_ms": [5605.942], "images_per_second": 0.178, "prompt_tokens": 1117, "response_tokens_est": 59, "n_tiles": 1, "output_text": " The yellow and blue bus is parked on the left side of the street, while the white van is driving on the right side. The bus is closer to the camera than the van, and the van is further away. The bus is in the foreground, while the van is in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.7, "ram_available_mb": 48846.2, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.283}, "power_stats": {"power_gpu_soc_mean_watts": 18.608, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 69.283}, "timestamp": "2026-01-30T16:25:35.622782"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3380.403, "latencies_ms": [3380.403], "images_per_second": 0.296, "prompt_tokens": 1111, "response_tokens_est": 23, "n_tiles": 1, "output_text": " A yellow and blue bus drives down a street in a small town, passing by a row of shops and houses.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.393}, "power_stats": {"power_gpu_soc_mean_watts": 23.191, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.243, "gpu_utilization_percent_mean": 74.393}, "timestamp": "2026-01-30T16:25:41.041541"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4279.928, "latencies_ms": [4279.928], "images_per_second": 0.234, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The image features a vibrant yellow and blue bus driving down a street, with a clear blue sky overhead. The bus is surrounded by lush green grass and colorful flowers, creating a picturesque scene.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.886}, "power_stats": {"power_gpu_soc_mean_watts": 21.061, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 8.175, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-30T16:25:47.363778"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3646.677, "latencies_ms": [3646.677], "images_per_second": 0.274, "prompt_tokens": 1099, "response_tokens_est": 26, "n_tiles": 1, "output_text": " A bird stands on a rock in the foreground of a beach, with the ocean and mountains in the background under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.733}, "power_stats": {"power_gpu_soc_mean_watts": 21.914, "power_cpu_cv_mean_watts": 1.188, "power_sys_5v0_mean_watts": 8.104, "gpu_utilization_percent_mean": 76.733}, "timestamp": "2026-01-30T16:25:53.048159"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5362.005, "latencies_ms": [5362.005], "images_per_second": 0.186, "prompt_tokens": 1113, "response_tokens_est": 56, "n_tiles": 1, "output_text": " 1. bird: 1\n2. rocks: 1\n3. beach: 1\n4. water: 1\n5. mountains: 1\n6. clouds: 1\n7. sky: 1\n8. pier: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.409}, "power_stats": {"power_gpu_soc_mean_watts": 19.109, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.409}, "timestamp": "2026-01-30T16:26:00.431501"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4071.57, "latencies_ms": [4071.57], "images_per_second": 0.246, "prompt_tokens": 1117, "response_tokens_est": 33, "n_tiles": 1, "output_text": " The bird is in the foreground, standing on a rock in the middle of the image. The beach is in the background, with the ocean and mountains beyond it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.235}, "power_stats": {"power_gpu_soc_mean_watts": 20.925, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 72.235}, "timestamp": "2026-01-30T16:26:06.538770"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3009.293, "latencies_ms": [3009.293], "images_per_second": 0.332, "prompt_tokens": 1111, "response_tokens_est": 16, "n_tiles": 1, "output_text": " A bird stands on a rock by the sea, with mountains in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.3, "ram_available_mb": 48846.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.625}, "power_stats": {"power_gpu_soc_mean_watts": 24.071, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.247, "gpu_utilization_percent_mean": 75.625}, "timestamp": "2026-01-30T16:26:11.592027"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3426.827, "latencies_ms": [3426.827], "images_per_second": 0.292, "prompt_tokens": 1109, "response_tokens_est": 23, "n_tiles": 1, "output_text": " The image features a beach with a bird perched on a rock, the sky is cloudy and the water is blue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.5}, "power_stats": {"power_gpu_soc_mean_watts": 22.85, "power_cpu_cv_mean_watts": 1.086, "power_sys_5v0_mean_watts": 8.17, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-30T16:26:17.049334"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3417.263, "latencies_ms": [3417.263], "images_per_second": 0.293, "prompt_tokens": 1099, "response_tokens_est": 24, "n_tiles": 1, "output_text": " A man wearing glasses and a black shirt is sitting in a chair and holding a brown paper bag and a blue pen.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.9, "ram_available_mb": 48846.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.607}, "power_stats": {"power_gpu_soc_mean_watts": 23.12, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.236, "gpu_utilization_percent_mean": 74.607}, "timestamp": "2026-01-30T16:26:22.496504"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5537.461, "latencies_ms": [5537.461], "images_per_second": 0.181, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. person: 1\n2. remote control: 1\n3. bag: 1\n4. glasses: 1\n5. chair: 1\n6. wall: 1\n7. television: 1\n8. television remote: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 67.13}, "power_stats": {"power_gpu_soc_mean_watts": 18.531, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 67.13}, "timestamp": "2026-01-30T16:26:30.068076"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4291.403, "latencies_ms": [4291.403], "images_per_second": 0.233, "prompt_tokens": 1117, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The man is sitting on the left side of the couch, with the remote control on the right side. The bag is in front of the man, and the remote control is behind him.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13995.4, "ram_available_mb": 48845.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.278}, "power_stats": {"power_gpu_soc_mean_watts": 20.785, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.108, "gpu_utilization_percent_mean": 71.278}, "timestamp": "2026-01-30T16:26:36.396126"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3225.776, "latencies_ms": [3225.776], "images_per_second": 0.31, "prompt_tokens": 1111, "response_tokens_est": 20, "n_tiles": 1, "output_text": " A man wearing glasses and a black shirt is sitting in a chair and holding a bag of chips.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.6, "ram_available_mb": 48845.3, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.885}, "power_stats": {"power_gpu_soc_mean_watts": 23.527, "power_cpu_cv_mean_watts": 0.985, "power_sys_5v0_mean_watts": 8.245, "gpu_utilization_percent_mean": 73.885}, "timestamp": "2026-01-30T16:26:41.641972"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3609.306, "latencies_ms": [3609.306], "images_per_second": 0.277, "prompt_tokens": 1109, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The man is wearing glasses and a black shirt, and the picture is taken in a room with a white wall and a gray couch.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.7}, "power_stats": {"power_gpu_soc_mean_watts": 22.43, "power_cpu_cv_mean_watts": 1.214, "power_sys_5v0_mean_watts": 8.18, "gpu_utilization_percent_mean": 73.7}, "timestamp": "2026-01-30T16:26:47.275116"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3549.49, "latencies_ms": [3549.49], "images_per_second": 0.282, "prompt_tokens": 1100, "response_tokens_est": 25, "n_tiles": 1, "output_text": " A man in an orange shirt and black shorts is playing tennis on a green court with a blue and white tennis racket.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.621}, "power_stats": {"power_gpu_soc_mean_watts": 22.613, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.196, "gpu_utilization_percent_mean": 72.621}, "timestamp": "2026-01-30T16:26:52.866264"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6274.997, "latencies_ms": [6274.997], "images_per_second": 0.159, "prompt_tokens": 1114, "response_tokens_est": 71, "n_tiles": 1, "output_text": " 1. Tennis racket: 1\n2. Tennis ball: 1\n3. Player: 1\n4. Tennis shoes: 1\n5. Tennis shorts: 1\n6. Tennis shirt: 1\n7. Tennis cap: 1\n8. Tennis net: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13996.1, "ram_available_mb": 48844.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.679}, "power_stats": {"power_gpu_soc_mean_watts": 17.783, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 68.679}, "timestamp": "2026-01-30T16:27:01.189437"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5041.871, "latencies_ms": [5041.871], "images_per_second": 0.198, "prompt_tokens": 1118, "response_tokens_est": 47, "n_tiles": 1, "output_text": " The tennis player is positioned on the left side of the image, with the tennis ball in the center and the net in the foreground. The player is closer to the camera than the ball, which is in the middle of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 66.952}, "power_stats": {"power_gpu_soc_mean_watts": 18.522, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 7.894, "gpu_utilization_percent_mean": 66.952}, "timestamp": "2026-01-30T16:27:08.252642"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2953.183, "latencies_ms": [2953.183], "images_per_second": 0.339, "prompt_tokens": 1112, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A man in an orange shirt and black shorts is playing tennis on a green court.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.5}, "power_stats": {"power_gpu_soc_mean_watts": 24.421, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.361, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-30T16:27:13.240476"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3058.643, "latencies_ms": [3058.643], "images_per_second": 0.327, "prompt_tokens": 1110, "response_tokens_est": 18, "n_tiles": 1, "output_text": " The tennis player is wearing an orange shirt and black shorts, and the court is green.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.2}, "power_stats": {"power_gpu_soc_mean_watts": 24.261, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.316, "gpu_utilization_percent_mean": 75.2}, "timestamp": "2026-01-30T16:27:18.327327"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5140.999, "latencies_ms": [5140.999], "images_per_second": 0.195, "prompt_tokens": 1432, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The image captures a cozy kitchen area with a mix of yellow and brown wooden cabinets, a sink, and a stove, all set against a backdrop of a yellow ceiling and a black and white checkered floor.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 13995.8, "ram_available_mb": 48845.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.442}, "power_stats": {"power_gpu_soc_mean_watts": 22.306, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.362, "gpu_utilization_percent_mean": 75.442}, "timestamp": "2026-01-30T16:27:25.504449"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6468.058, "latencies_ms": [6468.058], "images_per_second": 0.155, "prompt_tokens": 1446, "response_tokens_est": 63, "n_tiles": 1, "output_text": " 1. Kitchen counter: 1\n2. Shelf: 1\n3. Cabinet: 2\n4. Countertop: 1\n5. Sink: 1\n6. Faucet: 1\n7. Cabinet door: 1\n8. Chair: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13995.2, "ram_available_mb": 48845.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.2}, "power_stats": {"power_gpu_soc_mean_watts": 20.288, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 8.223, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-30T16:27:33.987343"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5516.622, "latencies_ms": [5516.622], "images_per_second": 0.181, "prompt_tokens": 1450, "response_tokens_est": 48, "n_tiles": 1, "output_text": " The kitchen is located in the center of the image, with the sink and stove on the right side and the counter on the left. The refrigerator is positioned in the background, while the door is located on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.674}, "power_stats": {"power_gpu_soc_mean_watts": 21.883, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 8.324, "gpu_utilization_percent_mean": 73.674}, "timestamp": "2026-01-30T16:27:41.555951"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4407.408, "latencies_ms": [4407.408], "images_per_second": 0.227, "prompt_tokens": 1444, "response_tokens_est": 29, "n_tiles": 1, "output_text": " The image captures a cozy kitchen scene inside a vintage camper van, where a variety of appliances and utensils are neatly arranged on the countertops.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13995.1, "ram_available_mb": 48845.8, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 73.333}, "power_stats": {"power_gpu_soc_mean_watts": 24.209, "power_cpu_cv_mean_watts": 1.19, "power_sys_5v0_mean_watts": 8.468, "gpu_utilization_percent_mean": 73.333}, "timestamp": "2026-01-30T16:27:47.975349"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3507.6, "latencies_ms": [3507.6], "images_per_second": 0.285, "prompt_tokens": 1442, "response_tokens_est": 14, "n_tiles": 1, "output_text": " The kitchen is painted yellow and has a black mat on the floor.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 79.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.298, "power_cpu_cv_mean_watts": 0.869, "power_sys_5v0_mean_watts": 8.59, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T16:27:53.512164"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3298.672, "latencies_ms": [3298.672], "images_per_second": 0.303, "prompt_tokens": 1099, "response_tokens_est": 22, "n_tiles": 1, "output_text": " A sandwich with lettuce, tomato, and ham is on a paper plate with pickles and mustard on a desk.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.444}, "power_stats": {"power_gpu_soc_mean_watts": 23.501, "power_cpu_cv_mean_watts": 1.082, "power_sys_5v0_mean_watts": 8.261, "gpu_utilization_percent_mean": 75.444}, "timestamp": "2026-01-30T16:27:58.848621"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5478.775, "latencies_ms": [5478.775], "images_per_second": 0.183, "prompt_tokens": 1113, "response_tokens_est": 58, "n_tiles": 1, "output_text": " 1. sandwich: 1\n2. lettuce: 1\n3. tomato: 1\n4. onion: 1\n5. pickle: 2\n6. mustard: 1\n7. paper plate: 1\n8. computer monitor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.8, "ram_available_mb": 48846.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.283}, "power_stats": {"power_gpu_soc_mean_watts": 18.827, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 70.283}, "timestamp": "2026-01-30T16:28:06.362519"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4150.583, "latencies_ms": [4150.583], "images_per_second": 0.241, "prompt_tokens": 1117, "response_tokens_est": 36, "n_tiles": 1, "output_text": " The sandwich is located in the foreground of the image, with the computer monitor in the background. The plate is placed on a desk, and the sandwich is positioned on the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13995.0, "ram_available_mb": 48845.9, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.176}, "power_stats": {"power_gpu_soc_mean_watts": 21.373, "power_cpu_cv_mean_watts": 1.342, "power_sys_5v0_mean_watts": 8.14, "gpu_utilization_percent_mean": 69.176}, "timestamp": "2026-01-30T16:28:12.548327"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3026.724, "latencies_ms": [3026.724], "images_per_second": 0.33, "prompt_tokens": 1111, "response_tokens_est": 17, "n_tiles": 1, "output_text": " A sandwich is on a paper plate on a desk with a computer in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.4, "ram_available_mb": 48846.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.72}, "power_stats": {"power_gpu_soc_mean_watts": 23.957, "power_cpu_cv_mean_watts": 0.945, "power_sys_5v0_mean_watts": 8.256, "gpu_utilization_percent_mean": 76.72}, "timestamp": "2026-01-30T16:28:17.629422"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4239.841, "latencies_ms": [4239.841], "images_per_second": 0.236, "prompt_tokens": 1109, "response_tokens_est": 38, "n_tiles": 1, "output_text": " The sandwich is on a white paper plate, and the plate is on a wooden table. The sandwich is on a white napkin, and the napkin is on a white paper plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 71.429}, "power_stats": {"power_gpu_soc_mean_watts": 21.23, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 8.178, "gpu_utilization_percent_mean": 71.429}, "timestamp": "2026-01-30T16:28:23.884306"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4379.818, "latencies_ms": [4379.818], "images_per_second": 0.228, "prompt_tokens": 1099, "response_tokens_est": 40, "n_tiles": 1, "output_text": " The image depicts a desk with two computer monitors, a keyboard, a mouse, and a smartphone, all arranged in a way that suggests a workspace or a tech-savvy individual's desk setup.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13994.5, "ram_available_mb": 48846.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.649}, "power_stats": {"power_gpu_soc_mean_watts": 20.582, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 8.092, "gpu_utilization_percent_mean": 72.649}, "timestamp": "2026-01-30T16:28:30.319136"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4143.751, "latencies_ms": [4143.751], "images_per_second": 0.241, "prompt_tokens": 1113, "response_tokens_est": 34, "n_tiles": 1, "output_text": " monitor: 2, keyboard: 1, mouse: 1, phone: 1, tablet: 1, camera: 1, laptop: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13993.9, "ram_available_mb": 48847.0, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.059}, "power_stats": {"power_gpu_soc_mean_watts": 20.96, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.134, "gpu_utilization_percent_mean": 68.059}, "timestamp": "2026-01-30T16:28:36.481128"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5310.939, "latencies_ms": [5310.939], "images_per_second": 0.188, "prompt_tokens": 1117, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The keyboard is positioned in the foreground, close to the camera, while the two monitors are placed in the background, farther away from the camera. The mouse is situated near the keyboard, and the tablet is positioned to the right of the keyboard, both in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 70.733}, "power_stats": {"power_gpu_soc_mean_watts": 18.861, "power_cpu_cv_mean_watts": 1.61, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 70.733}, "timestamp": "2026-01-30T16:28:43.819855"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5232.197, "latencies_ms": [5232.197], "images_per_second": 0.191, "prompt_tokens": 1111, "response_tokens_est": 54, "n_tiles": 1, "output_text": " The image captures a scene of a well-organized workspace, featuring a desk with two computer monitors, a keyboard, a mouse, and a tablet. The desk is situated in a room with a white wall and a window, suggesting a quiet and focused environment for work.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 14000.5, "ram_available_mb": 48840.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 69.326}, "power_stats": {"power_gpu_soc_mean_watts": 19.208, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 69.326}, "timestamp": "2026-01-30T16:28:51.075613"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5896.117, "latencies_ms": [5896.117], "images_per_second": 0.17, "prompt_tokens": 1109, "response_tokens_est": 64, "n_tiles": 1, "output_text": " The image depicts a desk with two computer monitors, a keyboard, a mouse, and a tablet. The monitors are displaying various web pages, and the desk is illuminated by a blue light. The overall color scheme of the image is neutral, with the white of the desk and the monitors standing out against the darker background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 14000.3, "ram_available_mb": 48840.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5565.5, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 68.429}, "power_stats": {"power_gpu_soc_mean_watts": 18.106, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 68.429}, "timestamp": "2026-01-30T16:28:58.987744"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4429.341, "latencies_ms": [4429.341], "images_per_second": 0.226, "prompt_tokens": 1432, "response_tokens_est": 31, "n_tiles": 1, "output_text": " The image captures a unique perspective of a bathroom, where the floor is adorned with a large mural of a group of people, creating an intriguing visual effect.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 13999.4, "ram_available_mb": 48841.5, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 77.946}, "power_stats": {"power_gpu_soc_mean_watts": 23.684, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.467, "gpu_utilization_percent_mean": 77.946}, "timestamp": "2026-01-30T16:29:05.452656"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6300.036, "latencies_ms": [6300.036], "images_per_second": 0.159, "prompt_tokens": 1446, "response_tokens_est": 61, "n_tiles": 1, "output_text": " 1. Toilet: 1\n2. Floor: 1\n3. Wall: 1\n4. Tile: 1\n5. People: 1\n6. Shoes: 1\n7. Bathroom: 1\n8. Urinal: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.3, "ram_available_mb": 48841.6, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 72.698}, "power_stats": {"power_gpu_soc_mean_watts": 20.576, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.262, "gpu_utilization_percent_mean": 72.698}, "timestamp": "2026-01-30T16:29:13.780737"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5264.123, "latencies_ms": [5264.123], "images_per_second": 0.19, "prompt_tokens": 1450, "response_tokens_est": 43, "n_tiles": 1, "output_text": " The toilet is located in the upper right corner of the image, while the group of people is situated in the lower left corner. The floor is directly beneath the toilet, and the people are standing on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.8, "ram_available_mb": 48841.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 74.227}, "power_stats": {"power_gpu_soc_mean_watts": 22.1, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.34, "gpu_utilization_percent_mean": 74.227}, "timestamp": "2026-01-30T16:29:21.094146"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3550.111, "latencies_ms": [3550.111], "images_per_second": 0.282, "prompt_tokens": 1444, "response_tokens_est": 15, "n_tiles": 1, "output_text": " A group of people are standing on a tiled floor in a bathroom.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 82.862}, "power_stats": {"power_gpu_soc_mean_watts": 26.326, "power_cpu_cv_mean_watts": 0.814, "power_sys_5v0_mean_watts": 8.597, "gpu_utilization_percent_mean": 82.862}, "timestamp": "2026-01-30T16:29:26.672321"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4663.485, "latencies_ms": [4663.485], "images_per_second": 0.214, "prompt_tokens": 1442, "response_tokens_est": 34, "n_tiles": 1, "output_text": " The image is taken in a well-lit room with white tiles on the floor and walls. The lighting is bright and even, and the tiles are clean and shiny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 75.846}, "power_stats": {"power_gpu_soc_mean_watts": 23.286, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 8.44, "gpu_utilization_percent_mean": 75.846}, "timestamp": "2026-01-30T16:29:33.369157"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3635.817, "latencies_ms": [3635.817], "images_per_second": 0.275, "prompt_tokens": 1432, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird with a gray body and black beak is perched on a branch in a forest.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.2, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.7}, "power_stats": {"power_gpu_soc_mean_watts": 25.795, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 8.62, "gpu_utilization_percent_mean": 80.7}, "timestamp": "2026-01-30T16:29:39.057992"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2902.516, "latencies_ms": [2902.516], "images_per_second": 0.345, "prompt_tokens": 1446, "response_tokens_est": 4, "n_tiles": 1, "output_text": " bird: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 2.6, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 86.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.517, "power_cpu_cv_mean_watts": 0.661, "power_sys_5v0_mean_watts": 8.645, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-30T16:29:43.973915"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4329.797, "latencies_ms": [4329.797], "images_per_second": 0.231, "prompt_tokens": 1450, "response_tokens_est": 27, "n_tiles": 1, "output_text": " The bird is positioned in the foreground, perched on a branch, while the background is filled with green foliage, creating a natural setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 14000.2, "ram_available_mb": 48840.7, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 76.167}, "power_stats": {"power_gpu_soc_mean_watts": 23.931, "power_cpu_cv_mean_watts": 1.123, "power_sys_5v0_mean_watts": 8.436, "gpu_utilization_percent_mean": 76.167}, "timestamp": "2026-01-30T16:29:50.361391"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3742.01, "latencies_ms": [3742.01], "images_per_second": 0.267, "prompt_tokens": 1444, "response_tokens_est": 18, "n_tiles": 1, "output_text": " A bird with a gray body and black beak is perched on a branch in a forest.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13999.5, "ram_available_mb": 48841.4, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 78.613}, "power_stats": {"power_gpu_soc_mean_watts": 25.626, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 8.554, "gpu_utilization_percent_mean": 78.613}, "timestamp": "2026-01-30T16:29:56.138475"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3544.896, "latencies_ms": [3544.896], "images_per_second": 0.282, "prompt_tokens": 1442, "response_tokens_est": 15, "n_tiles": 1, "output_text": " The bird is gray and black, and the background is green and white.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13998.8, "ram_available_mb": 48842.1, "ram_percent": 22.3}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 13998.7, "ram_available_mb": 48842.2, "ram_percent": 22.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4305.9, "gpu_mem_reserved_mb": 7158.0, "gpu_max_mem_alloc_mb": 5953.3, "gpu_max_mem_reserved_mb": 7158.0, "gpu_utilization_percent": 80.414}, "power_stats": {"power_gpu_soc_mean_watts": 26.285, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.604, "gpu_utilization_percent_mean": 80.414}, "timestamp": "2026-01-30T16:30:01.713642"}
